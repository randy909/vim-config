#!/usr/bin/env ruby
#
# vorax\\lib\\ruby\\Plsql.g
# 
# Generated using ANTLR version: 3.2.1-SNAPSHOT Jun 18, 2010 05:38:11
# Ruby runtime library version: 1.7.4
# Input grammar file: vorax\\lib\\ruby\\Plsql.g
# Generated at: 2010-07-16 10:19:31
# 

# ~~~> start load path setup
this_directory = File.expand_path( File.dirname( __FILE__ ) )
$LOAD_PATH.unshift( this_directory ) unless $LOAD_PATH.include?( this_directory )

antlr_load_failed = proc do
  load_path = $LOAD_PATH.map { |dir| '  - ' << dir }.join( $/ )
  raise LoadError, <<-END.strip!
  
Failed to load the ANTLR3 runtime library (version 1.7.4):

Ensure the library has been installed on your system and is available
on the load path. If rubygems is available on your system, this can
be done with the command:
  
  gem install antlr3

Current load path:
#{ load_path }

  END
end

defined?( ANTLR3 ) or begin
  
  # 1: try to load the ruby antlr3 runtime library from the system path
  require 'antlr3'
  
rescue LoadError
  
  # 2: try to load rubygems if it isn't already loaded
  defined?( Gem ) or begin
    require 'rubygems'
  rescue LoadError
    antlr_load_failed.call
  end
  
  # 3: try to activate the antlr3 gem
  begin
    Gem.activate( 'antlr3', '~> 1.7.4' )
  rescue Gem::LoadError
    antlr_load_failed.call
  end
  
  require 'antlr3'
  
end
# <~~~ end load path setup


module Plsql
  # TokenData defines all of the token type integer values
  # as constants, which will be included in all 
  # ANTLR-generated recognizers.
  const_defined?( :TokenData ) or TokenData = ANTLR3::TokenScheme.new

  module TokenData

    # define the token constants
    define_tokens( :BULK_ROWCOUNT_ATTR => 29, :EXPONENT => 32, :T__159 => 159, 
                    :T__158 => 158, :T__160 => 160, :DOUBLEDOT => 9, :FOUND_ATTR => 25, 
                    :T__167 => 167, :EOF => -1, :T__165 => 165, :T__166 => 166, 
                    :T__163 => 163, :T__164 => 164, :T__161 => 161, :T__162 => 162, 
                    :T__93 => 93, :T__94 => 94, :QUOTE => 46, :RPAREN => 8, 
                    :T__91 => 91, :T__92 => 92, :T__148 => 148, :T__147 => 147, 
                    :T__90 => 90, :T__149 => 149, :GEQ => 36, :EQ => 22, 
                    :T__154 => 154, :T__155 => 155, :T__156 => 156, :T__157 => 157, 
                    :T__99 => 99, :T__150 => 150, :T__98 => 98, :DIVIDE => 31, 
                    :T__151 => 151, :T__97 => 97, :T__152 => 152, :T__96 => 96, 
                    :T__153 => 153, :T__95 => 95, :RBRACK => 24, :T__139 => 139, 
                    :T__138 => 138, :T__137 => 137, :T__136 => 136, :T__80 => 80, 
                    :T__81 => 81, :T__82 => 82, :T__83 => 83, :N => 45, 
                    :NUMBER => 15, :AT_SIGN => 33, :ROWCOUNT_ATTR => 28, 
                    :DOUBLEVERTBAR => 30, :T__141 => 141, :T__85 => 85, 
                    :T__142 => 142, :T__84 => 84, :T__87 => 87, :T__140 => 140, 
                    :T__86 => 86, :PERCENTAGE => 43, :T__145 => 145, :T__89 => 89, 
                    :T__146 => 146, :T__88 => 88, :T__143 => 143, :T__144 => 144, 
                    :T__126 => 126, :T__125 => 125, :T__128 => 128, :T__127 => 127, 
                    :WS => 47, :T__71 => 71, :T__72 => 72, :T__129 => 129, 
                    :T__70 => 70, :SL_COMMENT => 48, :T__76 => 76, :T__75 => 75, 
                    :T__74 => 74, :T__130 => 130, :T__73 => 73, :T__131 => 131, 
                    :T__132 => 132, :T__79 => 79, :T__133 => 133, :ROWTYPE_ATTR => 20, 
                    :T__78 => 78, :T__134 => 134, :T__77 => 77, :T__135 => 135, 
                    :T__68 => 68, :T__69 => 69, :T__66 => 66, :T__67 => 67, 
                    :LBRACK => 23, :T__64 => 64, :T__65 => 65, :T__62 => 62, 
                    :T__63 => 63, :POINT => 42, :T__118 => 118, :T__119 => 119, 
                    :T__116 => 116, :GTH => 35, :T__117 => 117, :T__114 => 114, 
                    :T__115 => 115, :T__124 => 124, :LLABEL => 10, :T__123 => 123, 
                    :T__122 => 122, :T__121 => 121, :T__120 => 120, :ID => 40, 
                    :T__61 => 61, :T__60 => 60, :ASTERISK => 21, :LPAREN => 7, 
                    :TYPE_ATTR => 19, :RLABEL => 11, :T__55 => 55, :ML_COMMENT => 49, 
                    :T__56 => 56, :T__57 => 57, :T__58 => 58, :T__51 => 51, 
                    :T__52 => 52, :T__53 => 53, :T__54 => 54, :T__107 => 107, 
                    :COMMA => 12, :T__108 => 108, :T__109 => 109, :T__59 => 59, 
                    :T__103 => 103, :T__104 => 104, :T__105 => 105, :T__106 => 106, 
                    :T__111 => 111, :T__110 => 110, :T__113 => 113, :QUOTED_STRING => 16, 
                    :PLUS => 13, :T__112 => 112, :DOT => 5, :T__50 => 50, 
                    :ISOPEN_ATTR => 27, :NOTFOUND_ATTR => 26, :DOUBLEQUOTED_STRING => 41, 
                    :T__102 => 102, :T__101 => 101, :T__100 => 100, :MINUS => 14, 
                    :SEMI => 4, :NOT_EQ => 34, :VERTBAR => 44, :LTH => 37, 
                    :COLON => 17, :ASSIGN => 6, :ARROW => 39, :CHARSET_ATTR => 18, 
                    :LEQ => 38 )

    # register the proper human-readable name or literal value
    # for each token type
    #
    # this is necessary because anonymous tokens, which are
    # created from literal values in the grammar, do not
    # have descriptive names
    register_names( "SEMI", "DOT", "ASSIGN", "LPAREN", "RPAREN", "DOUBLEDOT", 
                     "LLABEL", "RLABEL", "COMMA", "PLUS", "MINUS", "NUMBER", 
                     "QUOTED_STRING", "COLON", "CHARSET_ATTR", "TYPE_ATTR", 
                     "ROWTYPE_ATTR", "ASTERISK", "EQ", "LBRACK", "RBRACK", 
                     "FOUND_ATTR", "NOTFOUND_ATTR", "ISOPEN_ATTR", "ROWCOUNT_ATTR", 
                     "BULK_ROWCOUNT_ATTR", "DOUBLEVERTBAR", "DIVIDE", "EXPONENT", 
                     "AT_SIGN", "NOT_EQ", "GTH", "GEQ", "LTH", "LEQ", "ARROW", 
                     "ID", "DOUBLEQUOTED_STRING", "POINT", "PERCENTAGE", 
                     "VERTBAR", "N", "QUOTE", "WS", "SL_COMMENT", "ML_COMMENT", 
                     "'CREATE'", "'OR'", "'IS'", "'AS'", "'END'", "'BEGIN'", 
                     "'CONSTANT'", "'NOT'", "'NULL'", "'DEFAULT'", "'DECLARE'", 
                     "'EXCEPTION'", "'GOTO'", "'WHEN'", "'BINARY_INTEGER'", 
                     "'BINARY_FLOAT'", "'BINARY_DOUBLE'", "'NATURAL'", "'POSITIVE'", 
                     "'NUMBER'", "'NUMERIC'", "'DECIMAL'", "'DEC'", "'LONG'", 
                     "'RAW'", "'BOOLEAN'", "'DATE'", "'TO'", "'WITH'", "'INTEGER'", 
                     "'INT'", "'SMALLINT'", "'FLOAT'", "'REAL'", "'DOUBLE'", 
                     "'CHAR'", "'CHARACTER'", "'SET'", "'VARCHAR'", "'VARCHAR2'", 
                     "'NCHAR'", "'NVARCHAR'", "'NVARCHAR2'", "'NATIONAL'", 
                     "'MLSLABEL'", "'PLS_INTEGER'", "'BLOB'", "'CLOB'", 
                     "'NCLOB'", "'BFILE'", "'ROWID'", "'UROWID'", "'IN'", 
                     "'PROCEDURE'", "'FUNCTION'", "'TABLE'", "'OF'", "'INDEX'", 
                     "'BY'", "'THEN'", "'TRUE'", "'FALSE'", "'FOR'", "'COMMIT'", 
                     "'IF'", "'ELSE'", "'SELECT'", "'DISTINCT'", "'UNIQUE'", 
                     "'ALL'", "'INTO'", "'FROM'", "'HAVING'", "'UNION'", 
                     "'INTERSECT'", "'MINUS'", "'ON'", "'WHERE'", "'START'", 
                     "'CONNECT'", "'GROUP'", "'ROWS'", "'UPDATE'", "'ORDER'", 
                     "'LIKE'", "'ASC'", "'DESC'", "'NOWAIT'", "'AND'", "'BETWEEN'", 
                     "'SQL'", "'PRIOR'", "'CASE'", "'AT'", "'EXISTS'", "'DELETE'", 
                     "'ANY'", "'INSERT'", "'VALUES'", "'FETCH'", "'LOCK'", 
                     "'MODE'", "'ROW'", "'SHARE'", "'EXCLUSIVE'", "'SAVEPOINT'", 
                     "'COMMENT'", "'ELSIF'", "'LOOP'", "'OUT'", "'PACKAGE'", 
                     "'PRAGMA'", "'RAISE'", "'RECORD'", "'RETURN'", "'RETURNING'", 
                     "'ROLLBACK'", "'WHILE'" )
    
  end


  class Parser < ANTLR3::Parser
    @grammar_home = Plsql
    include ANTLR3::ASTBuilder

    RULE_METHODS = [ :start_rule, :create_package, :package_spec, :package_body, 
                      :package_name, :package_obj_spec, :variable_declaration, 
                      :type_declaration, :subtype_declaration, :cursor_declaration, 
                      :package_obj_body, :seq_of_statements, :statement, 
                      :plsql_block, :declare_spec, :pragma_declaration, 
                      :pragma_params, :pragma_param, :assignment_statement, 
                      :lvalues, :lvalue, :field_name, :subscript, :host_variable, 
                      :goto_statement, :label_name, :exit_statement, :datatype, 
                      :type_spec, :type_name, :parameter_specs, :parameter_spec, 
                      :parameter_name, :cursor_spec, :procedure_spec, :function_spec, 
                      :exception_declaration, :exception_names, :exception_name, 
                      :exception_package_name, :record_declaration, :record_type_dec, 
                      :field_specs, :field_spec, :plsql_table_declaration, 
                      :table_type_dec, :table_var_dec, :plsql_table_name, 
                      :varray_declaration, :procedure_declaration, :procedure_body, 
                      :begin_block, :exception_handler, :proc_fun_start, 
                      :function_body, :function_name, :procedure_name, :arguments, 
                      :argument, :argument_name, :argument_type, :value, 
                      :return_type, :function_declaration, :function_call, 
                      :collection_function_call, :variable_names, :variable_name, 
                      :null_statement, :raise_statement, :return_statement, 
                      :loop_statement, :numeric_loop_param, :index_name, 
                      :integer_expr, :cursor_name, :cursor_loop_param, :record_name, 
                      :commit_statement, :if_statement, :sql_statement, 
                      :sql_command, :to_modify_data, :to_control_data, :select_command, 
                      :select_statement, :select_expression, :select_list, 
                      :table_reference_list_from, :table_reference_list, 
                      :join_clause, :inner_cross_join_clause, :outer_join_clause, 
                      :query_partition_clause, :outer_join_type, :outer_join_sign, 
                      :where_clause, :hierarchical_query_clause, :group_by_clause, 
                      :group_by_exprs, :group_by_expr, :rollup_cube_clause, 
                      :grouping_sets_clause, :grouping_sets_exprs, :grouping_sets_expr, 
                      :model_clause, :cell_reference_options, :return_rows_clause, 
                      :reference_model, :reference_model_name, :main_model, 
                      :main_model_name, :model_column_clauses, :model_columns, 
                      :model_column, :model_rules_clause, :model_rules_exprs, 
                      :model_rules_expr, :cell_assignment, :cell_assignment_exprs, 
                      :cell_assignment_expr, :measure_column, :single_column_for_loop, 
                      :literal, :literals, :bracket_literals, :bracket_literals_list, 
                      :pattern, :multi_column_for_loop, :order_by_clause, 
                      :order_by_exprs, :order_by_expr, :for_update_clause, 
                      :where_condition_whole, :where_condition, :displayed_column, 
                      :schema_name, :table_name, :nested_expressions, :nested_expression, 
                      :plsql_condition, :plsql_expressions, :plsql_expression, 
                      :expr_bool, :expr_or, :expr_and, :expr_not, :boolean_literal, 
                      :sql_expressions, :sql_expression, :expr_add, :expr_mul, 
                      :expr_sign, :expr_pow, :expr_expr, :simple_expression, 
                      :compound_expression, :expr_paren, :expr_prior, :case_expression, 
                      :simple_case_expression, :searched_case_expression, 
                      :else_case_expression, :case_statement, :simple_case_statement, 
                      :searched_case_statement, :else_case_statement, :cursor_expression, 
                      :datetime_expression, :function_expression, :special_expression, 
                      :interval_expression, :leading_field_precision, :fractional_second_precision, 
                      :object_access_expression, :scalar_subquery_expression, 
                      :model_expression, :type_constructor_expression, :variable_expression, 
                      :sequence_name, :integer, :objalias, :column_specs, 
                      :column_spec, :column_name, :nested_table, :nested_table_column_name, 
                      :user_defined_function, :selected_table, :table_spec, 
                      :table_alias, :link_name, :nested_condition, :sql_condition, 
                      :condition_paren, :condition_or, :condition_and, :condition_not, 
                      :condition_expr, :condition_exists, :condition_is, 
                      :condition_comparison, :condition_group_comparison, 
                      :condition_in, :condition_is_a_set, :condition_is_any, 
                      :condition_is_empty, :condition_is_of_type, :condition_is_of_type_names, 
                      :condition_is_of_type_name, :condition_is_present, 
                      :condition_like, :condition_memeber, :condition_between, 
                      :condition_regexp_like, :condition_submultiset, :condition_equals_path, 
                      :condition_under_path, :levels, :correlation_integer, 
                      :path_string, :grouping_expression_list, :expression_list, 
                      :cell_reference, :call_parameters, :call_parameter, 
                      :relational_op, :exp_set, :subquery, :connect_clause, 
                      :group_clause, :set_clause, :order_clause, :sorted_def, 
                      :update_clause, :insert_command, :update_command, 
                      :update_column_specs, :update_column_spec, :update_nested_column_specs, 
                      :update_nested_column_spec, :delete_command, :returning_clause, 
                      :set_transaction_command, :close_statement, :fetch_statement, 
                      :lock_table_statement, :lock_mode, :open_statement, 
                      :rollback_statement, :savepoint_statement, :savepoint_name, 
                      :identifier, :quoted_string, :match_string, :keyA, 
                      :keyAUTOMATIC, :keyCOUNT, :keyCROSS, :keyCUBE, :keyCURRENT_OF, 
                      :keyDAY, :keyDBTIMEZONE, :keyDECREMENT, :keyDIMENSION, 
                      :keyEMPTY, :keyEQUALS_PATH, :keyESCAPE, :keyFIRST, 
                      :keyFULL, :keyGROUPING, :keyIGNORE, :keyINCREMENT, 
                      :keyINFINITE, :keyINNER, :keyINTERVAL, :keyITERATE, 
                      :keyJOIN, :keyKEEP, :keyLAST, :keyLEFT, :keyLIKE2, 
                      :keyLIKE4, :keyLIKEC, :keyLOCAL, :keyMAIN, :keyMEASURES, 
                      :keyMEMBER, :keyMODEL, :keyMONTH, :keyNAN, :keyNATURAL, 
                      :keyNAV, :keyNOCYCLE, :keyNULLS, :keyONLY, :keyOUTER, 
                      :keyPARTITION, :keyPRECISION, :keyPRESENT, :keyREFERENCE, 
                      :keyREGEXP_LIKE, :keyRIGHT, :keyROLLUP, :keyRULES, 
                      :keySECOND, :keySECONDS, :keySEQUENTIAL, :keySESSIONTIMEZONE, 
                      :keySETS, :keySIBLINGS, :keySINGLE, :keySOME, :keySUBMULTISET, 
                      :keyTIME, :keyTIMESTAMP, :keyTHE, :keyUNDER_PATH, 
                      :keyUNTIL, :keyUPDATED, :keyUPSERT, :keyWAIT, :keyYEAR, 
                      :keyZONE, :keyARRAY, :keyAUTONOMOUS_TRANSACTION, :keyBODY, 
                      :keyBUILTIN, :keyBULK, :keyBYTE, :keyCLOSE, :keyCOLLECT, 
                      :keyCURSOR, :keyELSIF, :keyEXCEPTION_INIT, :keyEXIT, 
                      :keyFIPSFLAG, :keyFUNCTION, :keyINTERFACE, :keyLOOP, 
                      :keyNEW, :keyNEW_NAMES, :keyOPEN, :keyOUT, :keyPACKAGE, 
                      :keyPRAGMA, :keyRAISE, :keyRANGE, :keyREAD, :keyRECORD, 
                      :keyREF, :keyREPLACE, :keyRESTRICT_REFERENCES, :keyRETURN, 
                      :keyRETURNING, :keyREVERSE, :keyROLLBACK, :keySERIALLY_REUSABLE, 
                      :keySUBTYPE, :keyTRANSACTION, :keyTYPE, :keyUSING, 
                      :keyVARRAY, :keyVARYING, :keyWHILE, :keyWORK, :sql_identifier, 
                      :synpred13_Plsql, :synpred14_Plsql, :synpred27_Plsql, 
                      :synpred43_Plsql, :synpred44_Plsql, :synpred46_Plsql, 
                      :synpred48_Plsql, :synpred52_Plsql, :synpred53_Plsql, 
                      :synpred62_Plsql, :synpred70_Plsql, :synpred73_Plsql, 
                      :synpred74_Plsql, :synpred75_Plsql, :synpred76_Plsql, 
                      :synpred77_Plsql, :synpred78_Plsql, :synpred79_Plsql, 
                      :synpred80_Plsql, :synpred114_Plsql, :synpred116_Plsql, 
                      :synpred117_Plsql, :synpred172_Plsql, :synpred232_Plsql, 
                      :synpred238_Plsql, :synpred239_Plsql, :synpred242_Plsql, 
                      :synpred252_Plsql, :synpred256_Plsql, :synpred263_Plsql, 
                      :synpred264_Plsql, :synpred265_Plsql, :synpred266_Plsql, 
                      :synpred267_Plsql, :synpred268_Plsql, :synpred269_Plsql, 
                      :synpred274_Plsql, :synpred275_Plsql, :synpred278_Plsql, 
                      :synpred279_Plsql, :synpred280_Plsql, :synpred283_Plsql, 
                      :synpred284_Plsql, :synpred286_Plsql, :synpred287_Plsql, 
                      :synpred288_Plsql, :synpred289_Plsql, :synpred290_Plsql, 
                      :synpred291_Plsql, :synpred292_Plsql, :synpred293_Plsql, 
                      :synpred295_Plsql, :synpred296_Plsql, :synpred297_Plsql, 
                      :synpred298_Plsql, :synpred299_Plsql, :synpred301_Plsql, 
                      :synpred304_Plsql, :synpred305_Plsql, :synpred306_Plsql, 
                      :synpred311_Plsql, :synpred318_Plsql, :synpred330_Plsql, 
                      :synpred331_Plsql, :synpred335_Plsql, :synpred343_Plsql, 
                      :synpred346_Plsql, :synpred347_Plsql, :synpred354_Plsql, 
                      :synpred356_Plsql, :synpred357_Plsql, :synpred359_Plsql, 
                      :synpred360_Plsql, :synpred361_Plsql, :synpred362_Plsql, 
                      :synpred363_Plsql, :synpred364_Plsql, :synpred366_Plsql, 
                      :synpred368_Plsql, :synpred370_Plsql, :synpred372_Plsql, 
                      :synpred374_Plsql, :synpred377_Plsql, :synpred379_Plsql, 
                      :synpred382_Plsql, :synpred383_Plsql, :synpred384_Plsql, 
                      :synpred385_Plsql, :synpred386_Plsql, :synpred387_Plsql, 
                      :synpred388_Plsql, :synpred395_Plsql, :synpred409_Plsql, 
                      :synpred410_Plsql, :synpred412_Plsql, :synpred415_Plsql, 
                      :synpred420_Plsql, :synpred427_Plsql, :synpred431_Plsql, 
                      :synpred434_Plsql, :synpred440_Plsql, :synpred441_Plsql, 
                      :synpred442_Plsql, :synpred445_Plsql, :synpred446_Plsql, 
                      :synpred447_Plsql, :synpred448_Plsql, :synpred449_Plsql, 
                      :synpred450_Plsql, :synpred451_Plsql, :synpred452_Plsql, 
                      :synpred453_Plsql, :synpred454_Plsql, :synpred455_Plsql, 
                      :synpred456_Plsql, :synpred457_Plsql, :synpred458_Plsql, 
                      :synpred459_Plsql, :synpred460_Plsql, :synpred462_Plsql, 
                      :synpred463_Plsql, :synpred466_Plsql, :synpred467_Plsql, 
                      :synpred476_Plsql, :synpred477_Plsql, :synpred481_Plsql, 
                      :synpred482_Plsql, :synpred490_Plsql, :synpred492_Plsql, 
                      :synpred493_Plsql, :synpred495_Plsql, :synpred505_Plsql, 
                      :synpred506_Plsql, :synpred507_Plsql, :synpred516_Plsql, 
                      :synpred517_Plsql, :synpred525_Plsql, :synpred528_Plsql, 
                      :synpred529_Plsql, :synpred530_Plsql, :synpred539_Plsql, 
                      :synpred540_Plsql, :synpred561_Plsql ].freeze


    include TokenData

    begin
      generated_using( "vorax\\lib\\ruby\\Plsql.g", "3.2.1-SNAPSHOT Jun 18, 2010 05:38:11", "1.7.4" )
    rescue NoMethodError => error
      # ignore
    end

    def initialize( input, options = {} )
      super( input, options )
      @state.rule_memory = {}

      # - - - - - - begin action @parser::init - - - - - -
      # vorax\\lib\\ruby\\Plsql.g


        @columns = []
        @tables = []
        @skip = false
        @last_expr = nil
        @last_alias = nil

      # - - - - - - end action @parser::init - - - - - - -


    end

      attr_reader :columns, :tables
      @is_sql = false;

    # - - - - - - - - - - - - Rules - - - - - - - - - - - - -
    StartRuleReturnValue = define_return_scope 

    # 
    # parser rule start_rule
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 23:1: start_rule : ( create_package )* EOF ;
    # 
    def start_rule
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 1 )
      return_value = StartRuleReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      start_rule_start_index = @input.index

      root_0 = nil
      __EOF2__ = nil
      create_package1 = nil

      tree_for_EOF2 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 24:4: ( create_package )* EOF
        # at line 24:4: ( create_package )*
        while true # decision 1
          alt_1 = 2
          look_1_0 = @input.peek( 1 )

          if ( look_1_0 == T__50 )
            alt_1 = 1

          end
          case alt_1
          when 1
            # at line 24:5: create_package
            @state.following.push( TOKENS_FOLLOWING_create_package_IN_start_rule_58 )
            create_package1 = create_package
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, create_package1.tree )
            end

          else
            break # out of loop for decision 1
          end
        end # loop for decision 1
        __EOF2__ = match( EOF, TOKENS_FOLLOWING_EOF_IN_start_rule_62 )
        if @state.backtracking == 0

          tree_for_EOF2 = @adaptor.create_with_payload( __EOF2__ )
          @adaptor.add_child( root_0, tree_for_EOF2 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 1 )
        memoize( __method__, start_rule_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CreatePackageReturnValue = define_return_scope 

    # 
    # parser rule create_package
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 27:1: create_package : 'CREATE' ( 'OR' keyREPLACE )? ( package_spec | package_body ) ;
    # 
    def create_package
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 2 )
      return_value = CreatePackageReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      create_package_start_index = @input.index

      root_0 = nil
      string_literal3 = nil
      string_literal4 = nil
      keyREPLACE5 = nil
      package_spec6 = nil
      package_body7 = nil

      tree_for_string_literal3 = nil
      tree_for_string_literal4 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 28:4: 'CREATE' ( 'OR' keyREPLACE )? ( package_spec | package_body )
        string_literal3 = match( T__50, TOKENS_FOLLOWING_T__50_IN_create_package_73 )
        if @state.backtracking == 0

          tree_for_string_literal3 = @adaptor.create_with_payload( string_literal3 )
          @adaptor.add_child( root_0, tree_for_string_literal3 )

        end
        # at line 28:13: ( 'OR' keyREPLACE )?
        alt_2 = 2
        look_2_0 = @input.peek( 1 )

        if ( look_2_0 == T__51 )
          alt_2 = 1
        end
        case alt_2
        when 1
          # at line 28:15: 'OR' keyREPLACE
          string_literal4 = match( T__51, TOKENS_FOLLOWING_T__51_IN_create_package_77 )
          if @state.backtracking == 0

            tree_for_string_literal4 = @adaptor.create_with_payload( string_literal4 )
            @adaptor.add_child( root_0, tree_for_string_literal4 )

          end
          @state.following.push( TOKENS_FOLLOWING_keyREPLACE_IN_create_package_79 )
          keyREPLACE5 = keyREPLACE
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyREPLACE5.tree )
          end

        end
        # at line 29:3: ( package_spec | package_body )
        alt_3 = 2
        look_3_0 = @input.peek( 1 )

        if ( look_3_0 == T__160 )
          look_3_1 = @input.peek( 2 )

          if ( look_3_1 == ID )
            look_3_2 = @input.peek( 3 )

            if ( look_3_2.between?( ID, DOUBLEQUOTED_STRING ) || look_3_2 == T__100 )
              alt_3 = 2
            elsif ( look_3_2 == DOT || look_3_2.between?( T__52, T__53 ) )
              alt_3 = 1
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 3, 2 )
            end
          elsif ( look_3_1 == DOUBLEQUOTED_STRING || look_3_1 == T__100 )
            alt_3 = 1
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 3, 1 )
          end
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 3, 0 )
        end
        case alt_3
        when 1
          # at line 29:5: package_spec
          @state.following.push( TOKENS_FOLLOWING_package_spec_IN_create_package_88 )
          package_spec6 = package_spec
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, package_spec6.tree )
          end

        when 2
          # at line 29:20: package_body
          @state.following.push( TOKENS_FOLLOWING_package_body_IN_create_package_92 )
          package_body7 = package_body
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, package_body7.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 2 )
        memoize( __method__, create_package_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    PackageSpecReturnValue = define_return_scope 

    # 
    # parser rule package_spec
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 32:1: package_spec : keyPACKAGE package_name ( 'IS' | 'AS' ) ( package_obj_spec )* 'END' ( package_name )? SEMI ;
    # 
    def package_spec
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 3 )
      return_value = PackageSpecReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      package_spec_start_index = @input.index

      root_0 = nil
      set10 = nil
      string_literal12 = nil
      __SEMI14__ = nil
      keyPACKAGE8 = nil
      package_name9 = nil
      package_obj_spec11 = nil
      package_name13 = nil

      tree_for_set10 = nil
      tree_for_string_literal12 = nil
      tree_for_SEMI14 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 33:4: keyPACKAGE package_name ( 'IS' | 'AS' ) ( package_obj_spec )* 'END' ( package_name )? SEMI
        @state.following.push( TOKENS_FOLLOWING_keyPACKAGE_IN_package_spec_106 )
        keyPACKAGE8 = keyPACKAGE
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyPACKAGE8.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_package_name_IN_package_spec_108 )
        package_name9 = package_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, package_name9.tree )
        end
        set10 = @input.look
        if @input.peek( 1 ).between?( T__52, T__53 )
          @input.consume
          if @state.backtracking == 0
            @adaptor.add_child( root_0, @adaptor.create_with_payload( set10 ) )
          end
          @state.error_recovery = false
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          mse = MismatchedSet( nil )
          raise mse
        end


        # at line 34:3: ( package_obj_spec )*
        while true # decision 4
          alt_4 = 2
          look_4_0 = @input.peek( 1 )

          if ( look_4_0.between?( ID, DOUBLEQUOTED_STRING ) || look_4_0.between?( T__103, T__104 ) || look_4_0 == T__161 )
            alt_4 = 1

          end
          case alt_4
          when 1
            # at line 34:5: package_obj_spec
            @state.following.push( TOKENS_FOLLOWING_package_obj_spec_IN_package_spec_125 )
            package_obj_spec11 = package_obj_spec
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, package_obj_spec11.tree )
            end

          else
            break # out of loop for decision 4
          end
        end # loop for decision 4
        string_literal12 = match( T__54, TOKENS_FOLLOWING_T__54_IN_package_spec_132 )
        if @state.backtracking == 0

          tree_for_string_literal12 = @adaptor.create_with_payload( string_literal12 )
          @adaptor.add_child( root_0, tree_for_string_literal12 )

        end
        # at line 35:9: ( package_name )?
        alt_5 = 2
        look_5_0 = @input.peek( 1 )

        if ( look_5_0.between?( ID, DOUBLEQUOTED_STRING ) || look_5_0 == T__100 )
          alt_5 = 1
        end
        case alt_5
        when 1
          # at line 35:10: package_name
          @state.following.push( TOKENS_FOLLOWING_package_name_IN_package_spec_135 )
          package_name13 = package_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, package_name13.tree )
          end

        end
        __SEMI14__ = match( SEMI, TOKENS_FOLLOWING_SEMI_IN_package_spec_139 )
        if @state.backtracking == 0

          tree_for_SEMI14 = @adaptor.create_with_payload( __SEMI14__ )
          @adaptor.add_child( root_0, tree_for_SEMI14 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 3 )
        memoize( __method__, package_spec_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    PackageBodyReturnValue = define_return_scope 

    # 
    # parser rule package_body
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 38:1: package_body : keyPACKAGE ( keyBODY ) package_name ( 'IS' | 'AS' ) ( package_obj_body )* ( 'BEGIN' seq_of_statements )? 'END' ( package_name )? SEMI ;
    # 
    def package_body
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 4 )
      return_value = PackageBodyReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      package_body_start_index = @input.index

      root_0 = nil
      set18 = nil
      string_literal20 = nil
      string_literal22 = nil
      __SEMI24__ = nil
      keyPACKAGE15 = nil
      keyBODY16 = nil
      package_name17 = nil
      package_obj_body19 = nil
      seq_of_statements21 = nil
      package_name23 = nil

      tree_for_set18 = nil
      tree_for_string_literal20 = nil
      tree_for_string_literal22 = nil
      tree_for_SEMI24 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 39:4: keyPACKAGE ( keyBODY ) package_name ( 'IS' | 'AS' ) ( package_obj_body )* ( 'BEGIN' seq_of_statements )? 'END' ( package_name )? SEMI
        @state.following.push( TOKENS_FOLLOWING_keyPACKAGE_IN_package_body_151 )
        keyPACKAGE15 = keyPACKAGE
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyPACKAGE15.tree )
        end
        # at line 39:15: ( keyBODY )
        # at line 39:17: keyBODY
        @state.following.push( TOKENS_FOLLOWING_keyBODY_IN_package_body_155 )
        keyBODY16 = keyBODY
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyBODY16.tree )
        end

        @state.following.push( TOKENS_FOLLOWING_package_name_IN_package_body_159 )
        package_name17 = package_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, package_name17.tree )
        end
        set18 = @input.look
        if @input.peek( 1 ).between?( T__52, T__53 )
          @input.consume
          if @state.backtracking == 0
            @adaptor.add_child( root_0, @adaptor.create_with_payload( set18 ) )
          end
          @state.error_recovery = false
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          mse = MismatchedSet( nil )
          raise mse
        end


        # at line 40:3: ( package_obj_body )*
        while true # decision 6
          alt_6 = 2
          look_6_0 = @input.peek( 1 )

          if ( look_6_0.between?( ID, DOUBLEQUOTED_STRING ) || look_6_0 == T__50 || look_6_0.between?( T__103, T__104 ) || look_6_0 == T__161 )
            alt_6 = 1

          end
          case alt_6
          when 1
            # at line 40:5: package_obj_body
            @state.following.push( TOKENS_FOLLOWING_package_obj_body_IN_package_body_175 )
            package_obj_body19 = package_obj_body
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, package_obj_body19.tree )
            end

          else
            break # out of loop for decision 6
          end
        end # loop for decision 6
        # at line 41:3: ( 'BEGIN' seq_of_statements )?
        alt_7 = 2
        look_7_0 = @input.peek( 1 )

        if ( look_7_0 == T__55 )
          alt_7 = 1
        end
        case alt_7
        when 1
          # at line 41:5: 'BEGIN' seq_of_statements
          string_literal20 = match( T__55, TOKENS_FOLLOWING_T__55_IN_package_body_184 )
          if @state.backtracking == 0

            tree_for_string_literal20 = @adaptor.create_with_payload( string_literal20 )
            @adaptor.add_child( root_0, tree_for_string_literal20 )

          end
          @state.following.push( TOKENS_FOLLOWING_seq_of_statements_IN_package_body_186 )
          seq_of_statements21 = seq_of_statements
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, seq_of_statements21.tree )
          end

        end
        string_literal22 = match( T__54, TOKENS_FOLLOWING_T__54_IN_package_body_195 )
        if @state.backtracking == 0

          tree_for_string_literal22 = @adaptor.create_with_payload( string_literal22 )
          @adaptor.add_child( root_0, tree_for_string_literal22 )

        end
        # at line 42:9: ( package_name )?
        alt_8 = 2
        look_8_0 = @input.peek( 1 )

        if ( look_8_0.between?( ID, DOUBLEQUOTED_STRING ) || look_8_0 == T__100 )
          alt_8 = 1
        end
        case alt_8
        when 1
          # at line 42:11: package_name
          @state.following.push( TOKENS_FOLLOWING_package_name_IN_package_body_199 )
          package_name23 = package_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, package_name23.tree )
          end

        end
        __SEMI24__ = match( SEMI, TOKENS_FOLLOWING_SEMI_IN_package_body_204 )
        if @state.backtracking == 0

          tree_for_SEMI24 = @adaptor.create_with_payload( __SEMI24__ )
          @adaptor.add_child( root_0, tree_for_SEMI24 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 4 )
        memoize( __method__, package_body_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    PackageNameReturnValue = define_return_scope 

    # 
    # parser rule package_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 45:1: package_name : ( schema_name DOT )? identifier ;
    # 
    def package_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 5 )
      return_value = PackageNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      package_name_start_index = @input.index

      root_0 = nil
      __DOT26__ = nil
      schema_name25 = nil
      identifier27 = nil

      tree_for_DOT26 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 46:4: ( schema_name DOT )? identifier
        # at line 46:4: ( schema_name DOT )?
        alt_9 = 2
        look_9_0 = @input.peek( 1 )

        if ( look_9_0.between?( ID, DOUBLEQUOTED_STRING ) )
          look_9_1 = @input.peek( 2 )

          if ( look_9_1 == DOT )
            alt_9 = 1
          end
        elsif ( look_9_0 == T__100 )
          alt_9 = 1
        end
        case alt_9
        when 1
          # at line 46:6: schema_name DOT
          @state.following.push( TOKENS_FOLLOWING_schema_name_IN_package_name_217 )
          schema_name25 = schema_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, schema_name25.tree )
          end
          __DOT26__ = match( DOT, TOKENS_FOLLOWING_DOT_IN_package_name_219 )
          if @state.backtracking == 0

            tree_for_DOT26 = @adaptor.create_with_payload( __DOT26__ )
            @adaptor.add_child( root_0, tree_for_DOT26 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_identifier_IN_package_name_224 )
        identifier27 = identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, identifier27.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 5 )
        memoize( __method__, package_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    PackageObjSpecReturnValue = define_return_scope 

    # 
    # parser rule package_obj_spec
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 49:1: package_obj_spec : ( variable_declaration | type_declaration | subtype_declaration | record_declaration | plsql_table_declaration | varray_declaration | cursor_declaration | cursor_spec | procedure_spec | function_spec | exception_declaration | pragma_declaration );
    # 
    def package_obj_spec
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 6 )
      return_value = PackageObjSpecReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      package_obj_spec_start_index = @input.index

      root_0 = nil
      variable_declaration28 = nil
      type_declaration29 = nil
      subtype_declaration30 = nil
      record_declaration31 = nil
      plsql_table_declaration32 = nil
      varray_declaration33 = nil
      cursor_declaration34 = nil
      cursor_spec35 = nil
      procedure_spec36 = nil
      function_spec37 = nil
      exception_declaration38 = nil
      pragma_declaration39 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 50:2: ( variable_declaration | type_declaration | subtype_declaration | record_declaration | plsql_table_declaration | varray_declaration | cursor_declaration | cursor_spec | procedure_spec | function_spec | exception_declaration | pragma_declaration )
        alt_10 = 12
        alt_10 = @dfa10.predict( @input )
        case alt_10
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 50:4: variable_declaration
          @state.following.push( TOKENS_FOLLOWING_variable_declaration_IN_package_obj_spec_236 )
          variable_declaration28 = variable_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, variable_declaration28.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 51:4: type_declaration
          @state.following.push( TOKENS_FOLLOWING_type_declaration_IN_package_obj_spec_242 )
          type_declaration29 = type_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, type_declaration29.tree )
          end

        when 3
          root_0 = @adaptor.create_flat_list


          # at line 52:4: subtype_declaration
          @state.following.push( TOKENS_FOLLOWING_subtype_declaration_IN_package_obj_spec_247 )
          subtype_declaration30 = subtype_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, subtype_declaration30.tree )
          end

        when 4
          root_0 = @adaptor.create_flat_list


          # at line 53:4: record_declaration
          @state.following.push( TOKENS_FOLLOWING_record_declaration_IN_package_obj_spec_253 )
          record_declaration31 = record_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, record_declaration31.tree )
          end

        when 5
          root_0 = @adaptor.create_flat_list


          # at line 54:4: plsql_table_declaration
          @state.following.push( TOKENS_FOLLOWING_plsql_table_declaration_IN_package_obj_spec_259 )
          plsql_table_declaration32 = plsql_table_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, plsql_table_declaration32.tree )
          end

        when 6
          root_0 = @adaptor.create_flat_list


          # at line 55:4: varray_declaration
          @state.following.push( TOKENS_FOLLOWING_varray_declaration_IN_package_obj_spec_265 )
          varray_declaration33 = varray_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, varray_declaration33.tree )
          end

        when 7
          root_0 = @adaptor.create_flat_list


          # at line 56:4: cursor_declaration
          @state.following.push( TOKENS_FOLLOWING_cursor_declaration_IN_package_obj_spec_270 )
          cursor_declaration34 = cursor_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, cursor_declaration34.tree )
          end

        when 8
          root_0 = @adaptor.create_flat_list


          # at line 57:4: cursor_spec
          @state.following.push( TOKENS_FOLLOWING_cursor_spec_IN_package_obj_spec_276 )
          cursor_spec35 = cursor_spec
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, cursor_spec35.tree )
          end

        when 9
          root_0 = @adaptor.create_flat_list


          # at line 58:4: procedure_spec
          @state.following.push( TOKENS_FOLLOWING_procedure_spec_IN_package_obj_spec_282 )
          procedure_spec36 = procedure_spec
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, procedure_spec36.tree )
          end

        when 10
          root_0 = @adaptor.create_flat_list


          # at line 59:4: function_spec
          @state.following.push( TOKENS_FOLLOWING_function_spec_IN_package_obj_spec_288 )
          function_spec37 = function_spec
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, function_spec37.tree )
          end

        when 11
          root_0 = @adaptor.create_flat_list


          # at line 60:4: exception_declaration
          @state.following.push( TOKENS_FOLLOWING_exception_declaration_IN_package_obj_spec_294 )
          exception_declaration38 = exception_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, exception_declaration38.tree )
          end

        when 12
          root_0 = @adaptor.create_flat_list


          # at line 61:4: pragma_declaration
          @state.following.push( TOKENS_FOLLOWING_pragma_declaration_IN_package_obj_spec_300 )
          pragma_declaration39 = pragma_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, pragma_declaration39.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 6 )
        memoize( __method__, package_obj_spec_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    VariableDeclarationReturnValue = define_return_scope 

    # 
    # parser rule variable_declaration
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 64:1: variable_declaration : variable_name ( 'CONSTANT' )? type_spec ( 'NOT' 'NULL' )? ( ( ASSIGN | 'DEFAULT' ) plsql_expression )? SEMI ;
    # 
    def variable_declaration
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 7 )
      return_value = VariableDeclarationReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      variable_declaration_start_index = @input.index

      root_0 = nil
      string_literal41 = nil
      string_literal43 = nil
      string_literal44 = nil
      set45 = nil
      __SEMI47__ = nil
      variable_name40 = nil
      type_spec42 = nil
      plsql_expression46 = nil

      tree_for_string_literal41 = nil
      tree_for_string_literal43 = nil
      tree_for_string_literal44 = nil
      tree_for_set45 = nil
      tree_for_SEMI47 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 65:4: variable_name ( 'CONSTANT' )? type_spec ( 'NOT' 'NULL' )? ( ( ASSIGN | 'DEFAULT' ) plsql_expression )? SEMI
        @state.following.push( TOKENS_FOLLOWING_variable_name_IN_variable_declaration_311 )
        variable_name40 = variable_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, variable_name40.tree )
        end
        # at line 65:18: ( 'CONSTANT' )?
        alt_11 = 2
        look_11_0 = @input.peek( 1 )

        if ( look_11_0 == T__56 )
          alt_11 = 1
        end
        case alt_11
        when 1
          # at line 65:19: 'CONSTANT'
          string_literal41 = match( T__56, TOKENS_FOLLOWING_T__56_IN_variable_declaration_314 )
          if @state.backtracking == 0

            tree_for_string_literal41 = @adaptor.create_with_payload( string_literal41 )
            @adaptor.add_child( root_0, tree_for_string_literal41 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_type_spec_IN_variable_declaration_320 )
        type_spec42 = type_spec
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, type_spec42.tree )
        end
        # at line 66:13: ( 'NOT' 'NULL' )?
        alt_12 = 2
        look_12_0 = @input.peek( 1 )

        if ( look_12_0 == T__57 )
          alt_12 = 1
        end
        case alt_12
        when 1
          # at line 66:14: 'NOT' 'NULL'
          string_literal43 = match( T__57, TOKENS_FOLLOWING_T__57_IN_variable_declaration_323 )
          if @state.backtracking == 0

            tree_for_string_literal43 = @adaptor.create_with_payload( string_literal43 )
            @adaptor.add_child( root_0, tree_for_string_literal43 )

          end
          string_literal44 = match( T__58, TOKENS_FOLLOWING_T__58_IN_variable_declaration_325 )
          if @state.backtracking == 0

            tree_for_string_literal44 = @adaptor.create_with_payload( string_literal44 )
            @adaptor.add_child( root_0, tree_for_string_literal44 )

          end

        end
        # at line 67:3: ( ( ASSIGN | 'DEFAULT' ) plsql_expression )?
        alt_13 = 2
        look_13_0 = @input.peek( 1 )

        if ( look_13_0 == ASSIGN || look_13_0 == T__59 )
          alt_13 = 1
        end
        case alt_13
        when 1
          # at line 67:5: ( ASSIGN | 'DEFAULT' ) plsql_expression
          set45 = @input.look
          if @input.peek(1) == ASSIGN || @input.peek(1) == T__59
            @input.consume
            if @state.backtracking == 0
              @adaptor.add_child( root_0, @adaptor.create_with_payload( set45 ) )
            end
            @state.error_recovery = false
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            mse = MismatchedSet( nil )
            raise mse
          end


          @state.following.push( TOKENS_FOLLOWING_plsql_expression_IN_variable_declaration_344 )
          plsql_expression46 = plsql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, plsql_expression46.tree )
          end

        end
        __SEMI47__ = match( SEMI, TOKENS_FOLLOWING_SEMI_IN_variable_declaration_348 )
        if @state.backtracking == 0

          tree_for_SEMI47 = @adaptor.create_with_payload( __SEMI47__ )
          @adaptor.add_child( root_0, tree_for_SEMI47 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 7 )
        memoize( __method__, variable_declaration_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    TypeDeclarationReturnValue = define_return_scope 

    # 
    # parser rule type_declaration
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 70:1: type_declaration : keyTYPE type_spec 'IS' ( keyNEW )? ( type_spec ( 'NOT' 'NULL' )? | LPAREN plsql_expressions RPAREN ) SEMI ;
    # 
    def type_declaration
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 8 )
      return_value = TypeDeclarationReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      type_declaration_start_index = @input.index

      root_0 = nil
      string_literal50 = nil
      string_literal53 = nil
      string_literal54 = nil
      __LPAREN55__ = nil
      __RPAREN57__ = nil
      __SEMI58__ = nil
      keyTYPE48 = nil
      type_spec49 = nil
      keyNEW51 = nil
      type_spec52 = nil
      plsql_expressions56 = nil

      tree_for_string_literal50 = nil
      tree_for_string_literal53 = nil
      tree_for_string_literal54 = nil
      tree_for_LPAREN55 = nil
      tree_for_RPAREN57 = nil
      tree_for_SEMI58 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 71:4: keyTYPE type_spec 'IS' ( keyNEW )? ( type_spec ( 'NOT' 'NULL' )? | LPAREN plsql_expressions RPAREN ) SEMI
        @state.following.push( TOKENS_FOLLOWING_keyTYPE_IN_type_declaration_361 )
        keyTYPE48 = keyTYPE
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyTYPE48.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_type_spec_IN_type_declaration_363 )
        type_spec49 = type_spec
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, type_spec49.tree )
        end
        string_literal50 = match( T__52, TOKENS_FOLLOWING_T__52_IN_type_declaration_365 )
        if @state.backtracking == 0

          tree_for_string_literal50 = @adaptor.create_with_payload( string_literal50 )
          @adaptor.add_child( root_0, tree_for_string_literal50 )

        end
        # at line 71:27: ( keyNEW )?
        alt_14 = 2
        alt_14 = @dfa14.predict( @input )
        case alt_14
        when 1
          # at line 71:29: keyNEW
          @state.following.push( TOKENS_FOLLOWING_keyNEW_IN_type_declaration_369 )
          keyNEW51 = keyNEW
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyNEW51.tree )
          end

        end
        # at line 71:39: ( type_spec ( 'NOT' 'NULL' )? | LPAREN plsql_expressions RPAREN )
        alt_16 = 2
        look_16_0 = @input.peek( 1 )

        if ( look_16_0.between?( ID, DOUBLEQUOTED_STRING ) || look_16_0.between?( T__64, T__76 ) || look_16_0.between?( T__79, T__86 ) || look_16_0.between?( T__88, T__101 ) )
          alt_16 = 1
        elsif ( look_16_0 == LPAREN )
          alt_16 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 16, 0 )
        end
        case alt_16
        when 1
          # at line 71:41: type_spec ( 'NOT' 'NULL' )?
          @state.following.push( TOKENS_FOLLOWING_type_spec_IN_type_declaration_376 )
          type_spec52 = type_spec
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, type_spec52.tree )
          end
          # at line 71:51: ( 'NOT' 'NULL' )?
          alt_15 = 2
          look_15_0 = @input.peek( 1 )

          if ( look_15_0 == T__57 )
            alt_15 = 1
          end
          case alt_15
          when 1
            # at line 71:53: 'NOT' 'NULL'
            string_literal53 = match( T__57, TOKENS_FOLLOWING_T__57_IN_type_declaration_380 )
            if @state.backtracking == 0

              tree_for_string_literal53 = @adaptor.create_with_payload( string_literal53 )
              @adaptor.add_child( root_0, tree_for_string_literal53 )

            end
            string_literal54 = match( T__58, TOKENS_FOLLOWING_T__58_IN_type_declaration_382 )
            if @state.backtracking == 0

              tree_for_string_literal54 = @adaptor.create_with_payload( string_literal54 )
              @adaptor.add_child( root_0, tree_for_string_literal54 )

            end

          end

        when 2
          # at line 71:71: LPAREN plsql_expressions RPAREN
          __LPAREN55__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_type_declaration_389 )
          if @state.backtracking == 0

            tree_for_LPAREN55 = @adaptor.create_with_payload( __LPAREN55__ )
            @adaptor.add_child( root_0, tree_for_LPAREN55 )

          end
          @state.following.push( TOKENS_FOLLOWING_plsql_expressions_IN_type_declaration_391 )
          plsql_expressions56 = plsql_expressions
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, plsql_expressions56.tree )
          end
          __RPAREN57__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_type_declaration_393 )
          if @state.backtracking == 0

            tree_for_RPAREN57 = @adaptor.create_with_payload( __RPAREN57__ )
            @adaptor.add_child( root_0, tree_for_RPAREN57 )

          end

        end
        __SEMI58__ = match( SEMI, TOKENS_FOLLOWING_SEMI_IN_type_declaration_397 )
        if @state.backtracking == 0

          tree_for_SEMI58 = @adaptor.create_with_payload( __SEMI58__ )
          @adaptor.add_child( root_0, tree_for_SEMI58 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 8 )
        memoize( __method__, type_declaration_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SubtypeDeclarationReturnValue = define_return_scope 

    # 
    # parser rule subtype_declaration
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 74:1: subtype_declaration : keySUBTYPE type_spec 'IS' type_spec ( 'NOT' 'NULL' | keyRANGE literal DOUBLEDOT literal )? SEMI ;
    # 
    def subtype_declaration
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 9 )
      return_value = SubtypeDeclarationReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      subtype_declaration_start_index = @input.index

      root_0 = nil
      string_literal61 = nil
      string_literal63 = nil
      string_literal64 = nil
      __DOUBLEDOT67__ = nil
      __SEMI69__ = nil
      keySUBTYPE59 = nil
      type_spec60 = nil
      type_spec62 = nil
      keyRANGE65 = nil
      literal66 = nil
      literal68 = nil

      tree_for_string_literal61 = nil
      tree_for_string_literal63 = nil
      tree_for_string_literal64 = nil
      tree_for_DOUBLEDOT67 = nil
      tree_for_SEMI69 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 75:4: keySUBTYPE type_spec 'IS' type_spec ( 'NOT' 'NULL' | keyRANGE literal DOUBLEDOT literal )? SEMI
        @state.following.push( TOKENS_FOLLOWING_keySUBTYPE_IN_subtype_declaration_410 )
        keySUBTYPE59 = keySUBTYPE
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keySUBTYPE59.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_type_spec_IN_subtype_declaration_412 )
        type_spec60 = type_spec
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, type_spec60.tree )
        end
        string_literal61 = match( T__52, TOKENS_FOLLOWING_T__52_IN_subtype_declaration_414 )
        if @state.backtracking == 0

          tree_for_string_literal61 = @adaptor.create_with_payload( string_literal61 )
          @adaptor.add_child( root_0, tree_for_string_literal61 )

        end
        @state.following.push( TOKENS_FOLLOWING_type_spec_IN_subtype_declaration_416 )
        type_spec62 = type_spec
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, type_spec62.tree )
        end
        # at line 75:40: ( 'NOT' 'NULL' | keyRANGE literal DOUBLEDOT literal )?
        alt_17 = 3
        look_17_0 = @input.peek( 1 )

        if ( look_17_0 == T__57 )
          alt_17 = 1
        elsif ( look_17_0 == ID )
          alt_17 = 2
        end
        case alt_17
        when 1
          # at line 75:42: 'NOT' 'NULL'
          string_literal63 = match( T__57, TOKENS_FOLLOWING_T__57_IN_subtype_declaration_420 )
          if @state.backtracking == 0

            tree_for_string_literal63 = @adaptor.create_with_payload( string_literal63 )
            @adaptor.add_child( root_0, tree_for_string_literal63 )

          end
          string_literal64 = match( T__58, TOKENS_FOLLOWING_T__58_IN_subtype_declaration_422 )
          if @state.backtracking == 0

            tree_for_string_literal64 = @adaptor.create_with_payload( string_literal64 )
            @adaptor.add_child( root_0, tree_for_string_literal64 )

          end

        when 2
          # at line 75:57: keyRANGE literal DOUBLEDOT literal
          @state.following.push( TOKENS_FOLLOWING_keyRANGE_IN_subtype_declaration_426 )
          keyRANGE65 = keyRANGE
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyRANGE65.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_literal_IN_subtype_declaration_428 )
          literal66 = literal
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, literal66.tree )
          end
          __DOUBLEDOT67__ = match( DOUBLEDOT, TOKENS_FOLLOWING_DOUBLEDOT_IN_subtype_declaration_430 )
          if @state.backtracking == 0

            tree_for_DOUBLEDOT67 = @adaptor.create_with_payload( __DOUBLEDOT67__ )
            @adaptor.add_child( root_0, tree_for_DOUBLEDOT67 )

          end
          @state.following.push( TOKENS_FOLLOWING_literal_IN_subtype_declaration_432 )
          literal68 = literal
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, literal68.tree )
          end

        end
        __SEMI69__ = match( SEMI, TOKENS_FOLLOWING_SEMI_IN_subtype_declaration_437 )
        if @state.backtracking == 0

          tree_for_SEMI69 = @adaptor.create_with_payload( __SEMI69__ )
          @adaptor.add_child( root_0, tree_for_SEMI69 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 9 )
        memoize( __method__, subtype_declaration_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CursorDeclarationReturnValue = define_return_scope 

    # 
    # parser rule cursor_declaration
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 78:1: cursor_declaration : keyCURSOR cursor_name ( LPAREN parameter_specs RPAREN )? 'IS' select_command SEMI ;
    # 
    def cursor_declaration
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 10 )
      return_value = CursorDeclarationReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      cursor_declaration_start_index = @input.index

      root_0 = nil
      __LPAREN72__ = nil
      __RPAREN74__ = nil
      string_literal75 = nil
      __SEMI77__ = nil
      keyCURSOR70 = nil
      cursor_name71 = nil
      parameter_specs73 = nil
      select_command76 = nil

      tree_for_LPAREN72 = nil
      tree_for_RPAREN74 = nil
      tree_for_string_literal75 = nil
      tree_for_SEMI77 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 79:4: keyCURSOR cursor_name ( LPAREN parameter_specs RPAREN )? 'IS' select_command SEMI
        @state.following.push( TOKENS_FOLLOWING_keyCURSOR_IN_cursor_declaration_450 )
        keyCURSOR70 = keyCURSOR
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyCURSOR70.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_cursor_name_IN_cursor_declaration_452 )
        cursor_name71 = cursor_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, cursor_name71.tree )
        end
        # at line 80:3: ( LPAREN parameter_specs RPAREN )?
        alt_18 = 2
        look_18_0 = @input.peek( 1 )

        if ( look_18_0 == LPAREN )
          alt_18 = 1
        end
        case alt_18
        when 1
          # at line 80:5: LPAREN parameter_specs RPAREN
          __LPAREN72__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_cursor_declaration_458 )
          if @state.backtracking == 0

            tree_for_LPAREN72 = @adaptor.create_with_payload( __LPAREN72__ )
            @adaptor.add_child( root_0, tree_for_LPAREN72 )

          end
          @state.following.push( TOKENS_FOLLOWING_parameter_specs_IN_cursor_declaration_460 )
          parameter_specs73 = parameter_specs
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, parameter_specs73.tree )
          end
          __RPAREN74__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_cursor_declaration_462 )
          if @state.backtracking == 0

            tree_for_RPAREN74 = @adaptor.create_with_payload( __RPAREN74__ )
            @adaptor.add_child( root_0, tree_for_RPAREN74 )

          end

        end
        string_literal75 = match( T__52, TOKENS_FOLLOWING_T__52_IN_cursor_declaration_469 )
        if @state.backtracking == 0

          tree_for_string_literal75 = @adaptor.create_with_payload( string_literal75 )
          @adaptor.add_child( root_0, tree_for_string_literal75 )

        end
        @state.following.push( TOKENS_FOLLOWING_select_command_IN_cursor_declaration_471 )
        select_command76 = select_command
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, select_command76.tree )
        end
        __SEMI77__ = match( SEMI, TOKENS_FOLLOWING_SEMI_IN_cursor_declaration_473 )
        if @state.backtracking == 0

          tree_for_SEMI77 = @adaptor.create_with_payload( __SEMI77__ )
          @adaptor.add_child( root_0, tree_for_SEMI77 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 10 )
        memoize( __method__, cursor_declaration_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    PackageObjBodyReturnValue = define_return_scope 

    # 
    # parser rule package_obj_body
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 83:1: package_obj_body : ( variable_declaration | subtype_declaration | cursor_declaration | exception_declaration | record_declaration | plsql_table_declaration | varray_declaration | procedure_body | function_body | pragma_declaration );
    # 
    def package_obj_body
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 11 )
      return_value = PackageObjBodyReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      package_obj_body_start_index = @input.index

      root_0 = nil
      variable_declaration78 = nil
      subtype_declaration79 = nil
      cursor_declaration80 = nil
      exception_declaration81 = nil
      record_declaration82 = nil
      plsql_table_declaration83 = nil
      varray_declaration84 = nil
      procedure_body85 = nil
      function_body86 = nil
      pragma_declaration87 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 84:2: ( variable_declaration | subtype_declaration | cursor_declaration | exception_declaration | record_declaration | plsql_table_declaration | varray_declaration | procedure_body | function_body | pragma_declaration )
        alt_19 = 10
        alt_19 = @dfa19.predict( @input )
        case alt_19
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 84:4: variable_declaration
          @state.following.push( TOKENS_FOLLOWING_variable_declaration_IN_package_obj_body_483 )
          variable_declaration78 = variable_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, variable_declaration78.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 85:4: subtype_declaration
          @state.following.push( TOKENS_FOLLOWING_subtype_declaration_IN_package_obj_body_489 )
          subtype_declaration79 = subtype_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, subtype_declaration79.tree )
          end

        when 3
          root_0 = @adaptor.create_flat_list


          # at line 86:4: cursor_declaration
          @state.following.push( TOKENS_FOLLOWING_cursor_declaration_IN_package_obj_body_495 )
          cursor_declaration80 = cursor_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, cursor_declaration80.tree )
          end

        when 4
          root_0 = @adaptor.create_flat_list


          # at line 87:4: exception_declaration
          @state.following.push( TOKENS_FOLLOWING_exception_declaration_IN_package_obj_body_501 )
          exception_declaration81 = exception_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, exception_declaration81.tree )
          end

        when 5
          root_0 = @adaptor.create_flat_list


          # at line 88:4: record_declaration
          @state.following.push( TOKENS_FOLLOWING_record_declaration_IN_package_obj_body_507 )
          record_declaration82 = record_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, record_declaration82.tree )
          end

        when 6
          root_0 = @adaptor.create_flat_list


          # at line 89:4: plsql_table_declaration
          @state.following.push( TOKENS_FOLLOWING_plsql_table_declaration_IN_package_obj_body_513 )
          plsql_table_declaration83 = plsql_table_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, plsql_table_declaration83.tree )
          end

        when 7
          root_0 = @adaptor.create_flat_list


          # at line 90:4: varray_declaration
          @state.following.push( TOKENS_FOLLOWING_varray_declaration_IN_package_obj_body_519 )
          varray_declaration84 = varray_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, varray_declaration84.tree )
          end

        when 8
          root_0 = @adaptor.create_flat_list


          # at line 91:4: procedure_body
          @state.following.push( TOKENS_FOLLOWING_procedure_body_IN_package_obj_body_524 )
          procedure_body85 = procedure_body
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, procedure_body85.tree )
          end

        when 9
          root_0 = @adaptor.create_flat_list


          # at line 92:4: function_body
          @state.following.push( TOKENS_FOLLOWING_function_body_IN_package_obj_body_530 )
          function_body86 = function_body
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, function_body86.tree )
          end

        when 10
          root_0 = @adaptor.create_flat_list


          # at line 93:4: pragma_declaration
          @state.following.push( TOKENS_FOLLOWING_pragma_declaration_IN_package_obj_body_536 )
          pragma_declaration87 = pragma_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, pragma_declaration87.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 11 )
        memoize( __method__, package_obj_body_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SeqOfStatementsReturnValue = define_return_scope 

    # 
    # parser rule seq_of_statements
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 96:1: seq_of_statements : statement SEMI ( statement SEMI )* ;
    # 
    def seq_of_statements
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 12 )
      return_value = SeqOfStatementsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      seq_of_statements_start_index = @input.index

      root_0 = nil
      __SEMI89__ = nil
      __SEMI91__ = nil
      statement88 = nil
      statement90 = nil

      tree_for_SEMI89 = nil
      tree_for_SEMI91 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 97:4: statement SEMI ( statement SEMI )*
        @state.following.push( TOKENS_FOLLOWING_statement_IN_seq_of_statements_547 )
        statement88 = statement
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, statement88.tree )
        end
        __SEMI89__ = match( SEMI, TOKENS_FOLLOWING_SEMI_IN_seq_of_statements_549 )
        if @state.backtracking == 0

          tree_for_SEMI89 = @adaptor.create_with_payload( __SEMI89__ )
          @adaptor.add_child( root_0, tree_for_SEMI89 )

        end
        # at line 97:19: ( statement SEMI )*
        while true # decision 20
          alt_20 = 2
          look_20_0 = @input.peek( 1 )

          if ( look_20_0 == LLABEL || look_20_0 == COLON || look_20_0.between?( ID, DOUBLEQUOTED_STRING ) || look_20_0 == T__50 || look_20_0 == T__55 || look_20_0 == T__58 || look_20_0 == T__60 || look_20_0 == T__62 || look_20_0 == T__87 || look_20_0 == T__100 || look_20_0.between?( T__103, T__104 ) || look_20_0.between?( T__112, T__114 ) || look_20_0 == T__116 || look_20_0 == T__132 || look_20_0 == T__142 || look_20_0 == T__145 || look_20_0 == T__147 || look_20_0.between?( T__149, T__150 ) || look_20_0 == T__155 || look_20_0 == T__158 || look_20_0.between?( T__161, T__162 ) || look_20_0 == T__164 || look_20_0.between?( T__166, T__167 ) )
            alt_20 = 1

          end
          case alt_20
          when 1
            # at line 97:21: statement SEMI
            @state.following.push( TOKENS_FOLLOWING_statement_IN_seq_of_statements_553 )
            statement90 = statement
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, statement90.tree )
            end
            __SEMI91__ = match( SEMI, TOKENS_FOLLOWING_SEMI_IN_seq_of_statements_555 )
            if @state.backtracking == 0

              tree_for_SEMI91 = @adaptor.create_with_payload( __SEMI91__ )
              @adaptor.add_child( root_0, tree_for_SEMI91 )

            end

          else
            break # out of loop for decision 20
          end
        end # loop for decision 20
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 12 )
        memoize( __method__, seq_of_statements_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    StatementReturnValue = define_return_scope 

    # 
    # parser rule statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 100:1: statement : ( assignment_statement | exit_statement | goto_statement | case_statement | if_statement | loop_statement | null_statement | raise_statement | return_statement | sql_statement | plsql_block | function_call );
    # 
    def statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 13 )
      return_value = StatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      statement_start_index = @input.index

      root_0 = nil
      assignment_statement92 = nil
      exit_statement93 = nil
      goto_statement94 = nil
      case_statement95 = nil
      if_statement96 = nil
      loop_statement97 = nil
      null_statement98 = nil
      raise_statement99 = nil
      return_statement100 = nil
      sql_statement101 = nil
      plsql_block102 = nil
      function_call103 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 101:2: ( assignment_statement | exit_statement | goto_statement | case_statement | if_statement | loop_statement | null_statement | raise_statement | return_statement | sql_statement | plsql_block | function_call )
        alt_21 = 12
        alt_21 = @dfa21.predict( @input )
        case alt_21
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 101:4: assignment_statement
          @state.following.push( TOKENS_FOLLOWING_assignment_statement_IN_statement_570 )
          assignment_statement92 = assignment_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, assignment_statement92.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 102:4: exit_statement
          @state.following.push( TOKENS_FOLLOWING_exit_statement_IN_statement_575 )
          exit_statement93 = exit_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, exit_statement93.tree )
          end

        when 3
          root_0 = @adaptor.create_flat_list


          # at line 103:4: goto_statement
          @state.following.push( TOKENS_FOLLOWING_goto_statement_IN_statement_580 )
          goto_statement94 = goto_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, goto_statement94.tree )
          end

        when 4
          root_0 = @adaptor.create_flat_list


          # at line 104:4: case_statement
          @state.following.push( TOKENS_FOLLOWING_case_statement_IN_statement_585 )
          case_statement95 = case_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, case_statement95.tree )
          end

        when 5
          root_0 = @adaptor.create_flat_list


          # at line 105:4: if_statement
          @state.following.push( TOKENS_FOLLOWING_if_statement_IN_statement_590 )
          if_statement96 = if_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, if_statement96.tree )
          end

        when 6
          root_0 = @adaptor.create_flat_list


          # at line 106:4: loop_statement
          @state.following.push( TOKENS_FOLLOWING_loop_statement_IN_statement_596 )
          loop_statement97 = loop_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, loop_statement97.tree )
          end

        when 7
          root_0 = @adaptor.create_flat_list


          # at line 107:4: null_statement
          @state.following.push( TOKENS_FOLLOWING_null_statement_IN_statement_602 )
          null_statement98 = null_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, null_statement98.tree )
          end

        when 8
          root_0 = @adaptor.create_flat_list


          # at line 108:4: raise_statement
          @state.following.push( TOKENS_FOLLOWING_raise_statement_IN_statement_607 )
          raise_statement99 = raise_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, raise_statement99.tree )
          end

        when 9
          root_0 = @adaptor.create_flat_list


          # at line 109:4: return_statement
          @state.following.push( TOKENS_FOLLOWING_return_statement_IN_statement_612 )
          return_statement100 = return_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, return_statement100.tree )
          end

        when 10
          root_0 = @adaptor.create_flat_list


          # at line 110:4: sql_statement
          @state.following.push( TOKENS_FOLLOWING_sql_statement_IN_statement_617 )
          sql_statement101 = sql_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_statement101.tree )
          end

        when 11
          root_0 = @adaptor.create_flat_list


          # at line 111:4: plsql_block
          @state.following.push( TOKENS_FOLLOWING_plsql_block_IN_statement_622 )
          plsql_block102 = plsql_block
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, plsql_block102.tree )
          end

        when 12
          root_0 = @adaptor.create_flat_list


          # at line 113:4: function_call
          @state.following.push( TOKENS_FOLLOWING_function_call_IN_statement_628 )
          function_call103 = function_call
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, function_call103.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 13 )
        memoize( __method__, statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    PlsqlBlockReturnValue = define_return_scope 

    # 
    # parser rule plsql_block
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 116:1: plsql_block : ( LLABEL label_name RLABEL )? ( ( 'DECLARE' )? ( declare_spec )+ )? ( 'BEGIN' ) seq_of_statements ( 'EXCEPTION' ( exception_handler )+ )? ( 'END' ( label_name )? ) ;
    # 
    def plsql_block
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 14 )
      return_value = PlsqlBlockReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      plsql_block_start_index = @input.index

      root_0 = nil
      __LLABEL104__ = nil
      __RLABEL106__ = nil
      string_literal107 = nil
      string_literal109 = nil
      string_literal111 = nil
      string_literal113 = nil
      label_name105 = nil
      declare_spec108 = nil
      seq_of_statements110 = nil
      exception_handler112 = nil
      label_name114 = nil

      tree_for_LLABEL104 = nil
      tree_for_RLABEL106 = nil
      tree_for_string_literal107 = nil
      tree_for_string_literal109 = nil
      tree_for_string_literal111 = nil
      tree_for_string_literal113 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 117:4: ( LLABEL label_name RLABEL )? ( ( 'DECLARE' )? ( declare_spec )+ )? ( 'BEGIN' ) seq_of_statements ( 'EXCEPTION' ( exception_handler )+ )? ( 'END' ( label_name )? )
        # at line 117:4: ( LLABEL label_name RLABEL )?
        alt_22 = 2
        look_22_0 = @input.peek( 1 )

        if ( look_22_0 == LLABEL )
          alt_22 = 1
        end
        case alt_22
        when 1
          # at line 117:6: LLABEL label_name RLABEL
          __LLABEL104__ = match( LLABEL, TOKENS_FOLLOWING_LLABEL_IN_plsql_block_643 )
          if @state.backtracking == 0

            tree_for_LLABEL104 = @adaptor.create_with_payload( __LLABEL104__ )
            @adaptor.add_child( root_0, tree_for_LLABEL104 )

          end
          @state.following.push( TOKENS_FOLLOWING_label_name_IN_plsql_block_645 )
          label_name105 = label_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, label_name105.tree )
          end
          __RLABEL106__ = match( RLABEL, TOKENS_FOLLOWING_RLABEL_IN_plsql_block_647 )
          if @state.backtracking == 0

            tree_for_RLABEL106 = @adaptor.create_with_payload( __RLABEL106__ )
            @adaptor.add_child( root_0, tree_for_RLABEL106 )

          end

        end
        # at line 118:3: ( ( 'DECLARE' )? ( declare_spec )+ )?
        alt_25 = 2
        look_25_0 = @input.peek( 1 )

        if ( look_25_0.between?( ID, DOUBLEQUOTED_STRING ) || look_25_0 == T__50 || look_25_0 == T__60 || look_25_0.between?( T__103, T__104 ) || look_25_0 == T__161 )
          alt_25 = 1
        end
        case alt_25
        when 1
          # at line 118:5: ( 'DECLARE' )? ( declare_spec )+
          # at line 118:5: ( 'DECLARE' )?
          alt_23 = 2
          look_23_0 = @input.peek( 1 )

          if ( look_23_0 == T__60 )
            alt_23 = 1
          end
          case alt_23
          when 1
            # at line 118:7: 'DECLARE'
            string_literal107 = match( T__60, TOKENS_FOLLOWING_T__60_IN_plsql_block_658 )
            if @state.backtracking == 0

              tree_for_string_literal107 = @adaptor.create_with_payload( string_literal107 )
              @adaptor.add_child( root_0, tree_for_string_literal107 )

            end

          end
          # at file 118:20: ( declare_spec )+
          match_count_24 = 0
          while true
            alt_24 = 2
            look_24_0 = @input.peek( 1 )

            if ( look_24_0.between?( ID, DOUBLEQUOTED_STRING ) || look_24_0 == T__50 || look_24_0.between?( T__103, T__104 ) || look_24_0 == T__161 )
              alt_24 = 1

            end
            case alt_24
            when 1
              # at line 118:21: declare_spec
              @state.following.push( TOKENS_FOLLOWING_declare_spec_IN_plsql_block_664 )
              declare_spec108 = declare_spec
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, declare_spec108.tree )
              end

            else
              match_count_24 > 0 and break
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              eee = EarlyExit(24)


              raise eee
            end
            match_count_24 += 1
          end


        end
        # at line 119:3: ( 'BEGIN' )
        # at line 119:5: 'BEGIN'
        string_literal109 = match( T__55, TOKENS_FOLLOWING_T__55_IN_plsql_block_676 )
        if @state.backtracking == 0

          tree_for_string_literal109 = @adaptor.create_with_payload( string_literal109 )
          @adaptor.add_child( root_0, tree_for_string_literal109 )

        end

        @state.following.push( TOKENS_FOLLOWING_seq_of_statements_IN_plsql_block_682 )
        seq_of_statements110 = seq_of_statements
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, seq_of_statements110.tree )
        end
        # at line 121:3: ( 'EXCEPTION' ( exception_handler )+ )?
        alt_27 = 2
        look_27_0 = @input.peek( 1 )

        if ( look_27_0 == T__61 )
          alt_27 = 1
        end
        case alt_27
        when 1
          # at line 121:5: 'EXCEPTION' ( exception_handler )+
          string_literal111 = match( T__61, TOKENS_FOLLOWING_T__61_IN_plsql_block_688 )
          if @state.backtracking == 0

            tree_for_string_literal111 = @adaptor.create_with_payload( string_literal111 )
            @adaptor.add_child( root_0, tree_for_string_literal111 )

          end
          # at file 121:17: ( exception_handler )+
          match_count_26 = 0
          while true
            alt_26 = 2
            look_26_0 = @input.peek( 1 )

            if ( look_26_0 == T__63 )
              alt_26 = 1

            end
            case alt_26
            when 1
              # at line 121:19: exception_handler
              @state.following.push( TOKENS_FOLLOWING_exception_handler_IN_plsql_block_692 )
              exception_handler112 = exception_handler
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, exception_handler112.tree )
              end

            else
              match_count_26 > 0 and break
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              eee = EarlyExit(26)


              raise eee
            end
            match_count_26 += 1
          end


        end
        # at line 122:3: ( 'END' ( label_name )? )
        # at line 122:5: 'END' ( label_name )?
        string_literal113 = match( T__54, TOKENS_FOLLOWING_T__54_IN_plsql_block_705 )
        if @state.backtracking == 0

          tree_for_string_literal113 = @adaptor.create_with_payload( string_literal113 )
          @adaptor.add_child( root_0, tree_for_string_literal113 )

        end
        # at line 122:11: ( label_name )?
        alt_28 = 2
        look_28_0 = @input.peek( 1 )

        if ( look_28_0.between?( ID, DOUBLEQUOTED_STRING ) )
          alt_28 = 1
        end
        case alt_28
        when 1
          # at line 122:13: label_name
          @state.following.push( TOKENS_FOLLOWING_label_name_IN_plsql_block_709 )
          label_name114 = label_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, label_name114.tree )
          end

        end

        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 14 )
        memoize( __method__, plsql_block_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    DeclareSpecReturnValue = define_return_scope 

    # 
    # parser rule declare_spec
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 125:1: declare_spec : ( variable_declaration | subtype_declaration | cursor_declaration | exception_declaration | record_declaration | plsql_table_declaration | varray_declaration | procedure_declaration | function_declaration | type_declaration | pragma_declaration );
    # 
    def declare_spec
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 15 )
      return_value = DeclareSpecReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      declare_spec_start_index = @input.index

      root_0 = nil
      variable_declaration115 = nil
      subtype_declaration116 = nil
      cursor_declaration117 = nil
      exception_declaration118 = nil
      record_declaration119 = nil
      plsql_table_declaration120 = nil
      varray_declaration121 = nil
      procedure_declaration122 = nil
      function_declaration123 = nil
      type_declaration124 = nil
      pragma_declaration125 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 126:2: ( variable_declaration | subtype_declaration | cursor_declaration | exception_declaration | record_declaration | plsql_table_declaration | varray_declaration | procedure_declaration | function_declaration | type_declaration | pragma_declaration )
        alt_29 = 11
        alt_29 = @dfa29.predict( @input )
        case alt_29
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 126:4: variable_declaration
          @state.following.push( TOKENS_FOLLOWING_variable_declaration_IN_declare_spec_725 )
          variable_declaration115 = variable_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, variable_declaration115.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 127:4: subtype_declaration
          @state.following.push( TOKENS_FOLLOWING_subtype_declaration_IN_declare_spec_731 )
          subtype_declaration116 = subtype_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, subtype_declaration116.tree )
          end

        when 3
          root_0 = @adaptor.create_flat_list


          # at line 128:4: cursor_declaration
          @state.following.push( TOKENS_FOLLOWING_cursor_declaration_IN_declare_spec_737 )
          cursor_declaration117 = cursor_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, cursor_declaration117.tree )
          end

        when 4
          root_0 = @adaptor.create_flat_list


          # at line 129:4: exception_declaration
          @state.following.push( TOKENS_FOLLOWING_exception_declaration_IN_declare_spec_743 )
          exception_declaration118 = exception_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, exception_declaration118.tree )
          end

        when 5
          root_0 = @adaptor.create_flat_list


          # at line 130:4: record_declaration
          @state.following.push( TOKENS_FOLLOWING_record_declaration_IN_declare_spec_749 )
          record_declaration119 = record_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, record_declaration119.tree )
          end

        when 6
          root_0 = @adaptor.create_flat_list


          # at line 131:4: plsql_table_declaration
          @state.following.push( TOKENS_FOLLOWING_plsql_table_declaration_IN_declare_spec_755 )
          plsql_table_declaration120 = plsql_table_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, plsql_table_declaration120.tree )
          end

        when 7
          root_0 = @adaptor.create_flat_list


          # at line 132:4: varray_declaration
          @state.following.push( TOKENS_FOLLOWING_varray_declaration_IN_declare_spec_761 )
          varray_declaration121 = varray_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, varray_declaration121.tree )
          end

        when 8
          root_0 = @adaptor.create_flat_list


          # at line 133:4: procedure_declaration
          @state.following.push( TOKENS_FOLLOWING_procedure_declaration_IN_declare_spec_766 )
          procedure_declaration122 = procedure_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, procedure_declaration122.tree )
          end

        when 9
          root_0 = @adaptor.create_flat_list


          # at line 134:4: function_declaration
          @state.following.push( TOKENS_FOLLOWING_function_declaration_IN_declare_spec_772 )
          function_declaration123 = function_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, function_declaration123.tree )
          end

        when 10
          root_0 = @adaptor.create_flat_list


          # at line 135:4: type_declaration
          @state.following.push( TOKENS_FOLLOWING_type_declaration_IN_declare_spec_777 )
          type_declaration124 = type_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, type_declaration124.tree )
          end

        when 11
          root_0 = @adaptor.create_flat_list


          # at line 136:4: pragma_declaration
          @state.following.push( TOKENS_FOLLOWING_pragma_declaration_IN_declare_spec_783 )
          pragma_declaration125 = pragma_declaration
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, pragma_declaration125.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 15 )
        memoize( __method__, declare_spec_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    PragmaDeclarationReturnValue = define_return_scope 

    # 
    # parser rule pragma_declaration
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 139:1: pragma_declaration : keyPRAGMA ( keyRESTRICT_REFERENCES LPAREN ( 'DEFAULT' | function_name ) ( COMMA pragma_param )+ RPAREN | keyEXCEPTION_INIT LPAREN exception_name COMMA literal RPAREN | keyAUTONOMOUS_TRANSACTION | keySERIALLY_REUSABLE | keyBUILTIN LPAREN pragma_params RPAREN | keyFIPSFLAG LPAREN pragma_params RPAREN | keyINTERFACE LPAREN pragma_params RPAREN | keyNEW_NAMES LPAREN pragma_params RPAREN | keyTIMESTAMP LPAREN pragma_params RPAREN ) SEMI ;
    # 
    def pragma_declaration
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 16 )
      return_value = PragmaDeclarationReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      pragma_declaration_start_index = @input.index

      root_0 = nil
      __LPAREN128__ = nil
      string_literal129 = nil
      __COMMA131__ = nil
      __RPAREN133__ = nil
      __LPAREN135__ = nil
      __COMMA137__ = nil
      __RPAREN139__ = nil
      __LPAREN143__ = nil
      __RPAREN145__ = nil
      __LPAREN147__ = nil
      __RPAREN149__ = nil
      __LPAREN151__ = nil
      __RPAREN153__ = nil
      __LPAREN155__ = nil
      __RPAREN157__ = nil
      __LPAREN159__ = nil
      __RPAREN161__ = nil
      __SEMI162__ = nil
      keyPRAGMA126 = nil
      keyRESTRICT_REFERENCES127 = nil
      function_name130 = nil
      pragma_param132 = nil
      keyEXCEPTION_INIT134 = nil
      exception_name136 = nil
      literal138 = nil
      keyAUTONOMOUS_TRANSACTION140 = nil
      keySERIALLY_REUSABLE141 = nil
      keyBUILTIN142 = nil
      pragma_params144 = nil
      keyFIPSFLAG146 = nil
      pragma_params148 = nil
      keyINTERFACE150 = nil
      pragma_params152 = nil
      keyNEW_NAMES154 = nil
      pragma_params156 = nil
      keyTIMESTAMP158 = nil
      pragma_params160 = nil

      tree_for_LPAREN128 = nil
      tree_for_string_literal129 = nil
      tree_for_COMMA131 = nil
      tree_for_RPAREN133 = nil
      tree_for_LPAREN135 = nil
      tree_for_COMMA137 = nil
      tree_for_RPAREN139 = nil
      tree_for_LPAREN143 = nil
      tree_for_RPAREN145 = nil
      tree_for_LPAREN147 = nil
      tree_for_RPAREN149 = nil
      tree_for_LPAREN151 = nil
      tree_for_RPAREN153 = nil
      tree_for_LPAREN155 = nil
      tree_for_RPAREN157 = nil
      tree_for_LPAREN159 = nil
      tree_for_RPAREN161 = nil
      tree_for_SEMI162 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 140:4: keyPRAGMA ( keyRESTRICT_REFERENCES LPAREN ( 'DEFAULT' | function_name ) ( COMMA pragma_param )+ RPAREN | keyEXCEPTION_INIT LPAREN exception_name COMMA literal RPAREN | keyAUTONOMOUS_TRANSACTION | keySERIALLY_REUSABLE | keyBUILTIN LPAREN pragma_params RPAREN | keyFIPSFLAG LPAREN pragma_params RPAREN | keyINTERFACE LPAREN pragma_params RPAREN | keyNEW_NAMES LPAREN pragma_params RPAREN | keyTIMESTAMP LPAREN pragma_params RPAREN ) SEMI
        @state.following.push( TOKENS_FOLLOWING_keyPRAGMA_IN_pragma_declaration_794 )
        keyPRAGMA126 = keyPRAGMA
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyPRAGMA126.tree )
        end
        # at line 141:3: ( keyRESTRICT_REFERENCES LPAREN ( 'DEFAULT' | function_name ) ( COMMA pragma_param )+ RPAREN | keyEXCEPTION_INIT LPAREN exception_name COMMA literal RPAREN | keyAUTONOMOUS_TRANSACTION | keySERIALLY_REUSABLE | keyBUILTIN LPAREN pragma_params RPAREN | keyFIPSFLAG LPAREN pragma_params RPAREN | keyINTERFACE LPAREN pragma_params RPAREN | keyNEW_NAMES LPAREN pragma_params RPAREN | keyTIMESTAMP LPAREN pragma_params RPAREN )
        alt_32 = 9
        alt_32 = @dfa32.predict( @input )
        case alt_32
        when 1
          # at line 141:5: keyRESTRICT_REFERENCES LPAREN ( 'DEFAULT' | function_name ) ( COMMA pragma_param )+ RPAREN
          @state.following.push( TOKENS_FOLLOWING_keyRESTRICT_REFERENCES_IN_pragma_declaration_801 )
          keyRESTRICT_REFERENCES127 = keyRESTRICT_REFERENCES
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyRESTRICT_REFERENCES127.tree )
          end
          __LPAREN128__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_pragma_declaration_803 )
          if @state.backtracking == 0

            tree_for_LPAREN128 = @adaptor.create_with_payload( __LPAREN128__ )
            @adaptor.add_child( root_0, tree_for_LPAREN128 )

          end
          # at line 141:35: ( 'DEFAULT' | function_name )
          alt_30 = 2
          look_30_0 = @input.peek( 1 )

          if ( look_30_0 == T__59 )
            alt_30 = 1
          elsif ( look_30_0 == QUOTED_STRING || look_30_0.between?( ID, DOUBLEQUOTED_STRING ) )
            alt_30 = 2
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 30, 0 )
          end
          case alt_30
          when 1
            # at line 141:37: 'DEFAULT'
            string_literal129 = match( T__59, TOKENS_FOLLOWING_T__59_IN_pragma_declaration_807 )
            if @state.backtracking == 0

              tree_for_string_literal129 = @adaptor.create_with_payload( string_literal129 )
              @adaptor.add_child( root_0, tree_for_string_literal129 )

            end

          when 2
            # at line 141:49: function_name
            @state.following.push( TOKENS_FOLLOWING_function_name_IN_pragma_declaration_811 )
            function_name130 = function_name
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, function_name130.tree )
            end

          end
          # at file 141:65: ( COMMA pragma_param )+
          match_count_31 = 0
          while true
            alt_31 = 2
            look_31_0 = @input.peek( 1 )

            if ( look_31_0 == COMMA )
              alt_31 = 1

            end
            case alt_31
            when 1
              # at line 141:67: COMMA pragma_param
              __COMMA131__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_pragma_declaration_817 )
              if @state.backtracking == 0

                tree_for_COMMA131 = @adaptor.create_with_payload( __COMMA131__ )
                @adaptor.add_child( root_0, tree_for_COMMA131 )

              end
              @state.following.push( TOKENS_FOLLOWING_pragma_param_IN_pragma_declaration_819 )
              pragma_param132 = pragma_param
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, pragma_param132.tree )
              end

            else
              match_count_31 > 0 and break
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              eee = EarlyExit(31)


              raise eee
            end
            match_count_31 += 1
          end

          __RPAREN133__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_pragma_declaration_824 )
          if @state.backtracking == 0

            tree_for_RPAREN133 = @adaptor.create_with_payload( __RPAREN133__ )
            @adaptor.add_child( root_0, tree_for_RPAREN133 )

          end

        when 2
          # at line 142:5: keyEXCEPTION_INIT LPAREN exception_name COMMA literal RPAREN
          @state.following.push( TOKENS_FOLLOWING_keyEXCEPTION_INIT_IN_pragma_declaration_831 )
          keyEXCEPTION_INIT134 = keyEXCEPTION_INIT
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyEXCEPTION_INIT134.tree )
          end
          __LPAREN135__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_pragma_declaration_833 )
          if @state.backtracking == 0

            tree_for_LPAREN135 = @adaptor.create_with_payload( __LPAREN135__ )
            @adaptor.add_child( root_0, tree_for_LPAREN135 )

          end
          @state.following.push( TOKENS_FOLLOWING_exception_name_IN_pragma_declaration_835 )
          exception_name136 = exception_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, exception_name136.tree )
          end
          __COMMA137__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_pragma_declaration_837 )
          if @state.backtracking == 0

            tree_for_COMMA137 = @adaptor.create_with_payload( __COMMA137__ )
            @adaptor.add_child( root_0, tree_for_COMMA137 )

          end
          @state.following.push( TOKENS_FOLLOWING_literal_IN_pragma_declaration_839 )
          literal138 = literal
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, literal138.tree )
          end
          __RPAREN139__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_pragma_declaration_841 )
          if @state.backtracking == 0

            tree_for_RPAREN139 = @adaptor.create_with_payload( __RPAREN139__ )
            @adaptor.add_child( root_0, tree_for_RPAREN139 )

          end

        when 3
          # at line 143:5: keyAUTONOMOUS_TRANSACTION
          @state.following.push( TOKENS_FOLLOWING_keyAUTONOMOUS_TRANSACTION_IN_pragma_declaration_847 )
          keyAUTONOMOUS_TRANSACTION140 = keyAUTONOMOUS_TRANSACTION
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyAUTONOMOUS_TRANSACTION140.tree )
          end

        when 4
          # at line 144:5: keySERIALLY_REUSABLE
          @state.following.push( TOKENS_FOLLOWING_keySERIALLY_REUSABLE_IN_pragma_declaration_853 )
          keySERIALLY_REUSABLE141 = keySERIALLY_REUSABLE
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keySERIALLY_REUSABLE141.tree )
          end

        when 5
          # at line 145:5: keyBUILTIN LPAREN pragma_params RPAREN
          @state.following.push( TOKENS_FOLLOWING_keyBUILTIN_IN_pragma_declaration_859 )
          keyBUILTIN142 = keyBUILTIN
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyBUILTIN142.tree )
          end
          __LPAREN143__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_pragma_declaration_861 )
          if @state.backtracking == 0

            tree_for_LPAREN143 = @adaptor.create_with_payload( __LPAREN143__ )
            @adaptor.add_child( root_0, tree_for_LPAREN143 )

          end
          @state.following.push( TOKENS_FOLLOWING_pragma_params_IN_pragma_declaration_863 )
          pragma_params144 = pragma_params
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, pragma_params144.tree )
          end
          __RPAREN145__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_pragma_declaration_865 )
          if @state.backtracking == 0

            tree_for_RPAREN145 = @adaptor.create_with_payload( __RPAREN145__ )
            @adaptor.add_child( root_0, tree_for_RPAREN145 )

          end

        when 6
          # at line 146:5: keyFIPSFLAG LPAREN pragma_params RPAREN
          @state.following.push( TOKENS_FOLLOWING_keyFIPSFLAG_IN_pragma_declaration_871 )
          keyFIPSFLAG146 = keyFIPSFLAG
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyFIPSFLAG146.tree )
          end
          __LPAREN147__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_pragma_declaration_873 )
          if @state.backtracking == 0

            tree_for_LPAREN147 = @adaptor.create_with_payload( __LPAREN147__ )
            @adaptor.add_child( root_0, tree_for_LPAREN147 )

          end
          @state.following.push( TOKENS_FOLLOWING_pragma_params_IN_pragma_declaration_875 )
          pragma_params148 = pragma_params
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, pragma_params148.tree )
          end
          __RPAREN149__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_pragma_declaration_877 )
          if @state.backtracking == 0

            tree_for_RPAREN149 = @adaptor.create_with_payload( __RPAREN149__ )
            @adaptor.add_child( root_0, tree_for_RPAREN149 )

          end

        when 7
          # at line 147:5: keyINTERFACE LPAREN pragma_params RPAREN
          @state.following.push( TOKENS_FOLLOWING_keyINTERFACE_IN_pragma_declaration_883 )
          keyINTERFACE150 = keyINTERFACE
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyINTERFACE150.tree )
          end
          __LPAREN151__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_pragma_declaration_885 )
          if @state.backtracking == 0

            tree_for_LPAREN151 = @adaptor.create_with_payload( __LPAREN151__ )
            @adaptor.add_child( root_0, tree_for_LPAREN151 )

          end
          @state.following.push( TOKENS_FOLLOWING_pragma_params_IN_pragma_declaration_887 )
          pragma_params152 = pragma_params
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, pragma_params152.tree )
          end
          __RPAREN153__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_pragma_declaration_889 )
          if @state.backtracking == 0

            tree_for_RPAREN153 = @adaptor.create_with_payload( __RPAREN153__ )
            @adaptor.add_child( root_0, tree_for_RPAREN153 )

          end

        when 8
          # at line 148:5: keyNEW_NAMES LPAREN pragma_params RPAREN
          @state.following.push( TOKENS_FOLLOWING_keyNEW_NAMES_IN_pragma_declaration_895 )
          keyNEW_NAMES154 = keyNEW_NAMES
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyNEW_NAMES154.tree )
          end
          __LPAREN155__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_pragma_declaration_897 )
          if @state.backtracking == 0

            tree_for_LPAREN155 = @adaptor.create_with_payload( __LPAREN155__ )
            @adaptor.add_child( root_0, tree_for_LPAREN155 )

          end
          @state.following.push( TOKENS_FOLLOWING_pragma_params_IN_pragma_declaration_899 )
          pragma_params156 = pragma_params
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, pragma_params156.tree )
          end
          __RPAREN157__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_pragma_declaration_901 )
          if @state.backtracking == 0

            tree_for_RPAREN157 = @adaptor.create_with_payload( __RPAREN157__ )
            @adaptor.add_child( root_0, tree_for_RPAREN157 )

          end

        when 9
          # at line 149:5: keyTIMESTAMP LPAREN pragma_params RPAREN
          @state.following.push( TOKENS_FOLLOWING_keyTIMESTAMP_IN_pragma_declaration_907 )
          keyTIMESTAMP158 = keyTIMESTAMP
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyTIMESTAMP158.tree )
          end
          __LPAREN159__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_pragma_declaration_909 )
          if @state.backtracking == 0

            tree_for_LPAREN159 = @adaptor.create_with_payload( __LPAREN159__ )
            @adaptor.add_child( root_0, tree_for_LPAREN159 )

          end
          @state.following.push( TOKENS_FOLLOWING_pragma_params_IN_pragma_declaration_911 )
          pragma_params160 = pragma_params
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, pragma_params160.tree )
          end
          __RPAREN161__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_pragma_declaration_913 )
          if @state.backtracking == 0

            tree_for_RPAREN161 = @adaptor.create_with_payload( __RPAREN161__ )
            @adaptor.add_child( root_0, tree_for_RPAREN161 )

          end

        end
        __SEMI162__ = match( SEMI, TOKENS_FOLLOWING_SEMI_IN_pragma_declaration_921 )
        if @state.backtracking == 0

          tree_for_SEMI162 = @adaptor.create_with_payload( __SEMI162__ )
          @adaptor.add_child( root_0, tree_for_SEMI162 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 16 )
        memoize( __method__, pragma_declaration_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    PragmaParamsReturnValue = define_return_scope 

    # 
    # parser rule pragma_params
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 154:1: pragma_params : pragma_param ( COMMA pragma_param )* ;
    # 
    def pragma_params
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 17 )
      return_value = PragmaParamsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      pragma_params_start_index = @input.index

      root_0 = nil
      __COMMA164__ = nil
      pragma_param163 = nil
      pragma_param165 = nil

      tree_for_COMMA164 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 155:4: pragma_param ( COMMA pragma_param )*
        @state.following.push( TOKENS_FOLLOWING_pragma_param_IN_pragma_params_932 )
        pragma_param163 = pragma_param
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, pragma_param163.tree )
        end
        # at line 155:17: ( COMMA pragma_param )*
        while true # decision 33
          alt_33 = 2
          look_33_0 = @input.peek( 1 )

          if ( look_33_0 == COMMA )
            alt_33 = 1

          end
          case alt_33
          when 1
            # at line 155:19: COMMA pragma_param
            __COMMA164__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_pragma_params_936 )
            if @state.backtracking == 0

              tree_for_COMMA164 = @adaptor.create_with_payload( __COMMA164__ )
              @adaptor.add_child( root_0, tree_for_COMMA164 )

            end
            @state.following.push( TOKENS_FOLLOWING_pragma_param_IN_pragma_params_938 )
            pragma_param165 = pragma_param
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, pragma_param165.tree )
            end

          else
            break # out of loop for decision 33
          end
        end # loop for decision 33
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 17 )
        memoize( __method__, pragma_params_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    PragmaParamReturnValue = define_return_scope 

    # 
    # parser rule pragma_param
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 158:1: pragma_param : ( ( PLUS | MINUS )? NUMBER | QUOTED_STRING | identifier );
    # 
    def pragma_param
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 18 )
      return_value = PragmaParamReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      pragma_param_start_index = @input.index

      root_0 = nil
      set166 = nil
      __NUMBER167__ = nil
      __QUOTED_STRING168__ = nil
      identifier169 = nil

      tree_for_set166 = nil
      tree_for_NUMBER167 = nil
      tree_for_QUOTED_STRING168 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 159:2: ( ( PLUS | MINUS )? NUMBER | QUOTED_STRING | identifier )
        alt_35 = 3
        case look_35 = @input.peek( 1 )
        when PLUS, MINUS, NUMBER then alt_35 = 1
        when QUOTED_STRING then alt_35 = 2
        when ID, DOUBLEQUOTED_STRING then alt_35 = 3
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 35, 0 )
        end
        case alt_35
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 159:4: ( PLUS | MINUS )? NUMBER
          # at line 159:4: ( PLUS | MINUS )?
          alt_34 = 2
          look_34_0 = @input.peek( 1 )

          if ( look_34_0.between?( PLUS, MINUS ) )
            alt_34 = 1
          end
          case alt_34
          when 1
            # at line 
            set166 = @input.look
            if @input.peek( 1 ).between?( PLUS, MINUS )
              @input.consume
              if @state.backtracking == 0
                @adaptor.add_child( root_0, @adaptor.create_with_payload( set166 ) )
              end
              @state.error_recovery = false
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              mse = MismatchedSet( nil )
              raise mse
            end



          end
          __NUMBER167__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_pragma_param_963 )
          if @state.backtracking == 0

            tree_for_NUMBER167 = @adaptor.create_with_payload( __NUMBER167__ )
            @adaptor.add_child( root_0, tree_for_NUMBER167 )

          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 160:4: QUOTED_STRING
          __QUOTED_STRING168__ = match( QUOTED_STRING, TOKENS_FOLLOWING_QUOTED_STRING_IN_pragma_param_968 )
          if @state.backtracking == 0

            tree_for_QUOTED_STRING168 = @adaptor.create_with_payload( __QUOTED_STRING168__ )
            @adaptor.add_child( root_0, tree_for_QUOTED_STRING168 )

          end

        when 3
          root_0 = @adaptor.create_flat_list


          # at line 161:4: identifier
          @state.following.push( TOKENS_FOLLOWING_identifier_IN_pragma_param_973 )
          identifier169 = identifier
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, identifier169.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 18 )
        memoize( __method__, pragma_param_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    AssignmentStatementReturnValue = define_return_scope 

    # 
    # parser rule assignment_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 164:1: assignment_statement : ( lvalue ASSIGN plsql_expression ) ;
    # 
    def assignment_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 19 )
      return_value = AssignmentStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      assignment_statement_start_index = @input.index

      root_0 = nil
      __ASSIGN171__ = nil
      lvalue170 = nil
      plsql_expression172 = nil

      tree_for_ASSIGN171 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 167:3: ( lvalue ASSIGN plsql_expression )
        # at line 167:3: ( lvalue ASSIGN plsql_expression )
        # at line 167:4: lvalue ASSIGN plsql_expression
        @state.following.push( TOKENS_FOLLOWING_lvalue_IN_assignment_statement_989 )
        lvalue170 = lvalue
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, lvalue170.tree )
        end
        __ASSIGN171__ = match( ASSIGN, TOKENS_FOLLOWING_ASSIGN_IN_assignment_statement_991 )
        if @state.backtracking == 0

          tree_for_ASSIGN171 = @adaptor.create_with_payload( __ASSIGN171__ )
          @adaptor.add_child( root_0, tree_for_ASSIGN171 )

        end
        @state.following.push( TOKENS_FOLLOWING_plsql_expression_IN_assignment_statement_993 )
        plsql_expression172 = plsql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, plsql_expression172.tree )
        end

        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 19 )
        memoize( __method__, assignment_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    LvaluesReturnValue = define_return_scope 

    # 
    # parser rule lvalues
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 170:1: lvalues : lvalue ( COMMA lvalue )* ;
    # 
    def lvalues
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 20 )
      return_value = LvaluesReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      lvalues_start_index = @input.index

      root_0 = nil
      __COMMA174__ = nil
      lvalue173 = nil
      lvalue175 = nil

      tree_for_COMMA174 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 171:4: lvalue ( COMMA lvalue )*
        @state.following.push( TOKENS_FOLLOWING_lvalue_IN_lvalues_1005 )
        lvalue173 = lvalue
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, lvalue173.tree )
        end
        # at line 171:11: ( COMMA lvalue )*
        while true # decision 36
          alt_36 = 2
          look_36_0 = @input.peek( 1 )

          if ( look_36_0 == COMMA )
            alt_36 = 1

          end
          case alt_36
          when 1
            # at line 171:13: COMMA lvalue
            __COMMA174__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_lvalues_1009 )
            if @state.backtracking == 0

              tree_for_COMMA174 = @adaptor.create_with_payload( __COMMA174__ )
              @adaptor.add_child( root_0, tree_for_COMMA174 )

            end
            @state.following.push( TOKENS_FOLLOWING_lvalue_IN_lvalues_1011 )
            lvalue175 = lvalue
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, lvalue175.tree )
            end

          else
            break # out of loop for decision 36
          end
        end # loop for decision 36
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 20 )
        memoize( __method__, lvalues_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    LvalueReturnValue = define_return_scope 

    # 
    # parser rule lvalue
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 173:1: lvalue : ( variable_name | record_name DOT field_name | plsql_table_name LPAREN subscript RPAREN ( DOT field_name )* | COLON host_variable ( COLON host_variable )? );
    # 
    def lvalue
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 21 )
      return_value = LvalueReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      lvalue_start_index = @input.index

      root_0 = nil
      __DOT178__ = nil
      __LPAREN181__ = nil
      __RPAREN183__ = nil
      __DOT184__ = nil
      __COLON186__ = nil
      __COLON188__ = nil
      variable_name176 = nil
      record_name177 = nil
      field_name179 = nil
      plsql_table_name180 = nil
      subscript182 = nil
      field_name185 = nil
      host_variable187 = nil
      host_variable189 = nil

      tree_for_DOT178 = nil
      tree_for_LPAREN181 = nil
      tree_for_RPAREN183 = nil
      tree_for_DOT184 = nil
      tree_for_COLON186 = nil
      tree_for_COLON188 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 174:2: ( variable_name | record_name DOT field_name | plsql_table_name LPAREN subscript RPAREN ( DOT field_name )* | COLON host_variable ( COLON host_variable )? )
        alt_39 = 4
        look_39_0 = @input.peek( 1 )

        if ( look_39_0.between?( ID, DOUBLEQUOTED_STRING ) )
          case look_39 = @input.peek( 2 )
          when DOT then look_39_3 = @input.peek( 3 )

          if ( look_39_3.between?( ID, DOUBLEQUOTED_STRING ) )
            look_39_6 = @input.peek( 4 )

            if ( look_39_6 == DOT || look_39_6 == LPAREN )
              alt_39 = 3
            elsif ( look_39_6 == EOF || look_39_6 == SEMI || look_39_6 == ASSIGN || look_39_6 == COMMA || look_39_6 == T__121 )
              alt_39 = 2
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 39, 6 )
            end
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 39, 3 )
          end
          when EOF, SEMI, ASSIGN, COMMA, T__121 then alt_39 = 1
          when LPAREN then alt_39 = 3
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 39, 1 )
          end
        elsif ( look_39_0 == COLON )
          alt_39 = 4
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 39, 0 )
        end
        case alt_39
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 174:4: variable_name
          @state.following.push( TOKENS_FOLLOWING_variable_name_IN_lvalue_1024 )
          variable_name176 = variable_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, variable_name176.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 175:4: record_name DOT field_name
          @state.following.push( TOKENS_FOLLOWING_record_name_IN_lvalue_1029 )
          record_name177 = record_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, record_name177.tree )
          end
          __DOT178__ = match( DOT, TOKENS_FOLLOWING_DOT_IN_lvalue_1031 )
          if @state.backtracking == 0

            tree_for_DOT178 = @adaptor.create_with_payload( __DOT178__ )
            @adaptor.add_child( root_0, tree_for_DOT178 )

          end
          @state.following.push( TOKENS_FOLLOWING_field_name_IN_lvalue_1033 )
          field_name179 = field_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, field_name179.tree )
          end

        when 3
          root_0 = @adaptor.create_flat_list


          # at line 176:4: plsql_table_name LPAREN subscript RPAREN ( DOT field_name )*
          @state.following.push( TOKENS_FOLLOWING_plsql_table_name_IN_lvalue_1038 )
          plsql_table_name180 = plsql_table_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, plsql_table_name180.tree )
          end
          __LPAREN181__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_lvalue_1040 )
          if @state.backtracking == 0

            tree_for_LPAREN181 = @adaptor.create_with_payload( __LPAREN181__ )
            @adaptor.add_child( root_0, tree_for_LPAREN181 )

          end
          @state.following.push( TOKENS_FOLLOWING_subscript_IN_lvalue_1042 )
          subscript182 = subscript
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, subscript182.tree )
          end
          __RPAREN183__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_lvalue_1044 )
          if @state.backtracking == 0

            tree_for_RPAREN183 = @adaptor.create_with_payload( __RPAREN183__ )
            @adaptor.add_child( root_0, tree_for_RPAREN183 )

          end
          # at line 176:45: ( DOT field_name )*
          while true # decision 37
            alt_37 = 2
            look_37_0 = @input.peek( 1 )

            if ( look_37_0 == DOT )
              alt_37 = 1

            end
            case alt_37
            when 1
              # at line 176:47: DOT field_name
              __DOT184__ = match( DOT, TOKENS_FOLLOWING_DOT_IN_lvalue_1048 )
              if @state.backtracking == 0

                tree_for_DOT184 = @adaptor.create_with_payload( __DOT184__ )
                @adaptor.add_child( root_0, tree_for_DOT184 )

              end
              @state.following.push( TOKENS_FOLLOWING_field_name_IN_lvalue_1050 )
              field_name185 = field_name
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, field_name185.tree )
              end

            else
              break # out of loop for decision 37
            end
          end # loop for decision 37

        when 4
          root_0 = @adaptor.create_flat_list


          # at line 177:4: COLON host_variable ( COLON host_variable )?
          __COLON186__ = match( COLON, TOKENS_FOLLOWING_COLON_IN_lvalue_1058 )
          if @state.backtracking == 0

            tree_for_COLON186 = @adaptor.create_with_payload( __COLON186__ )
            @adaptor.add_child( root_0, tree_for_COLON186 )

          end
          @state.following.push( TOKENS_FOLLOWING_host_variable_IN_lvalue_1060 )
          host_variable187 = host_variable
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, host_variable187.tree )
          end
          # at line 177:24: ( COLON host_variable )?
          alt_38 = 2
          look_38_0 = @input.peek( 1 )

          if ( look_38_0 == COLON )
            alt_38 = 1
          end
          case alt_38
          when 1
            # at line 177:26: COLON host_variable
            __COLON188__ = match( COLON, TOKENS_FOLLOWING_COLON_IN_lvalue_1064 )
            if @state.backtracking == 0

              tree_for_COLON188 = @adaptor.create_with_payload( __COLON188__ )
              @adaptor.add_child( root_0, tree_for_COLON188 )

            end
            @state.following.push( TOKENS_FOLLOWING_host_variable_IN_lvalue_1066 )
            host_variable189 = host_variable
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, host_variable189.tree )
            end

          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 21 )
        memoize( __method__, lvalue_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    FieldNameReturnValue = define_return_scope 

    # 
    # parser rule field_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 180:1: field_name : identifier ;
    # 
    def field_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 22 )
      return_value = FieldNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      field_name_start_index = @input.index

      root_0 = nil
      identifier190 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 181:4: identifier
        @state.following.push( TOKENS_FOLLOWING_identifier_IN_field_name_1080 )
        identifier190 = identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, identifier190.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 22 )
        memoize( __method__, field_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SubscriptReturnValue = define_return_scope 

    # 
    # parser rule subscript
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 184:1: subscript : plsql_expression ;
    # 
    def subscript
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 23 )
      return_value = SubscriptReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      subscript_start_index = @input.index

      root_0 = nil
      plsql_expression191 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 185:4: plsql_expression
        @state.following.push( TOKENS_FOLLOWING_plsql_expression_IN_subscript_1092 )
        plsql_expression191 = plsql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, plsql_expression191.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 23 )
        memoize( __method__, subscript_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    HostVariableReturnValue = define_return_scope 

    # 
    # parser rule host_variable
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 188:1: host_variable : identifier ;
    # 
    def host_variable
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 24 )
      return_value = HostVariableReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      host_variable_start_index = @input.index

      root_0 = nil
      identifier192 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 189:4: identifier
        @state.following.push( TOKENS_FOLLOWING_identifier_IN_host_variable_1105 )
        identifier192 = identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, identifier192.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 24 )
        memoize( __method__, host_variable_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    GotoStatementReturnValue = define_return_scope 

    # 
    # parser rule goto_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 192:1: goto_statement : 'GOTO' label_name ;
    # 
    def goto_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 25 )
      return_value = GotoStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      goto_statement_start_index = @input.index

      root_0 = nil
      string_literal193 = nil
      label_name194 = nil

      tree_for_string_literal193 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 193:4: 'GOTO' label_name
        string_literal193 = match( T__62, TOKENS_FOLLOWING_T__62_IN_goto_statement_1117 )
        if @state.backtracking == 0

          tree_for_string_literal193 = @adaptor.create_with_payload( string_literal193 )
          @adaptor.add_child( root_0, tree_for_string_literal193 )

        end
        @state.following.push( TOKENS_FOLLOWING_label_name_IN_goto_statement_1119 )
        label_name194 = label_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, label_name194.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 25 )
        memoize( __method__, goto_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    LabelNameReturnValue = define_return_scope 

    # 
    # parser rule label_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 196:1: label_name : identifier ;
    # 
    def label_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 26 )
      return_value = LabelNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      label_name_start_index = @input.index

      root_0 = nil
      identifier195 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 197:4: identifier
        @state.following.push( TOKENS_FOLLOWING_identifier_IN_label_name_1131 )
        identifier195 = identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, identifier195.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 26 )
        memoize( __method__, label_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExitStatementReturnValue = define_return_scope 

    # 
    # parser rule exit_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 200:1: exit_statement : keyEXIT ( label_name )? ( 'WHEN' plsql_condition )? ;
    # 
    def exit_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 27 )
      return_value = ExitStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      exit_statement_start_index = @input.index

      root_0 = nil
      string_literal198 = nil
      keyEXIT196 = nil
      label_name197 = nil
      plsql_condition199 = nil

      tree_for_string_literal198 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 201:4: keyEXIT ( label_name )? ( 'WHEN' plsql_condition )?
        @state.following.push( TOKENS_FOLLOWING_keyEXIT_IN_exit_statement_1143 )
        keyEXIT196 = keyEXIT
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyEXIT196.tree )
        end
        # at line 201:12: ( label_name )?
        alt_40 = 2
        look_40_0 = @input.peek( 1 )

        if ( look_40_0.between?( ID, DOUBLEQUOTED_STRING ) )
          alt_40 = 1
        end
        case alt_40
        when 1
          # at line 201:14: label_name
          @state.following.push( TOKENS_FOLLOWING_label_name_IN_exit_statement_1147 )
          label_name197 = label_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, label_name197.tree )
          end

        end
        # at line 201:28: ( 'WHEN' plsql_condition )?
        alt_41 = 2
        look_41_0 = @input.peek( 1 )

        if ( look_41_0 == T__63 )
          alt_41 = 1
        end
        case alt_41
        when 1
          # at line 201:30: 'WHEN' plsql_condition
          string_literal198 = match( T__63, TOKENS_FOLLOWING_T__63_IN_exit_statement_1154 )
          if @state.backtracking == 0

            tree_for_string_literal198 = @adaptor.create_with_payload( string_literal198 )
            @adaptor.add_child( root_0, tree_for_string_literal198 )

          end
          @state.following.push( TOKENS_FOLLOWING_plsql_condition_IN_exit_statement_1156 )
          plsql_condition199 = plsql_condition
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, plsql_condition199.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 27 )
        memoize( __method__, exit_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    DatatypeReturnValue = define_return_scope 

    # 
    # parser rule datatype
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 204:1: datatype : ( 'BINARY_INTEGER' | 'BINARY_FLOAT' | 'BINARY_DOUBLE' | 'NATURAL' | 'POSITIVE' | ( 'NUMBER' | 'NUMERIC' | 'DECIMAL' | 'DEC' ) ( LPAREN NUMBER ( COMMA NUMBER )? RPAREN )? | 'LONG' ( 'RAW' )? ( LPAREN NUMBER RPAREN )? | 'RAW' ( LPAREN NUMBER RPAREN )? | 'BOOLEAN' | 'DATE' | keyINTERVAL keyDAY ( LPAREN NUMBER RPAREN )? 'TO' keySECOND ( LPAREN NUMBER RPAREN )? | keyINTERVAL keyYEAR ( LPAREN NUMBER RPAREN )? 'TO' keyMONTH | ( keyTIME | keyTIMESTAMP ) ( LPAREN NUMBER RPAREN )? ( 'WITH' ( keyLOCAL )? keyTIME keyZONE )? | 'INTEGER' | 'INT' | 'SMALLINT' | 'FLOAT' ( LPAREN NUMBER RPAREN )? | 'REAL' | 'DOUBLE' keyPRECISION | 'CHAR' ( keyVARYING )? ( LPAREN NUMBER ( keyBYTE | 'CHAR' )? RPAREN )? ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )? | 'VARCHAR' ( LPAREN NUMBER ( keyBYTE | 'CHAR' )? RPAREN )? ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )? | 'VARCHAR2' ( LPAREN NUMBER ( keyBYTE | 'CHAR' )? RPAREN )? ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )? | 'CHARACTER' ( keyVARYING )? ( LPAREN NUMBER RPAREN )? | 'NCHAR' ( keyVARYING )? ( LPAREN NUMBER RPAREN )? | 'NVARCHAR' ( LPAREN NUMBER RPAREN )? | 'NVARCHAR2' ( LPAREN NUMBER RPAREN )? | 'NATIONAL' ( 'CHARACTER' | 'CHAR' ) ( keyVARYING )? ( LPAREN NUMBER RPAREN )? | 'MLSLABEL' | 'PLS_INTEGER' | 'BLOB' | 'CLOB' ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )? | 'NCLOB' | 'BFILE' | 'ROWID' | 'UROWID' ( LPAREN NUMBER RPAREN )? );
    # 
    def datatype
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 28 )
      return_value = DatatypeReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      datatype_start_index = @input.index

      root_0 = nil
      string_literal200 = nil
      string_literal201 = nil
      string_literal202 = nil
      string_literal203 = nil
      string_literal204 = nil
      set205 = nil
      __LPAREN206__ = nil
      __NUMBER207__ = nil
      __COMMA208__ = nil
      __NUMBER209__ = nil
      __RPAREN210__ = nil
      string_literal211 = nil
      string_literal212 = nil
      __LPAREN213__ = nil
      __NUMBER214__ = nil
      __RPAREN215__ = nil
      string_literal216 = nil
      __LPAREN217__ = nil
      __NUMBER218__ = nil
      __RPAREN219__ = nil
      string_literal220 = nil
      string_literal221 = nil
      __LPAREN224__ = nil
      __NUMBER225__ = nil
      __RPAREN226__ = nil
      string_literal227 = nil
      __LPAREN229__ = nil
      __NUMBER230__ = nil
      __RPAREN231__ = nil
      __LPAREN234__ = nil
      __NUMBER235__ = nil
      __RPAREN236__ = nil
      string_literal237 = nil
      __LPAREN241__ = nil
      __NUMBER242__ = nil
      __RPAREN243__ = nil
      string_literal244 = nil
      string_literal248 = nil
      string_literal249 = nil
      string_literal250 = nil
      string_literal251 = nil
      __LPAREN252__ = nil
      __NUMBER253__ = nil
      __RPAREN254__ = nil
      string_literal255 = nil
      string_literal256 = nil
      string_literal258 = nil
      __LPAREN260__ = nil
      __NUMBER261__ = nil
      string_literal263 = nil
      __RPAREN264__ = nil
      string_literal265 = nil
      string_literal266 = nil
      __CHARSET_ATTR269__ = nil
      string_literal270 = nil
      __LPAREN271__ = nil
      __NUMBER272__ = nil
      string_literal274 = nil
      __RPAREN275__ = nil
      string_literal276 = nil
      string_literal277 = nil
      __CHARSET_ATTR280__ = nil
      string_literal281 = nil
      __LPAREN282__ = nil
      __NUMBER283__ = nil
      string_literal285 = nil
      __RPAREN286__ = nil
      string_literal287 = nil
      string_literal288 = nil
      __CHARSET_ATTR291__ = nil
      string_literal292 = nil
      __LPAREN294__ = nil
      __NUMBER295__ = nil
      __RPAREN296__ = nil
      string_literal297 = nil
      __LPAREN299__ = nil
      __NUMBER300__ = nil
      __RPAREN301__ = nil
      string_literal302 = nil
      __LPAREN303__ = nil
      __NUMBER304__ = nil
      __RPAREN305__ = nil
      string_literal306 = nil
      __LPAREN307__ = nil
      __NUMBER308__ = nil
      __RPAREN309__ = nil
      string_literal310 = nil
      set311 = nil
      __LPAREN313__ = nil
      __NUMBER314__ = nil
      __RPAREN315__ = nil
      string_literal316 = nil
      string_literal317 = nil
      string_literal318 = nil
      string_literal319 = nil
      string_literal320 = nil
      string_literal321 = nil
      __CHARSET_ATTR324__ = nil
      string_literal325 = nil
      string_literal326 = nil
      string_literal327 = nil
      string_literal328 = nil
      __LPAREN329__ = nil
      __NUMBER330__ = nil
      __RPAREN331__ = nil
      keyINTERVAL222 = nil
      keyDAY223 = nil
      keySECOND228 = nil
      keyINTERVAL232 = nil
      keyYEAR233 = nil
      keyMONTH238 = nil
      keyTIME239 = nil
      keyTIMESTAMP240 = nil
      keyLOCAL245 = nil
      keyTIME246 = nil
      keyZONE247 = nil
      keyPRECISION257 = nil
      keyVARYING259 = nil
      keyBYTE262 = nil
      identifier267 = nil
      column_spec268 = nil
      keyBYTE273 = nil
      identifier278 = nil
      column_spec279 = nil
      keyBYTE284 = nil
      identifier289 = nil
      column_spec290 = nil
      keyVARYING293 = nil
      keyVARYING298 = nil
      keyVARYING312 = nil
      identifier322 = nil
      column_spec323 = nil

      tree_for_string_literal200 = nil
      tree_for_string_literal201 = nil
      tree_for_string_literal202 = nil
      tree_for_string_literal203 = nil
      tree_for_string_literal204 = nil
      tree_for_set205 = nil
      tree_for_LPAREN206 = nil
      tree_for_NUMBER207 = nil
      tree_for_COMMA208 = nil
      tree_for_NUMBER209 = nil
      tree_for_RPAREN210 = nil
      tree_for_string_literal211 = nil
      tree_for_string_literal212 = nil
      tree_for_LPAREN213 = nil
      tree_for_NUMBER214 = nil
      tree_for_RPAREN215 = nil
      tree_for_string_literal216 = nil
      tree_for_LPAREN217 = nil
      tree_for_NUMBER218 = nil
      tree_for_RPAREN219 = nil
      tree_for_string_literal220 = nil
      tree_for_string_literal221 = nil
      tree_for_LPAREN224 = nil
      tree_for_NUMBER225 = nil
      tree_for_RPAREN226 = nil
      tree_for_string_literal227 = nil
      tree_for_LPAREN229 = nil
      tree_for_NUMBER230 = nil
      tree_for_RPAREN231 = nil
      tree_for_LPAREN234 = nil
      tree_for_NUMBER235 = nil
      tree_for_RPAREN236 = nil
      tree_for_string_literal237 = nil
      tree_for_LPAREN241 = nil
      tree_for_NUMBER242 = nil
      tree_for_RPAREN243 = nil
      tree_for_string_literal244 = nil
      tree_for_string_literal248 = nil
      tree_for_string_literal249 = nil
      tree_for_string_literal250 = nil
      tree_for_string_literal251 = nil
      tree_for_LPAREN252 = nil
      tree_for_NUMBER253 = nil
      tree_for_RPAREN254 = nil
      tree_for_string_literal255 = nil
      tree_for_string_literal256 = nil
      tree_for_string_literal258 = nil
      tree_for_LPAREN260 = nil
      tree_for_NUMBER261 = nil
      tree_for_string_literal263 = nil
      tree_for_RPAREN264 = nil
      tree_for_string_literal265 = nil
      tree_for_string_literal266 = nil
      tree_for_CHARSET_ATTR269 = nil
      tree_for_string_literal270 = nil
      tree_for_LPAREN271 = nil
      tree_for_NUMBER272 = nil
      tree_for_string_literal274 = nil
      tree_for_RPAREN275 = nil
      tree_for_string_literal276 = nil
      tree_for_string_literal277 = nil
      tree_for_CHARSET_ATTR280 = nil
      tree_for_string_literal281 = nil
      tree_for_LPAREN282 = nil
      tree_for_NUMBER283 = nil
      tree_for_string_literal285 = nil
      tree_for_RPAREN286 = nil
      tree_for_string_literal287 = nil
      tree_for_string_literal288 = nil
      tree_for_CHARSET_ATTR291 = nil
      tree_for_string_literal292 = nil
      tree_for_LPAREN294 = nil
      tree_for_NUMBER295 = nil
      tree_for_RPAREN296 = nil
      tree_for_string_literal297 = nil
      tree_for_LPAREN299 = nil
      tree_for_NUMBER300 = nil
      tree_for_RPAREN301 = nil
      tree_for_string_literal302 = nil
      tree_for_LPAREN303 = nil
      tree_for_NUMBER304 = nil
      tree_for_RPAREN305 = nil
      tree_for_string_literal306 = nil
      tree_for_LPAREN307 = nil
      tree_for_NUMBER308 = nil
      tree_for_RPAREN309 = nil
      tree_for_string_literal310 = nil
      tree_for_set311 = nil
      tree_for_LPAREN313 = nil
      tree_for_NUMBER314 = nil
      tree_for_RPAREN315 = nil
      tree_for_string_literal316 = nil
      tree_for_string_literal317 = nil
      tree_for_string_literal318 = nil
      tree_for_string_literal319 = nil
      tree_for_string_literal320 = nil
      tree_for_string_literal321 = nil
      tree_for_CHARSET_ATTR324 = nil
      tree_for_string_literal325 = nil
      tree_for_string_literal326 = nil
      tree_for_string_literal327 = nil
      tree_for_string_literal328 = nil
      tree_for_LPAREN329 = nil
      tree_for_NUMBER330 = nil
      tree_for_RPAREN331 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 205:2: ( 'BINARY_INTEGER' | 'BINARY_FLOAT' | 'BINARY_DOUBLE' | 'NATURAL' | 'POSITIVE' | ( 'NUMBER' | 'NUMERIC' | 'DECIMAL' | 'DEC' ) ( LPAREN NUMBER ( COMMA NUMBER )? RPAREN )? | 'LONG' ( 'RAW' )? ( LPAREN NUMBER RPAREN )? | 'RAW' ( LPAREN NUMBER RPAREN )? | 'BOOLEAN' | 'DATE' | keyINTERVAL keyDAY ( LPAREN NUMBER RPAREN )? 'TO' keySECOND ( LPAREN NUMBER RPAREN )? | keyINTERVAL keyYEAR ( LPAREN NUMBER RPAREN )? 'TO' keyMONTH | ( keyTIME | keyTIMESTAMP ) ( LPAREN NUMBER RPAREN )? ( 'WITH' ( keyLOCAL )? keyTIME keyZONE )? | 'INTEGER' | 'INT' | 'SMALLINT' | 'FLOAT' ( LPAREN NUMBER RPAREN )? | 'REAL' | 'DOUBLE' keyPRECISION | 'CHAR' ( keyVARYING )? ( LPAREN NUMBER ( keyBYTE | 'CHAR' )? RPAREN )? ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )? | 'VARCHAR' ( LPAREN NUMBER ( keyBYTE | 'CHAR' )? RPAREN )? ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )? | 'VARCHAR2' ( LPAREN NUMBER ( keyBYTE | 'CHAR' )? RPAREN )? ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )? | 'CHARACTER' ( keyVARYING )? ( LPAREN NUMBER RPAREN )? | 'NCHAR' ( keyVARYING )? ( LPAREN NUMBER RPAREN )? | 'NVARCHAR' ( LPAREN NUMBER RPAREN )? | 'NVARCHAR2' ( LPAREN NUMBER RPAREN )? | 'NATIONAL' ( 'CHARACTER' | 'CHAR' ) ( keyVARYING )? ( LPAREN NUMBER RPAREN )? | 'MLSLABEL' | 'PLS_INTEGER' | 'BLOB' | 'CLOB' ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )? | 'NCLOB' | 'BFILE' | 'ROWID' | 'UROWID' ( LPAREN NUMBER RPAREN )? )
        alt_79 = 35
        alt_79 = @dfa79.predict( @input )
        case alt_79
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 205:4: 'BINARY_INTEGER'
          string_literal200 = match( T__64, TOKENS_FOLLOWING_T__64_IN_datatype_1171 )
          if @state.backtracking == 0

            tree_for_string_literal200 = @adaptor.create_with_payload( string_literal200 )
            @adaptor.add_child( root_0, tree_for_string_literal200 )

          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 206:4: 'BINARY_FLOAT'
          string_literal201 = match( T__65, TOKENS_FOLLOWING_T__65_IN_datatype_1177 )
          if @state.backtracking == 0

            tree_for_string_literal201 = @adaptor.create_with_payload( string_literal201 )
            @adaptor.add_child( root_0, tree_for_string_literal201 )

          end

        when 3
          root_0 = @adaptor.create_flat_list


          # at line 207:4: 'BINARY_DOUBLE'
          string_literal202 = match( T__66, TOKENS_FOLLOWING_T__66_IN_datatype_1182 )
          if @state.backtracking == 0

            tree_for_string_literal202 = @adaptor.create_with_payload( string_literal202 )
            @adaptor.add_child( root_0, tree_for_string_literal202 )

          end

        when 4
          root_0 = @adaptor.create_flat_list


          # at line 208:4: 'NATURAL'
          string_literal203 = match( T__67, TOKENS_FOLLOWING_T__67_IN_datatype_1187 )
          if @state.backtracking == 0

            tree_for_string_literal203 = @adaptor.create_with_payload( string_literal203 )
            @adaptor.add_child( root_0, tree_for_string_literal203 )

          end

        when 5
          root_0 = @adaptor.create_flat_list


          # at line 209:4: 'POSITIVE'
          string_literal204 = match( T__68, TOKENS_FOLLOWING_T__68_IN_datatype_1193 )
          if @state.backtracking == 0

            tree_for_string_literal204 = @adaptor.create_with_payload( string_literal204 )
            @adaptor.add_child( root_0, tree_for_string_literal204 )

          end

        when 6
          root_0 = @adaptor.create_flat_list


          # at line 210:4: ( 'NUMBER' | 'NUMERIC' | 'DECIMAL' | 'DEC' ) ( LPAREN NUMBER ( COMMA NUMBER )? RPAREN )?
          set205 = @input.look
          if @input.peek( 1 ).between?( T__69, T__72 )
            @input.consume
            if @state.backtracking == 0
              @adaptor.add_child( root_0, @adaptor.create_with_payload( set205 ) )
            end
            @state.error_recovery = false
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            mse = MismatchedSet( nil )
            raise mse
          end


          # at line 210:49: ( LPAREN NUMBER ( COMMA NUMBER )? RPAREN )?
          alt_43 = 2
          look_43_0 = @input.peek( 1 )

          if ( look_43_0 == LPAREN )
            alt_43 = 1
          end
          case alt_43
          when 1
            # at line 210:51: LPAREN NUMBER ( COMMA NUMBER )? RPAREN
            __LPAREN206__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_datatype_1219 )
            if @state.backtracking == 0

              tree_for_LPAREN206 = @adaptor.create_with_payload( __LPAREN206__ )
              @adaptor.add_child( root_0, tree_for_LPAREN206 )

            end
            __NUMBER207__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_datatype_1221 )
            if @state.backtracking == 0

              tree_for_NUMBER207 = @adaptor.create_with_payload( __NUMBER207__ )
              @adaptor.add_child( root_0, tree_for_NUMBER207 )

            end
            # at line 210:65: ( COMMA NUMBER )?
            alt_42 = 2
            look_42_0 = @input.peek( 1 )

            if ( look_42_0 == COMMA )
              alt_42 = 1
            end
            case alt_42
            when 1
              # at line 210:67: COMMA NUMBER
              __COMMA208__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_datatype_1225 )
              if @state.backtracking == 0

                tree_for_COMMA208 = @adaptor.create_with_payload( __COMMA208__ )
                @adaptor.add_child( root_0, tree_for_COMMA208 )

              end
              __NUMBER209__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_datatype_1227 )
              if @state.backtracking == 0

                tree_for_NUMBER209 = @adaptor.create_with_payload( __NUMBER209__ )
                @adaptor.add_child( root_0, tree_for_NUMBER209 )

              end

            end
            __RPAREN210__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_datatype_1232 )
            if @state.backtracking == 0

              tree_for_RPAREN210 = @adaptor.create_with_payload( __RPAREN210__ )
              @adaptor.add_child( root_0, tree_for_RPAREN210 )

            end

          end

        when 7
          root_0 = @adaptor.create_flat_list


          # at line 211:4: 'LONG' ( 'RAW' )? ( LPAREN NUMBER RPAREN )?
          string_literal211 = match( T__73, TOKENS_FOLLOWING_T__73_IN_datatype_1240 )
          if @state.backtracking == 0

            tree_for_string_literal211 = @adaptor.create_with_payload( string_literal211 )
            @adaptor.add_child( root_0, tree_for_string_literal211 )

          end
          # at line 211:11: ( 'RAW' )?
          alt_44 = 2
          look_44_0 = @input.peek( 1 )

          if ( look_44_0 == T__74 )
            alt_44 = 1
          end
          case alt_44
          when 1
            # at line 211:13: 'RAW'
            string_literal212 = match( T__74, TOKENS_FOLLOWING_T__74_IN_datatype_1244 )
            if @state.backtracking == 0

              tree_for_string_literal212 = @adaptor.create_with_payload( string_literal212 )
              @adaptor.add_child( root_0, tree_for_string_literal212 )

            end

          end
          # at line 211:21: ( LPAREN NUMBER RPAREN )?
          alt_45 = 2
          look_45_0 = @input.peek( 1 )

          if ( look_45_0 == LPAREN )
            alt_45 = 1
          end
          case alt_45
          when 1
            # at line 211:23: LPAREN NUMBER RPAREN
            __LPAREN213__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_datatype_1250 )
            if @state.backtracking == 0

              tree_for_LPAREN213 = @adaptor.create_with_payload( __LPAREN213__ )
              @adaptor.add_child( root_0, tree_for_LPAREN213 )

            end
            __NUMBER214__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_datatype_1252 )
            if @state.backtracking == 0

              tree_for_NUMBER214 = @adaptor.create_with_payload( __NUMBER214__ )
              @adaptor.add_child( root_0, tree_for_NUMBER214 )

            end
            __RPAREN215__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_datatype_1254 )
            if @state.backtracking == 0

              tree_for_RPAREN215 = @adaptor.create_with_payload( __RPAREN215__ )
              @adaptor.add_child( root_0, tree_for_RPAREN215 )

            end

          end

        when 8
          root_0 = @adaptor.create_flat_list


          # at line 212:4: 'RAW' ( LPAREN NUMBER RPAREN )?
          string_literal216 = match( T__74, TOKENS_FOLLOWING_T__74_IN_datatype_1262 )
          if @state.backtracking == 0

            tree_for_string_literal216 = @adaptor.create_with_payload( string_literal216 )
            @adaptor.add_child( root_0, tree_for_string_literal216 )

          end
          # at line 212:10: ( LPAREN NUMBER RPAREN )?
          alt_46 = 2
          look_46_0 = @input.peek( 1 )

          if ( look_46_0 == LPAREN )
            alt_46 = 1
          end
          case alt_46
          when 1
            # at line 212:12: LPAREN NUMBER RPAREN
            __LPAREN217__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_datatype_1266 )
            if @state.backtracking == 0

              tree_for_LPAREN217 = @adaptor.create_with_payload( __LPAREN217__ )
              @adaptor.add_child( root_0, tree_for_LPAREN217 )

            end
            __NUMBER218__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_datatype_1268 )
            if @state.backtracking == 0

              tree_for_NUMBER218 = @adaptor.create_with_payload( __NUMBER218__ )
              @adaptor.add_child( root_0, tree_for_NUMBER218 )

            end
            __RPAREN219__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_datatype_1270 )
            if @state.backtracking == 0

              tree_for_RPAREN219 = @adaptor.create_with_payload( __RPAREN219__ )
              @adaptor.add_child( root_0, tree_for_RPAREN219 )

            end

          end

        when 9
          root_0 = @adaptor.create_flat_list


          # at line 213:4: 'BOOLEAN'
          string_literal220 = match( T__75, TOKENS_FOLLOWING_T__75_IN_datatype_1278 )
          if @state.backtracking == 0

            tree_for_string_literal220 = @adaptor.create_with_payload( string_literal220 )
            @adaptor.add_child( root_0, tree_for_string_literal220 )

          end

        when 10
          root_0 = @adaptor.create_flat_list


          # at line 214:4: 'DATE'
          string_literal221 = match( T__76, TOKENS_FOLLOWING_T__76_IN_datatype_1283 )
          if @state.backtracking == 0

            tree_for_string_literal221 = @adaptor.create_with_payload( string_literal221 )
            @adaptor.add_child( root_0, tree_for_string_literal221 )

          end

        when 11
          root_0 = @adaptor.create_flat_list


          # at line 215:4: keyINTERVAL keyDAY ( LPAREN NUMBER RPAREN )? 'TO' keySECOND ( LPAREN NUMBER RPAREN )?
          @state.following.push( TOKENS_FOLLOWING_keyINTERVAL_IN_datatype_1288 )
          keyINTERVAL222 = keyINTERVAL
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyINTERVAL222.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_keyDAY_IN_datatype_1290 )
          keyDAY223 = keyDAY
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyDAY223.tree )
          end
          # at line 215:23: ( LPAREN NUMBER RPAREN )?
          alt_47 = 2
          look_47_0 = @input.peek( 1 )

          if ( look_47_0 == LPAREN )
            alt_47 = 1
          end
          case alt_47
          when 1
            # at line 215:25: LPAREN NUMBER RPAREN
            __LPAREN224__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_datatype_1294 )
            if @state.backtracking == 0

              tree_for_LPAREN224 = @adaptor.create_with_payload( __LPAREN224__ )
              @adaptor.add_child( root_0, tree_for_LPAREN224 )

            end
            __NUMBER225__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_datatype_1296 )
            if @state.backtracking == 0

              tree_for_NUMBER225 = @adaptor.create_with_payload( __NUMBER225__ )
              @adaptor.add_child( root_0, tree_for_NUMBER225 )

            end
            __RPAREN226__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_datatype_1298 )
            if @state.backtracking == 0

              tree_for_RPAREN226 = @adaptor.create_with_payload( __RPAREN226__ )
              @adaptor.add_child( root_0, tree_for_RPAREN226 )

            end

          end
          string_literal227 = match( T__77, TOKENS_FOLLOWING_T__77_IN_datatype_1303 )
          if @state.backtracking == 0

            tree_for_string_literal227 = @adaptor.create_with_payload( string_literal227 )
            @adaptor.add_child( root_0, tree_for_string_literal227 )

          end
          @state.following.push( TOKENS_FOLLOWING_keySECOND_IN_datatype_1305 )
          keySECOND228 = keySECOND
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keySECOND228.tree )
          end
          # at line 215:64: ( LPAREN NUMBER RPAREN )?
          alt_48 = 2
          look_48_0 = @input.peek( 1 )

          if ( look_48_0 == LPAREN )
            alt_48 = 1
          end
          case alt_48
          when 1
            # at line 215:66: LPAREN NUMBER RPAREN
            __LPAREN229__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_datatype_1309 )
            if @state.backtracking == 0

              tree_for_LPAREN229 = @adaptor.create_with_payload( __LPAREN229__ )
              @adaptor.add_child( root_0, tree_for_LPAREN229 )

            end
            __NUMBER230__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_datatype_1311 )
            if @state.backtracking == 0

              tree_for_NUMBER230 = @adaptor.create_with_payload( __NUMBER230__ )
              @adaptor.add_child( root_0, tree_for_NUMBER230 )

            end
            __RPAREN231__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_datatype_1313 )
            if @state.backtracking == 0

              tree_for_RPAREN231 = @adaptor.create_with_payload( __RPAREN231__ )
              @adaptor.add_child( root_0, tree_for_RPAREN231 )

            end

          end

        when 12
          root_0 = @adaptor.create_flat_list


          # at line 216:4: keyINTERVAL keyYEAR ( LPAREN NUMBER RPAREN )? 'TO' keyMONTH
          @state.following.push( TOKENS_FOLLOWING_keyINTERVAL_IN_datatype_1321 )
          keyINTERVAL232 = keyINTERVAL
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyINTERVAL232.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_keyYEAR_IN_datatype_1323 )
          keyYEAR233 = keyYEAR
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyYEAR233.tree )
          end
          # at line 216:24: ( LPAREN NUMBER RPAREN )?
          alt_49 = 2
          look_49_0 = @input.peek( 1 )

          if ( look_49_0 == LPAREN )
            alt_49 = 1
          end
          case alt_49
          when 1
            # at line 216:26: LPAREN NUMBER RPAREN
            __LPAREN234__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_datatype_1327 )
            if @state.backtracking == 0

              tree_for_LPAREN234 = @adaptor.create_with_payload( __LPAREN234__ )
              @adaptor.add_child( root_0, tree_for_LPAREN234 )

            end
            __NUMBER235__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_datatype_1329 )
            if @state.backtracking == 0

              tree_for_NUMBER235 = @adaptor.create_with_payload( __NUMBER235__ )
              @adaptor.add_child( root_0, tree_for_NUMBER235 )

            end
            __RPAREN236__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_datatype_1331 )
            if @state.backtracking == 0

              tree_for_RPAREN236 = @adaptor.create_with_payload( __RPAREN236__ )
              @adaptor.add_child( root_0, tree_for_RPAREN236 )

            end

          end
          string_literal237 = match( T__77, TOKENS_FOLLOWING_T__77_IN_datatype_1336 )
          if @state.backtracking == 0

            tree_for_string_literal237 = @adaptor.create_with_payload( string_literal237 )
            @adaptor.add_child( root_0, tree_for_string_literal237 )

          end
          @state.following.push( TOKENS_FOLLOWING_keyMONTH_IN_datatype_1338 )
          keyMONTH238 = keyMONTH
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyMONTH238.tree )
          end

        when 13
          root_0 = @adaptor.create_flat_list


          # at line 217:4: ( keyTIME | keyTIMESTAMP ) ( LPAREN NUMBER RPAREN )? ( 'WITH' ( keyLOCAL )? keyTIME keyZONE )?
          # at line 217:4: ( keyTIME | keyTIMESTAMP )
          alt_50 = 2
          look_50_0 = @input.peek( 1 )

          if ( look_50_0 == ID )
            look_50_1 = @input.peek( 2 )

            if ( ( syntactic_predicate?( :synpred117_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("TIME") ) ) )
              alt_50 = 1
            elsif ( ( self.input.look(1).text.upcase == ("TIMESTAMP") ) )
              alt_50 = 2
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 50, 1 )
            end
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 50, 0 )
          end
          case alt_50
          when 1
            # at line 217:6: keyTIME
            @state.following.push( TOKENS_FOLLOWING_keyTIME_IN_datatype_1345 )
            keyTIME239 = keyTIME
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyTIME239.tree )
            end

          when 2
            # at line 217:16: keyTIMESTAMP
            @state.following.push( TOKENS_FOLLOWING_keyTIMESTAMP_IN_datatype_1349 )
            keyTIMESTAMP240 = keyTIMESTAMP
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyTIMESTAMP240.tree )
            end

          end
          # at line 217:31: ( LPAREN NUMBER RPAREN )?
          alt_51 = 2
          look_51_0 = @input.peek( 1 )

          if ( look_51_0 == LPAREN )
            alt_51 = 1
          end
          case alt_51
          when 1
            # at line 217:33: LPAREN NUMBER RPAREN
            __LPAREN241__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_datatype_1355 )
            if @state.backtracking == 0

              tree_for_LPAREN241 = @adaptor.create_with_payload( __LPAREN241__ )
              @adaptor.add_child( root_0, tree_for_LPAREN241 )

            end
            __NUMBER242__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_datatype_1357 )
            if @state.backtracking == 0

              tree_for_NUMBER242 = @adaptor.create_with_payload( __NUMBER242__ )
              @adaptor.add_child( root_0, tree_for_NUMBER242 )

            end
            __RPAREN243__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_datatype_1359 )
            if @state.backtracking == 0

              tree_for_RPAREN243 = @adaptor.create_with_payload( __RPAREN243__ )
              @adaptor.add_child( root_0, tree_for_RPAREN243 )

            end

          end
          # at line 217:57: ( 'WITH' ( keyLOCAL )? keyTIME keyZONE )?
          alt_53 = 2
          look_53_0 = @input.peek( 1 )

          if ( look_53_0 == T__78 )
            alt_53 = 1
          end
          case alt_53
          when 1
            # at line 217:59: 'WITH' ( keyLOCAL )? keyTIME keyZONE
            string_literal244 = match( T__78, TOKENS_FOLLOWING_T__78_IN_datatype_1366 )
            if @state.backtracking == 0

              tree_for_string_literal244 = @adaptor.create_with_payload( string_literal244 )
              @adaptor.add_child( root_0, tree_for_string_literal244 )

            end
            # at line 217:66: ( keyLOCAL )?
            alt_52 = 2
            alt_52 = @dfa52.predict( @input )
            case alt_52
            when 1
              # at line 217:68: keyLOCAL
              @state.following.push( TOKENS_FOLLOWING_keyLOCAL_IN_datatype_1370 )
              keyLOCAL245 = keyLOCAL
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, keyLOCAL245.tree )
              end

            end
            @state.following.push( TOKENS_FOLLOWING_keyTIME_IN_datatype_1375 )
            keyTIME246 = keyTIME
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyTIME246.tree )
            end
            @state.following.push( TOKENS_FOLLOWING_keyZONE_IN_datatype_1377 )
            keyZONE247 = keyZONE
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyZONE247.tree )
            end

          end

        when 14
          root_0 = @adaptor.create_flat_list


          # at line 218:4: 'INTEGER'
          string_literal248 = match( T__79, TOKENS_FOLLOWING_T__79_IN_datatype_1384 )
          if @state.backtracking == 0

            tree_for_string_literal248 = @adaptor.create_with_payload( string_literal248 )
            @adaptor.add_child( root_0, tree_for_string_literal248 )

          end

        when 15
          root_0 = @adaptor.create_flat_list


          # at line 219:4: 'INT'
          string_literal249 = match( T__80, TOKENS_FOLLOWING_T__80_IN_datatype_1389 )
          if @state.backtracking == 0

            tree_for_string_literal249 = @adaptor.create_with_payload( string_literal249 )
            @adaptor.add_child( root_0, tree_for_string_literal249 )

          end

        when 16
          root_0 = @adaptor.create_flat_list


          # at line 220:4: 'SMALLINT'
          string_literal250 = match( T__81, TOKENS_FOLLOWING_T__81_IN_datatype_1394 )
          if @state.backtracking == 0

            tree_for_string_literal250 = @adaptor.create_with_payload( string_literal250 )
            @adaptor.add_child( root_0, tree_for_string_literal250 )

          end

        when 17
          root_0 = @adaptor.create_flat_list


          # at line 221:4: 'FLOAT' ( LPAREN NUMBER RPAREN )?
          string_literal251 = match( T__82, TOKENS_FOLLOWING_T__82_IN_datatype_1399 )
          if @state.backtracking == 0

            tree_for_string_literal251 = @adaptor.create_with_payload( string_literal251 )
            @adaptor.add_child( root_0, tree_for_string_literal251 )

          end
          # at line 221:12: ( LPAREN NUMBER RPAREN )?
          alt_54 = 2
          look_54_0 = @input.peek( 1 )

          if ( look_54_0 == LPAREN )
            alt_54 = 1
          end
          case alt_54
          when 1
            # at line 221:14: LPAREN NUMBER RPAREN
            __LPAREN252__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_datatype_1403 )
            if @state.backtracking == 0

              tree_for_LPAREN252 = @adaptor.create_with_payload( __LPAREN252__ )
              @adaptor.add_child( root_0, tree_for_LPAREN252 )

            end
            __NUMBER253__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_datatype_1405 )
            if @state.backtracking == 0

              tree_for_NUMBER253 = @adaptor.create_with_payload( __NUMBER253__ )
              @adaptor.add_child( root_0, tree_for_NUMBER253 )

            end
            __RPAREN254__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_datatype_1407 )
            if @state.backtracking == 0

              tree_for_RPAREN254 = @adaptor.create_with_payload( __RPAREN254__ )
              @adaptor.add_child( root_0, tree_for_RPAREN254 )

            end

          end

        when 18
          root_0 = @adaptor.create_flat_list


          # at line 222:4: 'REAL'
          string_literal255 = match( T__83, TOKENS_FOLLOWING_T__83_IN_datatype_1415 )
          if @state.backtracking == 0

            tree_for_string_literal255 = @adaptor.create_with_payload( string_literal255 )
            @adaptor.add_child( root_0, tree_for_string_literal255 )

          end

        when 19
          root_0 = @adaptor.create_flat_list


          # at line 223:4: 'DOUBLE' keyPRECISION
          string_literal256 = match( T__84, TOKENS_FOLLOWING_T__84_IN_datatype_1420 )
          if @state.backtracking == 0

            tree_for_string_literal256 = @adaptor.create_with_payload( string_literal256 )
            @adaptor.add_child( root_0, tree_for_string_literal256 )

          end
          @state.following.push( TOKENS_FOLLOWING_keyPRECISION_IN_datatype_1422 )
          keyPRECISION257 = keyPRECISION
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyPRECISION257.tree )
          end

        when 20
          root_0 = @adaptor.create_flat_list


          # at line 224:4: 'CHAR' ( keyVARYING )? ( LPAREN NUMBER ( keyBYTE | 'CHAR' )? RPAREN )? ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )?
          string_literal258 = match( T__85, TOKENS_FOLLOWING_T__85_IN_datatype_1427 )
          if @state.backtracking == 0

            tree_for_string_literal258 = @adaptor.create_with_payload( string_literal258 )
            @adaptor.add_child( root_0, tree_for_string_literal258 )

          end
          # at line 224:16: ( keyVARYING )?
          alt_55 = 2
          alt_55 = @dfa55.predict( @input )
          case alt_55
          when 1
            # at line 224:18: keyVARYING
            @state.following.push( TOKENS_FOLLOWING_keyVARYING_IN_datatype_1436 )
            keyVARYING259 = keyVARYING
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyVARYING259.tree )
            end

          end
          # at line 224:32: ( LPAREN NUMBER ( keyBYTE | 'CHAR' )? RPAREN )?
          alt_57 = 2
          look_57_0 = @input.peek( 1 )

          if ( look_57_0 == LPAREN )
            alt_57 = 1
          end
          case alt_57
          when 1
            # at line 224:34: LPAREN NUMBER ( keyBYTE | 'CHAR' )? RPAREN
            __LPAREN260__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_datatype_1443 )
            if @state.backtracking == 0

              tree_for_LPAREN260 = @adaptor.create_with_payload( __LPAREN260__ )
              @adaptor.add_child( root_0, tree_for_LPAREN260 )

            end
            __NUMBER261__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_datatype_1445 )
            if @state.backtracking == 0

              tree_for_NUMBER261 = @adaptor.create_with_payload( __NUMBER261__ )
              @adaptor.add_child( root_0, tree_for_NUMBER261 )

            end
            # at line 224:48: ( keyBYTE | 'CHAR' )?
            alt_56 = 3
            look_56_0 = @input.peek( 1 )

            if ( look_56_0 == ID )
              alt_56 = 1
            elsif ( look_56_0 == T__85 )
              alt_56 = 2
            end
            case alt_56
            when 1
              # at line 224:50: keyBYTE
              @state.following.push( TOKENS_FOLLOWING_keyBYTE_IN_datatype_1449 )
              keyBYTE262 = keyBYTE
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, keyBYTE262.tree )
              end

            when 2
              # at line 224:60: 'CHAR'
              string_literal263 = match( T__85, TOKENS_FOLLOWING_T__85_IN_datatype_1453 )
              if @state.backtracking == 0

                tree_for_string_literal263 = @adaptor.create_with_payload( string_literal263 )
                @adaptor.add_child( root_0, tree_for_string_literal263 )

              end

            end
            __RPAREN264__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_datatype_1458 )
            if @state.backtracking == 0

              tree_for_RPAREN264 = @adaptor.create_with_payload( __RPAREN264__ )
              @adaptor.add_child( root_0, tree_for_RPAREN264 )

            end

          end
          # at line 224:80: ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )?
          alt_59 = 2
          look_59_0 = @input.peek( 1 )

          if ( look_59_0 == T__86 )
            alt_59 = 1
          end
          case alt_59
          when 1
            # at line 224:82: 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR )
            string_literal265 = match( T__86, TOKENS_FOLLOWING_T__86_IN_datatype_1465 )
            if @state.backtracking == 0

              tree_for_string_literal265 = @adaptor.create_with_payload( string_literal265 )
              @adaptor.add_child( root_0, tree_for_string_literal265 )

            end
            string_literal266 = match( T__87, TOKENS_FOLLOWING_T__87_IN_datatype_1467 )
            if @state.backtracking == 0

              tree_for_string_literal266 = @adaptor.create_with_payload( string_literal266 )
              @adaptor.add_child( root_0, tree_for_string_literal266 )

            end
            # at line 224:100: ( identifier | column_spec CHARSET_ATTR )
            alt_58 = 2
            look_58_0 = @input.peek( 1 )

            if ( look_58_0.between?( ID, DOUBLEQUOTED_STRING ) )
              look_58_1 = @input.peek( 2 )

              if ( look_58_1 == EOF || look_58_1 == SEMI || look_58_1 == ASSIGN || look_58_1 == RPAREN || look_58_1 == COMMA || look_58_1.between?( ID, DOUBLEQUOTED_STRING ) || look_58_1 == T__50 || look_58_1.between?( T__52, T__55 ) || look_58_1 == T__57 || look_58_1 == T__59 || look_58_1.between?( T__103, T__104 ) || look_58_1 == T__107 || look_58_1 == T__161 )
                alt_58 = 1
              elsif ( look_58_1 == DOT || look_58_1 == CHARSET_ATTR )
                alt_58 = 2
              else
                @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

                raise NoViableAlternative( "", 58, 1 )
              end
            elsif ( look_58_0 == T__100 )
              alt_58 = 2
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 58, 0 )
            end
            case alt_58
            when 1
              # at line 224:102: identifier
              @state.following.push( TOKENS_FOLLOWING_identifier_IN_datatype_1471 )
              identifier267 = identifier
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, identifier267.tree )
              end

            when 2
              # at line 224:115: column_spec CHARSET_ATTR
              @state.following.push( TOKENS_FOLLOWING_column_spec_IN_datatype_1475 )
              column_spec268 = column_spec
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, column_spec268.tree )
              end
              __CHARSET_ATTR269__ = match( CHARSET_ATTR, TOKENS_FOLLOWING_CHARSET_ATTR_IN_datatype_1477 )
              if @state.backtracking == 0

                tree_for_CHARSET_ATTR269 = @adaptor.create_with_payload( __CHARSET_ATTR269__ )
                @adaptor.add_child( root_0, tree_for_CHARSET_ATTR269 )

              end

            end

          end

        when 21
          root_0 = @adaptor.create_flat_list


          # at line 225:4: 'VARCHAR' ( LPAREN NUMBER ( keyBYTE | 'CHAR' )? RPAREN )? ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )?
          string_literal270 = match( T__88, TOKENS_FOLLOWING_T__88_IN_datatype_1487 )
          if @state.backtracking == 0

            tree_for_string_literal270 = @adaptor.create_with_payload( string_literal270 )
            @adaptor.add_child( root_0, tree_for_string_literal270 )

          end
          # at line 225:32: ( LPAREN NUMBER ( keyBYTE | 'CHAR' )? RPAREN )?
          alt_61 = 2
          look_61_0 = @input.peek( 1 )

          if ( look_61_0 == LPAREN )
            alt_61 = 1
          end
          case alt_61
          when 1
            # at line 225:34: LPAREN NUMBER ( keyBYTE | 'CHAR' )? RPAREN
            __LPAREN271__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_datatype_1509 )
            if @state.backtracking == 0

              tree_for_LPAREN271 = @adaptor.create_with_payload( __LPAREN271__ )
              @adaptor.add_child( root_0, tree_for_LPAREN271 )

            end
            __NUMBER272__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_datatype_1511 )
            if @state.backtracking == 0

              tree_for_NUMBER272 = @adaptor.create_with_payload( __NUMBER272__ )
              @adaptor.add_child( root_0, tree_for_NUMBER272 )

            end
            # at line 225:48: ( keyBYTE | 'CHAR' )?
            alt_60 = 3
            look_60_0 = @input.peek( 1 )

            if ( look_60_0 == ID )
              alt_60 = 1
            elsif ( look_60_0 == T__85 )
              alt_60 = 2
            end
            case alt_60
            when 1
              # at line 225:50: keyBYTE
              @state.following.push( TOKENS_FOLLOWING_keyBYTE_IN_datatype_1515 )
              keyBYTE273 = keyBYTE
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, keyBYTE273.tree )
              end

            when 2
              # at line 225:60: 'CHAR'
              string_literal274 = match( T__85, TOKENS_FOLLOWING_T__85_IN_datatype_1519 )
              if @state.backtracking == 0

                tree_for_string_literal274 = @adaptor.create_with_payload( string_literal274 )
                @adaptor.add_child( root_0, tree_for_string_literal274 )

              end

            end
            __RPAREN275__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_datatype_1524 )
            if @state.backtracking == 0

              tree_for_RPAREN275 = @adaptor.create_with_payload( __RPAREN275__ )
              @adaptor.add_child( root_0, tree_for_RPAREN275 )

            end

          end
          # at line 225:80: ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )?
          alt_63 = 2
          look_63_0 = @input.peek( 1 )

          if ( look_63_0 == T__86 )
            alt_63 = 1
          end
          case alt_63
          when 1
            # at line 225:82: 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR )
            string_literal276 = match( T__86, TOKENS_FOLLOWING_T__86_IN_datatype_1531 )
            if @state.backtracking == 0

              tree_for_string_literal276 = @adaptor.create_with_payload( string_literal276 )
              @adaptor.add_child( root_0, tree_for_string_literal276 )

            end
            string_literal277 = match( T__87, TOKENS_FOLLOWING_T__87_IN_datatype_1533 )
            if @state.backtracking == 0

              tree_for_string_literal277 = @adaptor.create_with_payload( string_literal277 )
              @adaptor.add_child( root_0, tree_for_string_literal277 )

            end
            # at line 225:100: ( identifier | column_spec CHARSET_ATTR )
            alt_62 = 2
            look_62_0 = @input.peek( 1 )

            if ( look_62_0.between?( ID, DOUBLEQUOTED_STRING ) )
              look_62_1 = @input.peek( 2 )

              if ( look_62_1 == EOF || look_62_1 == SEMI || look_62_1 == ASSIGN || look_62_1 == RPAREN || look_62_1 == COMMA || look_62_1.between?( ID, DOUBLEQUOTED_STRING ) || look_62_1 == T__50 || look_62_1.between?( T__52, T__55 ) || look_62_1 == T__57 || look_62_1 == T__59 || look_62_1.between?( T__103, T__104 ) || look_62_1 == T__107 || look_62_1 == T__161 )
                alt_62 = 1
              elsif ( look_62_1 == DOT || look_62_1 == CHARSET_ATTR )
                alt_62 = 2
              else
                @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

                raise NoViableAlternative( "", 62, 1 )
              end
            elsif ( look_62_0 == T__100 )
              alt_62 = 2
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 62, 0 )
            end
            case alt_62
            when 1
              # at line 225:102: identifier
              @state.following.push( TOKENS_FOLLOWING_identifier_IN_datatype_1537 )
              identifier278 = identifier
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, identifier278.tree )
              end

            when 2
              # at line 225:115: column_spec CHARSET_ATTR
              @state.following.push( TOKENS_FOLLOWING_column_spec_IN_datatype_1541 )
              column_spec279 = column_spec
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, column_spec279.tree )
              end
              __CHARSET_ATTR280__ = match( CHARSET_ATTR, TOKENS_FOLLOWING_CHARSET_ATTR_IN_datatype_1543 )
              if @state.backtracking == 0

                tree_for_CHARSET_ATTR280 = @adaptor.create_with_payload( __CHARSET_ATTR280__ )
                @adaptor.add_child( root_0, tree_for_CHARSET_ATTR280 )

              end

            end

          end

        when 22
          root_0 = @adaptor.create_flat_list


          # at line 226:4: 'VARCHAR2' ( LPAREN NUMBER ( keyBYTE | 'CHAR' )? RPAREN )? ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )?
          string_literal281 = match( T__89, TOKENS_FOLLOWING_T__89_IN_datatype_1553 )
          if @state.backtracking == 0

            tree_for_string_literal281 = @adaptor.create_with_payload( string_literal281 )
            @adaptor.add_child( root_0, tree_for_string_literal281 )

          end
          # at line 226:32: ( LPAREN NUMBER ( keyBYTE | 'CHAR' )? RPAREN )?
          alt_65 = 2
          look_65_0 = @input.peek( 1 )

          if ( look_65_0 == LPAREN )
            alt_65 = 1
          end
          case alt_65
          when 1
            # at line 226:34: LPAREN NUMBER ( keyBYTE | 'CHAR' )? RPAREN
            __LPAREN282__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_datatype_1574 )
            if @state.backtracking == 0

              tree_for_LPAREN282 = @adaptor.create_with_payload( __LPAREN282__ )
              @adaptor.add_child( root_0, tree_for_LPAREN282 )

            end
            __NUMBER283__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_datatype_1576 )
            if @state.backtracking == 0

              tree_for_NUMBER283 = @adaptor.create_with_payload( __NUMBER283__ )
              @adaptor.add_child( root_0, tree_for_NUMBER283 )

            end
            # at line 226:48: ( keyBYTE | 'CHAR' )?
            alt_64 = 3
            look_64_0 = @input.peek( 1 )

            if ( look_64_0 == ID )
              alt_64 = 1
            elsif ( look_64_0 == T__85 )
              alt_64 = 2
            end
            case alt_64
            when 1
              # at line 226:50: keyBYTE
              @state.following.push( TOKENS_FOLLOWING_keyBYTE_IN_datatype_1580 )
              keyBYTE284 = keyBYTE
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, keyBYTE284.tree )
              end

            when 2
              # at line 226:60: 'CHAR'
              string_literal285 = match( T__85, TOKENS_FOLLOWING_T__85_IN_datatype_1584 )
              if @state.backtracking == 0

                tree_for_string_literal285 = @adaptor.create_with_payload( string_literal285 )
                @adaptor.add_child( root_0, tree_for_string_literal285 )

              end

            end
            __RPAREN286__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_datatype_1589 )
            if @state.backtracking == 0

              tree_for_RPAREN286 = @adaptor.create_with_payload( __RPAREN286__ )
              @adaptor.add_child( root_0, tree_for_RPAREN286 )

            end

          end
          # at line 226:80: ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )?
          alt_67 = 2
          look_67_0 = @input.peek( 1 )

          if ( look_67_0 == T__86 )
            alt_67 = 1
          end
          case alt_67
          when 1
            # at line 226:82: 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR )
            string_literal287 = match( T__86, TOKENS_FOLLOWING_T__86_IN_datatype_1596 )
            if @state.backtracking == 0

              tree_for_string_literal287 = @adaptor.create_with_payload( string_literal287 )
              @adaptor.add_child( root_0, tree_for_string_literal287 )

            end
            string_literal288 = match( T__87, TOKENS_FOLLOWING_T__87_IN_datatype_1598 )
            if @state.backtracking == 0

              tree_for_string_literal288 = @adaptor.create_with_payload( string_literal288 )
              @adaptor.add_child( root_0, tree_for_string_literal288 )

            end
            # at line 226:100: ( identifier | column_spec CHARSET_ATTR )
            alt_66 = 2
            look_66_0 = @input.peek( 1 )

            if ( look_66_0.between?( ID, DOUBLEQUOTED_STRING ) )
              look_66_1 = @input.peek( 2 )

              if ( look_66_1 == DOT || look_66_1 == CHARSET_ATTR )
                alt_66 = 2
              elsif ( look_66_1 == EOF || look_66_1 == SEMI || look_66_1 == ASSIGN || look_66_1 == RPAREN || look_66_1 == COMMA || look_66_1.between?( ID, DOUBLEQUOTED_STRING ) || look_66_1 == T__50 || look_66_1.between?( T__52, T__55 ) || look_66_1 == T__57 || look_66_1 == T__59 || look_66_1.between?( T__103, T__104 ) || look_66_1 == T__107 || look_66_1 == T__161 )
                alt_66 = 1
              else
                @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

                raise NoViableAlternative( "", 66, 1 )
              end
            elsif ( look_66_0 == T__100 )
              alt_66 = 2
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 66, 0 )
            end
            case alt_66
            when 1
              # at line 226:102: identifier
              @state.following.push( TOKENS_FOLLOWING_identifier_IN_datatype_1602 )
              identifier289 = identifier
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, identifier289.tree )
              end

            when 2
              # at line 226:115: column_spec CHARSET_ATTR
              @state.following.push( TOKENS_FOLLOWING_column_spec_IN_datatype_1606 )
              column_spec290 = column_spec
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, column_spec290.tree )
              end
              __CHARSET_ATTR291__ = match( CHARSET_ATTR, TOKENS_FOLLOWING_CHARSET_ATTR_IN_datatype_1608 )
              if @state.backtracking == 0

                tree_for_CHARSET_ATTR291 = @adaptor.create_with_payload( __CHARSET_ATTR291__ )
                @adaptor.add_child( root_0, tree_for_CHARSET_ATTR291 )

              end

            end

          end

        when 23
          root_0 = @adaptor.create_flat_list


          # at line 227:4: 'CHARACTER' ( keyVARYING )? ( LPAREN NUMBER RPAREN )?
          string_literal292 = match( T__86, TOKENS_FOLLOWING_T__86_IN_datatype_1618 )
          if @state.backtracking == 0

            tree_for_string_literal292 = @adaptor.create_with_payload( string_literal292 )
            @adaptor.add_child( root_0, tree_for_string_literal292 )

          end
          # at line 227:16: ( keyVARYING )?
          alt_68 = 2
          alt_68 = @dfa68.predict( @input )
          case alt_68
          when 1
            # at line 227:18: keyVARYING
            @state.following.push( TOKENS_FOLLOWING_keyVARYING_IN_datatype_1622 )
            keyVARYING293 = keyVARYING
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyVARYING293.tree )
            end

          end
          # at line 227:32: ( LPAREN NUMBER RPAREN )?
          alt_69 = 2
          look_69_0 = @input.peek( 1 )

          if ( look_69_0 == LPAREN )
            alt_69 = 1
          end
          case alt_69
          when 1
            # at line 227:34: LPAREN NUMBER RPAREN
            __LPAREN294__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_datatype_1629 )
            if @state.backtracking == 0

              tree_for_LPAREN294 = @adaptor.create_with_payload( __LPAREN294__ )
              @adaptor.add_child( root_0, tree_for_LPAREN294 )

            end
            __NUMBER295__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_datatype_1631 )
            if @state.backtracking == 0

              tree_for_NUMBER295 = @adaptor.create_with_payload( __NUMBER295__ )
              @adaptor.add_child( root_0, tree_for_NUMBER295 )

            end
            __RPAREN296__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_datatype_1633 )
            if @state.backtracking == 0

              tree_for_RPAREN296 = @adaptor.create_with_payload( __RPAREN296__ )
              @adaptor.add_child( root_0, tree_for_RPAREN296 )

            end

          end

        when 24
          root_0 = @adaptor.create_flat_list


          # at line 228:4: 'NCHAR' ( keyVARYING )? ( LPAREN NUMBER RPAREN )?
          string_literal297 = match( T__90, TOKENS_FOLLOWING_T__90_IN_datatype_1641 )
          if @state.backtracking == 0

            tree_for_string_literal297 = @adaptor.create_with_payload( string_literal297 )
            @adaptor.add_child( root_0, tree_for_string_literal297 )

          end
          # at line 228:16: ( keyVARYING )?
          alt_70 = 2
          alt_70 = @dfa70.predict( @input )
          case alt_70
          when 1
            # at line 228:18: keyVARYING
            @state.following.push( TOKENS_FOLLOWING_keyVARYING_IN_datatype_1649 )
            keyVARYING298 = keyVARYING
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyVARYING298.tree )
            end

          end
          # at line 228:32: ( LPAREN NUMBER RPAREN )?
          alt_71 = 2
          look_71_0 = @input.peek( 1 )

          if ( look_71_0 == LPAREN )
            alt_71 = 1
          end
          case alt_71
          when 1
            # at line 228:34: LPAREN NUMBER RPAREN
            __LPAREN299__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_datatype_1656 )
            if @state.backtracking == 0

              tree_for_LPAREN299 = @adaptor.create_with_payload( __LPAREN299__ )
              @adaptor.add_child( root_0, tree_for_LPAREN299 )

            end
            __NUMBER300__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_datatype_1658 )
            if @state.backtracking == 0

              tree_for_NUMBER300 = @adaptor.create_with_payload( __NUMBER300__ )
              @adaptor.add_child( root_0, tree_for_NUMBER300 )

            end
            __RPAREN301__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_datatype_1660 )
            if @state.backtracking == 0

              tree_for_RPAREN301 = @adaptor.create_with_payload( __RPAREN301__ )
              @adaptor.add_child( root_0, tree_for_RPAREN301 )

            end

          end

        when 25
          root_0 = @adaptor.create_flat_list


          # at line 229:4: 'NVARCHAR' ( LPAREN NUMBER RPAREN )?
          string_literal302 = match( T__91, TOKENS_FOLLOWING_T__91_IN_datatype_1668 )
          if @state.backtracking == 0

            tree_for_string_literal302 = @adaptor.create_with_payload( string_literal302 )
            @adaptor.add_child( root_0, tree_for_string_literal302 )

          end
          # at line 229:16: ( LPAREN NUMBER RPAREN )?
          alt_72 = 2
          look_72_0 = @input.peek( 1 )

          if ( look_72_0 == LPAREN )
            alt_72 = 1
          end
          case alt_72
          when 1
            # at line 229:18: LPAREN NUMBER RPAREN
            __LPAREN303__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_datatype_1673 )
            if @state.backtracking == 0

              tree_for_LPAREN303 = @adaptor.create_with_payload( __LPAREN303__ )
              @adaptor.add_child( root_0, tree_for_LPAREN303 )

            end
            __NUMBER304__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_datatype_1675 )
            if @state.backtracking == 0

              tree_for_NUMBER304 = @adaptor.create_with_payload( __NUMBER304__ )
              @adaptor.add_child( root_0, tree_for_NUMBER304 )

            end
            __RPAREN305__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_datatype_1677 )
            if @state.backtracking == 0

              tree_for_RPAREN305 = @adaptor.create_with_payload( __RPAREN305__ )
              @adaptor.add_child( root_0, tree_for_RPAREN305 )

            end

          end

        when 26
          root_0 = @adaptor.create_flat_list


          # at line 230:4: 'NVARCHAR2' ( LPAREN NUMBER RPAREN )?
          string_literal306 = match( T__92, TOKENS_FOLLOWING_T__92_IN_datatype_1685 )
          if @state.backtracking == 0

            tree_for_string_literal306 = @adaptor.create_with_payload( string_literal306 )
            @adaptor.add_child( root_0, tree_for_string_literal306 )

          end
          # at line 230:16: ( LPAREN NUMBER RPAREN )?
          alt_73 = 2
          look_73_0 = @input.peek( 1 )

          if ( look_73_0 == LPAREN )
            alt_73 = 1
          end
          case alt_73
          when 1
            # at line 230:18: LPAREN NUMBER RPAREN
            __LPAREN307__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_datatype_1689 )
            if @state.backtracking == 0

              tree_for_LPAREN307 = @adaptor.create_with_payload( __LPAREN307__ )
              @adaptor.add_child( root_0, tree_for_LPAREN307 )

            end
            __NUMBER308__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_datatype_1691 )
            if @state.backtracking == 0

              tree_for_NUMBER308 = @adaptor.create_with_payload( __NUMBER308__ )
              @adaptor.add_child( root_0, tree_for_NUMBER308 )

            end
            __RPAREN309__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_datatype_1693 )
            if @state.backtracking == 0

              tree_for_RPAREN309 = @adaptor.create_with_payload( __RPAREN309__ )
              @adaptor.add_child( root_0, tree_for_RPAREN309 )

            end

          end

        when 27
          root_0 = @adaptor.create_flat_list


          # at line 231:4: 'NATIONAL' ( 'CHARACTER' | 'CHAR' ) ( keyVARYING )? ( LPAREN NUMBER RPAREN )?
          string_literal310 = match( T__93, TOKENS_FOLLOWING_T__93_IN_datatype_1701 )
          if @state.backtracking == 0

            tree_for_string_literal310 = @adaptor.create_with_payload( string_literal310 )
            @adaptor.add_child( root_0, tree_for_string_literal310 )

          end
          set311 = @input.look
          if @input.peek( 1 ).between?( T__85, T__86 )
            @input.consume
            if @state.backtracking == 0
              @adaptor.add_child( root_0, @adaptor.create_with_payload( set311 ) )
            end
            @state.error_recovery = false
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            mse = MismatchedSet( nil )
            raise mse
          end


          # at line 231:41: ( keyVARYING )?
          alt_74 = 2
          alt_74 = @dfa74.predict( @input )
          case alt_74
          when 1
            # at line 231:43: keyVARYING
            @state.following.push( TOKENS_FOLLOWING_keyVARYING_IN_datatype_1716 )
            keyVARYING312 = keyVARYING
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyVARYING312.tree )
            end

          end
          # at line 231:57: ( LPAREN NUMBER RPAREN )?
          alt_75 = 2
          look_75_0 = @input.peek( 1 )

          if ( look_75_0 == LPAREN )
            alt_75 = 1
          end
          case alt_75
          when 1
            # at line 231:59: LPAREN NUMBER RPAREN
            __LPAREN313__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_datatype_1723 )
            if @state.backtracking == 0

              tree_for_LPAREN313 = @adaptor.create_with_payload( __LPAREN313__ )
              @adaptor.add_child( root_0, tree_for_LPAREN313 )

            end
            __NUMBER314__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_datatype_1725 )
            if @state.backtracking == 0

              tree_for_NUMBER314 = @adaptor.create_with_payload( __NUMBER314__ )
              @adaptor.add_child( root_0, tree_for_NUMBER314 )

            end
            __RPAREN315__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_datatype_1727 )
            if @state.backtracking == 0

              tree_for_RPAREN315 = @adaptor.create_with_payload( __RPAREN315__ )
              @adaptor.add_child( root_0, tree_for_RPAREN315 )

            end

          end

        when 28
          root_0 = @adaptor.create_flat_list


          # at line 232:4: 'MLSLABEL'
          string_literal316 = match( T__94, TOKENS_FOLLOWING_T__94_IN_datatype_1735 )
          if @state.backtracking == 0

            tree_for_string_literal316 = @adaptor.create_with_payload( string_literal316 )
            @adaptor.add_child( root_0, tree_for_string_literal316 )

          end

        when 29
          root_0 = @adaptor.create_flat_list


          # at line 233:4: 'PLS_INTEGER'
          string_literal317 = match( T__95, TOKENS_FOLLOWING_T__95_IN_datatype_1740 )
          if @state.backtracking == 0

            tree_for_string_literal317 = @adaptor.create_with_payload( string_literal317 )
            @adaptor.add_child( root_0, tree_for_string_literal317 )

          end

        when 30
          root_0 = @adaptor.create_flat_list


          # at line 234:4: 'BLOB'
          string_literal318 = match( T__96, TOKENS_FOLLOWING_T__96_IN_datatype_1745 )
          if @state.backtracking == 0

            tree_for_string_literal318 = @adaptor.create_with_payload( string_literal318 )
            @adaptor.add_child( root_0, tree_for_string_literal318 )

          end

        when 31
          root_0 = @adaptor.create_flat_list


          # at line 235:4: 'CLOB' ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )?
          string_literal319 = match( T__97, TOKENS_FOLLOWING_T__97_IN_datatype_1750 )
          if @state.backtracking == 0

            tree_for_string_literal319 = @adaptor.create_with_payload( string_literal319 )
            @adaptor.add_child( root_0, tree_for_string_literal319 )

          end
          # at line 235:11: ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )?
          alt_77 = 2
          look_77_0 = @input.peek( 1 )

          if ( look_77_0 == T__86 )
            alt_77 = 1
          end
          case alt_77
          when 1
            # at line 235:13: 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR )
            string_literal320 = match( T__86, TOKENS_FOLLOWING_T__86_IN_datatype_1754 )
            if @state.backtracking == 0

              tree_for_string_literal320 = @adaptor.create_with_payload( string_literal320 )
              @adaptor.add_child( root_0, tree_for_string_literal320 )

            end
            string_literal321 = match( T__87, TOKENS_FOLLOWING_T__87_IN_datatype_1756 )
            if @state.backtracking == 0

              tree_for_string_literal321 = @adaptor.create_with_payload( string_literal321 )
              @adaptor.add_child( root_0, tree_for_string_literal321 )

            end
            # at line 235:31: ( identifier | column_spec CHARSET_ATTR )
            alt_76 = 2
            look_76_0 = @input.peek( 1 )

            if ( look_76_0.between?( ID, DOUBLEQUOTED_STRING ) )
              look_76_1 = @input.peek( 2 )

              if ( look_76_1 == EOF || look_76_1 == SEMI || look_76_1 == ASSIGN || look_76_1 == RPAREN || look_76_1 == COMMA || look_76_1.between?( ID, DOUBLEQUOTED_STRING ) || look_76_1 == T__50 || look_76_1.between?( T__52, T__55 ) || look_76_1 == T__57 || look_76_1 == T__59 || look_76_1.between?( T__103, T__104 ) || look_76_1 == T__107 || look_76_1 == T__161 )
                alt_76 = 1
              elsif ( look_76_1 == DOT || look_76_1 == CHARSET_ATTR )
                alt_76 = 2
              else
                @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

                raise NoViableAlternative( "", 76, 1 )
              end
            elsif ( look_76_0 == T__100 )
              alt_76 = 2
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 76, 0 )
            end
            case alt_76
            when 1
              # at line 235:33: identifier
              @state.following.push( TOKENS_FOLLOWING_identifier_IN_datatype_1760 )
              identifier322 = identifier
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, identifier322.tree )
              end

            when 2
              # at line 235:46: column_spec CHARSET_ATTR
              @state.following.push( TOKENS_FOLLOWING_column_spec_IN_datatype_1764 )
              column_spec323 = column_spec
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, column_spec323.tree )
              end
              __CHARSET_ATTR324__ = match( CHARSET_ATTR, TOKENS_FOLLOWING_CHARSET_ATTR_IN_datatype_1766 )
              if @state.backtracking == 0

                tree_for_CHARSET_ATTR324 = @adaptor.create_with_payload( __CHARSET_ATTR324__ )
                @adaptor.add_child( root_0, tree_for_CHARSET_ATTR324 )

              end

            end

          end

        when 32
          root_0 = @adaptor.create_flat_list


          # at line 236:4: 'NCLOB'
          string_literal325 = match( T__98, TOKENS_FOLLOWING_T__98_IN_datatype_1776 )
          if @state.backtracking == 0

            tree_for_string_literal325 = @adaptor.create_with_payload( string_literal325 )
            @adaptor.add_child( root_0, tree_for_string_literal325 )

          end

        when 33
          root_0 = @adaptor.create_flat_list


          # at line 237:4: 'BFILE'
          string_literal326 = match( T__99, TOKENS_FOLLOWING_T__99_IN_datatype_1781 )
          if @state.backtracking == 0

            tree_for_string_literal326 = @adaptor.create_with_payload( string_literal326 )
            @adaptor.add_child( root_0, tree_for_string_literal326 )

          end

        when 34
          root_0 = @adaptor.create_flat_list


          # at line 238:4: 'ROWID'
          string_literal327 = match( T__100, TOKENS_FOLLOWING_T__100_IN_datatype_1786 )
          if @state.backtracking == 0

            tree_for_string_literal327 = @adaptor.create_with_payload( string_literal327 )
            @adaptor.add_child( root_0, tree_for_string_literal327 )

          end

        when 35
          root_0 = @adaptor.create_flat_list


          # at line 239:4: 'UROWID' ( LPAREN NUMBER RPAREN )?
          string_literal328 = match( T__101, TOKENS_FOLLOWING_T__101_IN_datatype_1792 )
          if @state.backtracking == 0

            tree_for_string_literal328 = @adaptor.create_with_payload( string_literal328 )
            @adaptor.add_child( root_0, tree_for_string_literal328 )

          end
          # at line 239:13: ( LPAREN NUMBER RPAREN )?
          alt_78 = 2
          look_78_0 = @input.peek( 1 )

          if ( look_78_0 == LPAREN )
            alt_78 = 1
          end
          case alt_78
          when 1
            # at line 239:15: LPAREN NUMBER RPAREN
            __LPAREN329__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_datatype_1796 )
            if @state.backtracking == 0

              tree_for_LPAREN329 = @adaptor.create_with_payload( __LPAREN329__ )
              @adaptor.add_child( root_0, tree_for_LPAREN329 )

            end
            __NUMBER330__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_datatype_1798 )
            if @state.backtracking == 0

              tree_for_NUMBER330 = @adaptor.create_with_payload( __NUMBER330__ )
              @adaptor.add_child( root_0, tree_for_NUMBER330 )

            end
            __RPAREN331__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_datatype_1800 )
            if @state.backtracking == 0

              tree_for_RPAREN331 = @adaptor.create_with_payload( __RPAREN331__ )
              @adaptor.add_child( root_0, tree_for_RPAREN331 )

            end

          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 28 )
        memoize( __method__, datatype_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    TypeSpecReturnValue = define_return_scope 

    # 
    # parser rule type_spec
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 242:1: type_spec : ( datatype | column_spec TYPE_ATTR | table_spec ROWTYPE_ATTR | type_name ( LPAREN NUMBER RPAREN )? );
    # 
    def type_spec
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 29 )
      return_value = TypeSpecReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      type_spec_start_index = @input.index

      root_0 = nil
      __TYPE_ATTR334__ = nil
      __ROWTYPE_ATTR336__ = nil
      __LPAREN338__ = nil
      __NUMBER339__ = nil
      __RPAREN340__ = nil
      datatype332 = nil
      column_spec333 = nil
      table_spec335 = nil
      type_name337 = nil

      tree_for_TYPE_ATTR334 = nil
      tree_for_ROWTYPE_ATTR336 = nil
      tree_for_LPAREN338 = nil
      tree_for_NUMBER339 = nil
      tree_for_RPAREN340 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 243:2: ( datatype | column_spec TYPE_ATTR | table_spec ROWTYPE_ATTR | type_name ( LPAREN NUMBER RPAREN )? )
        alt_81 = 4
        alt_81 = @dfa81.predict( @input )
        case alt_81
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 243:4: datatype
          @state.following.push( TOKENS_FOLLOWING_datatype_IN_type_spec_1814 )
          datatype332 = datatype
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, datatype332.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 245:4: column_spec TYPE_ATTR
          @state.following.push( TOKENS_FOLLOWING_column_spec_IN_type_spec_1821 )
          column_spec333 = column_spec
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, column_spec333.tree )
          end
          __TYPE_ATTR334__ = match( TYPE_ATTR, TOKENS_FOLLOWING_TYPE_ATTR_IN_type_spec_1823 )
          if @state.backtracking == 0

            tree_for_TYPE_ATTR334 = @adaptor.create_with_payload( __TYPE_ATTR334__ )
            @adaptor.add_child( root_0, tree_for_TYPE_ATTR334 )

          end

        when 3
          root_0 = @adaptor.create_flat_list


          # at line 247:4: table_spec ROWTYPE_ATTR
          @state.following.push( TOKENS_FOLLOWING_table_spec_IN_type_spec_1829 )
          table_spec335 = table_spec
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, table_spec335.tree )
          end
          __ROWTYPE_ATTR336__ = match( ROWTYPE_ATTR, TOKENS_FOLLOWING_ROWTYPE_ATTR_IN_type_spec_1831 )
          if @state.backtracking == 0

            tree_for_ROWTYPE_ATTR336 = @adaptor.create_with_payload( __ROWTYPE_ATTR336__ )
            @adaptor.add_child( root_0, tree_for_ROWTYPE_ATTR336 )

          end

        when 4
          root_0 = @adaptor.create_flat_list


          # at line 249:4: type_name ( LPAREN NUMBER RPAREN )?
          @state.following.push( TOKENS_FOLLOWING_type_name_IN_type_spec_1837 )
          type_name337 = type_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, type_name337.tree )
          end
          # at line 249:14: ( LPAREN NUMBER RPAREN )?
          alt_80 = 2
          look_80_0 = @input.peek( 1 )

          if ( look_80_0 == LPAREN )
            alt_80 = 1
          end
          case alt_80
          when 1
            # at line 249:16: LPAREN NUMBER RPAREN
            __LPAREN338__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_type_spec_1841 )
            if @state.backtracking == 0

              tree_for_LPAREN338 = @adaptor.create_with_payload( __LPAREN338__ )
              @adaptor.add_child( root_0, tree_for_LPAREN338 )

            end
            __NUMBER339__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_type_spec_1843 )
            if @state.backtracking == 0

              tree_for_NUMBER339 = @adaptor.create_with_payload( __NUMBER339__ )
              @adaptor.add_child( root_0, tree_for_NUMBER339 )

            end
            __RPAREN340__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_type_spec_1845 )
            if @state.backtracking == 0

              tree_for_RPAREN340 = @adaptor.create_with_payload( __RPAREN340__ )
              @adaptor.add_child( root_0, tree_for_RPAREN340 )

            end

          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 29 )
        memoize( __method__, type_spec_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    TypeNameReturnValue = define_return_scope 

    # 
    # parser rule type_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 252:1: type_name : identifier ( DOT identifier )* ;
    # 
    def type_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 30 )
      return_value = TypeNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      type_name_start_index = @input.index

      root_0 = nil
      __DOT342__ = nil
      identifier341 = nil
      identifier343 = nil

      tree_for_DOT342 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 253:4: identifier ( DOT identifier )*
        @state.following.push( TOKENS_FOLLOWING_identifier_IN_type_name_1859 )
        identifier341 = identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, identifier341.tree )
        end
        # at line 253:15: ( DOT identifier )*
        while true # decision 82
          alt_82 = 2
          look_82_0 = @input.peek( 1 )

          if ( look_82_0 == DOT )
            alt_82 = 1

          end
          case alt_82
          when 1
            # at line 253:17: DOT identifier
            __DOT342__ = match( DOT, TOKENS_FOLLOWING_DOT_IN_type_name_1863 )
            if @state.backtracking == 0

              tree_for_DOT342 = @adaptor.create_with_payload( __DOT342__ )
              @adaptor.add_child( root_0, tree_for_DOT342 )

            end
            @state.following.push( TOKENS_FOLLOWING_identifier_IN_type_name_1865 )
            identifier343 = identifier
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, identifier343.tree )
            end

          else
            break # out of loop for decision 82
          end
        end # loop for decision 82
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 30 )
        memoize( __method__, type_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ParameterSpecsReturnValue = define_return_scope 

    # 
    # parser rule parameter_specs
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 256:1: parameter_specs : parameter_spec ( COMMA parameter_spec )* ;
    # 
    def parameter_specs
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 31 )
      return_value = ParameterSpecsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      parameter_specs_start_index = @input.index

      root_0 = nil
      __COMMA345__ = nil
      parameter_spec344 = nil
      parameter_spec346 = nil

      tree_for_COMMA345 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 257:4: parameter_spec ( COMMA parameter_spec )*
        @state.following.push( TOKENS_FOLLOWING_parameter_spec_IN_parameter_specs_1879 )
        parameter_spec344 = parameter_spec
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, parameter_spec344.tree )
        end
        # at line 257:19: ( COMMA parameter_spec )*
        while true # decision 83
          alt_83 = 2
          look_83_0 = @input.peek( 1 )

          if ( look_83_0 == COMMA )
            alt_83 = 1

          end
          case alt_83
          when 1
            # at line 257:21: COMMA parameter_spec
            __COMMA345__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_parameter_specs_1883 )
            if @state.backtracking == 0

              tree_for_COMMA345 = @adaptor.create_with_payload( __COMMA345__ )
              @adaptor.add_child( root_0, tree_for_COMMA345 )

            end
            @state.following.push( TOKENS_FOLLOWING_parameter_spec_IN_parameter_specs_1885 )
            parameter_spec346 = parameter_spec
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, parameter_spec346.tree )
            end

          else
            break # out of loop for decision 83
          end
        end # loop for decision 83
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 31 )
        memoize( __method__, parameter_specs_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ParameterSpecReturnValue = define_return_scope 

    # 
    # parser rule parameter_spec
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 260:1: parameter_spec : parameter_name ( 'IN' )? ( type_spec )? ;
    # 
    def parameter_spec
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 32 )
      return_value = ParameterSpecReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      parameter_spec_start_index = @input.index

      root_0 = nil
      string_literal348 = nil
      parameter_name347 = nil
      type_spec349 = nil

      tree_for_string_literal348 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 261:4: parameter_name ( 'IN' )? ( type_spec )?
        @state.following.push( TOKENS_FOLLOWING_parameter_name_IN_parameter_spec_1899 )
        parameter_name347 = parameter_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, parameter_name347.tree )
        end
        # at line 261:19: ( 'IN' )?
        alt_84 = 2
        look_84_0 = @input.peek( 1 )

        if ( look_84_0 == T__102 )
          alt_84 = 1
        end
        case alt_84
        when 1
          # at line 261:21: 'IN'
          string_literal348 = match( T__102, TOKENS_FOLLOWING_T__102_IN_parameter_spec_1903 )
          if @state.backtracking == 0

            tree_for_string_literal348 = @adaptor.create_with_payload( string_literal348 )
            @adaptor.add_child( root_0, tree_for_string_literal348 )

          end

        end
        # at line 261:29: ( type_spec )?
        alt_85 = 2
        look_85_0 = @input.peek( 1 )

        if ( look_85_0.between?( ID, DOUBLEQUOTED_STRING ) || look_85_0.between?( T__64, T__76 ) || look_85_0.between?( T__79, T__86 ) || look_85_0.between?( T__88, T__101 ) )
          alt_85 = 1
        end
        case alt_85
        when 1
          # at line 261:31: type_spec
          @state.following.push( TOKENS_FOLLOWING_type_spec_IN_parameter_spec_1910 )
          type_spec349 = type_spec
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, type_spec349.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 32 )
        memoize( __method__, parameter_spec_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ParameterNameReturnValue = define_return_scope 

    # 
    # parser rule parameter_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 264:1: parameter_name : identifier ;
    # 
    def parameter_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 33 )
      return_value = ParameterNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      parameter_name_start_index = @input.index

      root_0 = nil
      identifier350 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 265:4: identifier
        @state.following.push( TOKENS_FOLLOWING_identifier_IN_parameter_name_1925 )
        identifier350 = identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, identifier350.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 33 )
        memoize( __method__, parameter_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CursorSpecReturnValue = define_return_scope 

    # 
    # parser rule cursor_spec
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 268:1: cursor_spec : keyCURSOR cursor_name ( LPAREN parameter_specs RPAREN )? keyRETURN return_type SEMI ;
    # 
    def cursor_spec
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 34 )
      return_value = CursorSpecReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      cursor_spec_start_index = @input.index

      root_0 = nil
      __LPAREN353__ = nil
      __RPAREN355__ = nil
      __SEMI358__ = nil
      keyCURSOR351 = nil
      cursor_name352 = nil
      parameter_specs354 = nil
      keyRETURN356 = nil
      return_type357 = nil

      tree_for_LPAREN353 = nil
      tree_for_RPAREN355 = nil
      tree_for_SEMI358 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 269:4: keyCURSOR cursor_name ( LPAREN parameter_specs RPAREN )? keyRETURN return_type SEMI
        @state.following.push( TOKENS_FOLLOWING_keyCURSOR_IN_cursor_spec_1936 )
        keyCURSOR351 = keyCURSOR
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyCURSOR351.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_cursor_name_IN_cursor_spec_1938 )
        cursor_name352 = cursor_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, cursor_name352.tree )
        end
        # at line 270:3: ( LPAREN parameter_specs RPAREN )?
        alt_86 = 2
        look_86_0 = @input.peek( 1 )

        if ( look_86_0 == LPAREN )
          alt_86 = 1
        end
        case alt_86
        when 1
          # at line 270:5: LPAREN parameter_specs RPAREN
          __LPAREN353__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_cursor_spec_1945 )
          if @state.backtracking == 0

            tree_for_LPAREN353 = @adaptor.create_with_payload( __LPAREN353__ )
            @adaptor.add_child( root_0, tree_for_LPAREN353 )

          end
          @state.following.push( TOKENS_FOLLOWING_parameter_specs_IN_cursor_spec_1947 )
          parameter_specs354 = parameter_specs
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, parameter_specs354.tree )
          end
          __RPAREN355__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_cursor_spec_1949 )
          if @state.backtracking == 0

            tree_for_RPAREN355 = @adaptor.create_with_payload( __RPAREN355__ )
            @adaptor.add_child( root_0, tree_for_RPAREN355 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_keyRETURN_IN_cursor_spec_1956 )
        keyRETURN356 = keyRETURN
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyRETURN356.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_return_type_IN_cursor_spec_1958 )
        return_type357 = return_type
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, return_type357.tree )
        end
        __SEMI358__ = match( SEMI, TOKENS_FOLLOWING_SEMI_IN_cursor_spec_1960 )
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 34 )
        memoize( __method__, cursor_spec_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ProcedureSpecReturnValue = define_return_scope 

    # 
    # parser rule procedure_spec
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 274:1: procedure_spec : 'PROCEDURE' procedure_name ( LPAREN arguments RPAREN )? SEMI ;
    # 
    def procedure_spec
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 35 )
      return_value = ProcedureSpecReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      procedure_spec_start_index = @input.index

      root_0 = nil
      string_literal359 = nil
      __LPAREN361__ = nil
      __RPAREN363__ = nil
      __SEMI364__ = nil
      procedure_name360 = nil
      arguments362 = nil

      tree_for_string_literal359 = nil
      tree_for_LPAREN361 = nil
      tree_for_RPAREN363 = nil
      tree_for_SEMI364 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 275:2: 'PROCEDURE' procedure_name ( LPAREN arguments RPAREN )? SEMI
        string_literal359 = match( T__103, TOKENS_FOLLOWING_T__103_IN_procedure_spec_1973 )
        if @state.backtracking == 0

          tree_for_string_literal359 = @adaptor.create_with_payload( string_literal359 )
          @adaptor.add_child( root_0, tree_for_string_literal359 )

        end
        @state.following.push( TOKENS_FOLLOWING_procedure_name_IN_procedure_spec_1975 )
        procedure_name360 = procedure_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, procedure_name360.tree )
        end
        # at line 276:2: ( LPAREN arguments RPAREN )?
        alt_87 = 2
        look_87_0 = @input.peek( 1 )

        if ( look_87_0 == LPAREN )
          alt_87 = 1
        end
        case alt_87
        when 1
          # at line 276:4: LPAREN arguments RPAREN
          __LPAREN361__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_procedure_spec_1981 )
          if @state.backtracking == 0

            tree_for_LPAREN361 = @adaptor.create_with_payload( __LPAREN361__ )
            @adaptor.add_child( root_0, tree_for_LPAREN361 )

          end
          @state.following.push( TOKENS_FOLLOWING_arguments_IN_procedure_spec_1983 )
          arguments362 = arguments
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, arguments362.tree )
          end
          __RPAREN363__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_procedure_spec_1985 )
          if @state.backtracking == 0

            tree_for_RPAREN363 = @adaptor.create_with_payload( __RPAREN363__ )
            @adaptor.add_child( root_0, tree_for_RPAREN363 )

          end

        end
        __SEMI364__ = match( SEMI, TOKENS_FOLLOWING_SEMI_IN_procedure_spec_1990 )
        if @state.backtracking == 0

          tree_for_SEMI364 = @adaptor.create_with_payload( __SEMI364__ )
          @adaptor.add_child( root_0, tree_for_SEMI364 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 35 )
        memoize( __method__, procedure_spec_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    FunctionSpecReturnValue = define_return_scope 

    # 
    # parser rule function_spec
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 279:1: function_spec : 'FUNCTION' function_name ( LPAREN arguments RPAREN )? keyRETURN return_type SEMI ;
    # 
    def function_spec
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 36 )
      return_value = FunctionSpecReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      function_spec_start_index = @input.index

      root_0 = nil
      string_literal365 = nil
      __LPAREN367__ = nil
      __RPAREN369__ = nil
      __SEMI372__ = nil
      function_name366 = nil
      arguments368 = nil
      keyRETURN370 = nil
      return_type371 = nil

      tree_for_string_literal365 = nil
      tree_for_LPAREN367 = nil
      tree_for_RPAREN369 = nil
      tree_for_SEMI372 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 280:4: 'FUNCTION' function_name ( LPAREN arguments RPAREN )? keyRETURN return_type SEMI
        string_literal365 = match( T__104, TOKENS_FOLLOWING_T__104_IN_function_spec_2001 )
        if @state.backtracking == 0

          tree_for_string_literal365 = @adaptor.create_with_payload( string_literal365 )
          @adaptor.add_child( root_0, tree_for_string_literal365 )

        end
        @state.following.push( TOKENS_FOLLOWING_function_name_IN_function_spec_2003 )
        function_name366 = function_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, function_name366.tree )
        end
        # at line 281:3: ( LPAREN arguments RPAREN )?
        alt_88 = 2
        look_88_0 = @input.peek( 1 )

        if ( look_88_0 == LPAREN )
          alt_88 = 1
        end
        case alt_88
        when 1
          # at line 281:5: LPAREN arguments RPAREN
          __LPAREN367__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_function_spec_2010 )
          if @state.backtracking == 0

            tree_for_LPAREN367 = @adaptor.create_with_payload( __LPAREN367__ )
            @adaptor.add_child( root_0, tree_for_LPAREN367 )

          end
          @state.following.push( TOKENS_FOLLOWING_arguments_IN_function_spec_2012 )
          arguments368 = arguments
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, arguments368.tree )
          end
          __RPAREN369__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_function_spec_2014 )
          if @state.backtracking == 0

            tree_for_RPAREN369 = @adaptor.create_with_payload( __RPAREN369__ )
            @adaptor.add_child( root_0, tree_for_RPAREN369 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_keyRETURN_IN_function_spec_2021 )
        keyRETURN370 = keyRETURN
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyRETURN370.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_return_type_IN_function_spec_2023 )
        return_type371 = return_type
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, return_type371.tree )
        end
        __SEMI372__ = match( SEMI, TOKENS_FOLLOWING_SEMI_IN_function_spec_2025 )
        if @state.backtracking == 0

          tree_for_SEMI372 = @adaptor.create_with_payload( __SEMI372__ )
          @adaptor.add_child( root_0, tree_for_SEMI372 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 36 )
        memoize( __method__, function_spec_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExceptionDeclarationReturnValue = define_return_scope 

    # 
    # parser rule exception_declaration
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 285:1: exception_declaration : exception_name 'EXCEPTION' SEMI ;
    # 
    def exception_declaration
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 37 )
      return_value = ExceptionDeclarationReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      exception_declaration_start_index = @input.index

      root_0 = nil
      string_literal374 = nil
      __SEMI375__ = nil
      exception_name373 = nil

      tree_for_string_literal374 = nil
      tree_for_SEMI375 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 286:4: exception_name 'EXCEPTION' SEMI
        @state.following.push( TOKENS_FOLLOWING_exception_name_IN_exception_declaration_2036 )
        exception_name373 = exception_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, exception_name373.tree )
        end
        string_literal374 = match( T__61, TOKENS_FOLLOWING_T__61_IN_exception_declaration_2038 )
        if @state.backtracking == 0

          tree_for_string_literal374 = @adaptor.create_with_payload( string_literal374 )
          @adaptor.add_child( root_0, tree_for_string_literal374 )

        end
        __SEMI375__ = match( SEMI, TOKENS_FOLLOWING_SEMI_IN_exception_declaration_2040 )
        if @state.backtracking == 0

          tree_for_SEMI375 = @adaptor.create_with_payload( __SEMI375__ )
          @adaptor.add_child( root_0, tree_for_SEMI375 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 37 )
        memoize( __method__, exception_declaration_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExceptionNamesReturnValue = define_return_scope 

    # 
    # parser rule exception_names
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 289:1: exception_names : exception_name ( 'OR' exception_name )* ;
    # 
    def exception_names
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 38 )
      return_value = ExceptionNamesReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      exception_names_start_index = @input.index

      root_0 = nil
      string_literal377 = nil
      exception_name376 = nil
      exception_name378 = nil

      tree_for_string_literal377 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 290:4: exception_name ( 'OR' exception_name )*
        @state.following.push( TOKENS_FOLLOWING_exception_name_IN_exception_names_2051 )
        exception_name376 = exception_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, exception_name376.tree )
        end
        # at line 290:19: ( 'OR' exception_name )*
        while true # decision 89
          alt_89 = 2
          look_89_0 = @input.peek( 1 )

          if ( look_89_0 == T__51 )
            alt_89 = 1

          end
          case alt_89
          when 1
            # at line 290:21: 'OR' exception_name
            string_literal377 = match( T__51, TOKENS_FOLLOWING_T__51_IN_exception_names_2055 )
            if @state.backtracking == 0

              tree_for_string_literal377 = @adaptor.create_with_payload( string_literal377 )
              @adaptor.add_child( root_0, tree_for_string_literal377 )

            end
            @state.following.push( TOKENS_FOLLOWING_exception_name_IN_exception_names_2057 )
            exception_name378 = exception_name
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, exception_name378.tree )
            end

          else
            break # out of loop for decision 89
          end
        end # loop for decision 89
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 38 )
        memoize( __method__, exception_names_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExceptionNameReturnValue = define_return_scope 

    # 
    # parser rule exception_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 293:1: exception_name : ( exception_package_name DOT )? identifier ;
    # 
    def exception_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 39 )
      return_value = ExceptionNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      exception_name_start_index = @input.index

      root_0 = nil
      __DOT380__ = nil
      exception_package_name379 = nil
      identifier381 = nil

      tree_for_DOT380 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 294:4: ( exception_package_name DOT )? identifier
        # at line 294:4: ( exception_package_name DOT )?
        alt_90 = 2
        look_90_0 = @input.peek( 1 )

        if ( look_90_0.between?( ID, DOUBLEQUOTED_STRING ) )
          look_90_1 = @input.peek( 2 )

          if ( look_90_1 == DOT )
            alt_90 = 1
          end
        end
        case alt_90
        when 1
          # at line 294:6: exception_package_name DOT
          @state.following.push( TOKENS_FOLLOWING_exception_package_name_IN_exception_name_2073 )
          exception_package_name379 = exception_package_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, exception_package_name379.tree )
          end
          __DOT380__ = match( DOT, TOKENS_FOLLOWING_DOT_IN_exception_name_2075 )
          if @state.backtracking == 0

            tree_for_DOT380 = @adaptor.create_with_payload( __DOT380__ )
            @adaptor.add_child( root_0, tree_for_DOT380 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_identifier_IN_exception_name_2080 )
        identifier381 = identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, identifier381.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 39 )
        memoize( __method__, exception_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExceptionPackageNameReturnValue = define_return_scope 

    # 
    # parser rule exception_package_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 297:1: exception_package_name : identifier ;
    # 
    def exception_package_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 40 )
      return_value = ExceptionPackageNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      exception_package_name_start_index = @input.index

      root_0 = nil
      identifier382 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 298:4: identifier
        @state.following.push( TOKENS_FOLLOWING_identifier_IN_exception_package_name_2091 )
        identifier382 = identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, identifier382.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 40 )
        memoize( __method__, exception_package_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    RecordDeclarationReturnValue = define_return_scope 

    # 
    # parser rule record_declaration
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 307:1: record_declaration : record_type_dec ;
    # 
    def record_declaration
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 41 )
      return_value = RecordDeclarationReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      record_declaration_start_index = @input.index

      root_0 = nil
      record_type_dec383 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 308:4: record_type_dec
        @state.following.push( TOKENS_FOLLOWING_record_type_dec_IN_record_declaration_2110 )
        record_type_dec383 = record_type_dec
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, record_type_dec383.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 41 )
        memoize( __method__, record_declaration_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    RecordTypeDecReturnValue = define_return_scope 

    # 
    # parser rule record_type_dec
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 312:1: record_type_dec : keyTYPE type_name 'IS' keyRECORD LPAREN field_specs RPAREN SEMI ;
    # 
    def record_type_dec
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 42 )
      return_value = RecordTypeDecReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      record_type_dec_start_index = @input.index

      root_0 = nil
      string_literal386 = nil
      __LPAREN388__ = nil
      __RPAREN390__ = nil
      __SEMI391__ = nil
      keyTYPE384 = nil
      type_name385 = nil
      keyRECORD387 = nil
      field_specs389 = nil

      tree_for_string_literal386 = nil
      tree_for_LPAREN388 = nil
      tree_for_RPAREN390 = nil
      tree_for_SEMI391 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 313:4: keyTYPE type_name 'IS' keyRECORD LPAREN field_specs RPAREN SEMI
        @state.following.push( TOKENS_FOLLOWING_keyTYPE_IN_record_type_dec_2123 )
        keyTYPE384 = keyTYPE
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyTYPE384.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_type_name_IN_record_type_dec_2125 )
        type_name385 = type_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, type_name385.tree )
        end
        string_literal386 = match( T__52, TOKENS_FOLLOWING_T__52_IN_record_type_dec_2127 )
        if @state.backtracking == 0

          tree_for_string_literal386 = @adaptor.create_with_payload( string_literal386 )
          @adaptor.add_child( root_0, tree_for_string_literal386 )

        end
        @state.following.push( TOKENS_FOLLOWING_keyRECORD_IN_record_type_dec_2129 )
        keyRECORD387 = keyRECORD
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyRECORD387.tree )
        end
        __LPAREN388__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_record_type_dec_2134 )
        if @state.backtracking == 0

          tree_for_LPAREN388 = @adaptor.create_with_payload( __LPAREN388__ )
          @adaptor.add_child( root_0, tree_for_LPAREN388 )

        end
        @state.following.push( TOKENS_FOLLOWING_field_specs_IN_record_type_dec_2136 )
        field_specs389 = field_specs
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, field_specs389.tree )
        end
        __RPAREN390__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_record_type_dec_2138 )
        if @state.backtracking == 0

          tree_for_RPAREN390 = @adaptor.create_with_payload( __RPAREN390__ )
          @adaptor.add_child( root_0, tree_for_RPAREN390 )

        end
        __SEMI391__ = match( SEMI, TOKENS_FOLLOWING_SEMI_IN_record_type_dec_2140 )
        if @state.backtracking == 0

          tree_for_SEMI391 = @adaptor.create_with_payload( __SEMI391__ )
          @adaptor.add_child( root_0, tree_for_SEMI391 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 42 )
        memoize( __method__, record_type_dec_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    FieldSpecsReturnValue = define_return_scope 

    # 
    # parser rule field_specs
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 321:1: field_specs : field_spec ( COMMA field_spec )* ;
    # 
    def field_specs
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 43 )
      return_value = FieldSpecsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      field_specs_start_index = @input.index

      root_0 = nil
      __COMMA393__ = nil
      field_spec392 = nil
      field_spec394 = nil

      tree_for_COMMA393 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 322:4: field_spec ( COMMA field_spec )*
        @state.following.push( TOKENS_FOLLOWING_field_spec_IN_field_specs_2155 )
        field_spec392 = field_spec
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, field_spec392.tree )
        end
        # at line 322:15: ( COMMA field_spec )*
        while true # decision 91
          alt_91 = 2
          look_91_0 = @input.peek( 1 )

          if ( look_91_0 == COMMA )
            alt_91 = 1

          end
          case alt_91
          when 1
            # at line 322:17: COMMA field_spec
            __COMMA393__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_field_specs_2159 )
            if @state.backtracking == 0

              tree_for_COMMA393 = @adaptor.create_with_payload( __COMMA393__ )
              @adaptor.add_child( root_0, tree_for_COMMA393 )

            end
            @state.following.push( TOKENS_FOLLOWING_field_spec_IN_field_specs_2161 )
            field_spec394 = field_spec
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, field_spec394.tree )
            end

          else
            break # out of loop for decision 91
          end
        end # loop for decision 91
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 43 )
        memoize( __method__, field_specs_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    FieldSpecReturnValue = define_return_scope 

    # 
    # parser rule field_spec
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 324:1: field_spec : column_name type_spec ( 'NOT' 'NULL' )? ( ( ASSIGN | 'DEFAULT' ) plsql_expression )? ;
    # 
    def field_spec
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 44 )
      return_value = FieldSpecReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      field_spec_start_index = @input.index

      root_0 = nil
      string_literal397 = nil
      string_literal398 = nil
      set399 = nil
      column_name395 = nil
      type_spec396 = nil
      plsql_expression400 = nil

      tree_for_string_literal397 = nil
      tree_for_string_literal398 = nil
      tree_for_set399 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 325:4: column_name type_spec ( 'NOT' 'NULL' )? ( ( ASSIGN | 'DEFAULT' ) plsql_expression )?
        @state.following.push( TOKENS_FOLLOWING_column_name_IN_field_spec_2174 )
        column_name395 = column_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, column_name395.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_type_spec_IN_field_spec_2176 )
        type_spec396 = type_spec
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, type_spec396.tree )
        end
        # at line 326:3: ( 'NOT' 'NULL' )?
        alt_92 = 2
        look_92_0 = @input.peek( 1 )

        if ( look_92_0 == T__57 )
          alt_92 = 1
        end
        case alt_92
        when 1
          # at line 326:4: 'NOT' 'NULL'
          string_literal397 = match( T__57, TOKENS_FOLLOWING_T__57_IN_field_spec_2181 )
          if @state.backtracking == 0

            tree_for_string_literal397 = @adaptor.create_with_payload( string_literal397 )
            @adaptor.add_child( root_0, tree_for_string_literal397 )

          end
          string_literal398 = match( T__58, TOKENS_FOLLOWING_T__58_IN_field_spec_2183 )
          if @state.backtracking == 0

            tree_for_string_literal398 = @adaptor.create_with_payload( string_literal398 )
            @adaptor.add_child( root_0, tree_for_string_literal398 )

          end

        end
        # at line 327:3: ( ( ASSIGN | 'DEFAULT' ) plsql_expression )?
        alt_93 = 2
        look_93_0 = @input.peek( 1 )

        if ( look_93_0 == ASSIGN || look_93_0 == T__59 )
          alt_93 = 1
        end
        case alt_93
        when 1
          # at line 327:5: ( ASSIGN | 'DEFAULT' ) plsql_expression
          set399 = @input.look
          if @input.peek(1) == ASSIGN || @input.peek(1) == T__59
            @input.consume
            if @state.backtracking == 0
              @adaptor.add_child( root_0, @adaptor.create_with_payload( set399 ) )
            end
            @state.error_recovery = false
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            mse = MismatchedSet( nil )
            raise mse
          end


          @state.following.push( TOKENS_FOLLOWING_plsql_expression_IN_field_spec_2202 )
          plsql_expression400 = plsql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, plsql_expression400.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 44 )
        memoize( __method__, field_spec_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    PlsqlTableDeclarationReturnValue = define_return_scope 

    # 
    # parser rule plsql_table_declaration
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 330:1: plsql_table_declaration : table_type_dec ;
    # 
    def plsql_table_declaration
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 45 )
      return_value = PlsqlTableDeclarationReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      plsql_table_declaration_start_index = @input.index

      root_0 = nil
      table_type_dec401 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 331:4: table_type_dec
        @state.following.push( TOKENS_FOLLOWING_table_type_dec_IN_plsql_table_declaration_2215 )
        table_type_dec401 = table_type_dec
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, table_type_dec401.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 45 )
        memoize( __method__, plsql_table_declaration_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    TableTypeDecReturnValue = define_return_scope 

    # 
    # parser rule table_type_dec
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 335:1: table_type_dec : keyTYPE type_name 'IS' 'TABLE' 'OF' type_spec ( 'NOT' 'NULL' )? ( 'INDEX' 'BY' ( 'BINARY_INTEGER' | 'PLS_INTEGER' | 'VARCHAR2' LPAREN integer RPAREN ) )? SEMI ;
    # 
    def table_type_dec
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 46 )
      return_value = TableTypeDecReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      table_type_dec_start_index = @input.index

      root_0 = nil
      string_literal404 = nil
      string_literal405 = nil
      string_literal406 = nil
      string_literal408 = nil
      string_literal409 = nil
      string_literal410 = nil
      string_literal411 = nil
      string_literal412 = nil
      string_literal413 = nil
      string_literal414 = nil
      __LPAREN415__ = nil
      __RPAREN417__ = nil
      __SEMI418__ = nil
      keyTYPE402 = nil
      type_name403 = nil
      type_spec407 = nil
      integer416 = nil

      tree_for_string_literal404 = nil
      tree_for_string_literal405 = nil
      tree_for_string_literal406 = nil
      tree_for_string_literal408 = nil
      tree_for_string_literal409 = nil
      tree_for_string_literal410 = nil
      tree_for_string_literal411 = nil
      tree_for_string_literal412 = nil
      tree_for_string_literal413 = nil
      tree_for_string_literal414 = nil
      tree_for_LPAREN415 = nil
      tree_for_RPAREN417 = nil
      tree_for_SEMI418 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 336:4: keyTYPE type_name 'IS' 'TABLE' 'OF' type_spec ( 'NOT' 'NULL' )? ( 'INDEX' 'BY' ( 'BINARY_INTEGER' | 'PLS_INTEGER' | 'VARCHAR2' LPAREN integer RPAREN ) )? SEMI
        @state.following.push( TOKENS_FOLLOWING_keyTYPE_IN_table_type_dec_2227 )
        keyTYPE402 = keyTYPE
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyTYPE402.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_type_name_IN_table_type_dec_2229 )
        type_name403 = type_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, type_name403.tree )
        end
        string_literal404 = match( T__52, TOKENS_FOLLOWING_T__52_IN_table_type_dec_2231 )
        if @state.backtracking == 0

          tree_for_string_literal404 = @adaptor.create_with_payload( string_literal404 )
          @adaptor.add_child( root_0, tree_for_string_literal404 )

        end
        string_literal405 = match( T__105, TOKENS_FOLLOWING_T__105_IN_table_type_dec_2233 )
        if @state.backtracking == 0

          tree_for_string_literal405 = @adaptor.create_with_payload( string_literal405 )
          @adaptor.add_child( root_0, tree_for_string_literal405 )

        end
        string_literal406 = match( T__106, TOKENS_FOLLOWING_T__106_IN_table_type_dec_2238 )
        if @state.backtracking == 0

          tree_for_string_literal406 = @adaptor.create_with_payload( string_literal406 )
          @adaptor.add_child( root_0, tree_for_string_literal406 )

        end
        @state.following.push( TOKENS_FOLLOWING_type_spec_IN_table_type_dec_2240 )
        type_spec407 = type_spec
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, type_spec407.tree )
        end
        # at line 337:18: ( 'NOT' 'NULL' )?
        alt_94 = 2
        look_94_0 = @input.peek( 1 )

        if ( look_94_0 == T__57 )
          alt_94 = 1
        end
        case alt_94
        when 1
          # at line 337:20: 'NOT' 'NULL'
          string_literal408 = match( T__57, TOKENS_FOLLOWING_T__57_IN_table_type_dec_2244 )
          if @state.backtracking == 0

            tree_for_string_literal408 = @adaptor.create_with_payload( string_literal408 )
            @adaptor.add_child( root_0, tree_for_string_literal408 )

          end
          string_literal409 = match( T__58, TOKENS_FOLLOWING_T__58_IN_table_type_dec_2246 )
          if @state.backtracking == 0

            tree_for_string_literal409 = @adaptor.create_with_payload( string_literal409 )
            @adaptor.add_child( root_0, tree_for_string_literal409 )

          end

        end
        # at line 338:3: ( 'INDEX' 'BY' ( 'BINARY_INTEGER' | 'PLS_INTEGER' | 'VARCHAR2' LPAREN integer RPAREN ) )?
        alt_96 = 2
        look_96_0 = @input.peek( 1 )

        if ( look_96_0 == T__107 )
          alt_96 = 1
        end
        case alt_96
        when 1
          # at line 338:5: 'INDEX' 'BY' ( 'BINARY_INTEGER' | 'PLS_INTEGER' | 'VARCHAR2' LPAREN integer RPAREN )
          string_literal410 = match( T__107, TOKENS_FOLLOWING_T__107_IN_table_type_dec_2255 )
          if @state.backtracking == 0

            tree_for_string_literal410 = @adaptor.create_with_payload( string_literal410 )
            @adaptor.add_child( root_0, tree_for_string_literal410 )

          end
          string_literal411 = match( T__108, TOKENS_FOLLOWING_T__108_IN_table_type_dec_2257 )
          if @state.backtracking == 0

            tree_for_string_literal411 = @adaptor.create_with_payload( string_literal411 )
            @adaptor.add_child( root_0, tree_for_string_literal411 )

          end
          # at line 339:4: ( 'BINARY_INTEGER' | 'PLS_INTEGER' | 'VARCHAR2' LPAREN integer RPAREN )
          alt_95 = 3
          case look_95 = @input.peek( 1 )
          when T__64 then alt_95 = 1
          when T__95 then alt_95 = 2
          when T__89 then alt_95 = 3
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 95, 0 )
          end
          case alt_95
          when 1
            # at line 339:6: 'BINARY_INTEGER'
            string_literal412 = match( T__64, TOKENS_FOLLOWING_T__64_IN_table_type_dec_2265 )
            if @state.backtracking == 0

              tree_for_string_literal412 = @adaptor.create_with_payload( string_literal412 )
              @adaptor.add_child( root_0, tree_for_string_literal412 )

            end

          when 2
            # at line 340:6: 'PLS_INTEGER'
            string_literal413 = match( T__95, TOKENS_FOLLOWING_T__95_IN_table_type_dec_2272 )
            if @state.backtracking == 0

              tree_for_string_literal413 = @adaptor.create_with_payload( string_literal413 )
              @adaptor.add_child( root_0, tree_for_string_literal413 )

            end

          when 3
            # at line 341:6: 'VARCHAR2' LPAREN integer RPAREN
            string_literal414 = match( T__89, TOKENS_FOLLOWING_T__89_IN_table_type_dec_2279 )
            if @state.backtracking == 0

              tree_for_string_literal414 = @adaptor.create_with_payload( string_literal414 )
              @adaptor.add_child( root_0, tree_for_string_literal414 )

            end
            __LPAREN415__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_table_type_dec_2281 )
            if @state.backtracking == 0

              tree_for_LPAREN415 = @adaptor.create_with_payload( __LPAREN415__ )
              @adaptor.add_child( root_0, tree_for_LPAREN415 )

            end
            @state.following.push( TOKENS_FOLLOWING_integer_IN_table_type_dec_2283 )
            integer416 = integer
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, integer416.tree )
            end
            __RPAREN417__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_table_type_dec_2285 )
            if @state.backtracking == 0

              tree_for_RPAREN417 = @adaptor.create_with_payload( __RPAREN417__ )
              @adaptor.add_child( root_0, tree_for_RPAREN417 )

            end

          end

        end
        __SEMI418__ = match( SEMI, TOKENS_FOLLOWING_SEMI_IN_table_type_dec_2299 )
        if @state.backtracking == 0

          tree_for_SEMI418 = @adaptor.create_with_payload( __SEMI418__ )
          @adaptor.add_child( root_0, tree_for_SEMI418 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 46 )
        memoize( __method__, table_type_dec_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    TableVarDecReturnValue = define_return_scope 

    # 
    # parser rule table_var_dec
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 347:1: table_var_dec : plsql_table_name type_name SEMI ;
    # 
    def table_var_dec
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 47 )
      return_value = TableVarDecReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      table_var_dec_start_index = @input.index

      root_0 = nil
      __SEMI421__ = nil
      plsql_table_name419 = nil
      type_name420 = nil

      tree_for_SEMI421 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 348:4: plsql_table_name type_name SEMI
        @state.following.push( TOKENS_FOLLOWING_plsql_table_name_IN_table_var_dec_2310 )
        plsql_table_name419 = plsql_table_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, plsql_table_name419.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_type_name_IN_table_var_dec_2312 )
        type_name420 = type_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, type_name420.tree )
        end
        __SEMI421__ = match( SEMI, TOKENS_FOLLOWING_SEMI_IN_table_var_dec_2314 )
        if @state.backtracking == 0

          tree_for_SEMI421 = @adaptor.create_with_payload( __SEMI421__ )
          @adaptor.add_child( root_0, tree_for_SEMI421 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 47 )
        memoize( __method__, table_var_dec_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    PlsqlTableNameReturnValue = define_return_scope 

    # 
    # parser rule plsql_table_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 351:1: plsql_table_name : identifier ( DOT identifier )* ;
    # 
    def plsql_table_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 48 )
      return_value = PlsqlTableNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      plsql_table_name_start_index = @input.index

      root_0 = nil
      __DOT423__ = nil
      identifier422 = nil
      identifier424 = nil

      tree_for_DOT423 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 352:4: identifier ( DOT identifier )*
        @state.following.push( TOKENS_FOLLOWING_identifier_IN_plsql_table_name_2325 )
        identifier422 = identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, identifier422.tree )
        end
        # at line 352:15: ( DOT identifier )*
        while true # decision 97
          alt_97 = 2
          look_97_0 = @input.peek( 1 )

          if ( look_97_0 == DOT )
            alt_97 = 1

          end
          case alt_97
          when 1
            # at line 352:17: DOT identifier
            __DOT423__ = match( DOT, TOKENS_FOLLOWING_DOT_IN_plsql_table_name_2329 )
            if @state.backtracking == 0

              tree_for_DOT423 = @adaptor.create_with_payload( __DOT423__ )
              @adaptor.add_child( root_0, tree_for_DOT423 )

            end
            @state.following.push( TOKENS_FOLLOWING_identifier_IN_plsql_table_name_2331 )
            identifier424 = identifier
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, identifier424.tree )
            end

          else
            break # out of loop for decision 97
          end
        end # loop for decision 97
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 48 )
        memoize( __method__, plsql_table_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    VarrayDeclarationReturnValue = define_return_scope 

    # 
    # parser rule varray_declaration
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 355:1: varray_declaration : keyTYPE type_name 'IS' ( keyVARRAY | keyVARYING keyARRAY ) LPAREN integer RPAREN 'OF' type_spec ( 'NOT' 'NULL' )? ;
    # 
    def varray_declaration
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 49 )
      return_value = VarrayDeclarationReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      varray_declaration_start_index = @input.index

      root_0 = nil
      string_literal427 = nil
      __LPAREN431__ = nil
      __RPAREN433__ = nil
      string_literal434 = nil
      string_literal436 = nil
      string_literal437 = nil
      keyTYPE425 = nil
      type_name426 = nil
      keyVARRAY428 = nil
      keyVARYING429 = nil
      keyARRAY430 = nil
      integer432 = nil
      type_spec435 = nil

      tree_for_string_literal427 = nil
      tree_for_LPAREN431 = nil
      tree_for_RPAREN433 = nil
      tree_for_string_literal434 = nil
      tree_for_string_literal436 = nil
      tree_for_string_literal437 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 356:4: keyTYPE type_name 'IS' ( keyVARRAY | keyVARYING keyARRAY ) LPAREN integer RPAREN 'OF' type_spec ( 'NOT' 'NULL' )?
        @state.following.push( TOKENS_FOLLOWING_keyTYPE_IN_varray_declaration_2345 )
        keyTYPE425 = keyTYPE
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyTYPE425.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_type_name_IN_varray_declaration_2347 )
        type_name426 = type_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, type_name426.tree )
        end
        string_literal427 = match( T__52, TOKENS_FOLLOWING_T__52_IN_varray_declaration_2349 )
        if @state.backtracking == 0

          tree_for_string_literal427 = @adaptor.create_with_payload( string_literal427 )
          @adaptor.add_child( root_0, tree_for_string_literal427 )

        end
        # at line 357:3: ( keyVARRAY | keyVARYING keyARRAY )
        alt_98 = 2
        look_98_0 = @input.peek( 1 )

        if ( look_98_0 == ID )
          look_98_1 = @input.peek( 2 )

          if ( look_98_1 == LPAREN )
            alt_98 = 1
          elsif ( look_98_1 == ID )
            alt_98 = 2
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 98, 1 )
          end
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 98, 0 )
        end
        case alt_98
        when 1
          # at line 357:5: keyVARRAY
          @state.following.push( TOKENS_FOLLOWING_keyVARRAY_IN_varray_declaration_2356 )
          keyVARRAY428 = keyVARRAY
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyVARRAY428.tree )
          end

        when 2
          # at line 357:17: keyVARYING keyARRAY
          @state.following.push( TOKENS_FOLLOWING_keyVARYING_IN_varray_declaration_2360 )
          keyVARYING429 = keyVARYING
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyVARYING429.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_keyARRAY_IN_varray_declaration_2362 )
          keyARRAY430 = keyARRAY
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyARRAY430.tree )
          end

        end
        __LPAREN431__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_varray_declaration_2366 )
        if @state.backtracking == 0

          tree_for_LPAREN431 = @adaptor.create_with_payload( __LPAREN431__ )
          @adaptor.add_child( root_0, tree_for_LPAREN431 )

        end
        @state.following.push( TOKENS_FOLLOWING_integer_IN_varray_declaration_2368 )
        integer432 = integer
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, integer432.tree )
        end
        __RPAREN433__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_varray_declaration_2370 )
        if @state.backtracking == 0

          tree_for_RPAREN433 = @adaptor.create_with_payload( __RPAREN433__ )
          @adaptor.add_child( root_0, tree_for_RPAREN433 )

        end
        string_literal434 = match( T__106, TOKENS_FOLLOWING_T__106_IN_varray_declaration_2374 )
        if @state.backtracking == 0

          tree_for_string_literal434 = @adaptor.create_with_payload( string_literal434 )
          @adaptor.add_child( root_0, tree_for_string_literal434 )

        end
        @state.following.push( TOKENS_FOLLOWING_type_spec_IN_varray_declaration_2376 )
        type_spec435 = type_spec
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, type_spec435.tree )
        end
        # at line 358:18: ( 'NOT' 'NULL' )?
        alt_99 = 2
        look_99_0 = @input.peek( 1 )

        if ( look_99_0 == T__57 )
          alt_99 = 1
        end
        case alt_99
        when 1
          # at line 358:20: 'NOT' 'NULL'
          string_literal436 = match( T__57, TOKENS_FOLLOWING_T__57_IN_varray_declaration_2380 )
          if @state.backtracking == 0

            tree_for_string_literal436 = @adaptor.create_with_payload( string_literal436 )
            @adaptor.add_child( root_0, tree_for_string_literal436 )

          end
          string_literal437 = match( T__58, TOKENS_FOLLOWING_T__58_IN_varray_declaration_2382 )
          if @state.backtracking == 0

            tree_for_string_literal437 = @adaptor.create_with_payload( string_literal437 )
            @adaptor.add_child( root_0, tree_for_string_literal437 )

          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 49 )
        memoize( __method__, varray_declaration_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ProcedureDeclarationReturnValue = define_return_scope 

    # 
    # parser rule procedure_declaration
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 361:1: procedure_declaration : procedure_body ;
    # 
    def procedure_declaration
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 50 )
      return_value = ProcedureDeclarationReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      procedure_declaration_start_index = @input.index

      root_0 = nil
      procedure_body438 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 362:4: procedure_body
        @state.following.push( TOKENS_FOLLOWING_procedure_body_IN_procedure_declaration_2396 )
        procedure_body438 = procedure_body
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, procedure_body438.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 50 )
        memoize( __method__, procedure_declaration_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ProcedureBodyReturnValue = define_return_scope 

    # 
    # parser rule procedure_body
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 365:1: procedure_body : ( proc_fun_start )? 'PROCEDURE' procedure_name ( LPAREN argument ( COMMA argument )* RPAREN )? ( 'IS' | 'AS' ) ( ( declare_spec )=> ( declare_spec )* ) ( 'BEGIN' ) ( seq_of_statements ) ( 'EXCEPTION' ( exception_handler )* )? 'END' ( procedure_name )? SEMI ;
    # 
    def procedure_body
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 51 )
      return_value = ProcedureBodyReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      procedure_body_start_index = @input.index

      root_0 = nil
      string_literal440 = nil
      __LPAREN442__ = nil
      __COMMA444__ = nil
      __RPAREN446__ = nil
      set447 = nil
      string_literal449 = nil
      string_literal451 = nil
      string_literal453 = nil
      __SEMI455__ = nil
      proc_fun_start439 = nil
      procedure_name441 = nil
      argument443 = nil
      argument445 = nil
      declare_spec448 = nil
      seq_of_statements450 = nil
      exception_handler452 = nil
      procedure_name454 = nil

      tree_for_string_literal440 = nil
      tree_for_LPAREN442 = nil
      tree_for_COMMA444 = nil
      tree_for_RPAREN446 = nil
      tree_for_set447 = nil
      tree_for_string_literal449 = nil
      tree_for_string_literal451 = nil
      tree_for_string_literal453 = nil
      tree_for_SEMI455 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 366:4: ( proc_fun_start )? 'PROCEDURE' procedure_name ( LPAREN argument ( COMMA argument )* RPAREN )? ( 'IS' | 'AS' ) ( ( declare_spec )=> ( declare_spec )* ) ( 'BEGIN' ) ( seq_of_statements ) ( 'EXCEPTION' ( exception_handler )* )? 'END' ( procedure_name )? SEMI
        # at line 366:4: ( proc_fun_start )?
        alt_100 = 2
        look_100_0 = @input.peek( 1 )

        if ( look_100_0 == T__50 )
          alt_100 = 1
        end
        case alt_100
        when 1
          # at line 366:6: proc_fun_start
          @state.following.push( TOKENS_FOLLOWING_proc_fun_start_IN_procedure_body_2409 )
          proc_fun_start439 = proc_fun_start
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, proc_fun_start439.tree )
          end

        end
        string_literal440 = match( T__103, TOKENS_FOLLOWING_T__103_IN_procedure_body_2414 )
        if @state.backtracking == 0

          tree_for_string_literal440 = @adaptor.create_with_payload( string_literal440 )
          root_0 = @adaptor.become_root( tree_for_string_literal440, root_0 )

        end
        @state.following.push( TOKENS_FOLLOWING_procedure_name_IN_procedure_body_2417 )
        procedure_name441 = procedure_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, procedure_name441.tree )
        end
        # at line 367:3: ( LPAREN argument ( COMMA argument )* RPAREN )?
        alt_102 = 2
        look_102_0 = @input.peek( 1 )

        if ( look_102_0 == LPAREN )
          alt_102 = 1
        end
        case alt_102
        when 1
          # at line 367:5: LPAREN argument ( COMMA argument )* RPAREN
          __LPAREN442__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_procedure_body_2424 )
          if @state.backtracking == 0

            tree_for_LPAREN442 = @adaptor.create_with_payload( __LPAREN442__ )
            @adaptor.add_child( root_0, tree_for_LPAREN442 )

          end
          @state.following.push( TOKENS_FOLLOWING_argument_IN_procedure_body_2426 )
          argument443 = argument
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, argument443.tree )
          end
          # at line 367:21: ( COMMA argument )*
          while true # decision 101
            alt_101 = 2
            look_101_0 = @input.peek( 1 )

            if ( look_101_0 == COMMA )
              alt_101 = 1

            end
            case alt_101
            when 1
              # at line 367:23: COMMA argument
              __COMMA444__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_procedure_body_2430 )
              if @state.backtracking == 0

                tree_for_COMMA444 = @adaptor.create_with_payload( __COMMA444__ )
                @adaptor.add_child( root_0, tree_for_COMMA444 )

              end
              @state.following.push( TOKENS_FOLLOWING_argument_IN_procedure_body_2432 )
              argument445 = argument
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, argument445.tree )
              end

            else
              break # out of loop for decision 101
            end
          end # loop for decision 101
          __RPAREN446__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_procedure_body_2437 )
          if @state.backtracking == 0

            tree_for_RPAREN446 = @adaptor.create_with_payload( __RPAREN446__ )
            @adaptor.add_child( root_0, tree_for_RPAREN446 )

          end

        end
        set447 = @input.look
        if @input.peek( 1 ).between?( T__52, T__53 )
          @input.consume
          if @state.backtracking == 0
            @adaptor.add_child( root_0, @adaptor.create_with_payload( set447 ) )
          end
          @state.error_recovery = false
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          mse = MismatchedSet( nil )
          raise mse
        end


        # at line 370:3: ( ( declare_spec )=> ( declare_spec )* )
        # at line 370:5: ( declare_spec )=> ( declare_spec )*
        # at line 370:25: ( declare_spec )*
        while true # decision 103
          alt_103 = 2
          look_103_0 = @input.peek( 1 )

          if ( look_103_0.between?( ID, DOUBLEQUOTED_STRING ) || look_103_0 == T__50 || look_103_0.between?( T__103, T__104 ) || look_103_0 == T__161 )
            alt_103 = 1

          end
          case alt_103
          when 1
            # at line 370:27: declare_spec
            @state.following.push( TOKENS_FOLLOWING_declare_spec_IN_procedure_body_2472 )
            declare_spec448 = declare_spec
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, declare_spec448.tree )
            end

          else
            break # out of loop for decision 103
          end
        end # loop for decision 103

        # at line 371:3: ( 'BEGIN' )
        # at line 371:5: 'BEGIN'
        string_literal449 = match( T__55, TOKENS_FOLLOWING_T__55_IN_procedure_body_2483 )
        if @state.backtracking == 0

          tree_for_string_literal449 = @adaptor.create_with_payload( string_literal449 )
          @adaptor.add_child( root_0, tree_for_string_literal449 )

        end

        # at line 372:3: ( seq_of_statements )
        # at line 372:5: seq_of_statements
        @state.following.push( TOKENS_FOLLOWING_seq_of_statements_IN_procedure_body_2491 )
        seq_of_statements450 = seq_of_statements
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, seq_of_statements450.tree )
        end

        # at line 373:3: ( 'EXCEPTION' ( exception_handler )* )?
        alt_105 = 2
        look_105_0 = @input.peek( 1 )

        if ( look_105_0 == T__61 )
          alt_105 = 1
        end
        case alt_105
        when 1
          # at line 373:5: 'EXCEPTION' ( exception_handler )*
          string_literal451 = match( T__61, TOKENS_FOLLOWING_T__61_IN_procedure_body_2499 )
          if @state.backtracking == 0

            tree_for_string_literal451 = @adaptor.create_with_payload( string_literal451 )
            @adaptor.add_child( root_0, tree_for_string_literal451 )

          end
          # at line 373:17: ( exception_handler )*
          while true # decision 104
            alt_104 = 2
            look_104_0 = @input.peek( 1 )

            if ( look_104_0 == T__63 )
              alt_104 = 1

            end
            case alt_104
            when 1
              # at line 373:19: exception_handler
              @state.following.push( TOKENS_FOLLOWING_exception_handler_IN_procedure_body_2503 )
              exception_handler452 = exception_handler
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, exception_handler452.tree )
              end

            else
              break # out of loop for decision 104
            end
          end # loop for decision 104

        end
        string_literal453 = match( T__54, TOKENS_FOLLOWING_T__54_IN_procedure_body_2513 )
        if @state.backtracking == 0

          tree_for_string_literal453 = @adaptor.create_with_payload( string_literal453 )
          @adaptor.add_child( root_0, tree_for_string_literal453 )

        end
        # at line 374:9: ( procedure_name )?
        alt_106 = 2
        look_106_0 = @input.peek( 1 )

        if ( look_106_0 == QUOTED_STRING || look_106_0.between?( ID, DOUBLEQUOTED_STRING ) )
          alt_106 = 1
        end
        case alt_106
        when 1
          # at line 374:11: procedure_name
          @state.following.push( TOKENS_FOLLOWING_procedure_name_IN_procedure_body_2517 )
          procedure_name454 = procedure_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, procedure_name454.tree )
          end

        end
        __SEMI455__ = match( SEMI, TOKENS_FOLLOWING_SEMI_IN_procedure_body_2522 )
        if @state.backtracking == 0

          tree_for_SEMI455 = @adaptor.create_with_payload( __SEMI455__ )
          @adaptor.add_child( root_0, tree_for_SEMI455 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 51 )
        memoize( __method__, procedure_body_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    BeginBlockReturnValue = define_return_scope 

    # 
    # parser rule begin_block
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 377:1: begin_block : 'BEGIN' ( seq_of_statements ) ( 'EXCEPTION' ( exception_handler )+ )? 'END' ;
    # 
    def begin_block
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 52 )
      return_value = BeginBlockReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      begin_block_start_index = @input.index

      root_0 = nil
      string_literal456 = nil
      string_literal458 = nil
      string_literal460 = nil
      seq_of_statements457 = nil
      exception_handler459 = nil

      tree_for_string_literal456 = nil
      tree_for_string_literal458 = nil
      tree_for_string_literal460 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 378:4: 'BEGIN' ( seq_of_statements ) ( 'EXCEPTION' ( exception_handler )+ )? 'END'
        string_literal456 = match( T__55, TOKENS_FOLLOWING_T__55_IN_begin_block_2533 )
        if @state.backtracking == 0

          tree_for_string_literal456 = @adaptor.create_with_payload( string_literal456 )
          @adaptor.add_child( root_0, tree_for_string_literal456 )

        end
        # at line 379:3: ( seq_of_statements )
        # at line 379:5: seq_of_statements
        @state.following.push( TOKENS_FOLLOWING_seq_of_statements_IN_begin_block_2539 )
        seq_of_statements457 = seq_of_statements
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, seq_of_statements457.tree )
        end

        # at line 380:3: ( 'EXCEPTION' ( exception_handler )+ )?
        alt_108 = 2
        look_108_0 = @input.peek( 1 )

        if ( look_108_0 == T__61 )
          alt_108 = 1
        end
        case alt_108
        when 1
          # at line 380:5: 'EXCEPTION' ( exception_handler )+
          string_literal458 = match( T__61, TOKENS_FOLLOWING_T__61_IN_begin_block_2547 )
          if @state.backtracking == 0

            tree_for_string_literal458 = @adaptor.create_with_payload( string_literal458 )
            @adaptor.add_child( root_0, tree_for_string_literal458 )

          end
          # at file 380:17: ( exception_handler )+
          match_count_107 = 0
          while true
            alt_107 = 2
            look_107_0 = @input.peek( 1 )

            if ( look_107_0 == T__63 )
              alt_107 = 1

            end
            case alt_107
            when 1
              # at line 380:19: exception_handler
              @state.following.push( TOKENS_FOLLOWING_exception_handler_IN_begin_block_2551 )
              exception_handler459 = exception_handler
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, exception_handler459.tree )
              end

            else
              match_count_107 > 0 and break
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              eee = EarlyExit(107)


              raise eee
            end
            match_count_107 += 1
          end


        end
        string_literal460 = match( T__54, TOKENS_FOLLOWING_T__54_IN_begin_block_2561 )
        if @state.backtracking == 0

          tree_for_string_literal460 = @adaptor.create_with_payload( string_literal460 )
          @adaptor.add_child( root_0, tree_for_string_literal460 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 52 )
        memoize( __method__, begin_block_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExceptionHandlerReturnValue = define_return_scope 

    # 
    # parser rule exception_handler
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 385:1: exception_handler : 'WHEN' exception_names 'THEN' seq_of_statements ;
    # 
    def exception_handler
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 53 )
      return_value = ExceptionHandlerReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      exception_handler_start_index = @input.index

      root_0 = nil
      string_literal461 = nil
      string_literal463 = nil
      exception_names462 = nil
      seq_of_statements464 = nil

      tree_for_string_literal461 = nil
      tree_for_string_literal463 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 386:4: 'WHEN' exception_names 'THEN' seq_of_statements
        string_literal461 = match( T__63, TOKENS_FOLLOWING_T__63_IN_exception_handler_2573 )
        if @state.backtracking == 0

          tree_for_string_literal461 = @adaptor.create_with_payload( string_literal461 )
          @adaptor.add_child( root_0, tree_for_string_literal461 )

        end
        @state.following.push( TOKENS_FOLLOWING_exception_names_IN_exception_handler_2575 )
        exception_names462 = exception_names
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, exception_names462.tree )
        end
        string_literal463 = match( T__109, TOKENS_FOLLOWING_T__109_IN_exception_handler_2577 )
        if @state.backtracking == 0

          tree_for_string_literal463 = @adaptor.create_with_payload( string_literal463 )
          @adaptor.add_child( root_0, tree_for_string_literal463 )

        end
        @state.following.push( TOKENS_FOLLOWING_seq_of_statements_IN_exception_handler_2581 )
        seq_of_statements464 = seq_of_statements
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, seq_of_statements464.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 53 )
        memoize( __method__, exception_handler_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ProcFunStartReturnValue = define_return_scope 

    # 
    # parser rule proc_fun_start
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 390:1: proc_fun_start : 'CREATE' ( 'OR' keyREPLACE )? ;
    # 
    def proc_fun_start
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 54 )
      return_value = ProcFunStartReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      proc_fun_start_start_index = @input.index

      root_0 = nil
      string_literal465 = nil
      string_literal466 = nil
      keyREPLACE467 = nil

      tree_for_string_literal465 = nil
      tree_for_string_literal466 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 391:4: 'CREATE' ( 'OR' keyREPLACE )?
        string_literal465 = match( T__50, TOKENS_FOLLOWING_T__50_IN_proc_fun_start_2592 )
        if @state.backtracking == 0

          tree_for_string_literal465 = @adaptor.create_with_payload( string_literal465 )
          @adaptor.add_child( root_0, tree_for_string_literal465 )

        end
        # at line 391:13: ( 'OR' keyREPLACE )?
        alt_109 = 2
        look_109_0 = @input.peek( 1 )

        if ( look_109_0 == T__51 )
          alt_109 = 1
        end
        case alt_109
        when 1
          # at line 391:15: 'OR' keyREPLACE
          string_literal466 = match( T__51, TOKENS_FOLLOWING_T__51_IN_proc_fun_start_2596 )
          if @state.backtracking == 0

            tree_for_string_literal466 = @adaptor.create_with_payload( string_literal466 )
            @adaptor.add_child( root_0, tree_for_string_literal466 )

          end
          @state.following.push( TOKENS_FOLLOWING_keyREPLACE_IN_proc_fun_start_2598 )
          keyREPLACE467 = keyREPLACE
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyREPLACE467.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 54 )
        memoize( __method__, proc_fun_start_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    FunctionBodyReturnValue = define_return_scope 

    # 
    # parser rule function_body
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 394:1: function_body : ( proc_fun_start )? 'FUNCTION' function_name ( LPAREN arguments RPAREN )? keyRETURN return_type ( 'IS' | 'AS' ) ( ( declare_spec )=> ( declare_spec )* ) ( 'BEGIN' ) ( seq_of_statements ) ( 'EXCEPTION' ( exception_handler )+ )? 'END' ( function_name )? SEMI ;
    # 
    def function_body
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 55 )
      return_value = FunctionBodyReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      function_body_start_index = @input.index

      root_0 = nil
      string_literal469 = nil
      __LPAREN471__ = nil
      __RPAREN473__ = nil
      set476 = nil
      string_literal478 = nil
      string_literal480 = nil
      string_literal482 = nil
      __SEMI484__ = nil
      proc_fun_start468 = nil
      function_name470 = nil
      arguments472 = nil
      keyRETURN474 = nil
      return_type475 = nil
      declare_spec477 = nil
      seq_of_statements479 = nil
      exception_handler481 = nil
      function_name483 = nil

      tree_for_string_literal469 = nil
      tree_for_LPAREN471 = nil
      tree_for_RPAREN473 = nil
      tree_for_set476 = nil
      tree_for_string_literal478 = nil
      tree_for_string_literal480 = nil
      tree_for_string_literal482 = nil
      tree_for_SEMI484 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 395:4: ( proc_fun_start )? 'FUNCTION' function_name ( LPAREN arguments RPAREN )? keyRETURN return_type ( 'IS' | 'AS' ) ( ( declare_spec )=> ( declare_spec )* ) ( 'BEGIN' ) ( seq_of_statements ) ( 'EXCEPTION' ( exception_handler )+ )? 'END' ( function_name )? SEMI
        # at line 395:4: ( proc_fun_start )?
        alt_110 = 2
        look_110_0 = @input.peek( 1 )

        if ( look_110_0 == T__50 )
          alt_110 = 1
        end
        case alt_110
        when 1
          # at line 395:6: proc_fun_start
          @state.following.push( TOKENS_FOLLOWING_proc_fun_start_IN_function_body_2614 )
          proc_fun_start468 = proc_fun_start
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, proc_fun_start468.tree )
          end

        end
        string_literal469 = match( T__104, TOKENS_FOLLOWING_T__104_IN_function_body_2619 )
        if @state.backtracking == 0

          tree_for_string_literal469 = @adaptor.create_with_payload( string_literal469 )
          root_0 = @adaptor.become_root( tree_for_string_literal469, root_0 )

        end
        @state.following.push( TOKENS_FOLLOWING_function_name_IN_function_body_2622 )
        function_name470 = function_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, function_name470.tree )
        end
        # at line 396:3: ( LPAREN arguments RPAREN )?
        alt_111 = 2
        look_111_0 = @input.peek( 1 )

        if ( look_111_0 == LPAREN )
          alt_111 = 1
        end
        case alt_111
        when 1
          # at line 396:5: LPAREN arguments RPAREN
          __LPAREN471__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_function_body_2629 )
          if @state.backtracking == 0

            tree_for_LPAREN471 = @adaptor.create_with_payload( __LPAREN471__ )
            @adaptor.add_child( root_0, tree_for_LPAREN471 )

          end
          @state.following.push( TOKENS_FOLLOWING_arguments_IN_function_body_2631 )
          arguments472 = arguments
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, arguments472.tree )
          end
          __RPAREN473__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_function_body_2633 )
          if @state.backtracking == 0

            tree_for_RPAREN473 = @adaptor.create_with_payload( __RPAREN473__ )
            @adaptor.add_child( root_0, tree_for_RPAREN473 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_keyRETURN_IN_function_body_2641 )
        keyRETURN474 = keyRETURN
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyRETURN474.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_return_type_IN_function_body_2643 )
        return_type475 = return_type
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, return_type475.tree )
        end
        set476 = @input.look
        if @input.peek( 1 ).between?( T__52, T__53 )
          @input.consume
          if @state.backtracking == 0
            @adaptor.add_child( root_0, @adaptor.create_with_payload( set476 ) )
          end
          @state.error_recovery = false
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          mse = MismatchedSet( nil )
          raise mse
        end


        # at line 399:3: ( ( declare_spec )=> ( declare_spec )* )
        # at line 399:5: ( declare_spec )=> ( declare_spec )*
        # at line 399:25: ( declare_spec )*
        while true # decision 112
          alt_112 = 2
          look_112_0 = @input.peek( 1 )

          if ( look_112_0.between?( ID, DOUBLEQUOTED_STRING ) || look_112_0 == T__50 || look_112_0.between?( T__103, T__104 ) || look_112_0 == T__161 )
            alt_112 = 1

          end
          case alt_112
          when 1
            # at line 399:27: declare_spec
            @state.following.push( TOKENS_FOLLOWING_declare_spec_IN_function_body_2672 )
            declare_spec477 = declare_spec
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, declare_spec477.tree )
            end

          else
            break # out of loop for decision 112
          end
        end # loop for decision 112

        # at line 400:3: ( 'BEGIN' )
        # at line 400:5: 'BEGIN'
        string_literal478 = match( T__55, TOKENS_FOLLOWING_T__55_IN_function_body_2683 )
        if @state.backtracking == 0

          tree_for_string_literal478 = @adaptor.create_with_payload( string_literal478 )
          @adaptor.add_child( root_0, tree_for_string_literal478 )

        end

        # at line 401:3: ( seq_of_statements )
        # at line 401:5: seq_of_statements
        @state.following.push( TOKENS_FOLLOWING_seq_of_statements_IN_function_body_2691 )
        seq_of_statements479 = seq_of_statements
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, seq_of_statements479.tree )
        end

        # at line 402:3: ( 'EXCEPTION' ( exception_handler )+ )?
        alt_114 = 2
        look_114_0 = @input.peek( 1 )

        if ( look_114_0 == T__61 )
          alt_114 = 1
        end
        case alt_114
        when 1
          # at line 402:5: 'EXCEPTION' ( exception_handler )+
          string_literal480 = match( T__61, TOKENS_FOLLOWING_T__61_IN_function_body_2699 )
          if @state.backtracking == 0

            tree_for_string_literal480 = @adaptor.create_with_payload( string_literal480 )
            @adaptor.add_child( root_0, tree_for_string_literal480 )

          end
          # at file 402:17: ( exception_handler )+
          match_count_113 = 0
          while true
            alt_113 = 2
            look_113_0 = @input.peek( 1 )

            if ( look_113_0 == T__63 )
              alt_113 = 1

            end
            case alt_113
            when 1
              # at line 402:19: exception_handler
              @state.following.push( TOKENS_FOLLOWING_exception_handler_IN_function_body_2703 )
              exception_handler481 = exception_handler
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, exception_handler481.tree )
              end

            else
              match_count_113 > 0 and break
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              eee = EarlyExit(113)


              raise eee
            end
            match_count_113 += 1
          end


        end
        string_literal482 = match( T__54, TOKENS_FOLLOWING_T__54_IN_function_body_2713 )
        if @state.backtracking == 0

          tree_for_string_literal482 = @adaptor.create_with_payload( string_literal482 )
          @adaptor.add_child( root_0, tree_for_string_literal482 )

        end
        # at line 403:9: ( function_name )?
        alt_115 = 2
        look_115_0 = @input.peek( 1 )

        if ( look_115_0 == QUOTED_STRING || look_115_0.between?( ID, DOUBLEQUOTED_STRING ) )
          alt_115 = 1
        end
        case alt_115
        when 1
          # at line 403:11: function_name
          @state.following.push( TOKENS_FOLLOWING_function_name_IN_function_body_2717 )
          function_name483 = function_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, function_name483.tree )
          end

        end
        __SEMI484__ = match( SEMI, TOKENS_FOLLOWING_SEMI_IN_function_body_2722 )
        if @state.backtracking == 0

          tree_for_SEMI484 = @adaptor.create_with_payload( __SEMI484__ )
          @adaptor.add_child( root_0, tree_for_SEMI484 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 55 )
        memoize( __method__, function_body_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    FunctionNameReturnValue = define_return_scope 

    # 
    # parser rule function_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 406:1: function_name : ( identifier | QUOTED_STRING );
    # 
    def function_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 56 )
      return_value = FunctionNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      function_name_start_index = @input.index

      root_0 = nil
      __QUOTED_STRING486__ = nil
      identifier485 = nil

      tree_for_QUOTED_STRING486 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 407:2: ( identifier | QUOTED_STRING )
        alt_116 = 2
        look_116_0 = @input.peek( 1 )

        if ( look_116_0.between?( ID, DOUBLEQUOTED_STRING ) )
          alt_116 = 1
        elsif ( look_116_0 == QUOTED_STRING )
          alt_116 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 116, 0 )
        end
        case alt_116
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 407:4: identifier
          @state.following.push( TOKENS_FOLLOWING_identifier_IN_function_name_2733 )
          identifier485 = identifier
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, identifier485.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 407:17: QUOTED_STRING
          __QUOTED_STRING486__ = match( QUOTED_STRING, TOKENS_FOLLOWING_QUOTED_STRING_IN_function_name_2737 )
          if @state.backtracking == 0

            tree_for_QUOTED_STRING486 = @adaptor.create_with_payload( __QUOTED_STRING486__ )
            @adaptor.add_child( root_0, tree_for_QUOTED_STRING486 )

          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 56 )
        memoize( __method__, function_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ProcedureNameReturnValue = define_return_scope 

    # 
    # parser rule procedure_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 410:1: procedure_name : ( identifier | QUOTED_STRING );
    # 
    def procedure_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 57 )
      return_value = ProcedureNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      procedure_name_start_index = @input.index

      root_0 = nil
      __QUOTED_STRING488__ = nil
      identifier487 = nil

      tree_for_QUOTED_STRING488 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 411:2: ( identifier | QUOTED_STRING )
        alt_117 = 2
        look_117_0 = @input.peek( 1 )

        if ( look_117_0.between?( ID, DOUBLEQUOTED_STRING ) )
          alt_117 = 1
        elsif ( look_117_0 == QUOTED_STRING )
          alt_117 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 117, 0 )
        end
        case alt_117
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 411:4: identifier
          @state.following.push( TOKENS_FOLLOWING_identifier_IN_procedure_name_2749 )
          identifier487 = identifier
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, identifier487.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 411:17: QUOTED_STRING
          __QUOTED_STRING488__ = match( QUOTED_STRING, TOKENS_FOLLOWING_QUOTED_STRING_IN_procedure_name_2753 )
          if @state.backtracking == 0

            tree_for_QUOTED_STRING488 = @adaptor.create_with_payload( __QUOTED_STRING488__ )
            @adaptor.add_child( root_0, tree_for_QUOTED_STRING488 )

          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 57 )
        memoize( __method__, procedure_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ArgumentsReturnValue = define_return_scope 

    # 
    # parser rule arguments
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 414:1: arguments : argument ( COMMA argument )* ;
    # 
    def arguments
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 58 )
      return_value = ArgumentsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      arguments_start_index = @input.index

      root_0 = nil
      __COMMA490__ = nil
      argument489 = nil
      argument491 = nil

      tree_for_COMMA490 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 415:4: argument ( COMMA argument )*
        @state.following.push( TOKENS_FOLLOWING_argument_IN_arguments_2765 )
        argument489 = argument
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, argument489.tree )
        end
        # at line 415:13: ( COMMA argument )*
        while true # decision 118
          alt_118 = 2
          look_118_0 = @input.peek( 1 )

          if ( look_118_0 == COMMA )
            alt_118 = 1

          end
          case alt_118
          when 1
            # at line 415:15: COMMA argument
            __COMMA490__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_arguments_2769 )
            if @state.backtracking == 0

              tree_for_COMMA490 = @adaptor.create_with_payload( __COMMA490__ )
              @adaptor.add_child( root_0, tree_for_COMMA490 )

            end
            @state.following.push( TOKENS_FOLLOWING_argument_IN_arguments_2771 )
            argument491 = argument
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, argument491.tree )
            end

          else
            break # out of loop for decision 118
          end
        end # loop for decision 118
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 58 )
        memoize( __method__, arguments_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ArgumentReturnValue = define_return_scope 

    # 
    # parser rule argument
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 418:1: argument : argument_name ( keyOUT | 'IN' keyOUT | 'IN' )? ( argument_type )? ( ( ASSIGN | 'DEFAULT' ) plsql_expression )? ;
    # 
    def argument
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 59 )
      return_value = ArgumentReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      argument_start_index = @input.index

      root_0 = nil
      string_literal494 = nil
      string_literal496 = nil
      set498 = nil
      argument_name492 = nil
      keyOUT493 = nil
      keyOUT495 = nil
      argument_type497 = nil
      plsql_expression499 = nil

      tree_for_string_literal494 = nil
      tree_for_string_literal496 = nil
      tree_for_set498 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 419:4: argument_name ( keyOUT | 'IN' keyOUT | 'IN' )? ( argument_type )? ( ( ASSIGN | 'DEFAULT' ) plsql_expression )?
        @state.following.push( TOKENS_FOLLOWING_argument_name_IN_argument_2785 )
        argument_name492 = argument_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, argument_name492.tree )
        end
        # at line 419:18: ( keyOUT | 'IN' keyOUT | 'IN' )?
        alt_119 = 4
        look_119_0 = @input.peek( 1 )

        if ( look_119_0 == T__159 )
          alt_119 = 1
        elsif ( look_119_0 == T__102 )
          look_119_2 = @input.peek( 2 )

          if ( look_119_2 == EOF || look_119_2 == ASSIGN || look_119_2 == RPAREN || look_119_2 == COMMA || look_119_2.between?( ID, DOUBLEQUOTED_STRING ) || look_119_2 == T__59 || look_119_2.between?( T__64, T__76 ) || look_119_2.between?( T__79, T__86 ) || look_119_2.between?( T__88, T__101 ) )
            alt_119 = 3
          elsif ( look_119_2 == T__159 )
            alt_119 = 2
          end
        end
        case alt_119
        when 1
          # at line 419:20: keyOUT
          @state.following.push( TOKENS_FOLLOWING_keyOUT_IN_argument_2789 )
          keyOUT493 = keyOUT
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyOUT493.tree )
          end

        when 2
          # at line 419:29: 'IN' keyOUT
          string_literal494 = match( T__102, TOKENS_FOLLOWING_T__102_IN_argument_2793 )
          if @state.backtracking == 0

            tree_for_string_literal494 = @adaptor.create_with_payload( string_literal494 )
            @adaptor.add_child( root_0, tree_for_string_literal494 )

          end
          @state.following.push( TOKENS_FOLLOWING_keyOUT_IN_argument_2795 )
          keyOUT495 = keyOUT
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyOUT495.tree )
          end

        when 3
          # at line 419:43: 'IN'
          string_literal496 = match( T__102, TOKENS_FOLLOWING_T__102_IN_argument_2799 )
          if @state.backtracking == 0

            tree_for_string_literal496 = @adaptor.create_with_payload( string_literal496 )
            @adaptor.add_child( root_0, tree_for_string_literal496 )

          end

        end
        # at line 419:51: ( argument_type )?
        alt_120 = 2
        look_120_0 = @input.peek( 1 )

        if ( look_120_0.between?( ID, DOUBLEQUOTED_STRING ) || look_120_0.between?( T__64, T__76 ) || look_120_0.between?( T__79, T__86 ) || look_120_0.between?( T__88, T__101 ) )
          alt_120 = 1
        end
        case alt_120
        when 1
          # at line 419:52: argument_type
          @state.following.push( TOKENS_FOLLOWING_argument_type_IN_argument_2805 )
          argument_type497 = argument_type
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, argument_type497.tree )
          end

        end
        # at line 420:3: ( ( ASSIGN | 'DEFAULT' ) plsql_expression )?
        alt_121 = 2
        look_121_0 = @input.peek( 1 )

        if ( look_121_0 == ASSIGN || look_121_0 == T__59 )
          alt_121 = 1
        end
        case alt_121
        when 1
          # at line 420:5: ( ASSIGN | 'DEFAULT' ) plsql_expression
          set498 = @input.look
          if @input.peek(1) == ASSIGN || @input.peek(1) == T__59
            @input.consume
            if @state.backtracking == 0
              @adaptor.add_child( root_0, @adaptor.create_with_payload( set498 ) )
            end
            @state.error_recovery = false
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            mse = MismatchedSet( nil )
            raise mse
          end


          @state.following.push( TOKENS_FOLLOWING_plsql_expression_IN_argument_2824 )
          plsql_expression499 = plsql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, plsql_expression499.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 59 )
        memoize( __method__, argument_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ArgumentNameReturnValue = define_return_scope 

    # 
    # parser rule argument_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 423:1: argument_name : identifier ;
    # 
    def argument_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 60 )
      return_value = ArgumentNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      argument_name_start_index = @input.index

      root_0 = nil
      identifier500 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 424:4: identifier
        @state.following.push( TOKENS_FOLLOWING_identifier_IN_argument_name_2838 )
        identifier500 = identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, identifier500.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 60 )
        memoize( __method__, argument_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ArgumentTypeReturnValue = define_return_scope 

    # 
    # parser rule argument_type
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 427:1: argument_type : type_spec ;
    # 
    def argument_type
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 61 )
      return_value = ArgumentTypeReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      argument_type_start_index = @input.index

      root_0 = nil
      type_spec501 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 428:4: type_spec
        @state.following.push( TOKENS_FOLLOWING_type_spec_IN_argument_type_2849 )
        type_spec501 = type_spec
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, type_spec501.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 61 )
        memoize( __method__, argument_type_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ValueReturnValue = define_return_scope 

    # 
    # parser rule value
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 431:1: value : ( ( PLUS | MINUS )? NUMBER | quoted_string | 'TRUE' | 'FALSE' | 'NULL' );
    # 
    def value
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 62 )
      return_value = ValueReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      value_start_index = @input.index

      root_0 = nil
      set502 = nil
      __NUMBER503__ = nil
      string_literal505 = nil
      string_literal506 = nil
      string_literal507 = nil
      quoted_string504 = nil

      tree_for_set502 = nil
      tree_for_NUMBER503 = nil
      tree_for_string_literal505 = nil
      tree_for_string_literal506 = nil
      tree_for_string_literal507 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 432:2: ( ( PLUS | MINUS )? NUMBER | quoted_string | 'TRUE' | 'FALSE' | 'NULL' )
        alt_123 = 5
        case look_123 = @input.peek( 1 )
        when PLUS, MINUS, NUMBER then alt_123 = 1
        when QUOTED_STRING then alt_123 = 2
        when T__110 then alt_123 = 3
        when T__111 then alt_123 = 4
        when T__58 then alt_123 = 5
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 123, 0 )
        end
        case alt_123
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 432:4: ( PLUS | MINUS )? NUMBER
          # at line 432:4: ( PLUS | MINUS )?
          alt_122 = 2
          look_122_0 = @input.peek( 1 )

          if ( look_122_0.between?( PLUS, MINUS ) )
            alt_122 = 1
          end
          case alt_122
          when 1
            # at line 
            set502 = @input.look
            if @input.peek( 1 ).between?( PLUS, MINUS )
              @input.consume
              if @state.backtracking == 0
                @adaptor.add_child( root_0, @adaptor.create_with_payload( set502 ) )
              end
              @state.error_recovery = false
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              mse = MismatchedSet( nil )
              raise mse
            end



          end
          __NUMBER503__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_value_2871 )
          if @state.backtracking == 0

            tree_for_NUMBER503 = @adaptor.create_with_payload( __NUMBER503__ )
            @adaptor.add_child( root_0, tree_for_NUMBER503 )

          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 433:4: quoted_string
          @state.following.push( TOKENS_FOLLOWING_quoted_string_IN_value_2876 )
          quoted_string504 = quoted_string
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, quoted_string504.tree )
          end

        when 3
          root_0 = @adaptor.create_flat_list


          # at line 434:4: 'TRUE'
          string_literal505 = match( T__110, TOKENS_FOLLOWING_T__110_IN_value_2881 )
          if @state.backtracking == 0

            tree_for_string_literal505 = @adaptor.create_with_payload( string_literal505 )
            @adaptor.add_child( root_0, tree_for_string_literal505 )

          end

        when 4
          root_0 = @adaptor.create_flat_list


          # at line 434:13: 'FALSE'
          string_literal506 = match( T__111, TOKENS_FOLLOWING_T__111_IN_value_2885 )
          if @state.backtracking == 0

            tree_for_string_literal506 = @adaptor.create_with_payload( string_literal506 )
            @adaptor.add_child( root_0, tree_for_string_literal506 )

          end

        when 5
          root_0 = @adaptor.create_flat_list


          # at line 435:4: 'NULL'
          string_literal507 = match( T__58, TOKENS_FOLLOWING_T__58_IN_value_2890 )
          if @state.backtracking == 0

            tree_for_string_literal507 = @adaptor.create_with_payload( string_literal507 )
            @adaptor.add_child( root_0, tree_for_string_literal507 )

          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 62 )
        memoize( __method__, value_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ReturnTypeReturnValue = define_return_scope 

    # 
    # parser rule return_type
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 438:1: return_type : type_spec ;
    # 
    def return_type
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 63 )
      return_value = ReturnTypeReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      return_type_start_index = @input.index

      root_0 = nil
      type_spec508 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 439:4: type_spec
        @state.following.push( TOKENS_FOLLOWING_type_spec_IN_return_type_2901 )
        type_spec508 = type_spec
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, type_spec508.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 63 )
        memoize( __method__, return_type_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    FunctionDeclarationReturnValue = define_return_scope 

    # 
    # parser rule function_declaration
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 442:1: function_declaration : function_body ;
    # 
    def function_declaration
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 64 )
      return_value = FunctionDeclarationReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      function_declaration_start_index = @input.index

      root_0 = nil
      function_body509 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 443:4: function_body
        @state.following.push( TOKENS_FOLLOWING_function_body_IN_function_declaration_2912 )
        function_body509 = function_body
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, function_body509.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 64 )
        memoize( __method__, function_declaration_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    FunctionCallReturnValue = define_return_scope 

    # 
    # parser rule function_call
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 446:1: function_call : user_defined_function ({...}? LPAREN ( call_parameters )? RPAREN )? ;
    # 
    def function_call
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 65 )
      return_value = FunctionCallReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      function_call_start_index = @input.index

      root_0 = nil
      __LPAREN511__ = nil
      __RPAREN513__ = nil
      user_defined_function510 = nil
      call_parameters512 = nil

      tree_for_LPAREN511 = nil
      tree_for_RPAREN513 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 447:4: user_defined_function ({...}? LPAREN ( call_parameters )? RPAREN )?
        @state.following.push( TOKENS_FOLLOWING_user_defined_function_IN_function_call_2923 )
        user_defined_function510 = user_defined_function
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, user_defined_function510.tree )
        end
        # at line 447:26: ({...}? LPAREN ( call_parameters )? RPAREN )?
        alt_125 = 2
        alt_125 = @dfa125.predict( @input )
        case alt_125
        when 1
          # at line 447:28: {...}? LPAREN ( call_parameters )? RPAREN
          unless ( (  @input.peek(1) != LPAREN || @input.peek(2) != PLUS || @input.peek(3) != RPAREN  ) )
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise FailedPredicate( "function_call", " @input.peek(1) != LPAREN || @input.peek(2) != PLUS || @input.peek(3) != RPAREN " )
          end
          __LPAREN511__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_function_call_2929 )
          if @state.backtracking == 0

            tree_for_LPAREN511 = @adaptor.create_with_payload( __LPAREN511__ )
            @adaptor.add_child( root_0, tree_for_LPAREN511 )

          end
          # at line 447:119: ( call_parameters )?
          alt_124 = 2
          look_124_0 = @input.peek( 1 )

          if ( look_124_0 == LPAREN || look_124_0.between?( PLUS, QUOTED_STRING ) || look_124_0.between?( ID, DOUBLEQUOTED_STRING ) || look_124_0.between?( T__57, T__58 ) || look_124_0 == T__100 || look_124_0.between?( T__110, T__111 ) || look_124_0.between?( T__116, T__117 ) || look_124_0 == T__140 || look_124_0 == T__142 )
            alt_124 = 1
          end
          case alt_124
          when 1
            # at line 447:121: call_parameters
            @state.following.push( TOKENS_FOLLOWING_call_parameters_IN_function_call_2933 )
            call_parameters512 = call_parameters
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, call_parameters512.tree )
            end

          end
          __RPAREN513__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_function_call_2938 )
          if @state.backtracking == 0

            tree_for_RPAREN513 = @adaptor.create_with_payload( __RPAREN513__ )
            @adaptor.add_child( root_0, tree_for_RPAREN513 )

          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 65 )
        memoize( __method__, function_call_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CollectionFunctionCallReturnValue = define_return_scope 

    # 
    # parser rule collection_function_call
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 450:1: collection_function_call : plsql_table_name ;
    # 
    def collection_function_call
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 66 )
      return_value = CollectionFunctionCallReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      collection_function_call_start_index = @input.index

      root_0 = nil
      plsql_table_name514 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 451:4: plsql_table_name
        @state.following.push( TOKENS_FOLLOWING_plsql_table_name_IN_collection_function_call_2952 )
        plsql_table_name514 = plsql_table_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, plsql_table_name514.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 66 )
        memoize( __method__, collection_function_call_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    VariableNamesReturnValue = define_return_scope 

    # 
    # parser rule variable_names
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 454:1: variable_names : variable_name ( COMMA variable_name )* ;
    # 
    def variable_names
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 67 )
      return_value = VariableNamesReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      variable_names_start_index = @input.index

      root_0 = nil
      __COMMA516__ = nil
      variable_name515 = nil
      variable_name517 = nil

      tree_for_COMMA516 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 455:4: variable_name ( COMMA variable_name )*
        @state.following.push( TOKENS_FOLLOWING_variable_name_IN_variable_names_2963 )
        variable_name515 = variable_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, variable_name515.tree )
        end
        # at line 455:18: ( COMMA variable_name )*
        while true # decision 126
          alt_126 = 2
          look_126_0 = @input.peek( 1 )

          if ( look_126_0 == COMMA )
            alt_126 = 1

          end
          case alt_126
          when 1
            # at line 455:20: COMMA variable_name
            __COMMA516__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_variable_names_2967 )
            if @state.backtracking == 0

              tree_for_COMMA516 = @adaptor.create_with_payload( __COMMA516__ )
              @adaptor.add_child( root_0, tree_for_COMMA516 )

            end
            @state.following.push( TOKENS_FOLLOWING_variable_name_IN_variable_names_2969 )
            variable_name517 = variable_name
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, variable_name517.tree )
            end

          else
            break # out of loop for decision 126
          end
        end # loop for decision 126
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 67 )
        memoize( __method__, variable_names_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    VariableNameReturnValue = define_return_scope 

    # 
    # parser rule variable_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 457:1: variable_name : identifier ;
    # 
    def variable_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 68 )
      return_value = VariableNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      variable_name_start_index = @input.index

      root_0 = nil
      identifier518 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 458:4: identifier
        @state.following.push( TOKENS_FOLLOWING_identifier_IN_variable_name_2982 )
        identifier518 = identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, identifier518.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 68 )
        memoize( __method__, variable_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    NullStatementReturnValue = define_return_scope 

    # 
    # parser rule null_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 461:1: null_statement : 'NULL' ;
    # 
    def null_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 69 )
      return_value = NullStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      null_statement_start_index = @input.index

      root_0 = nil
      string_literal519 = nil

      tree_for_string_literal519 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 462:4: 'NULL'
        string_literal519 = match( T__58, TOKENS_FOLLOWING_T__58_IN_null_statement_2993 )
        if @state.backtracking == 0

          tree_for_string_literal519 = @adaptor.create_with_payload( string_literal519 )
          @adaptor.add_child( root_0, tree_for_string_literal519 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 69 )
        memoize( __method__, null_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    RaiseStatementReturnValue = define_return_scope 

    # 
    # parser rule raise_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 465:1: raise_statement : keyRAISE ( exception_name )? ;
    # 
    def raise_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 70 )
      return_value = RaiseStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      raise_statement_start_index = @input.index

      root_0 = nil
      keyRAISE520 = nil
      exception_name521 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 466:4: keyRAISE ( exception_name )?
        @state.following.push( TOKENS_FOLLOWING_keyRAISE_IN_raise_statement_3005 )
        keyRAISE520 = keyRAISE
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyRAISE520.tree )
        end
        # at line 466:13: ( exception_name )?
        alt_127 = 2
        look_127_0 = @input.peek( 1 )

        if ( look_127_0.between?( ID, DOUBLEQUOTED_STRING ) )
          alt_127 = 1
        end
        case alt_127
        when 1
          # at line 466:15: exception_name
          @state.following.push( TOKENS_FOLLOWING_exception_name_IN_raise_statement_3009 )
          exception_name521 = exception_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, exception_name521.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 70 )
        memoize( __method__, raise_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ReturnStatementReturnValue = define_return_scope 

    # 
    # parser rule return_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 469:1: return_statement : keyRETURN ( plsql_expression )? ;
    # 
    def return_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 71 )
      return_value = ReturnStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      return_statement_start_index = @input.index

      root_0 = nil
      keyRETURN522 = nil
      plsql_expression523 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 470:4: keyRETURN ( plsql_expression )?
        @state.following.push( TOKENS_FOLLOWING_keyRETURN_IN_return_statement_3024 )
        keyRETURN522 = keyRETURN
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyRETURN522.tree )
        end
        # at line 470:14: ( plsql_expression )?
        alt_128 = 2
        look_128_0 = @input.peek( 1 )

        if ( look_128_0 == LPAREN || look_128_0.between?( PLUS, QUOTED_STRING ) || look_128_0.between?( ID, DOUBLEQUOTED_STRING ) || look_128_0.between?( T__57, T__58 ) || look_128_0 == T__100 || look_128_0.between?( T__110, T__111 ) || look_128_0.between?( T__116, T__117 ) || look_128_0 == T__140 || look_128_0 == T__142 )
          alt_128 = 1
        end
        case alt_128
        when 1
          # at line 470:16: plsql_expression
          @state.following.push( TOKENS_FOLLOWING_plsql_expression_IN_return_statement_3028 )
          plsql_expression523 = plsql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, plsql_expression523.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 71 )
        memoize( __method__, return_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    LoopStatementReturnValue = define_return_scope 

    # 
    # parser rule loop_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 473:1: loop_statement : ( LLABEL label_name RLABEL )? ( keyWHILE plsql_condition | ( 'FOR' ( ( numeric_loop_param )=> numeric_loop_param | ( cursor_loop_param )=> cursor_loop_param ) ) )? keyLOOP seq_of_statements 'END' keyLOOP ( label_name )? ;
    # 
    def loop_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 72 )
      return_value = LoopStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      loop_statement_start_index = @input.index

      root_0 = nil
      __LLABEL524__ = nil
      __RLABEL526__ = nil
      string_literal529 = nil
      string_literal534 = nil
      label_name525 = nil
      keyWHILE527 = nil
      plsql_condition528 = nil
      numeric_loop_param530 = nil
      cursor_loop_param531 = nil
      keyLOOP532 = nil
      seq_of_statements533 = nil
      keyLOOP535 = nil
      label_name536 = nil

      tree_for_LLABEL524 = nil
      tree_for_RLABEL526 = nil
      tree_for_string_literal529 = nil
      tree_for_string_literal534 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 474:4: ( LLABEL label_name RLABEL )? ( keyWHILE plsql_condition | ( 'FOR' ( ( numeric_loop_param )=> numeric_loop_param | ( cursor_loop_param )=> cursor_loop_param ) ) )? keyLOOP seq_of_statements 'END' keyLOOP ( label_name )?
        # at line 474:4: ( LLABEL label_name RLABEL )?
        alt_129 = 2
        look_129_0 = @input.peek( 1 )

        if ( look_129_0 == LLABEL )
          alt_129 = 1
        end
        case alt_129
        when 1
          # at line 474:6: LLABEL label_name RLABEL
          __LLABEL524__ = match( LLABEL, TOKENS_FOLLOWING_LLABEL_IN_loop_statement_3044 )
          if @state.backtracking == 0

            tree_for_LLABEL524 = @adaptor.create_with_payload( __LLABEL524__ )
            @adaptor.add_child( root_0, tree_for_LLABEL524 )

          end
          @state.following.push( TOKENS_FOLLOWING_label_name_IN_loop_statement_3046 )
          label_name525 = label_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, label_name525.tree )
          end
          __RLABEL526__ = match( RLABEL, TOKENS_FOLLOWING_RLABEL_IN_loop_statement_3048 )
          if @state.backtracking == 0

            tree_for_RLABEL526 = @adaptor.create_with_payload( __RLABEL526__ )
            @adaptor.add_child( root_0, tree_for_RLABEL526 )

          end

        end
        # at line 475:3: ( keyWHILE plsql_condition | ( 'FOR' ( ( numeric_loop_param )=> numeric_loop_param | ( cursor_loop_param )=> cursor_loop_param ) ) )?
        alt_131 = 3
        look_131_0 = @input.peek( 1 )

        if ( look_131_0 == T__167 )
          alt_131 = 1
        elsif ( look_131_0 == T__112 )
          alt_131 = 2
        end
        case alt_131
        when 1
          # at line 475:5: keyWHILE plsql_condition
          @state.following.push( TOKENS_FOLLOWING_keyWHILE_IN_loop_statement_3057 )
          keyWHILE527 = keyWHILE
          @state.following.pop
          if @state.backtracking == 0
            root_0 = @adaptor.become_root( keyWHILE527.tree, root_0 )
          end
          @state.following.push( TOKENS_FOLLOWING_plsql_condition_IN_loop_statement_3060 )
          plsql_condition528 = plsql_condition
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, plsql_condition528.tree )
          end

        when 2
          # at line 476:6: ( 'FOR' ( ( numeric_loop_param )=> numeric_loop_param | ( cursor_loop_param )=> cursor_loop_param ) )
          # at line 476:6: ( 'FOR' ( ( numeric_loop_param )=> numeric_loop_param | ( cursor_loop_param )=> cursor_loop_param ) )
          # at line 476:8: 'FOR' ( ( numeric_loop_param )=> numeric_loop_param | ( cursor_loop_param )=> cursor_loop_param )
          string_literal529 = match( T__112, TOKENS_FOLLOWING_T__112_IN_loop_statement_3069 )
          if @state.backtracking == 0

            tree_for_string_literal529 = @adaptor.create_with_payload( string_literal529 )
            root_0 = @adaptor.become_root( tree_for_string_literal529, root_0 )

          end
          # at line 477:5: ( ( numeric_loop_param )=> numeric_loop_param | ( cursor_loop_param )=> cursor_loop_param )
          alt_130 = 2
          look_130_0 = @input.peek( 1 )

          if ( look_130_0.between?( ID, DOUBLEQUOTED_STRING ) )
            look_130_1 = @input.peek( 2 )

            if ( syntactic_predicate?( :synpred238_Plsql ) )
              alt_130 = 1
            elsif ( syntactic_predicate?( :synpred239_Plsql ) )
              alt_130 = 2
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 130, 1 )
            end
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 130, 0 )
          end
          case alt_130
          when 1
            # at line 477:7: ( numeric_loop_param )=> numeric_loop_param
            @state.following.push( TOKENS_FOLLOWING_numeric_loop_param_IN_loop_statement_3086 )
            numeric_loop_param530 = numeric_loop_param
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, numeric_loop_param530.tree )
            end

          when 2
            # at line 478:7: ( cursor_loop_param )=> cursor_loop_param
            @state.following.push( TOKENS_FOLLOWING_cursor_loop_param_IN_loop_statement_3102 )
            cursor_loop_param531 = cursor_loop_param
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, cursor_loop_param531.tree )
            end

          end


        end
        @state.following.push( TOKENS_FOLLOWING_keyLOOP_IN_loop_statement_3123 )
        keyLOOP532 = keyLOOP
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyLOOP532.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_seq_of_statements_IN_loop_statement_3127 )
        seq_of_statements533 = seq_of_statements
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, seq_of_statements533.tree )
        end
        string_literal534 = match( T__54, TOKENS_FOLLOWING_T__54_IN_loop_statement_3131 )
        if @state.backtracking == 0

          tree_for_string_literal534 = @adaptor.create_with_payload( string_literal534 )
          @adaptor.add_child( root_0, tree_for_string_literal534 )

        end
        @state.following.push( TOKENS_FOLLOWING_keyLOOP_IN_loop_statement_3133 )
        keyLOOP535 = keyLOOP
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyLOOP535.tree )
        end
        # at line 485:3: ( label_name )?
        alt_132 = 2
        look_132_0 = @input.peek( 1 )

        if ( look_132_0.between?( ID, DOUBLEQUOTED_STRING ) )
          alt_132 = 1
        end
        case alt_132
        when 1
          # at line 485:5: label_name
          @state.following.push( TOKENS_FOLLOWING_label_name_IN_loop_statement_3140 )
          label_name536 = label_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, label_name536.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 72 )
        memoize( __method__, loop_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    NumericLoopParamReturnValue = define_return_scope 

    # 
    # parser rule numeric_loop_param
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 488:1: numeric_loop_param : index_name 'IN' ( keyREVERSE )? integer_expr DOUBLEDOT integer_expr ;
    # 
    def numeric_loop_param
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 73 )
      return_value = NumericLoopParamReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      numeric_loop_param_start_index = @input.index

      root_0 = nil
      string_literal538 = nil
      __DOUBLEDOT541__ = nil
      index_name537 = nil
      keyREVERSE539 = nil
      integer_expr540 = nil
      integer_expr542 = nil

      tree_for_string_literal538 = nil
      tree_for_DOUBLEDOT541 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 489:4: index_name 'IN' ( keyREVERSE )? integer_expr DOUBLEDOT integer_expr
        @state.following.push( TOKENS_FOLLOWING_index_name_IN_numeric_loop_param_3154 )
        index_name537 = index_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, index_name537.tree )
        end
        string_literal538 = match( T__102, TOKENS_FOLLOWING_T__102_IN_numeric_loop_param_3156 )
        if @state.backtracking == 0

          tree_for_string_literal538 = @adaptor.create_with_payload( string_literal538 )
          @adaptor.add_child( root_0, tree_for_string_literal538 )

        end
        # at line 489:20: ( keyREVERSE )?
        alt_133 = 2
        alt_133 = @dfa133.predict( @input )
        case alt_133
        when 1
          # at line 489:22: keyREVERSE
          @state.following.push( TOKENS_FOLLOWING_keyREVERSE_IN_numeric_loop_param_3160 )
          keyREVERSE539 = keyREVERSE
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyREVERSE539.tree )
          end

        end
        @state.following.push( TOKENS_FOLLOWING_integer_expr_IN_numeric_loop_param_3165 )
        integer_expr540 = integer_expr
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, integer_expr540.tree )
        end
        __DOUBLEDOT541__ = match( DOUBLEDOT, TOKENS_FOLLOWING_DOUBLEDOT_IN_numeric_loop_param_3167 )
        if @state.backtracking == 0

          tree_for_DOUBLEDOT541 = @adaptor.create_with_payload( __DOUBLEDOT541__ )
          @adaptor.add_child( root_0, tree_for_DOUBLEDOT541 )

        end
        @state.following.push( TOKENS_FOLLOWING_integer_expr_IN_numeric_loop_param_3169 )
        integer_expr542 = integer_expr
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, integer_expr542.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 73 )
        memoize( __method__, numeric_loop_param_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    IndexNameReturnValue = define_return_scope 

    # 
    # parser rule index_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 492:1: index_name : identifier ;
    # 
    def index_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 74 )
      return_value = IndexNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      index_name_start_index = @input.index

      root_0 = nil
      identifier543 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 493:4: identifier
        @state.following.push( TOKENS_FOLLOWING_identifier_IN_index_name_3180 )
        identifier543 = identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, identifier543.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 74 )
        memoize( __method__, index_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    IntegerExprReturnValue = define_return_scope 

    # 
    # parser rule integer_expr
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 497:1: integer_expr : sql_expression ;
    # 
    def integer_expr
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 75 )
      return_value = IntegerExprReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      integer_expr_start_index = @input.index

      root_0 = nil
      sql_expression544 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 498:4: sql_expression
        @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_integer_expr_3192 )
        sql_expression544 = sql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_expression544.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 75 )
        memoize( __method__, integer_expr_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CursorNameReturnValue = define_return_scope 

    # 
    # parser rule cursor_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 501:1: cursor_name : identifier ;
    # 
    def cursor_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 76 )
      return_value = CursorNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      cursor_name_start_index = @input.index

      root_0 = nil
      identifier545 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 502:4: identifier
        @state.following.push( TOKENS_FOLLOWING_identifier_IN_cursor_name_3203 )
        identifier545 = identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, identifier545.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 76 )
        memoize( __method__, cursor_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CursorLoopParamReturnValue = define_return_scope 

    # 
    # parser rule cursor_loop_param
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 505:1: cursor_loop_param : record_name 'IN' ( cursor_name ( LPAREN plsql_expressions RPAREN )? | LPAREN select_statement RPAREN ) ;
    # 
    def cursor_loop_param
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 77 )
      return_value = CursorLoopParamReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      cursor_loop_param_start_index = @input.index

      root_0 = nil
      string_literal547 = nil
      __LPAREN549__ = nil
      __RPAREN551__ = nil
      __LPAREN552__ = nil
      __RPAREN554__ = nil
      record_name546 = nil
      cursor_name548 = nil
      plsql_expressions550 = nil
      select_statement553 = nil

      tree_for_string_literal547 = nil
      tree_for_LPAREN549 = nil
      tree_for_RPAREN551 = nil
      tree_for_LPAREN552 = nil
      tree_for_RPAREN554 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 506:4: record_name 'IN' ( cursor_name ( LPAREN plsql_expressions RPAREN )? | LPAREN select_statement RPAREN )
        @state.following.push( TOKENS_FOLLOWING_record_name_IN_cursor_loop_param_3214 )
        record_name546 = record_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, record_name546.tree )
        end
        string_literal547 = match( T__102, TOKENS_FOLLOWING_T__102_IN_cursor_loop_param_3216 )
        if @state.backtracking == 0

          tree_for_string_literal547 = @adaptor.create_with_payload( string_literal547 )
          @adaptor.add_child( root_0, tree_for_string_literal547 )

        end
        # at line 507:3: ( cursor_name ( LPAREN plsql_expressions RPAREN )? | LPAREN select_statement RPAREN )
        alt_135 = 2
        look_135_0 = @input.peek( 1 )

        if ( look_135_0.between?( ID, DOUBLEQUOTED_STRING ) )
          alt_135 = 1
        elsif ( look_135_0 == LPAREN )
          alt_135 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 135, 0 )
        end
        case alt_135
        when 1
          # at line 507:5: cursor_name ( LPAREN plsql_expressions RPAREN )?
          @state.following.push( TOKENS_FOLLOWING_cursor_name_IN_cursor_loop_param_3222 )
          cursor_name548 = cursor_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, cursor_name548.tree )
          end
          # at line 507:17: ( LPAREN plsql_expressions RPAREN )?
          alt_134 = 2
          look_134_0 = @input.peek( 1 )

          if ( look_134_0 == LPAREN )
            alt_134 = 1
          end
          case alt_134
          when 1
            # at line 507:19: LPAREN plsql_expressions RPAREN
            __LPAREN549__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_cursor_loop_param_3226 )
            if @state.backtracking == 0

              tree_for_LPAREN549 = @adaptor.create_with_payload( __LPAREN549__ )
              @adaptor.add_child( root_0, tree_for_LPAREN549 )

            end
            @state.following.push( TOKENS_FOLLOWING_plsql_expressions_IN_cursor_loop_param_3228 )
            plsql_expressions550 = plsql_expressions
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, plsql_expressions550.tree )
            end
            __RPAREN551__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_cursor_loop_param_3230 )
            if @state.backtracking == 0

              tree_for_RPAREN551 = @adaptor.create_with_payload( __RPAREN551__ )
              @adaptor.add_child( root_0, tree_for_RPAREN551 )

            end

          end

        when 2
          # at line 508:5: LPAREN select_statement RPAREN
          __LPAREN552__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_cursor_loop_param_3239 )
          if @state.backtracking == 0

            tree_for_LPAREN552 = @adaptor.create_with_payload( __LPAREN552__ )
            @adaptor.add_child( root_0, tree_for_LPAREN552 )

          end
          @state.following.push( TOKENS_FOLLOWING_select_statement_IN_cursor_loop_param_3241 )
          select_statement553 = select_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, select_statement553.tree )
          end
          __RPAREN554__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_cursor_loop_param_3243 )
          if @state.backtracking == 0

            tree_for_RPAREN554 = @adaptor.create_with_payload( __RPAREN554__ )
            @adaptor.add_child( root_0, tree_for_RPAREN554 )

          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 77 )
        memoize( __method__, cursor_loop_param_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    RecordNameReturnValue = define_return_scope 

    # 
    # parser rule record_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 512:1: record_name : identifier ;
    # 
    def record_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 78 )
      return_value = RecordNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      record_name_start_index = @input.index

      root_0 = nil
      identifier555 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 513:4: identifier
        @state.following.push( TOKENS_FOLLOWING_identifier_IN_record_name_3258 )
        identifier555 = identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, identifier555.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 78 )
        memoize( __method__, record_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CommitStatementReturnValue = define_return_scope 

    # 
    # parser rule commit_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 516:1: commit_statement : 'COMMIT' ;
    # 
    def commit_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 79 )
      return_value = CommitStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      commit_statement_start_index = @input.index

      root_0 = nil
      string_literal556 = nil

      tree_for_string_literal556 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 517:4: 'COMMIT'
        string_literal556 = match( T__113, TOKENS_FOLLOWING_T__113_IN_commit_statement_3269 )
        if @state.backtracking == 0

          tree_for_string_literal556 = @adaptor.create_with_payload( string_literal556 )
          @adaptor.add_child( root_0, tree_for_string_literal556 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 79 )
        memoize( __method__, commit_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    IfStatementReturnValue = define_return_scope 

    # 
    # parser rule if_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 520:1: if_statement : 'IF' plsql_condition 'THEN' seq_of_statements ( keyELSIF plsql_condition 'THEN' seq_of_statements )* ( 'ELSE' seq_of_statements )? 'END' 'IF' ;
    # 
    def if_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 80 )
      return_value = IfStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      if_statement_start_index = @input.index

      root_0 = nil
      string_literal557 = nil
      string_literal559 = nil
      string_literal563 = nil
      string_literal565 = nil
      string_literal567 = nil
      string_literal568 = nil
      plsql_condition558 = nil
      seq_of_statements560 = nil
      keyELSIF561 = nil
      plsql_condition562 = nil
      seq_of_statements564 = nil
      seq_of_statements566 = nil

      tree_for_string_literal557 = nil
      tree_for_string_literal559 = nil
      tree_for_string_literal563 = nil
      tree_for_string_literal565 = nil
      tree_for_string_literal567 = nil
      tree_for_string_literal568 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 521:4: 'IF' plsql_condition 'THEN' seq_of_statements ( keyELSIF plsql_condition 'THEN' seq_of_statements )* ( 'ELSE' seq_of_statements )? 'END' 'IF'
        string_literal557 = match( T__114, TOKENS_FOLLOWING_T__114_IN_if_statement_3280 )
        if @state.backtracking == 0

          tree_for_string_literal557 = @adaptor.create_with_payload( string_literal557 )
          root_0 = @adaptor.become_root( tree_for_string_literal557, root_0 )

        end
        @state.following.push( TOKENS_FOLLOWING_plsql_condition_IN_if_statement_3283 )
        plsql_condition558 = plsql_condition
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, plsql_condition558.tree )
        end
        string_literal559 = match( T__109, TOKENS_FOLLOWING_T__109_IN_if_statement_3285 )
        if @state.backtracking == 0

          tree_for_string_literal559 = @adaptor.create_with_payload( string_literal559 )
          @adaptor.add_child( root_0, tree_for_string_literal559 )

        end
        @state.following.push( TOKENS_FOLLOWING_seq_of_statements_IN_if_statement_3287 )
        seq_of_statements560 = seq_of_statements
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, seq_of_statements560.tree )
        end
        # at line 522:3: ( keyELSIF plsql_condition 'THEN' seq_of_statements )*
        while true # decision 136
          alt_136 = 2
          look_136_0 = @input.peek( 1 )

          if ( look_136_0 == T__157 )
            alt_136 = 1

          end
          case alt_136
          when 1
            # at line 523:4: keyELSIF plsql_condition 'THEN' seq_of_statements
            @state.following.push( TOKENS_FOLLOWING_keyELSIF_IN_if_statement_3297 )
            keyELSIF561 = keyELSIF
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyELSIF561.tree )
            end
            @state.following.push( TOKENS_FOLLOWING_plsql_condition_IN_if_statement_3299 )
            plsql_condition562 = plsql_condition
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, plsql_condition562.tree )
            end
            string_literal563 = match( T__109, TOKENS_FOLLOWING_T__109_IN_if_statement_3301 )
            if @state.backtracking == 0

              tree_for_string_literal563 = @adaptor.create_with_payload( string_literal563 )
              @adaptor.add_child( root_0, tree_for_string_literal563 )

            end
            @state.following.push( TOKENS_FOLLOWING_seq_of_statements_IN_if_statement_3303 )
            seq_of_statements564 = seq_of_statements
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, seq_of_statements564.tree )
            end

          else
            break # out of loop for decision 136
          end
        end # loop for decision 136
        # at line 525:3: ( 'ELSE' seq_of_statements )?
        alt_137 = 2
        look_137_0 = @input.peek( 1 )

        if ( look_137_0 == T__115 )
          alt_137 = 1
        end
        case alt_137
        when 1
          # at line 525:5: 'ELSE' seq_of_statements
          string_literal565 = match( T__115, TOKENS_FOLLOWING_T__115_IN_if_statement_3314 )
          if @state.backtracking == 0

            tree_for_string_literal565 = @adaptor.create_with_payload( string_literal565 )
            @adaptor.add_child( root_0, tree_for_string_literal565 )

          end
          @state.following.push( TOKENS_FOLLOWING_seq_of_statements_IN_if_statement_3316 )
          seq_of_statements566 = seq_of_statements
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, seq_of_statements566.tree )
          end

        end
        string_literal567 = match( T__54, TOKENS_FOLLOWING_T__54_IN_if_statement_3323 )
        if @state.backtracking == 0

          tree_for_string_literal567 = @adaptor.create_with_payload( string_literal567 )
          @adaptor.add_child( root_0, tree_for_string_literal567 )

        end
        string_literal568 = match( T__114, TOKENS_FOLLOWING_T__114_IN_if_statement_3325 )
        if @state.backtracking == 0

          tree_for_string_literal568 = @adaptor.create_with_payload( string_literal568 )
          @adaptor.add_child( root_0, tree_for_string_literal568 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 80 )
        memoize( __method__, if_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SqlStatementReturnValue = define_return_scope 

    # 
    # parser rule sql_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 529:1: sql_statement : sql_command ;
    # 
    def sql_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 81 )
      return_value = SqlStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      sql_statement_start_index = @input.index

      root_0 = nil
      sql_command569 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 530:4: sql_command
        @state.following.push( TOKENS_FOLLOWING_sql_command_IN_sql_statement_3336 )
        sql_command569 = sql_command
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_command569.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 81 )
        memoize( __method__, sql_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SqlCommandReturnValue = define_return_scope 

    # 
    # parser rule sql_command
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 533:1: sql_command : ( to_modify_data | to_control_data );
    # 
    def sql_command
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 82 )
      return_value = SqlCommandReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      sql_command_start_index = @input.index

      root_0 = nil
      to_modify_data570 = nil
      to_control_data571 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 534:2: ( to_modify_data | to_control_data )
        alt_138 = 2
        look_138_0 = @input.peek( 1 )

        if ( look_138_0 == T__87 || look_138_0 == T__116 || look_138_0 == T__132 || look_138_0 == T__145 || look_138_0 == T__147 )
          alt_138 = 1
        elsif ( look_138_0 == ID || look_138_0 == T__113 || look_138_0.between?( T__149, T__150 ) || look_138_0 == T__155 || look_138_0 == T__166 )
          alt_138 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 138, 0 )
        end
        case alt_138
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 534:4: to_modify_data
          @state.following.push( TOKENS_FOLLOWING_to_modify_data_IN_sql_command_3347 )
          to_modify_data570 = to_modify_data
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, to_modify_data570.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 535:4: to_control_data
          @state.following.push( TOKENS_FOLLOWING_to_control_data_IN_sql_command_3352 )
          to_control_data571 = to_control_data
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, to_control_data571.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 82 )
        memoize( __method__, sql_command_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ToModifyDataReturnValue = define_return_scope 

    # 
    # parser rule to_modify_data
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 538:1: to_modify_data : ( select_command | insert_command | update_command | delete_command | set_transaction_command );
    # 
    def to_modify_data
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 83 )
      return_value = ToModifyDataReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      to_modify_data_start_index = @input.index

      root_0 = nil
      select_command572 = nil
      insert_command573 = nil
      update_command574 = nil
      delete_command575 = nil
      set_transaction_command576 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 539:2: ( select_command | insert_command | update_command | delete_command | set_transaction_command )
        alt_139 = 5
        case look_139 = @input.peek( 1 )
        when T__116 then alt_139 = 1
        when T__147 then alt_139 = 2
        when T__132 then alt_139 = 3
        when T__145 then alt_139 = 4
        when T__87 then alt_139 = 5
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 139, 0 )
        end
        case alt_139
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 539:4: select_command
          @state.following.push( TOKENS_FOLLOWING_select_command_IN_to_modify_data_3363 )
          select_command572 = select_command
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, select_command572.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 540:4: insert_command
          @state.following.push( TOKENS_FOLLOWING_insert_command_IN_to_modify_data_3368 )
          insert_command573 = insert_command
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, insert_command573.tree )
          end

        when 3
          root_0 = @adaptor.create_flat_list


          # at line 541:4: update_command
          @state.following.push( TOKENS_FOLLOWING_update_command_IN_to_modify_data_3373 )
          update_command574 = update_command
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, update_command574.tree )
          end

        when 4
          root_0 = @adaptor.create_flat_list


          # at line 542:4: delete_command
          @state.following.push( TOKENS_FOLLOWING_delete_command_IN_to_modify_data_3378 )
          delete_command575 = delete_command
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, delete_command575.tree )
          end

        when 5
          root_0 = @adaptor.create_flat_list


          # at line 543:4: set_transaction_command
          @state.following.push( TOKENS_FOLLOWING_set_transaction_command_IN_to_modify_data_3383 )
          set_transaction_command576 = set_transaction_command
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, set_transaction_command576.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 83 )
        memoize( __method__, to_modify_data_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ToControlDataReturnValue = define_return_scope 

    # 
    # parser rule to_control_data
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 546:1: to_control_data : ( close_statement | commit_statement | fetch_statement | lock_table_statement | open_statement | rollback_statement | savepoint_statement );
    # 
    def to_control_data
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 84 )
      return_value = ToControlDataReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      to_control_data_start_index = @input.index

      root_0 = nil
      close_statement577 = nil
      commit_statement578 = nil
      fetch_statement579 = nil
      lock_table_statement580 = nil
      open_statement581 = nil
      rollback_statement582 = nil
      savepoint_statement583 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 547:2: ( close_statement | commit_statement | fetch_statement | lock_table_statement | open_statement | rollback_statement | savepoint_statement )
        alt_140 = 7
        alt_140 = @dfa140.predict( @input )
        case alt_140
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 547:4: close_statement
          @state.following.push( TOKENS_FOLLOWING_close_statement_IN_to_control_data_3394 )
          close_statement577 = close_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, close_statement577.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 548:4: commit_statement
          @state.following.push( TOKENS_FOLLOWING_commit_statement_IN_to_control_data_3399 )
          commit_statement578 = commit_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, commit_statement578.tree )
          end

        when 3
          root_0 = @adaptor.create_flat_list


          # at line 549:4: fetch_statement
          @state.following.push( TOKENS_FOLLOWING_fetch_statement_IN_to_control_data_3404 )
          fetch_statement579 = fetch_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, fetch_statement579.tree )
          end

        when 4
          root_0 = @adaptor.create_flat_list


          # at line 550:4: lock_table_statement
          @state.following.push( TOKENS_FOLLOWING_lock_table_statement_IN_to_control_data_3409 )
          lock_table_statement580 = lock_table_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, lock_table_statement580.tree )
          end

        when 5
          root_0 = @adaptor.create_flat_list


          # at line 551:4: open_statement
          @state.following.push( TOKENS_FOLLOWING_open_statement_IN_to_control_data_3414 )
          open_statement581 = open_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, open_statement581.tree )
          end

        when 6
          root_0 = @adaptor.create_flat_list


          # at line 552:4: rollback_statement
          @state.following.push( TOKENS_FOLLOWING_rollback_statement_IN_to_control_data_3419 )
          rollback_statement582 = rollback_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, rollback_statement582.tree )
          end

        when 7
          root_0 = @adaptor.create_flat_list


          # at line 553:4: savepoint_statement
          @state.following.push( TOKENS_FOLLOWING_savepoint_statement_IN_to_control_data_3424 )
          savepoint_statement583 = savepoint_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, savepoint_statement583.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 84 )
        memoize( __method__, to_control_data_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SelectCommandReturnValue = define_return_scope 

    # 
    # parser rule select_command
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 556:1: select_command : select_statement ;
    # 
    def select_command
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 85 )
      return_value = SelectCommandReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      select_command_start_index = @input.index

      root_0 = nil
      select_statement584 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 557:4: select_statement
        @state.following.push( TOKENS_FOLLOWING_select_statement_IN_select_command_3435 )
        select_statement584 = select_statement
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, select_statement584.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 85 )
        memoize( __method__, select_command_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SelectStatementReturnValue = define_return_scope 

    # 
    # parser rule select_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 560:1: select_statement : select_expression ;
    # 
    def select_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 86 )
      return_value = SelectStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      select_statement_start_index = @input.index

      root_0 = nil
      select_expression585 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 562:3: select_expression
        @state.following.push( TOKENS_FOLLOWING_select_expression_IN_select_statement_3449 )
        select_expression585 = select_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, select_expression585.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 86 )
        memoize( __method__, select_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SelectExpressionReturnValue = define_return_scope 

    # 
    # parser rule select_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 565:1: select_expression : 'SELECT' ( 'DISTINCT' | 'UNIQUE' | 'ALL' )? select_list ( keyBULK keyCOLLECT )? ( 'INTO' lvalues )? 'FROM' ( join_clause | LPAREN join_clause RPAREN | table_reference_list ) ( where_clause )? ( hierarchical_query_clause )? ( group_by_clause )? ( 'HAVING' sql_condition )? ( model_clause )? ( ( 'UNION' ( 'ALL' )? | 'INTERSECT' | 'MINUS' ) ( select_expression | subquery ) )? ( order_by_clause )? ;
    # 
    def select_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 87 )
      return_value = SelectExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      select_expression_start_index = @input.index

      root_0 = nil
      string_literal586 = nil
      set587 = nil
      string_literal591 = nil
      string_literal593 = nil
      __LPAREN595__ = nil
      __RPAREN597__ = nil
      string_literal602 = nil
      string_literal605 = nil
      string_literal606 = nil
      string_literal607 = nil
      string_literal608 = nil
      select_list588 = nil
      keyBULK589 = nil
      keyCOLLECT590 = nil
      lvalues592 = nil
      join_clause594 = nil
      join_clause596 = nil
      table_reference_list598 = nil
      where_clause599 = nil
      hierarchical_query_clause600 = nil
      group_by_clause601 = nil
      sql_condition603 = nil
      model_clause604 = nil
      select_expression609 = nil
      subquery610 = nil
      order_by_clause611 = nil

      tree_for_string_literal586 = nil
      tree_for_set587 = nil
      tree_for_string_literal591 = nil
      tree_for_string_literal593 = nil
      tree_for_LPAREN595 = nil
      tree_for_RPAREN597 = nil
      tree_for_string_literal602 = nil
      tree_for_string_literal605 = nil
      tree_for_string_literal606 = nil
      tree_for_string_literal607 = nil
      tree_for_string_literal608 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 567:3: 'SELECT' ( 'DISTINCT' | 'UNIQUE' | 'ALL' )? select_list ( keyBULK keyCOLLECT )? ( 'INTO' lvalues )? 'FROM' ( join_clause | LPAREN join_clause RPAREN | table_reference_list ) ( where_clause )? ( hierarchical_query_clause )? ( group_by_clause )? ( 'HAVING' sql_condition )? ( model_clause )? ( ( 'UNION' ( 'ALL' )? | 'INTERSECT' | 'MINUS' ) ( select_expression | subquery ) )? ( order_by_clause )?
        string_literal586 = match( T__116, TOKENS_FOLLOWING_T__116_IN_select_expression_3464 )
        if @state.backtracking == 0

          tree_for_string_literal586 = @adaptor.create_with_payload( string_literal586 )
          @adaptor.add_child( root_0, tree_for_string_literal586 )

        end
        # at line 567:26: ( 'DISTINCT' | 'UNIQUE' | 'ALL' )?
        alt_141 = 2
        alt_141 = @dfa141.predict( @input )
        case alt_141
        when 1
          # at line 
          set587 = @input.look
          if @input.peek( 1 ).between?( T__117, T__119 )
            @input.consume
            if @state.backtracking == 0
              @adaptor.add_child( root_0, @adaptor.create_with_payload( set587 ) )
            end
            @state.error_recovery = false
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            mse = MismatchedSet( nil )
            raise mse
          end



        end
        @state.following.push( TOKENS_FOLLOWING_select_list_IN_select_expression_3483 )
        select_list588 = select_list
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, select_list588.tree )
        end
        # at line 568:3: ( keyBULK keyCOLLECT )?
        alt_142 = 2
        look_142_0 = @input.peek( 1 )

        if ( look_142_0 == ID )
          alt_142 = 1
        end
        case alt_142
        when 1
          # at line 568:5: keyBULK keyCOLLECT
          @state.following.push( TOKENS_FOLLOWING_keyBULK_IN_select_expression_3489 )
          keyBULK589 = keyBULK
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyBULK589.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_keyCOLLECT_IN_select_expression_3491 )
          keyCOLLECT590 = keyCOLLECT
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyCOLLECT590.tree )
          end

        end
        # at line 569:3: ( 'INTO' lvalues )?
        alt_143 = 2
        look_143_0 = @input.peek( 1 )

        if ( look_143_0 == T__120 )
          alt_143 = 1
        end
        case alt_143
        when 1
          # at line 569:5: 'INTO' lvalues
          string_literal591 = match( T__120, TOKENS_FOLLOWING_T__120_IN_select_expression_3500 )
          if @state.backtracking == 0

            tree_for_string_literal591 = @adaptor.create_with_payload( string_literal591 )
            @adaptor.add_child( root_0, tree_for_string_literal591 )

          end
          @state.following.push( TOKENS_FOLLOWING_lvalues_IN_select_expression_3502 )
          lvalues592 = lvalues
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, lvalues592.tree )
          end

        end
        string_literal593 = match( T__121, TOKENS_FOLLOWING_T__121_IN_select_expression_3509 )
        if @state.backtracking == 0

          tree_for_string_literal593 = @adaptor.create_with_payload( string_literal593 )
          @adaptor.add_child( root_0, tree_for_string_literal593 )

        end
        # syntactic predicate action gate test
        if @state.backtracking == 0
          # --> action
           raise 'Exit bre' unless @skip 
          # <-- action
        end
        # at line 570:44: ( join_clause | LPAREN join_clause RPAREN | table_reference_list )
        alt_144 = 3
        case look_144 = @input.peek( 1 )
        when ID then look_144_1 = @input.peek( 2 )

        if ( ( syntactic_predicate?( :synpred263_Plsql ) ) or ( ( syntactic_predicate?( :synpred263_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("THE") ) ) ) )
          alt_144 = 1
        elsif ( true )
          alt_144 = 3
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 144, 1 )
        end
        when T__100 then look_144_2 = @input.peek( 2 )

        if ( syntactic_predicate?( :synpred263_Plsql ) )
          alt_144 = 1
        elsif ( true )
          alt_144 = 3
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 144, 2 )
        end
        when T__105 then look_144_3 = @input.peek( 2 )

        if ( syntactic_predicate?( :synpred263_Plsql ) )
          alt_144 = 1
        elsif ( true )
          alt_144 = 3
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 144, 3 )
        end
        when DOUBLEQUOTED_STRING then look_144_4 = @input.peek( 2 )

        if ( syntactic_predicate?( :synpred263_Plsql ) )
          alt_144 = 1
        elsif ( true )
          alt_144 = 3
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 144, 4 )
        end
        when LPAREN then look_144_5 = @input.peek( 2 )

        if ( syntactic_predicate?( :synpred263_Plsql ) )
          alt_144 = 1
        elsif ( syntactic_predicate?( :synpred264_Plsql ) )
          alt_144 = 2
        elsif ( true )
          alt_144 = 3
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 144, 5 )
        end
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 144, 0 )
        end
        case alt_144
        when 1
          # at line 570:46: join_clause
          @state.following.push( TOKENS_FOLLOWING_join_clause_IN_select_expression_3515 )
          join_clause594 = join_clause
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, join_clause594.tree )
          end

        when 2
          # at line 570:60: LPAREN join_clause RPAREN
          __LPAREN595__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_select_expression_3519 )
          if @state.backtracking == 0

            tree_for_LPAREN595 = @adaptor.create_with_payload( __LPAREN595__ )
            @adaptor.add_child( root_0, tree_for_LPAREN595 )

          end
          @state.following.push( TOKENS_FOLLOWING_join_clause_IN_select_expression_3521 )
          join_clause596 = join_clause
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, join_clause596.tree )
          end
          __RPAREN597__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_select_expression_3523 )
          if @state.backtracking == 0

            tree_for_RPAREN597 = @adaptor.create_with_payload( __RPAREN597__ )
            @adaptor.add_child( root_0, tree_for_RPAREN597 )

          end

        when 3
          # at line 570:88: table_reference_list
          @state.following.push( TOKENS_FOLLOWING_table_reference_list_IN_select_expression_3527 )
          table_reference_list598 = table_reference_list
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, table_reference_list598.tree )
          end

        end
        # at line 571:3: ( where_clause )?
        alt_145 = 2
        look_145_0 = @input.peek( 1 )

        if ( look_145_0 == T__127 )
          look_145_1 = @input.peek( 2 )

          if ( syntactic_predicate?( :synpred265_Plsql ) )
            alt_145 = 1
          end
        end
        case alt_145
        when 1
          # at line 571:5: where_clause
          @state.following.push( TOKENS_FOLLOWING_where_clause_IN_select_expression_3535 )
          where_clause599 = where_clause
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, where_clause599.tree )
          end

        end
        # at line 571:21: ( hierarchical_query_clause )?
        alt_146 = 2
        look_146_0 = @input.peek( 1 )

        if ( look_146_0 == T__128 )
          look_146_1 = @input.peek( 2 )

          if ( syntactic_predicate?( :synpred266_Plsql ) )
            alt_146 = 1
          end
        elsif ( look_146_0 == T__129 )
          look_146_2 = @input.peek( 2 )

          if ( syntactic_predicate?( :synpred266_Plsql ) )
            alt_146 = 1
          end
        end
        case alt_146
        when 1
          # at line 571:23: hierarchical_query_clause
          @state.following.push( TOKENS_FOLLOWING_hierarchical_query_clause_IN_select_expression_3542 )
          hierarchical_query_clause600 = hierarchical_query_clause
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, hierarchical_query_clause600.tree )
          end

        end
        # at line 571:52: ( group_by_clause )?
        alt_147 = 2
        look_147_0 = @input.peek( 1 )

        if ( look_147_0 == T__130 )
          look_147_1 = @input.peek( 2 )

          if ( syntactic_predicate?( :synpred267_Plsql ) )
            alt_147 = 1
          end
        end
        case alt_147
        when 1
          # at line 571:54: group_by_clause
          @state.following.push( TOKENS_FOLLOWING_group_by_clause_IN_select_expression_3549 )
          group_by_clause601 = group_by_clause
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, group_by_clause601.tree )
          end

        end
        # at line 572:3: ( 'HAVING' sql_condition )?
        alt_148 = 2
        look_148_0 = @input.peek( 1 )

        if ( look_148_0 == T__122 )
          look_148_1 = @input.peek( 2 )

          if ( syntactic_predicate?( :synpred268_Plsql ) )
            alt_148 = 1
          end
        end
        case alt_148
        when 1
          # at line 572:5: 'HAVING' sql_condition
          string_literal602 = match( T__122, TOKENS_FOLLOWING_T__122_IN_select_expression_3558 )
          if @state.backtracking == 0

            tree_for_string_literal602 = @adaptor.create_with_payload( string_literal602 )
            @adaptor.add_child( root_0, tree_for_string_literal602 )

          end
          @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_select_expression_3560 )
          sql_condition603 = sql_condition
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_condition603.tree )
          end

        end
        # at line 572:31: ( model_clause )?
        alt_149 = 2
        look_149_0 = @input.peek( 1 )

        if ( look_149_0 == ID )
          look_149_1 = @input.peek( 2 )

          if ( ( syntactic_predicate?( :synpred269_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("MODEL") ) ) )
            alt_149 = 1
          end
        end
        case alt_149
        when 1
          # at line 572:33: model_clause
          @state.following.push( TOKENS_FOLLOWING_model_clause_IN_select_expression_3567 )
          model_clause604 = model_clause
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, model_clause604.tree )
          end

        end
        # at line 573:3: ( ( 'UNION' ( 'ALL' )? | 'INTERSECT' | 'MINUS' ) ( select_expression | subquery ) )?
        alt_153 = 2
        case look_153 = @input.peek( 1 )
        when T__123 then look_153_1 = @input.peek( 2 )

        if ( syntactic_predicate?( :synpred274_Plsql ) )
          alt_153 = 1
        end
        when T__124 then look_153_2 = @input.peek( 2 )

        if ( syntactic_predicate?( :synpred274_Plsql ) )
          alt_153 = 1
        end
        when T__125 then look_153_3 = @input.peek( 2 )

        if ( syntactic_predicate?( :synpred274_Plsql ) )
          alt_153 = 1
        end
        end
        case alt_153
        when 1
          # at line 573:5: ( 'UNION' ( 'ALL' )? | 'INTERSECT' | 'MINUS' ) ( select_expression | subquery )
          # at line 573:5: ( 'UNION' ( 'ALL' )? | 'INTERSECT' | 'MINUS' )
          alt_151 = 3
          case look_151 = @input.peek( 1 )
          when T__123 then alt_151 = 1
          when T__124 then alt_151 = 2
          when T__125 then alt_151 = 3
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 151, 0 )
          end
          case alt_151
          when 1
            # at line 573:7: 'UNION' ( 'ALL' )?
            string_literal605 = match( T__123, TOKENS_FOLLOWING_T__123_IN_select_expression_3578 )
            if @state.backtracking == 0

              tree_for_string_literal605 = @adaptor.create_with_payload( string_literal605 )
              @adaptor.add_child( root_0, tree_for_string_literal605 )

            end
            # at line 573:15: ( 'ALL' )?
            alt_150 = 2
            look_150_0 = @input.peek( 1 )

            if ( look_150_0 == T__119 )
              alt_150 = 1
            end
            case alt_150
            when 1
              # at line 573:17: 'ALL'
              string_literal606 = match( T__119, TOKENS_FOLLOWING_T__119_IN_select_expression_3582 )
              if @state.backtracking == 0

                tree_for_string_literal606 = @adaptor.create_with_payload( string_literal606 )
                @adaptor.add_child( root_0, tree_for_string_literal606 )

              end

            end

          when 2
            # at line 574:6: 'INTERSECT'
            string_literal607 = match( T__124, TOKENS_FOLLOWING_T__124_IN_select_expression_3592 )
            if @state.backtracking == 0

              tree_for_string_literal607 = @adaptor.create_with_payload( string_literal607 )
              @adaptor.add_child( root_0, tree_for_string_literal607 )

            end

          when 3
            # at line 575:6: 'MINUS'
            string_literal608 = match( T__125, TOKENS_FOLLOWING_T__125_IN_select_expression_3599 )
            if @state.backtracking == 0

              tree_for_string_literal608 = @adaptor.create_with_payload( string_literal608 )
              @adaptor.add_child( root_0, tree_for_string_literal608 )

            end

          end
          # at line 577:4: ( select_expression | subquery )
          alt_152 = 2
          look_152_0 = @input.peek( 1 )

          if ( look_152_0 == T__116 )
            alt_152 = 1
          elsif ( look_152_0 == LPAREN )
            alt_152 = 2
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 152, 0 )
          end
          case alt_152
          when 1
            # at line 577:6: select_expression
            @state.following.push( TOKENS_FOLLOWING_select_expression_IN_select_expression_3611 )
            select_expression609 = select_expression
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, select_expression609.tree )
            end

          when 2
            # at line 578:6: subquery
            @state.following.push( TOKENS_FOLLOWING_subquery_IN_select_expression_3619 )
            subquery610 = subquery
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, subquery610.tree )
            end

          end

        end
        # at line 581:3: ( order_by_clause )?
        alt_154 = 2
        look_154_0 = @input.peek( 1 )

        if ( look_154_0 == T__133 )
          look_154_1 = @input.peek( 2 )

          if ( syntactic_predicate?( :synpred275_Plsql ) )
            alt_154 = 1
          end
        end
        case alt_154
        when 1
          # at line 581:5: order_by_clause
          @state.following.push( TOKENS_FOLLOWING_order_by_clause_IN_select_expression_3635 )
          order_by_clause611 = order_by_clause
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, order_by_clause611.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 87 )
        memoize( __method__, select_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SelectListReturnValue = define_return_scope 

    # 
    # parser rule select_list
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 584:1: select_list : ( ASTERISK | displayed_column ( COMMA displayed_column )* );
    # 
    def select_list
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 88 )
      return_value = SelectListReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      select_list_start_index = @input.index

      root_0 = nil
      __ASTERISK612__ = nil
      __COMMA614__ = nil
      displayed_column613 = nil
      displayed_column615 = nil

      tree_for_ASTERISK612 = nil
      tree_for_COMMA614 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 585:2: ( ASTERISK | displayed_column ( COMMA displayed_column )* )
        alt_156 = 2
        look_156_0 = @input.peek( 1 )

        if ( look_156_0 == ASTERISK )
          alt_156 = 1
        elsif ( look_156_0 == LPAREN || look_156_0.between?( PLUS, QUOTED_STRING ) || look_156_0.between?( ID, DOUBLEQUOTED_STRING ) || look_156_0 == T__58 || look_156_0 == T__100 || look_156_0.between?( T__110, T__111 ) || look_156_0.between?( T__116, T__117 ) || look_156_0 == T__140 || look_156_0 == T__142 )
          alt_156 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 156, 0 )
        end
        case alt_156
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 585:4: ASTERISK
          __ASTERISK612__ = match( ASTERISK, TOKENS_FOLLOWING_ASTERISK_IN_select_list_3649 )
          if @state.backtracking == 0

            tree_for_ASTERISK612 = @adaptor.create_with_payload( __ASTERISK612__ )
            @adaptor.add_child( root_0, tree_for_ASTERISK612 )

          end
          # syntactic predicate action gate test
          if @state.backtracking == 0
            # --> action
             @columns << '*' unless @skip 
            # <-- action
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 586:4: displayed_column ( COMMA displayed_column )*
          @state.following.push( TOKENS_FOLLOWING_displayed_column_IN_select_list_3656 )
          displayed_column613 = displayed_column
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, displayed_column613.tree )
          end
          # at line 586:21: ( COMMA displayed_column )*
          while true # decision 155
            alt_155 = 2
            look_155_0 = @input.peek( 1 )

            if ( look_155_0 == COMMA )
              alt_155 = 1

            end
            case alt_155
            when 1
              # at line 586:23: COMMA displayed_column
              __COMMA614__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_select_list_3660 )
              if @state.backtracking == 0

                tree_for_COMMA614 = @adaptor.create_with_payload( __COMMA614__ )
                @adaptor.add_child( root_0, tree_for_COMMA614 )

              end
              @state.following.push( TOKENS_FOLLOWING_displayed_column_IN_select_list_3662 )
              displayed_column615 = displayed_column
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, displayed_column615.tree )
              end

            else
              break # out of loop for decision 155
            end
          end # loop for decision 155

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 88 )
        memoize( __method__, select_list_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    TableReferenceListFromReturnValue = define_return_scope 

    # 
    # parser rule table_reference_list_from
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 589:1: table_reference_list_from : 'FROM' table_reference_list ;
    # 
    def table_reference_list_from
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 89 )
      return_value = TableReferenceListFromReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      table_reference_list_from_start_index = @input.index

      root_0 = nil
      string_literal616 = nil
      table_reference_list617 = nil

      tree_for_string_literal616 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 590:4: 'FROM' table_reference_list
        string_literal616 = match( T__121, TOKENS_FOLLOWING_T__121_IN_table_reference_list_from_3677 )
        if @state.backtracking == 0

          tree_for_string_literal616 = @adaptor.create_with_payload( string_literal616 )
          @adaptor.add_child( root_0, tree_for_string_literal616 )

        end
        @state.following.push( TOKENS_FOLLOWING_table_reference_list_IN_table_reference_list_from_3679 )
        table_reference_list617 = table_reference_list
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, table_reference_list617.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 89 )
        memoize( __method__, table_reference_list_from_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    TableReferenceListReturnValue = define_return_scope 

    # 
    # parser rule table_reference_list
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 593:1: table_reference_list : selected_table ( COMMA selected_table )* ;
    # 
    def table_reference_list
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 90 )
      return_value = TableReferenceListReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      table_reference_list_start_index = @input.index

      root_0 = nil
      __COMMA619__ = nil
      selected_table618 = nil
      selected_table620 = nil

      tree_for_COMMA619 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 594:4: selected_table ( COMMA selected_table )*
        @state.following.push( TOKENS_FOLLOWING_selected_table_IN_table_reference_list_3690 )
        selected_table618 = selected_table
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, selected_table618.tree )
        end
        # at line 594:19: ( COMMA selected_table )*
        while true # decision 157
          alt_157 = 2
          alt_157 = @dfa157.predict( @input )
          case alt_157
          when 1
            # at line 594:21: COMMA selected_table
            __COMMA619__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_table_reference_list_3694 )
            if @state.backtracking == 0

              tree_for_COMMA619 = @adaptor.create_with_payload( __COMMA619__ )
              @adaptor.add_child( root_0, tree_for_COMMA619 )

            end
            @state.following.push( TOKENS_FOLLOWING_selected_table_IN_table_reference_list_3696 )
            selected_table620 = selected_table
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, selected_table620.tree )
            end

          else
            break # out of loop for decision 157
          end
        end # loop for decision 157
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 90 )
        memoize( __method__, table_reference_list_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    JoinClauseReturnValue = define_return_scope 

    # 
    # parser rule join_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 597:1: join_clause : selected_table ( inner_cross_join_clause | outer_join_clause )+ ;
    # 
    def join_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 91 )
      return_value = JoinClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      join_clause_start_index = @input.index

      root_0 = nil
      selected_table621 = nil
      inner_cross_join_clause622 = nil
      outer_join_clause623 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 598:4: selected_table ( inner_cross_join_clause | outer_join_clause )+
        @state.following.push( TOKENS_FOLLOWING_selected_table_IN_join_clause_3710 )
        selected_table621 = selected_table
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, selected_table621.tree )
        end
        # at file 598:19: ( inner_cross_join_clause | outer_join_clause )+
        match_count_158 = 0
        while true
          alt_158 = 3
          look_158_0 = @input.peek( 1 )

          if ( look_158_0 == ID )
            look_158_2 = @input.peek( 2 )

            if ( ( ( syntactic_predicate?( :synpred279_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("JOIN") ) ) ) or ( ( syntactic_predicate?( :synpred279_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CROSS") ) ) ) or ( ( syntactic_predicate?( :synpred279_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("NATURAL") ) ) ) or ( ( syntactic_predicate?( :synpred279_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("INNER") ) ) ) )
              alt_158 = 1
            elsif ( ( ( syntactic_predicate?( :synpred280_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("FULL") ) ) ) or ( ( syntactic_predicate?( :synpred280_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("PARTITION") ) ) ) or ( ( syntactic_predicate?( :synpred280_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("RIGHT") ) ) ) or ( ( syntactic_predicate?( :synpred280_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("NATURAL") ) ) ) or ( ( syntactic_predicate?( :synpred280_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("LEFT") ) ) ) )
              alt_158 = 2

            end

          end
          case alt_158
          when 1
            # at line 598:21: inner_cross_join_clause
            @state.following.push( TOKENS_FOLLOWING_inner_cross_join_clause_IN_join_clause_3714 )
            inner_cross_join_clause622 = inner_cross_join_clause
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, inner_cross_join_clause622.tree )
            end

          when 2
            # at line 598:47: outer_join_clause
            @state.following.push( TOKENS_FOLLOWING_outer_join_clause_IN_join_clause_3718 )
            outer_join_clause623 = outer_join_clause
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, outer_join_clause623.tree )
            end

          else
            match_count_158 > 0 and break
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            eee = EarlyExit(158)


            raise eee
          end
          match_count_158 += 1
        end

        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 91 )
        memoize( __method__, join_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    InnerCrossJoinClauseReturnValue = define_return_scope 

    # 
    # parser rule inner_cross_join_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 600:1: inner_cross_join_clause : ( ( keyINNER )? keyJOIN table_name ( 'ON' sql_condition | keyUSING LPAREN column_specs RPAREN ) | ( keyCROSS | keyNATURAL ( keyINNER ) ) keyJOIN table_name );
    # 
    def inner_cross_join_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 92 )
      return_value = InnerCrossJoinClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      inner_cross_join_clause_start_index = @input.index

      root_0 = nil
      string_literal627 = nil
      __LPAREN630__ = nil
      __RPAREN632__ = nil
      keyINNER624 = nil
      keyJOIN625 = nil
      table_name626 = nil
      sql_condition628 = nil
      keyUSING629 = nil
      column_specs631 = nil
      keyCROSS633 = nil
      keyNATURAL634 = nil
      keyINNER635 = nil
      keyJOIN636 = nil
      table_name637 = nil

      tree_for_string_literal627 = nil
      tree_for_LPAREN630 = nil
      tree_for_RPAREN632 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 601:2: ( ( keyINNER )? keyJOIN table_name ( 'ON' sql_condition | keyUSING LPAREN column_specs RPAREN ) | ( keyCROSS | keyNATURAL ( keyINNER ) ) keyJOIN table_name )
        alt_162 = 2
        look_162_0 = @input.peek( 1 )

        if ( look_162_0 == ID )
          look_162_1 = @input.peek( 2 )

          if ( ( ( syntactic_predicate?( :synpred283_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("JOIN") ) ) ) or ( ( syntactic_predicate?( :synpred283_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("INNER") ) ) ) )
            alt_162 = 1
          elsif ( ( ( self.input.look(1).text.upcase == ("CROSS") ) ) or ( ( self.input.look(1).text.upcase == ("NATURAL") ) ) )
            alt_162 = 2
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 162, 1 )
          end
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 162, 0 )
        end
        case alt_162
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 601:4: ( keyINNER )? keyJOIN table_name ( 'ON' sql_condition | keyUSING LPAREN column_specs RPAREN )
          # at line 601:4: ( keyINNER )?
          alt_159 = 2
          look_159_0 = @input.peek( 1 )

          if ( look_159_0 == ID )
            look_159_1 = @input.peek( 2 )

            if ( look_159_1 == ID )
              look_159_2 = @input.peek( 3 )

              if ( look_159_2 == ID )
                look_159_4 = @input.peek( 4 )

                if ( look_159_4 == ID || look_159_4 == T__126 )
                  alt_159 = 1
                end
              elsif ( look_159_2 == DOUBLEQUOTED_STRING || look_159_2 == T__100 )
                alt_159 = 1
              end
            end
          end
          case alt_159
          when 1
            # at line 601:6: keyINNER
            @state.following.push( TOKENS_FOLLOWING_keyINNER_IN_inner_cross_join_clause_3733 )
            keyINNER624 = keyINNER
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyINNER624.tree )
            end

          end
          @state.following.push( TOKENS_FOLLOWING_keyJOIN_IN_inner_cross_join_clause_3738 )
          keyJOIN625 = keyJOIN
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyJOIN625.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_table_name_IN_inner_cross_join_clause_3740 )
          table_name626 = table_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, table_name626.tree )
          end
          # at line 601:37: ( 'ON' sql_condition | keyUSING LPAREN column_specs RPAREN )
          alt_160 = 2
          look_160_0 = @input.peek( 1 )

          if ( look_160_0 == T__126 )
            alt_160 = 1
          elsif ( look_160_0 == ID )
            alt_160 = 2
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 160, 0 )
          end
          case alt_160
          when 1
            # at line 601:39: 'ON' sql_condition
            string_literal627 = match( T__126, TOKENS_FOLLOWING_T__126_IN_inner_cross_join_clause_3744 )
            if @state.backtracking == 0

              tree_for_string_literal627 = @adaptor.create_with_payload( string_literal627 )
              @adaptor.add_child( root_0, tree_for_string_literal627 )

            end
            @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_inner_cross_join_clause_3746 )
            sql_condition628 = sql_condition
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, sql_condition628.tree )
            end

          when 2
            # at line 601:60: keyUSING LPAREN column_specs RPAREN
            @state.following.push( TOKENS_FOLLOWING_keyUSING_IN_inner_cross_join_clause_3750 )
            keyUSING629 = keyUSING
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyUSING629.tree )
            end
            __LPAREN630__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_inner_cross_join_clause_3752 )
            if @state.backtracking == 0

              tree_for_LPAREN630 = @adaptor.create_with_payload( __LPAREN630__ )
              @adaptor.add_child( root_0, tree_for_LPAREN630 )

            end
            @state.following.push( TOKENS_FOLLOWING_column_specs_IN_inner_cross_join_clause_3754 )
            column_specs631 = column_specs
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, column_specs631.tree )
            end
            __RPAREN632__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_inner_cross_join_clause_3756 )
            if @state.backtracking == 0

              tree_for_RPAREN632 = @adaptor.create_with_payload( __RPAREN632__ )
              @adaptor.add_child( root_0, tree_for_RPAREN632 )

            end

          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 602:4: ( keyCROSS | keyNATURAL ( keyINNER ) ) keyJOIN table_name
          # at line 602:4: ( keyCROSS | keyNATURAL ( keyINNER ) )
          alt_161 = 2
          look_161_0 = @input.peek( 1 )

          if ( look_161_0 == ID )
            look_161_1 = @input.peek( 2 )

            if ( look_161_1 == ID )
              look_161_2 = @input.peek( 3 )

              if ( look_161_2 == ID )
                case look_161 = @input.peek( 4 )
                when EOF, SEMI, LPAREN, RPAREN, DOUBLEDOT, COMMA, PLUS, MINUS, NUMBER, QUOTED_STRING, ASTERISK, EQ, RBRACK, FOUND_ATTR, NOTFOUND_ATTR, ISOPEN_ATTR, ROWCOUNT_ATTR, BULK_ROWCOUNT_ATTR, DOUBLEVERTBAR, DIVIDE, EXPONENT, NOT_EQ, GTH, GEQ, LTH, LEQ, T__51, T__52, T__53, T__54, T__57, T__58, T__63, T__102, T__109, T__110, T__111, T__115, T__116, T__117, T__120, T__121, T__122, T__123, T__124, T__125, T__126, T__127, T__128, T__129, T__130, T__133, T__134, T__135, T__136, T__138, T__139, T__140, T__141, T__142, T__143, T__144, T__146, T__158, T__164, T__165 then alt_161 = 1
                when ID then look_161_5 = @input.peek( 5 )

                if ( ( syntactic_predicate?( :synpred284_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CROSS") ) ) )
                  alt_161 = 1
                elsif ( ( self.input.look(1).text.upcase == ("NATURAL") ) )
                  alt_161 = 2
                else
                  @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

                  raise NoViableAlternative( "", 161, 5 )
                end
                when DOUBLEQUOTED_STRING then look_161_6 = @input.peek( 5 )

                if ( ( syntactic_predicate?( :synpred284_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CROSS") ) ) )
                  alt_161 = 1
                elsif ( ( self.input.look(1).text.upcase == ("NATURAL") ) )
                  alt_161 = 2
                else
                  @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

                  raise NoViableAlternative( "", 161, 6 )
                end
                when T__100 then look_161_7 = @input.peek( 5 )

                if ( ( syntactic_predicate?( :synpred284_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CROSS") ) ) )
                  alt_161 = 1
                elsif ( ( self.input.look(1).text.upcase == ("NATURAL") ) )
                  alt_161 = 2
                else
                  @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

                  raise NoViableAlternative( "", 161, 7 )
                end
                else
                  @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

                  raise NoViableAlternative( "", 161, 3 )
                end
              elsif ( look_161_2 == DOUBLEQUOTED_STRING || look_161_2 == T__100 )
                alt_161 = 1
              else
                @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

                raise NoViableAlternative( "", 161, 2 )
              end
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 161, 1 )
            end
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 161, 0 )
          end
          case alt_161
          when 1
            # at line 602:6: keyCROSS
            @state.following.push( TOKENS_FOLLOWING_keyCROSS_IN_inner_cross_join_clause_3765 )
            keyCROSS633 = keyCROSS
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyCROSS633.tree )
            end

          when 2
            # at line 602:17: keyNATURAL ( keyINNER )
            @state.following.push( TOKENS_FOLLOWING_keyNATURAL_IN_inner_cross_join_clause_3769 )
            keyNATURAL634 = keyNATURAL
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyNATURAL634.tree )
            end
            # at line 602:28: ( keyINNER )
            # at line 602:30: keyINNER
            @state.following.push( TOKENS_FOLLOWING_keyINNER_IN_inner_cross_join_clause_3773 )
            keyINNER635 = keyINNER
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyINNER635.tree )
            end


          end
          @state.following.push( TOKENS_FOLLOWING_keyJOIN_IN_inner_cross_join_clause_3779 )
          keyJOIN636 = keyJOIN
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyJOIN636.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_table_name_IN_inner_cross_join_clause_3781 )
          table_name637 = table_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, table_name637.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 92 )
        memoize( __method__, inner_cross_join_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    OuterJoinClauseReturnValue = define_return_scope 

    # 
    # parser rule outer_join_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 604:1: outer_join_clause : ( query_partition_clause )? ( outer_join_type keyJOIN | keyNATURAL ( outer_join_type )? keyJOIN ) selected_table ( query_partition_clause )? ( 'ON' sql_condition | keyUSING LPAREN column_specs RPAREN )? ;
    # 
    def outer_join_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 93 )
      return_value = OuterJoinClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      outer_join_clause_start_index = @input.index

      root_0 = nil
      string_literal646 = nil
      __LPAREN649__ = nil
      __RPAREN651__ = nil
      query_partition_clause638 = nil
      outer_join_type639 = nil
      keyJOIN640 = nil
      keyNATURAL641 = nil
      outer_join_type642 = nil
      keyJOIN643 = nil
      selected_table644 = nil
      query_partition_clause645 = nil
      sql_condition647 = nil
      keyUSING648 = nil
      column_specs650 = nil

      tree_for_string_literal646 = nil
      tree_for_LPAREN649 = nil
      tree_for_RPAREN651 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 605:4: ( query_partition_clause )? ( outer_join_type keyJOIN | keyNATURAL ( outer_join_type )? keyJOIN ) selected_table ( query_partition_clause )? ( 'ON' sql_condition | keyUSING LPAREN column_specs RPAREN )?
        # at line 605:4: ( query_partition_clause )?
        alt_163 = 2
        look_163_0 = @input.peek( 1 )

        if ( look_163_0 == ID )
          look_163_1 = @input.peek( 2 )

          if ( look_163_1 == T__108 )
            alt_163 = 1
          end
        end
        case alt_163
        when 1
          # at line 605:6: query_partition_clause
          @state.following.push( TOKENS_FOLLOWING_query_partition_clause_IN_outer_join_clause_3793 )
          query_partition_clause638 = query_partition_clause
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, query_partition_clause638.tree )
          end

        end
        # at line 606:3: ( outer_join_type keyJOIN | keyNATURAL ( outer_join_type )? keyJOIN )
        alt_165 = 2
        look_165_0 = @input.peek( 1 )

        if ( look_165_0 == ID )
          look_165_1 = @input.peek( 2 )

          if ( look_165_1 == ID )
            look_165_2 = @input.peek( 3 )

            if ( ( ( syntactic_predicate?( :synpred286_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("LEFT") ) ) ) or ( ( syntactic_predicate?( :synpred286_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("RIGHT") ) ) ) or ( ( syntactic_predicate?( :synpred286_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("FULL") ) ) ) )
              alt_165 = 1
            elsif ( ( self.input.look(1).text.upcase == ("NATURAL") ) )
              alt_165 = 2
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 165, 2 )
            end
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 165, 1 )
          end
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 165, 0 )
        end
        case alt_165
        when 1
          # at line 606:5: outer_join_type keyJOIN
          @state.following.push( TOKENS_FOLLOWING_outer_join_type_IN_outer_join_clause_3802 )
          outer_join_type639 = outer_join_type
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, outer_join_type639.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_keyJOIN_IN_outer_join_clause_3804 )
          keyJOIN640 = keyJOIN
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyJOIN640.tree )
          end

        when 2
          # at line 607:5: keyNATURAL ( outer_join_type )? keyJOIN
          @state.following.push( TOKENS_FOLLOWING_keyNATURAL_IN_outer_join_clause_3810 )
          keyNATURAL641 = keyNATURAL
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyNATURAL641.tree )
          end
          # at line 607:16: ( outer_join_type )?
          alt_164 = 2
          look_164_0 = @input.peek( 1 )

          if ( look_164_0 == ID )
            look_164_1 = @input.peek( 2 )

            if ( look_164_1 == ID )
              look_164_2 = @input.peek( 3 )

              if ( ( ( syntactic_predicate?( :synpred287_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("RIGHT") ) ) ) or ( ( syntactic_predicate?( :synpred287_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("FULL") ) ) ) or ( ( syntactic_predicate?( :synpred287_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("LEFT") ) ) ) )
                alt_164 = 1
              end
            end
          end
          case alt_164
          when 1
            # at line 607:18: outer_join_type
            @state.following.push( TOKENS_FOLLOWING_outer_join_type_IN_outer_join_clause_3814 )
            outer_join_type642 = outer_join_type
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, outer_join_type642.tree )
            end

          end
          @state.following.push( TOKENS_FOLLOWING_keyJOIN_IN_outer_join_clause_3819 )
          keyJOIN643 = keyJOIN
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyJOIN643.tree )
          end

        end
        @state.following.push( TOKENS_FOLLOWING_selected_table_IN_outer_join_clause_3827 )
        selected_table644 = selected_table
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, selected_table644.tree )
        end
        # at line 609:18: ( query_partition_clause )?
        alt_166 = 2
        alt_166 = @dfa166.predict( @input )
        case alt_166
        when 1
          # at line 609:20: query_partition_clause
          @state.following.push( TOKENS_FOLLOWING_query_partition_clause_IN_outer_join_clause_3831 )
          query_partition_clause645 = query_partition_clause
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, query_partition_clause645.tree )
          end

        end
        # at line 610:3: ( 'ON' sql_condition | keyUSING LPAREN column_specs RPAREN )?
        alt_167 = 3
        look_167_0 = @input.peek( 1 )

        if ( look_167_0 == T__126 )
          look_167_1 = @input.peek( 2 )

          if ( syntactic_predicate?( :synpred289_Plsql ) )
            alt_167 = 1
          end
        elsif ( look_167_0 == ID )
          look_167_2 = @input.peek( 2 )

          if ( ( syntactic_predicate?( :synpred290_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("USING") ) ) )
            alt_167 = 2
          end
        end
        case alt_167
        when 1
          # at line 610:5: 'ON' sql_condition
          string_literal646 = match( T__126, TOKENS_FOLLOWING_T__126_IN_outer_join_clause_3840 )
          if @state.backtracking == 0

            tree_for_string_literal646 = @adaptor.create_with_payload( string_literal646 )
            @adaptor.add_child( root_0, tree_for_string_literal646 )

          end
          @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_outer_join_clause_3842 )
          sql_condition647 = sql_condition
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_condition647.tree )
          end

        when 2
          # at line 610:26: keyUSING LPAREN column_specs RPAREN
          @state.following.push( TOKENS_FOLLOWING_keyUSING_IN_outer_join_clause_3846 )
          keyUSING648 = keyUSING
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyUSING648.tree )
          end
          __LPAREN649__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_outer_join_clause_3848 )
          if @state.backtracking == 0

            tree_for_LPAREN649 = @adaptor.create_with_payload( __LPAREN649__ )
            @adaptor.add_child( root_0, tree_for_LPAREN649 )

          end
          @state.following.push( TOKENS_FOLLOWING_column_specs_IN_outer_join_clause_3850 )
          column_specs650 = column_specs
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, column_specs650.tree )
          end
          __RPAREN651__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_outer_join_clause_3852 )
          if @state.backtracking == 0

            tree_for_RPAREN651 = @adaptor.create_with_payload( __RPAREN651__ )
            @adaptor.add_child( root_0, tree_for_RPAREN651 )

          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 93 )
        memoize( __method__, outer_join_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    QueryPartitionClauseReturnValue = define_return_scope 

    # 
    # parser rule query_partition_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 612:1: query_partition_clause : keyPARTITION 'BY' expression_list ;
    # 
    def query_partition_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 94 )
      return_value = QueryPartitionClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      query_partition_clause_start_index = @input.index

      root_0 = nil
      string_literal653 = nil
      keyPARTITION652 = nil
      expression_list654 = nil

      tree_for_string_literal653 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 613:4: keyPARTITION 'BY' expression_list
        @state.following.push( TOKENS_FOLLOWING_keyPARTITION_IN_query_partition_clause_3865 )
        keyPARTITION652 = keyPARTITION
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyPARTITION652.tree )
        end
        string_literal653 = match( T__108, TOKENS_FOLLOWING_T__108_IN_query_partition_clause_3867 )
        if @state.backtracking == 0

          tree_for_string_literal653 = @adaptor.create_with_payload( string_literal653 )
          @adaptor.add_child( root_0, tree_for_string_literal653 )

        end
        @state.following.push( TOKENS_FOLLOWING_expression_list_IN_query_partition_clause_3869 )
        expression_list654 = expression_list
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, expression_list654.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 94 )
        memoize( __method__, query_partition_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    OuterJoinTypeReturnValue = define_return_scope 

    # 
    # parser rule outer_join_type
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 615:1: outer_join_type : ( keyFULL | keyLEFT | keyRIGHT ) ( keyOUTER )? ;
    # 
    def outer_join_type
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 95 )
      return_value = OuterJoinTypeReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      outer_join_type_start_index = @input.index

      root_0 = nil
      keyFULL655 = nil
      keyLEFT656 = nil
      keyRIGHT657 = nil
      keyOUTER658 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 616:4: ( keyFULL | keyLEFT | keyRIGHT ) ( keyOUTER )?
        # at line 616:4: ( keyFULL | keyLEFT | keyRIGHT )
        alt_168 = 3
        look_168_0 = @input.peek( 1 )

        if ( look_168_0 == ID )
          look_168_1 = @input.peek( 2 )

          if ( ( syntactic_predicate?( :synpred291_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("FULL") ) ) )
            alt_168 = 1
          elsif ( ( syntactic_predicate?( :synpred292_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("LEFT") ) ) )
            alt_168 = 2
          elsif ( ( self.input.look(1).text.upcase == ("RIGHT") ) )
            alt_168 = 3
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 168, 1 )
          end
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 168, 0 )
        end
        case alt_168
        when 1
          # at line 616:6: keyFULL
          @state.following.push( TOKENS_FOLLOWING_keyFULL_IN_outer_join_type_3881 )
          keyFULL655 = keyFULL
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyFULL655.tree )
          end

        when 2
          # at line 616:16: keyLEFT
          @state.following.push( TOKENS_FOLLOWING_keyLEFT_IN_outer_join_type_3885 )
          keyLEFT656 = keyLEFT
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyLEFT656.tree )
          end

        when 3
          # at line 616:26: keyRIGHT
          @state.following.push( TOKENS_FOLLOWING_keyRIGHT_IN_outer_join_type_3889 )
          keyRIGHT657 = keyRIGHT
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyRIGHT657.tree )
          end

        end
        # at line 616:37: ( keyOUTER )?
        alt_169 = 2
        look_169_0 = @input.peek( 1 )

        if ( look_169_0 == ID )
          look_169_1 = @input.peek( 2 )

          if ( look_169_1 == ID )
            look_169_3 = @input.peek( 3 )

            if ( ( syntactic_predicate?( :synpred293_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("OUTER") ) ) )
              alt_169 = 1
            end
          elsif ( look_169_1 == EOF )
            alt_169 = 1
          end
        end
        case alt_169
        when 1
          # at line 616:39: keyOUTER
          @state.following.push( TOKENS_FOLLOWING_keyOUTER_IN_outer_join_type_3895 )
          keyOUTER658 = keyOUTER
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyOUTER658.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 95 )
        memoize( __method__, outer_join_type_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    OuterJoinSignReturnValue = define_return_scope 

    # 
    # parser rule outer_join_sign
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 618:1: outer_join_sign : LPAREN PLUS RPAREN ;
    # 
    def outer_join_sign
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 96 )
      return_value = OuterJoinSignReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      outer_join_sign_start_index = @input.index

      root_0 = nil
      __LPAREN659__ = nil
      __PLUS660__ = nil
      __RPAREN661__ = nil

      tree_for_LPAREN659 = nil
      tree_for_PLUS660 = nil
      tree_for_RPAREN661 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 619:4: LPAREN PLUS RPAREN
        __LPAREN659__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_outer_join_sign_3908 )
        if @state.backtracking == 0

          tree_for_LPAREN659 = @adaptor.create_with_payload( __LPAREN659__ )
          @adaptor.add_child( root_0, tree_for_LPAREN659 )

        end
        __PLUS660__ = match( PLUS, TOKENS_FOLLOWING_PLUS_IN_outer_join_sign_3910 )
        if @state.backtracking == 0

          tree_for_PLUS660 = @adaptor.create_with_payload( __PLUS660__ )
          @adaptor.add_child( root_0, tree_for_PLUS660 )

        end
        __RPAREN661__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_outer_join_sign_3912 )
        if @state.backtracking == 0

          tree_for_RPAREN661 = @adaptor.create_with_payload( __RPAREN661__ )
          @adaptor.add_child( root_0, tree_for_RPAREN661 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 96 )
        memoize( __method__, outer_join_sign_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    WhereClauseReturnValue = define_return_scope 

    # 
    # parser rule where_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 621:1: where_clause : 'WHERE' sql_condition ;
    # 
    def where_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 97 )
      return_value = WhereClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      where_clause_start_index = @input.index

      root_0 = nil
      string_literal662 = nil
      sql_condition663 = nil

      tree_for_string_literal662 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 622:4: 'WHERE' sql_condition
        string_literal662 = match( T__127, TOKENS_FOLLOWING_T__127_IN_where_clause_3922 )
        if @state.backtracking == 0

          tree_for_string_literal662 = @adaptor.create_with_payload( string_literal662 )
          @adaptor.add_child( root_0, tree_for_string_literal662 )

        end
        @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_where_clause_3924 )
        sql_condition663 = sql_condition
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_condition663.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 97 )
        memoize( __method__, where_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    HierarchicalQueryClauseReturnValue = define_return_scope 

    # 
    # parser rule hierarchical_query_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 624:1: hierarchical_query_clause : ( 'START' 'WITH' sql_condition )? 'CONNECT' 'BY' ( keyNOCYCLE )? sql_condition ;
    # 
    def hierarchical_query_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 98 )
      return_value = HierarchicalQueryClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      hierarchical_query_clause_start_index = @input.index

      root_0 = nil
      string_literal664 = nil
      string_literal665 = nil
      string_literal667 = nil
      string_literal668 = nil
      sql_condition666 = nil
      keyNOCYCLE669 = nil
      sql_condition670 = nil

      tree_for_string_literal664 = nil
      tree_for_string_literal665 = nil
      tree_for_string_literal667 = nil
      tree_for_string_literal668 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 625:4: ( 'START' 'WITH' sql_condition )? 'CONNECT' 'BY' ( keyNOCYCLE )? sql_condition
        # at line 625:4: ( 'START' 'WITH' sql_condition )?
        alt_170 = 2
        look_170_0 = @input.peek( 1 )

        if ( look_170_0 == T__128 )
          alt_170 = 1
        end
        case alt_170
        when 1
          # at line 625:6: 'START' 'WITH' sql_condition
          string_literal664 = match( T__128, TOKENS_FOLLOWING_T__128_IN_hierarchical_query_clause_3936 )
          if @state.backtracking == 0

            tree_for_string_literal664 = @adaptor.create_with_payload( string_literal664 )
            @adaptor.add_child( root_0, tree_for_string_literal664 )

          end
          string_literal665 = match( T__78, TOKENS_FOLLOWING_T__78_IN_hierarchical_query_clause_3938 )
          if @state.backtracking == 0

            tree_for_string_literal665 = @adaptor.create_with_payload( string_literal665 )
            @adaptor.add_child( root_0, tree_for_string_literal665 )

          end
          @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_hierarchical_query_clause_3940 )
          sql_condition666 = sql_condition
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_condition666.tree )
          end

        end
        string_literal667 = match( T__129, TOKENS_FOLLOWING_T__129_IN_hierarchical_query_clause_3945 )
        if @state.backtracking == 0

          tree_for_string_literal667 = @adaptor.create_with_payload( string_literal667 )
          @adaptor.add_child( root_0, tree_for_string_literal667 )

        end
        string_literal668 = match( T__108, TOKENS_FOLLOWING_T__108_IN_hierarchical_query_clause_3947 )
        if @state.backtracking == 0

          tree_for_string_literal668 = @adaptor.create_with_payload( string_literal668 )
          @adaptor.add_child( root_0, tree_for_string_literal668 )

        end
        # at line 625:53: ( keyNOCYCLE )?
        alt_171 = 2
        alt_171 = @dfa171.predict( @input )
        case alt_171
        when 1
          # at line 625:55: keyNOCYCLE
          @state.following.push( TOKENS_FOLLOWING_keyNOCYCLE_IN_hierarchical_query_clause_3951 )
          keyNOCYCLE669 = keyNOCYCLE
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyNOCYCLE669.tree )
          end

        end
        @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_hierarchical_query_clause_3956 )
        sql_condition670 = sql_condition
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_condition670.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 98 )
        memoize( __method__, hierarchical_query_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    GroupByClauseReturnValue = define_return_scope 

    # 
    # parser rule group_by_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 627:1: group_by_clause : 'GROUP' 'BY' group_by_exprs ;
    # 
    def group_by_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 99 )
      return_value = GroupByClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      group_by_clause_start_index = @input.index

      root_0 = nil
      string_literal671 = nil
      string_literal672 = nil
      group_by_exprs673 = nil

      tree_for_string_literal671 = nil
      tree_for_string_literal672 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 628:4: 'GROUP' 'BY' group_by_exprs
        string_literal671 = match( T__130, TOKENS_FOLLOWING_T__130_IN_group_by_clause_3966 )
        if @state.backtracking == 0

          tree_for_string_literal671 = @adaptor.create_with_payload( string_literal671 )
          @adaptor.add_child( root_0, tree_for_string_literal671 )

        end
        string_literal672 = match( T__108, TOKENS_FOLLOWING_T__108_IN_group_by_clause_3968 )
        if @state.backtracking == 0

          tree_for_string_literal672 = @adaptor.create_with_payload( string_literal672 )
          @adaptor.add_child( root_0, tree_for_string_literal672 )

        end
        @state.following.push( TOKENS_FOLLOWING_group_by_exprs_IN_group_by_clause_3970 )
        group_by_exprs673 = group_by_exprs
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, group_by_exprs673.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 99 )
        memoize( __method__, group_by_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    GroupByExprsReturnValue = define_return_scope 

    # 
    # parser rule group_by_exprs
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 630:1: group_by_exprs : group_by_expr ( COMMA group_by_expr )* ;
    # 
    def group_by_exprs
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 100 )
      return_value = GroupByExprsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      group_by_exprs_start_index = @input.index

      root_0 = nil
      __COMMA675__ = nil
      group_by_expr674 = nil
      group_by_expr676 = nil

      tree_for_COMMA675 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 631:4: group_by_expr ( COMMA group_by_expr )*
        @state.following.push( TOKENS_FOLLOWING_group_by_expr_IN_group_by_exprs_3980 )
        group_by_expr674 = group_by_expr
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, group_by_expr674.tree )
        end
        # at line 631:18: ( COMMA group_by_expr )*
        while true # decision 172
          alt_172 = 2
          look_172_0 = @input.peek( 1 )

          if ( look_172_0 == COMMA )
            look_172_2 = @input.peek( 2 )

            if ( syntactic_predicate?( :synpred296_Plsql ) )
              alt_172 = 1

            end

          end
          case alt_172
          when 1
            # at line 631:20: COMMA group_by_expr
            __COMMA675__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_group_by_exprs_3984 )
            if @state.backtracking == 0

              tree_for_COMMA675 = @adaptor.create_with_payload( __COMMA675__ )
              @adaptor.add_child( root_0, tree_for_COMMA675 )

            end
            @state.following.push( TOKENS_FOLLOWING_group_by_expr_IN_group_by_exprs_3986 )
            group_by_expr676 = group_by_expr
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, group_by_expr676.tree )
            end

          else
            break # out of loop for decision 172
          end
        end # loop for decision 172
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 100 )
        memoize( __method__, group_by_exprs_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    GroupByExprReturnValue = define_return_scope 

    # 
    # parser rule group_by_expr
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 633:1: group_by_expr : ( rollup_cube_clause | grouping_sets_clause | grouping_expression_list );
    # 
    def group_by_expr
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 101 )
      return_value = GroupByExprReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      group_by_expr_start_index = @input.index

      root_0 = nil
      rollup_cube_clause677 = nil
      grouping_sets_clause678 = nil
      grouping_expression_list679 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 634:2: ( rollup_cube_clause | grouping_sets_clause | grouping_expression_list )
        alt_173 = 3
        alt_173 = @dfa173.predict( @input )
        case alt_173
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 634:4: rollup_cube_clause
          @state.following.push( TOKENS_FOLLOWING_rollup_cube_clause_IN_group_by_expr_3999 )
          rollup_cube_clause677 = rollup_cube_clause
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, rollup_cube_clause677.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 635:4: grouping_sets_clause
          @state.following.push( TOKENS_FOLLOWING_grouping_sets_clause_IN_group_by_expr_4004 )
          grouping_sets_clause678 = grouping_sets_clause
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, grouping_sets_clause678.tree )
          end

        when 3
          root_0 = @adaptor.create_flat_list


          # at line 636:4: grouping_expression_list
          @state.following.push( TOKENS_FOLLOWING_grouping_expression_list_IN_group_by_expr_4009 )
          grouping_expression_list679 = grouping_expression_list
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, grouping_expression_list679.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 101 )
        memoize( __method__, group_by_expr_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    RollupCubeClauseReturnValue = define_return_scope 

    # 
    # parser rule rollup_cube_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 638:1: rollup_cube_clause : ( keyROLLUP | keyCUBE ) LPAREN grouping_expression_list RPAREN ;
    # 
    def rollup_cube_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 102 )
      return_value = RollupCubeClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      rollup_cube_clause_start_index = @input.index

      root_0 = nil
      __LPAREN682__ = nil
      __RPAREN684__ = nil
      keyROLLUP680 = nil
      keyCUBE681 = nil
      grouping_expression_list683 = nil

      tree_for_LPAREN682 = nil
      tree_for_RPAREN684 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 639:4: ( keyROLLUP | keyCUBE ) LPAREN grouping_expression_list RPAREN
        # at line 639:4: ( keyROLLUP | keyCUBE )
        alt_174 = 2
        look_174_0 = @input.peek( 1 )

        if ( look_174_0 == ID )
          look_174_1 = @input.peek( 2 )

          if ( ( syntactic_predicate?( :synpred299_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("ROLLUP") ) ) )
            alt_174 = 1
          elsif ( ( self.input.look(1).text.upcase == ("CUBE") ) )
            alt_174 = 2
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 174, 1 )
          end
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 174, 0 )
        end
        case alt_174
        when 1
          # at line 639:6: keyROLLUP
          @state.following.push( TOKENS_FOLLOWING_keyROLLUP_IN_rollup_cube_clause_4021 )
          keyROLLUP680 = keyROLLUP
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyROLLUP680.tree )
          end

        when 2
          # at line 639:18: keyCUBE
          @state.following.push( TOKENS_FOLLOWING_keyCUBE_IN_rollup_cube_clause_4025 )
          keyCUBE681 = keyCUBE
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyCUBE681.tree )
          end

        end
        __LPAREN682__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_rollup_cube_clause_4029 )
        if @state.backtracking == 0

          tree_for_LPAREN682 = @adaptor.create_with_payload( __LPAREN682__ )
          @adaptor.add_child( root_0, tree_for_LPAREN682 )

        end
        @state.following.push( TOKENS_FOLLOWING_grouping_expression_list_IN_rollup_cube_clause_4031 )
        grouping_expression_list683 = grouping_expression_list
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, grouping_expression_list683.tree )
        end
        __RPAREN684__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_rollup_cube_clause_4033 )
        if @state.backtracking == 0

          tree_for_RPAREN684 = @adaptor.create_with_payload( __RPAREN684__ )
          @adaptor.add_child( root_0, tree_for_RPAREN684 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 102 )
        memoize( __method__, rollup_cube_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    GroupingSetsClauseReturnValue = define_return_scope 

    # 
    # parser rule grouping_sets_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 641:1: grouping_sets_clause : keyGROUPING keySETS LPAREN grouping_expression_list RPAREN ;
    # 
    def grouping_sets_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 103 )
      return_value = GroupingSetsClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      grouping_sets_clause_start_index = @input.index

      root_0 = nil
      __LPAREN687__ = nil
      __RPAREN689__ = nil
      keyGROUPING685 = nil
      keySETS686 = nil
      grouping_expression_list688 = nil

      tree_for_LPAREN687 = nil
      tree_for_RPAREN689 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 642:4: keyGROUPING keySETS LPAREN grouping_expression_list RPAREN
        @state.following.push( TOKENS_FOLLOWING_keyGROUPING_IN_grouping_sets_clause_4043 )
        keyGROUPING685 = keyGROUPING
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyGROUPING685.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_keySETS_IN_grouping_sets_clause_4045 )
        keySETS686 = keySETS
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keySETS686.tree )
        end
        __LPAREN687__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_grouping_sets_clause_4047 )
        if @state.backtracking == 0

          tree_for_LPAREN687 = @adaptor.create_with_payload( __LPAREN687__ )
          @adaptor.add_child( root_0, tree_for_LPAREN687 )

        end
        @state.following.push( TOKENS_FOLLOWING_grouping_expression_list_IN_grouping_sets_clause_4049 )
        grouping_expression_list688 = grouping_expression_list
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, grouping_expression_list688.tree )
        end
        __RPAREN689__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_grouping_sets_clause_4051 )
        if @state.backtracking == 0

          tree_for_RPAREN689 = @adaptor.create_with_payload( __RPAREN689__ )
          @adaptor.add_child( root_0, tree_for_RPAREN689 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 103 )
        memoize( __method__, grouping_sets_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    GroupingSetsExprsReturnValue = define_return_scope 

    # 
    # parser rule grouping_sets_exprs
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 644:1: grouping_sets_exprs : grouping_sets_expr ( COMMA grouping_sets_expr )* ;
    # 
    def grouping_sets_exprs
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 104 )
      return_value = GroupingSetsExprsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      grouping_sets_exprs_start_index = @input.index

      root_0 = nil
      __COMMA691__ = nil
      grouping_sets_expr690 = nil
      grouping_sets_expr692 = nil

      tree_for_COMMA691 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 645:4: grouping_sets_expr ( COMMA grouping_sets_expr )*
        @state.following.push( TOKENS_FOLLOWING_grouping_sets_expr_IN_grouping_sets_exprs_4061 )
        grouping_sets_expr690 = grouping_sets_expr
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, grouping_sets_expr690.tree )
        end
        # at line 645:23: ( COMMA grouping_sets_expr )*
        while true # decision 175
          alt_175 = 2
          look_175_0 = @input.peek( 1 )

          if ( look_175_0 == COMMA )
            alt_175 = 1

          end
          case alt_175
          when 1
            # at line 645:25: COMMA grouping_sets_expr
            __COMMA691__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_grouping_sets_exprs_4065 )
            if @state.backtracking == 0

              tree_for_COMMA691 = @adaptor.create_with_payload( __COMMA691__ )
              @adaptor.add_child( root_0, tree_for_COMMA691 )

            end
            @state.following.push( TOKENS_FOLLOWING_grouping_sets_expr_IN_grouping_sets_exprs_4067 )
            grouping_sets_expr692 = grouping_sets_expr
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, grouping_sets_expr692.tree )
            end

          else
            break # out of loop for decision 175
          end
        end # loop for decision 175
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 104 )
        memoize( __method__, grouping_sets_exprs_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    GroupingSetsExprReturnValue = define_return_scope 

    # 
    # parser rule grouping_sets_expr
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 647:1: grouping_sets_expr : ( rollup_cube_clause | grouping_expression_list );
    # 
    def grouping_sets_expr
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 105 )
      return_value = GroupingSetsExprReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      grouping_sets_expr_start_index = @input.index

      root_0 = nil
      rollup_cube_clause693 = nil
      grouping_expression_list694 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 648:2: ( rollup_cube_clause | grouping_expression_list )
        alt_176 = 2
        alt_176 = @dfa176.predict( @input )
        case alt_176
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 648:4: rollup_cube_clause
          @state.following.push( TOKENS_FOLLOWING_rollup_cube_clause_IN_grouping_sets_expr_4080 )
          rollup_cube_clause693 = rollup_cube_clause
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, rollup_cube_clause693.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 648:25: grouping_expression_list
          @state.following.push( TOKENS_FOLLOWING_grouping_expression_list_IN_grouping_sets_expr_4084 )
          grouping_expression_list694 = grouping_expression_list
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, grouping_expression_list694.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 105 )
        memoize( __method__, grouping_sets_expr_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ModelClauseReturnValue = define_return_scope 

    # 
    # parser rule model_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 650:1: model_clause : keyMODEL ( cell_reference_options ) ( return_rows_clause )? ( reference_model )+ main_model ;
    # 
    def model_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 106 )
      return_value = ModelClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      model_clause_start_index = @input.index

      root_0 = nil
      keyMODEL695 = nil
      cell_reference_options696 = nil
      return_rows_clause697 = nil
      reference_model698 = nil
      main_model699 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 651:4: keyMODEL ( cell_reference_options ) ( return_rows_clause )? ( reference_model )+ main_model
        @state.following.push( TOKENS_FOLLOWING_keyMODEL_IN_model_clause_4094 )
        keyMODEL695 = keyMODEL
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyMODEL695.tree )
        end
        # at line 651:13: ( cell_reference_options )
        # at line 651:15: cell_reference_options
        @state.following.push( TOKENS_FOLLOWING_cell_reference_options_IN_model_clause_4098 )
        cell_reference_options696 = cell_reference_options
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, cell_reference_options696.tree )
        end

        # at line 652:3: ( return_rows_clause )?
        alt_177 = 2
        look_177_0 = @input.peek( 1 )

        if ( look_177_0 == T__164 )
          alt_177 = 1
        end
        case alt_177
        when 1
          # at line 652:5: return_rows_clause
          @state.following.push( TOKENS_FOLLOWING_return_rows_clause_IN_model_clause_4106 )
          return_rows_clause697 = return_rows_clause
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, return_rows_clause697.tree )
          end

        end
        # at file 653:3: ( reference_model )+
        match_count_178 = 0
        while true
          alt_178 = 2
          look_178_0 = @input.peek( 1 )

          if ( look_178_0 == ID )
            look_178_1 = @input.peek( 2 )

            if ( look_178_1.between?( ID, DOUBLEQUOTED_STRING ) )
              look_178_3 = @input.peek( 3 )

              if ( look_178_3 == T__126 )
                alt_178 = 1

              end

            end

          end
          case alt_178
          when 1
            # at line 653:5: reference_model
            @state.following.push( TOKENS_FOLLOWING_reference_model_IN_model_clause_4115 )
            reference_model698 = reference_model
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, reference_model698.tree )
            end

          else
            match_count_178 > 0 and break
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            eee = EarlyExit(178)


            raise eee
          end
          match_count_178 += 1
        end

        @state.following.push( TOKENS_FOLLOWING_main_model_IN_model_clause_4120 )
        main_model699 = main_model
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, main_model699.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 106 )
        memoize( __method__, model_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CellReferenceOptionsReturnValue = define_return_scope 

    # 
    # parser rule cell_reference_options
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 655:1: cell_reference_options : ( ( keyIGNORE | keyKEEP ) keyNAV )? ( 'UNIQUE' ( keyDIMENSION | keySINGLE keyREFERENCE ) )? ;
    # 
    def cell_reference_options
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 107 )
      return_value = CellReferenceOptionsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      cell_reference_options_start_index = @input.index

      root_0 = nil
      string_literal703 = nil
      keyIGNORE700 = nil
      keyKEEP701 = nil
      keyNAV702 = nil
      keyDIMENSION704 = nil
      keySINGLE705 = nil
      keyREFERENCE706 = nil

      tree_for_string_literal703 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 656:4: ( ( keyIGNORE | keyKEEP ) keyNAV )? ( 'UNIQUE' ( keyDIMENSION | keySINGLE keyREFERENCE ) )?
        # at line 656:4: ( ( keyIGNORE | keyKEEP ) keyNAV )?
        alt_180 = 2
        look_180_0 = @input.peek( 1 )

        if ( look_180_0 == ID )
          look_180_1 = @input.peek( 2 )

          if ( look_180_1 == ID )
            look_180_3 = @input.peek( 3 )

            if ( ( ( syntactic_predicate?( :synpred305_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("IGNORE") ) ) ) or ( ( syntactic_predicate?( :synpred305_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("KEEP") ) ) ) )
              alt_180 = 1
            end
          end
        end
        case alt_180
        when 1
          # at line 656:6: ( keyIGNORE | keyKEEP ) keyNAV
          # at line 656:6: ( keyIGNORE | keyKEEP )
          alt_179 = 2
          look_179_0 = @input.peek( 1 )

          if ( look_179_0 == ID )
            look_179_1 = @input.peek( 2 )

            if ( ( syntactic_predicate?( :synpred304_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("IGNORE") ) ) )
              alt_179 = 1
            elsif ( ( self.input.look(1).text.upcase == ("KEEP") ) )
              alt_179 = 2
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 179, 1 )
            end
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 179, 0 )
          end
          case alt_179
          when 1
            # at line 656:8: keyIGNORE
            @state.following.push( TOKENS_FOLLOWING_keyIGNORE_IN_cell_reference_options_4134 )
            keyIGNORE700 = keyIGNORE
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyIGNORE700.tree )
            end

          when 2
            # at line 656:20: keyKEEP
            @state.following.push( TOKENS_FOLLOWING_keyKEEP_IN_cell_reference_options_4138 )
            keyKEEP701 = keyKEEP
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyKEEP701.tree )
            end

          end
          @state.following.push( TOKENS_FOLLOWING_keyNAV_IN_cell_reference_options_4142 )
          keyNAV702 = keyNAV
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyNAV702.tree )
          end

        end
        # at line 657:3: ( 'UNIQUE' ( keyDIMENSION | keySINGLE keyREFERENCE ) )?
        alt_182 = 2
        look_182_0 = @input.peek( 1 )

        if ( look_182_0 == T__118 )
          alt_182 = 1
        end
        case alt_182
        when 1
          # at line 657:5: 'UNIQUE' ( keyDIMENSION | keySINGLE keyREFERENCE )
          string_literal703 = match( T__118, TOKENS_FOLLOWING_T__118_IN_cell_reference_options_4151 )
          if @state.backtracking == 0

            tree_for_string_literal703 = @adaptor.create_with_payload( string_literal703 )
            @adaptor.add_child( root_0, tree_for_string_literal703 )

          end
          # at line 657:14: ( keyDIMENSION | keySINGLE keyREFERENCE )
          alt_181 = 2
          look_181_0 = @input.peek( 1 )

          if ( look_181_0 == ID )
            look_181_1 = @input.peek( 2 )

            if ( look_181_1 == ID )
              look_181_2 = @input.peek( 3 )

              if ( ( syntactic_predicate?( :synpred306_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("DIMENSION") ) ) )
                alt_181 = 1
              elsif ( ( self.input.look(1).text.upcase == ("SINGLE") ) )
                alt_181 = 2
              else
                @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

                raise NoViableAlternative( "", 181, 2 )
              end
            elsif ( look_181_1 == EOF || look_181_1 == LPAREN || look_181_1 == T__164 )
              alt_181 = 1
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 181, 1 )
            end
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 181, 0 )
          end
          case alt_181
          when 1
            # at line 657:16: keyDIMENSION
            @state.following.push( TOKENS_FOLLOWING_keyDIMENSION_IN_cell_reference_options_4155 )
            keyDIMENSION704 = keyDIMENSION
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyDIMENSION704.tree )
            end

          when 2
            # at line 657:31: keySINGLE keyREFERENCE
            @state.following.push( TOKENS_FOLLOWING_keySINGLE_IN_cell_reference_options_4159 )
            keySINGLE705 = keySINGLE
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keySINGLE705.tree )
            end
            @state.following.push( TOKENS_FOLLOWING_keyREFERENCE_IN_cell_reference_options_4161 )
            keyREFERENCE706 = keyREFERENCE
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyREFERENCE706.tree )
            end

          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 107 )
        memoize( __method__, cell_reference_options_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ReturnRowsClauseReturnValue = define_return_scope 

    # 
    # parser rule return_rows_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 659:1: return_rows_clause : keyRETURN ( keyUPDATED | 'ALL' ) 'ROWS' ;
    # 
    def return_rows_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 108 )
      return_value = ReturnRowsClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      return_rows_clause_start_index = @input.index

      root_0 = nil
      string_literal709 = nil
      string_literal710 = nil
      keyRETURN707 = nil
      keyUPDATED708 = nil

      tree_for_string_literal709 = nil
      tree_for_string_literal710 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 660:4: keyRETURN ( keyUPDATED | 'ALL' ) 'ROWS'
        @state.following.push( TOKENS_FOLLOWING_keyRETURN_IN_return_rows_clause_4176 )
        keyRETURN707 = keyRETURN
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyRETURN707.tree )
        end
        # at line 660:14: ( keyUPDATED | 'ALL' )
        alt_183 = 2
        look_183_0 = @input.peek( 1 )

        if ( look_183_0 == ID )
          alt_183 = 1
        elsif ( look_183_0 == T__119 )
          alt_183 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 183, 0 )
        end
        case alt_183
        when 1
          # at line 660:16: keyUPDATED
          @state.following.push( TOKENS_FOLLOWING_keyUPDATED_IN_return_rows_clause_4180 )
          keyUPDATED708 = keyUPDATED
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyUPDATED708.tree )
          end

        when 2
          # at line 660:29: 'ALL'
          string_literal709 = match( T__119, TOKENS_FOLLOWING_T__119_IN_return_rows_clause_4184 )
          if @state.backtracking == 0

            tree_for_string_literal709 = @adaptor.create_with_payload( string_literal709 )
            @adaptor.add_child( root_0, tree_for_string_literal709 )

          end

        end
        string_literal710 = match( T__131, TOKENS_FOLLOWING_T__131_IN_return_rows_clause_4188 )
        if @state.backtracking == 0

          tree_for_string_literal710 = @adaptor.create_with_payload( string_literal710 )
          @adaptor.add_child( root_0, tree_for_string_literal710 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 108 )
        memoize( __method__, return_rows_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ReferenceModelReturnValue = define_return_scope 

    # 
    # parser rule reference_model
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 662:1: reference_model : keyREFERENCE reference_model_name 'ON' LPAREN subquery RPAREN model_column_clauses ( cell_reference_options ) ;
    # 
    def reference_model
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 109 )
      return_value = ReferenceModelReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      reference_model_start_index = @input.index

      root_0 = nil
      string_literal713 = nil
      __LPAREN714__ = nil
      __RPAREN716__ = nil
      keyREFERENCE711 = nil
      reference_model_name712 = nil
      subquery715 = nil
      model_column_clauses717 = nil
      cell_reference_options718 = nil

      tree_for_string_literal713 = nil
      tree_for_LPAREN714 = nil
      tree_for_RPAREN716 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 663:4: keyREFERENCE reference_model_name 'ON' LPAREN subquery RPAREN model_column_clauses ( cell_reference_options )
        @state.following.push( TOKENS_FOLLOWING_keyREFERENCE_IN_reference_model_4198 )
        keyREFERENCE711 = keyREFERENCE
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyREFERENCE711.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_reference_model_name_IN_reference_model_4200 )
        reference_model_name712 = reference_model_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, reference_model_name712.tree )
        end
        string_literal713 = match( T__126, TOKENS_FOLLOWING_T__126_IN_reference_model_4202 )
        if @state.backtracking == 0

          tree_for_string_literal713 = @adaptor.create_with_payload( string_literal713 )
          @adaptor.add_child( root_0, tree_for_string_literal713 )

        end
        __LPAREN714__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_reference_model_4204 )
        if @state.backtracking == 0

          tree_for_LPAREN714 = @adaptor.create_with_payload( __LPAREN714__ )
          @adaptor.add_child( root_0, tree_for_LPAREN714 )

        end
        @state.following.push( TOKENS_FOLLOWING_subquery_IN_reference_model_4206 )
        subquery715 = subquery
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, subquery715.tree )
        end
        __RPAREN716__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_reference_model_4208 )
        if @state.backtracking == 0

          tree_for_RPAREN716 = @adaptor.create_with_payload( __RPAREN716__ )
          @adaptor.add_child( root_0, tree_for_RPAREN716 )

        end
        @state.following.push( TOKENS_FOLLOWING_model_column_clauses_IN_reference_model_4212 )
        model_column_clauses717 = model_column_clauses
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, model_column_clauses717.tree )
        end
        # at line 664:24: ( cell_reference_options )
        # at line 664:26: cell_reference_options
        @state.following.push( TOKENS_FOLLOWING_cell_reference_options_IN_reference_model_4216 )
        cell_reference_options718 = cell_reference_options
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, cell_reference_options718.tree )
        end

        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 109 )
        memoize( __method__, reference_model_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ReferenceModelNameReturnValue = define_return_scope 

    # 
    # parser rule reference_model_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 666:1: reference_model_name : identifier ;
    # 
    def reference_model_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 110 )
      return_value = ReferenceModelNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      reference_model_name_start_index = @input.index

      root_0 = nil
      identifier719 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 667:4: identifier
        @state.following.push( TOKENS_FOLLOWING_identifier_IN_reference_model_name_4228 )
        identifier719 = identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, identifier719.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 110 )
        memoize( __method__, reference_model_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    MainModelReturnValue = define_return_scope 

    # 
    # parser rule main_model
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 669:1: main_model : ( keyMAIN main_model_name )? model_column_clauses ( cell_reference_options ) model_rules_clause ;
    # 
    def main_model
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 111 )
      return_value = MainModelReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      main_model_start_index = @input.index

      root_0 = nil
      keyMAIN720 = nil
      main_model_name721 = nil
      model_column_clauses722 = nil
      cell_reference_options723 = nil
      model_rules_clause724 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 670:4: ( keyMAIN main_model_name )? model_column_clauses ( cell_reference_options ) model_rules_clause
        # at line 670:4: ( keyMAIN main_model_name )?
        alt_184 = 2
        look_184_0 = @input.peek( 1 )

        if ( look_184_0 == ID )
          look_184_1 = @input.peek( 2 )

          if ( look_184_1.between?( ID, DOUBLEQUOTED_STRING ) )
            alt_184 = 1
          end
        end
        case alt_184
        when 1
          # at line 670:6: keyMAIN main_model_name
          @state.following.push( TOKENS_FOLLOWING_keyMAIN_IN_main_model_4240 )
          keyMAIN720 = keyMAIN
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyMAIN720.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_main_model_name_IN_main_model_4242 )
          main_model_name721 = main_model_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, main_model_name721.tree )
          end

        end
        @state.following.push( TOKENS_FOLLOWING_model_column_clauses_IN_main_model_4247 )
        model_column_clauses722 = model_column_clauses
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, model_column_clauses722.tree )
        end
        # at line 671:3: ( cell_reference_options )
        # at line 671:5: cell_reference_options
        @state.following.push( TOKENS_FOLLOWING_cell_reference_options_IN_main_model_4253 )
        cell_reference_options723 = cell_reference_options
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, cell_reference_options723.tree )
        end

        @state.following.push( TOKENS_FOLLOWING_model_rules_clause_IN_main_model_4257 )
        model_rules_clause724 = model_rules_clause
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, model_rules_clause724.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 111 )
        memoize( __method__, main_model_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    MainModelNameReturnValue = define_return_scope 

    # 
    # parser rule main_model_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 673:1: main_model_name : identifier ;
    # 
    def main_model_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 112 )
      return_value = MainModelNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      main_model_name_start_index = @input.index

      root_0 = nil
      identifier725 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 674:4: identifier
        @state.following.push( TOKENS_FOLLOWING_identifier_IN_main_model_name_4267 )
        identifier725 = identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, identifier725.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 112 )
        memoize( __method__, main_model_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ModelColumnClausesReturnValue = define_return_scope 

    # 
    # parser rule model_column_clauses
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 676:1: model_column_clauses : ( query_partition_clause ( column_spec )? )? keyDIMENSION 'BY' LPAREN model_columns RPAREN keyMEASURES LPAREN model_columns RPAREN ;
    # 
    def model_column_clauses
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 113 )
      return_value = ModelColumnClausesReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      model_column_clauses_start_index = @input.index

      root_0 = nil
      string_literal729 = nil
      __LPAREN730__ = nil
      __RPAREN732__ = nil
      __LPAREN734__ = nil
      __RPAREN736__ = nil
      query_partition_clause726 = nil
      column_spec727 = nil
      keyDIMENSION728 = nil
      model_columns731 = nil
      keyMEASURES733 = nil
      model_columns735 = nil

      tree_for_string_literal729 = nil
      tree_for_LPAREN730 = nil
      tree_for_RPAREN732 = nil
      tree_for_LPAREN734 = nil
      tree_for_RPAREN736 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 677:4: ( query_partition_clause ( column_spec )? )? keyDIMENSION 'BY' LPAREN model_columns RPAREN keyMEASURES LPAREN model_columns RPAREN
        # at line 677:4: ( query_partition_clause ( column_spec )? )?
        alt_186 = 2
        look_186_0 = @input.peek( 1 )

        if ( look_186_0 == ID )
          look_186_1 = @input.peek( 2 )

          if ( ( syntactic_predicate?( :synpred311_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("PARTITION") ) ) )
            alt_186 = 1
          end
        end
        case alt_186
        when 1
          # at line 677:6: query_partition_clause ( column_spec )?
          @state.following.push( TOKENS_FOLLOWING_query_partition_clause_IN_model_column_clauses_4279 )
          query_partition_clause726 = query_partition_clause
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, query_partition_clause726.tree )
          end
          # at line 677:29: ( column_spec )?
          alt_185 = 2
          look_185_0 = @input.peek( 1 )

          if ( look_185_0 == ID )
            look_185_1 = @input.peek( 2 )

            if ( look_185_1 == DOT || look_185_1 == ID )
              alt_185 = 1
            end
          elsif ( look_185_0 == DOUBLEQUOTED_STRING || look_185_0 == T__100 )
            alt_185 = 1
          end
          case alt_185
          when 1
            # at line 677:31: column_spec
            @state.following.push( TOKENS_FOLLOWING_column_spec_IN_model_column_clauses_4283 )
            column_spec727 = column_spec
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, column_spec727.tree )
            end

          end

        end
        @state.following.push( TOKENS_FOLLOWING_keyDIMENSION_IN_model_column_clauses_4293 )
        keyDIMENSION728 = keyDIMENSION
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyDIMENSION728.tree )
        end
        string_literal729 = match( T__108, TOKENS_FOLLOWING_T__108_IN_model_column_clauses_4295 )
        if @state.backtracking == 0

          tree_for_string_literal729 = @adaptor.create_with_payload( string_literal729 )
          @adaptor.add_child( root_0, tree_for_string_literal729 )

        end
        __LPAREN730__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_model_column_clauses_4297 )
        if @state.backtracking == 0

          tree_for_LPAREN730 = @adaptor.create_with_payload( __LPAREN730__ )
          @adaptor.add_child( root_0, tree_for_LPAREN730 )

        end
        @state.following.push( TOKENS_FOLLOWING_model_columns_IN_model_column_clauses_4299 )
        model_columns731 = model_columns
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, model_columns731.tree )
        end
        __RPAREN732__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_model_column_clauses_4301 )
        if @state.backtracking == 0

          tree_for_RPAREN732 = @adaptor.create_with_payload( __RPAREN732__ )
          @adaptor.add_child( root_0, tree_for_RPAREN732 )

        end
        @state.following.push( TOKENS_FOLLOWING_keyMEASURES_IN_model_column_clauses_4305 )
        keyMEASURES733 = keyMEASURES
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyMEASURES733.tree )
        end
        __LPAREN734__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_model_column_clauses_4307 )
        if @state.backtracking == 0

          tree_for_LPAREN734 = @adaptor.create_with_payload( __LPAREN734__ )
          @adaptor.add_child( root_0, tree_for_LPAREN734 )

        end
        @state.following.push( TOKENS_FOLLOWING_model_columns_IN_model_column_clauses_4309 )
        model_columns735 = model_columns
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, model_columns735.tree )
        end
        __RPAREN736__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_model_column_clauses_4311 )
        if @state.backtracking == 0

          tree_for_RPAREN736 = @adaptor.create_with_payload( __RPAREN736__ )
          @adaptor.add_child( root_0, tree_for_RPAREN736 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 113 )
        memoize( __method__, model_column_clauses_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ModelColumnsReturnValue = define_return_scope 

    # 
    # parser rule model_columns
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 681:1: model_columns : model_column ( COMMA model_column )* ;
    # 
    def model_columns
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 114 )
      return_value = ModelColumnsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      model_columns_start_index = @input.index

      root_0 = nil
      __COMMA738__ = nil
      model_column737 = nil
      model_column739 = nil

      tree_for_COMMA738 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 682:4: model_column ( COMMA model_column )*
        @state.following.push( TOKENS_FOLLOWING_model_column_IN_model_columns_4321 )
        model_column737 = model_column
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, model_column737.tree )
        end
        # at line 682:17: ( COMMA model_column )*
        while true # decision 187
          alt_187 = 2
          look_187_0 = @input.peek( 1 )

          if ( look_187_0 == COMMA )
            alt_187 = 1

          end
          case alt_187
          when 1
            # at line 682:19: COMMA model_column
            __COMMA738__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_model_columns_4325 )
            if @state.backtracking == 0

              tree_for_COMMA738 = @adaptor.create_with_payload( __COMMA738__ )
              @adaptor.add_child( root_0, tree_for_COMMA738 )

            end
            @state.following.push( TOKENS_FOLLOWING_model_column_IN_model_columns_4327 )
            model_column739 = model_column
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, model_column739.tree )
            end

          else
            break # out of loop for decision 187
          end
        end # loop for decision 187
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 114 )
        memoize( __method__, model_columns_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ModelColumnReturnValue = define_return_scope 

    # 
    # parser rule model_column
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 684:1: model_column : sql_expression ( ( 'AS' )? column_spec )? ;
    # 
    def model_column
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 115 )
      return_value = ModelColumnReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      model_column_start_index = @input.index

      root_0 = nil
      string_literal741 = nil
      sql_expression740 = nil
      column_spec742 = nil

      tree_for_string_literal741 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 685:4: sql_expression ( ( 'AS' )? column_spec )?
        @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_model_column_4340 )
        sql_expression740 = sql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_expression740.tree )
        end
        # at line 685:19: ( ( 'AS' )? column_spec )?
        alt_189 = 2
        look_189_0 = @input.peek( 1 )

        if ( look_189_0.between?( ID, DOUBLEQUOTED_STRING ) || look_189_0 == T__53 || look_189_0 == T__100 )
          alt_189 = 1
        end
        case alt_189
        when 1
          # at line 685:21: ( 'AS' )? column_spec
          # at line 685:21: ( 'AS' )?
          alt_188 = 2
          look_188_0 = @input.peek( 1 )

          if ( look_188_0 == T__53 )
            alt_188 = 1
          end
          case alt_188
          when 1
            # at line 685:23: 'AS'
            string_literal741 = match( T__53, TOKENS_FOLLOWING_T__53_IN_model_column_4346 )
            if @state.backtracking == 0

              tree_for_string_literal741 = @adaptor.create_with_payload( string_literal741 )
              @adaptor.add_child( root_0, tree_for_string_literal741 )

            end

          end
          @state.following.push( TOKENS_FOLLOWING_column_spec_IN_model_column_4351 )
          column_spec742 = column_spec
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, column_spec742.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 115 )
        memoize( __method__, model_column_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ModelRulesClauseReturnValue = define_return_scope 

    # 
    # parser rule model_rules_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 687:1: model_rules_clause : ( keyRULES ( 'UPDATE' | keyUPSERT ( 'ALL' )? )? ( ( keyAUTOMATIC | keySEQUENTIAL ) 'ORDER' )? )? ( keyITERATE LPAREN NUMBER RPAREN ( keyUNTIL LPAREN sql_condition RPAREN )? )? LPAREN model_rules_exprs RPAREN ;
    # 
    def model_rules_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 116 )
      return_value = ModelRulesClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      model_rules_clause_start_index = @input.index

      root_0 = nil
      string_literal744 = nil
      string_literal746 = nil
      string_literal749 = nil
      __LPAREN751__ = nil
      __NUMBER752__ = nil
      __RPAREN753__ = nil
      __LPAREN755__ = nil
      __RPAREN757__ = nil
      __LPAREN758__ = nil
      __RPAREN760__ = nil
      keyRULES743 = nil
      keyUPSERT745 = nil
      keyAUTOMATIC747 = nil
      keySEQUENTIAL748 = nil
      keyITERATE750 = nil
      keyUNTIL754 = nil
      sql_condition756 = nil
      model_rules_exprs759 = nil

      tree_for_string_literal744 = nil
      tree_for_string_literal746 = nil
      tree_for_string_literal749 = nil
      tree_for_LPAREN751 = nil
      tree_for_NUMBER752 = nil
      tree_for_RPAREN753 = nil
      tree_for_LPAREN755 = nil
      tree_for_RPAREN757 = nil
      tree_for_LPAREN758 = nil
      tree_for_RPAREN760 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 688:4: ( keyRULES ( 'UPDATE' | keyUPSERT ( 'ALL' )? )? ( ( keyAUTOMATIC | keySEQUENTIAL ) 'ORDER' )? )? ( keyITERATE LPAREN NUMBER RPAREN ( keyUNTIL LPAREN sql_condition RPAREN )? )? LPAREN model_rules_exprs RPAREN
        # at line 688:4: ( keyRULES ( 'UPDATE' | keyUPSERT ( 'ALL' )? )? ( ( keyAUTOMATIC | keySEQUENTIAL ) 'ORDER' )? )?
        alt_194 = 2
        look_194_0 = @input.peek( 1 )

        if ( look_194_0 == ID )
          look_194_1 = @input.peek( 2 )

          if ( look_194_1 == ID || look_194_1 == T__132 )
            alt_194 = 1
          elsif ( look_194_1 == LPAREN )
            look_194_4 = @input.peek( 3 )

            if ( look_194_4.between?( ID, DOUBLEQUOTED_STRING ) || look_194_4 == T__100 || look_194_4 == T__132 )
              alt_194 = 1
            end
          end
        end
        case alt_194
        when 1
          # at line 688:6: keyRULES ( 'UPDATE' | keyUPSERT ( 'ALL' )? )? ( ( keyAUTOMATIC | keySEQUENTIAL ) 'ORDER' )?
          @state.following.push( TOKENS_FOLLOWING_keyRULES_IN_model_rules_clause_4366 )
          keyRULES743 = keyRULES
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyRULES743.tree )
          end
          # at line 688:15: ( 'UPDATE' | keyUPSERT ( 'ALL' )? )?
          alt_191 = 3
          look_191_0 = @input.peek( 1 )

          if ( look_191_0 == T__132 )
            alt_191 = 1
          elsif ( look_191_0 == ID )
            look_191_2 = @input.peek( 2 )

            if ( look_191_2 == ID || look_191_2 == T__119 )
              alt_191 = 2
            elsif ( look_191_2 == LPAREN )
              look_191_5 = @input.peek( 3 )

              if ( look_191_5.between?( ID, DOUBLEQUOTED_STRING ) || look_191_5 == T__100 || look_191_5 == T__132 )
                alt_191 = 2
              end
            end
          end
          case alt_191
          when 1
            # at line 688:17: 'UPDATE'
            string_literal744 = match( T__132, TOKENS_FOLLOWING_T__132_IN_model_rules_clause_4370 )
            if @state.backtracking == 0

              tree_for_string_literal744 = @adaptor.create_with_payload( string_literal744 )
              @adaptor.add_child( root_0, tree_for_string_literal744 )

            end

          when 2
            # at line 688:28: keyUPSERT ( 'ALL' )?
            @state.following.push( TOKENS_FOLLOWING_keyUPSERT_IN_model_rules_clause_4374 )
            keyUPSERT745 = keyUPSERT
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyUPSERT745.tree )
            end
            # at line 688:38: ( 'ALL' )?
            alt_190 = 2
            look_190_0 = @input.peek( 1 )

            if ( look_190_0 == T__119 )
              alt_190 = 1
            end
            case alt_190
            when 1
              # at line 688:40: 'ALL'
              string_literal746 = match( T__119, TOKENS_FOLLOWING_T__119_IN_model_rules_clause_4378 )
              if @state.backtracking == 0

                tree_for_string_literal746 = @adaptor.create_with_payload( string_literal746 )
                @adaptor.add_child( root_0, tree_for_string_literal746 )

              end

            end

          end
          # at line 688:52: ( ( keyAUTOMATIC | keySEQUENTIAL ) 'ORDER' )?
          alt_193 = 2
          look_193_0 = @input.peek( 1 )

          if ( look_193_0 == ID )
            look_193_1 = @input.peek( 2 )

            if ( look_193_1 == T__133 )
              alt_193 = 1
            end
          end
          case alt_193
          when 1
            # at line 688:54: ( keyAUTOMATIC | keySEQUENTIAL ) 'ORDER'
            # at line 688:54: ( keyAUTOMATIC | keySEQUENTIAL )
            alt_192 = 2
            look_192_0 = @input.peek( 1 )

            if ( look_192_0 == ID )
              look_192_1 = @input.peek( 2 )

              if ( ( syntactic_predicate?( :synpred318_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("AUTOMATIC") ) ) )
                alt_192 = 1
              elsif ( ( self.input.look(1).text.upcase == ("SEQUENTIAL") ) )
                alt_192 = 2
              else
                @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

                raise NoViableAlternative( "", 192, 1 )
              end
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 192, 0 )
            end
            case alt_192
            when 1
              # at line 688:56: keyAUTOMATIC
              @state.following.push( TOKENS_FOLLOWING_keyAUTOMATIC_IN_model_rules_clause_4390 )
              keyAUTOMATIC747 = keyAUTOMATIC
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, keyAUTOMATIC747.tree )
              end

            when 2
              # at line 688:71: keySEQUENTIAL
              @state.following.push( TOKENS_FOLLOWING_keySEQUENTIAL_IN_model_rules_clause_4394 )
              keySEQUENTIAL748 = keySEQUENTIAL
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, keySEQUENTIAL748.tree )
              end

            end
            string_literal749 = match( T__133, TOKENS_FOLLOWING_T__133_IN_model_rules_clause_4398 )
            if @state.backtracking == 0

              tree_for_string_literal749 = @adaptor.create_with_payload( string_literal749 )
              @adaptor.add_child( root_0, tree_for_string_literal749 )

            end

          end

        end
        # at line 689:3: ( keyITERATE LPAREN NUMBER RPAREN ( keyUNTIL LPAREN sql_condition RPAREN )? )?
        alt_196 = 2
        look_196_0 = @input.peek( 1 )

        if ( look_196_0 == ID )
          alt_196 = 1
        end
        case alt_196
        when 1
          # at line 689:5: keyITERATE LPAREN NUMBER RPAREN ( keyUNTIL LPAREN sql_condition RPAREN )?
          @state.following.push( TOKENS_FOLLOWING_keyITERATE_IN_model_rules_clause_4410 )
          keyITERATE750 = keyITERATE
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyITERATE750.tree )
          end
          __LPAREN751__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_model_rules_clause_4412 )
          if @state.backtracking == 0

            tree_for_LPAREN751 = @adaptor.create_with_payload( __LPAREN751__ )
            @adaptor.add_child( root_0, tree_for_LPAREN751 )

          end
          __NUMBER752__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_model_rules_clause_4414 )
          if @state.backtracking == 0

            tree_for_NUMBER752 = @adaptor.create_with_payload( __NUMBER752__ )
            @adaptor.add_child( root_0, tree_for_NUMBER752 )

          end
          __RPAREN753__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_model_rules_clause_4416 )
          if @state.backtracking == 0

            tree_for_RPAREN753 = @adaptor.create_with_payload( __RPAREN753__ )
            @adaptor.add_child( root_0, tree_for_RPAREN753 )

          end
          # at line 689:37: ( keyUNTIL LPAREN sql_condition RPAREN )?
          alt_195 = 2
          look_195_0 = @input.peek( 1 )

          if ( look_195_0 == ID )
            alt_195 = 1
          end
          case alt_195
          when 1
            # at line 689:39: keyUNTIL LPAREN sql_condition RPAREN
            @state.following.push( TOKENS_FOLLOWING_keyUNTIL_IN_model_rules_clause_4420 )
            keyUNTIL754 = keyUNTIL
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyUNTIL754.tree )
            end
            __LPAREN755__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_model_rules_clause_4422 )
            if @state.backtracking == 0

              tree_for_LPAREN755 = @adaptor.create_with_payload( __LPAREN755__ )
              @adaptor.add_child( root_0, tree_for_LPAREN755 )

            end
            @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_model_rules_clause_4424 )
            sql_condition756 = sql_condition
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, sql_condition756.tree )
            end
            __RPAREN757__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_model_rules_clause_4426 )
            if @state.backtracking == 0

              tree_for_RPAREN757 = @adaptor.create_with_payload( __RPAREN757__ )
              @adaptor.add_child( root_0, tree_for_RPAREN757 )

            end

          end

        end
        __LPAREN758__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_model_rules_clause_4436 )
        if @state.backtracking == 0

          tree_for_LPAREN758 = @adaptor.create_with_payload( __LPAREN758__ )
          @adaptor.add_child( root_0, tree_for_LPAREN758 )

        end
        @state.following.push( TOKENS_FOLLOWING_model_rules_exprs_IN_model_rules_clause_4438 )
        model_rules_exprs759 = model_rules_exprs
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, model_rules_exprs759.tree )
        end
        __RPAREN760__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_model_rules_clause_4440 )
        if @state.backtracking == 0

          tree_for_RPAREN760 = @adaptor.create_with_payload( __RPAREN760__ )
          @adaptor.add_child( root_0, tree_for_RPAREN760 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 116 )
        memoize( __method__, model_rules_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ModelRulesExprsReturnValue = define_return_scope 

    # 
    # parser rule model_rules_exprs
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 692:1: model_rules_exprs : model_rules_expr ( COMMA model_rules_expr )* ;
    # 
    def model_rules_exprs
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 117 )
      return_value = ModelRulesExprsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      model_rules_exprs_start_index = @input.index

      root_0 = nil
      __COMMA762__ = nil
      model_rules_expr761 = nil
      model_rules_expr763 = nil

      tree_for_COMMA762 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 693:4: model_rules_expr ( COMMA model_rules_expr )*
        @state.following.push( TOKENS_FOLLOWING_model_rules_expr_IN_model_rules_exprs_4450 )
        model_rules_expr761 = model_rules_expr
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, model_rules_expr761.tree )
        end
        # at line 693:21: ( COMMA model_rules_expr )*
        while true # decision 197
          alt_197 = 2
          look_197_0 = @input.peek( 1 )

          if ( look_197_0 == COMMA )
            alt_197 = 1

          end
          case alt_197
          when 1
            # at line 693:23: COMMA model_rules_expr
            __COMMA762__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_model_rules_exprs_4454 )
            if @state.backtracking == 0

              tree_for_COMMA762 = @adaptor.create_with_payload( __COMMA762__ )
              @adaptor.add_child( root_0, tree_for_COMMA762 )

            end
            @state.following.push( TOKENS_FOLLOWING_model_rules_expr_IN_model_rules_exprs_4456 )
            model_rules_expr763 = model_rules_expr
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, model_rules_expr763.tree )
            end

          else
            break # out of loop for decision 197
          end
        end # loop for decision 197
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 117 )
        memoize( __method__, model_rules_exprs_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ModelRulesExprReturnValue = define_return_scope 

    # 
    # parser rule model_rules_expr
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 695:1: model_rules_expr : ( 'UPDATE' | keyUPSERT ( 'ALL' )? )? cell_assignment ( order_by_clause )? EQ sql_expression ;
    # 
    def model_rules_expr
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 118 )
      return_value = ModelRulesExprReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      model_rules_expr_start_index = @input.index

      root_0 = nil
      string_literal764 = nil
      string_literal766 = nil
      __EQ769__ = nil
      keyUPSERT765 = nil
      cell_assignment767 = nil
      order_by_clause768 = nil
      sql_expression770 = nil

      tree_for_string_literal764 = nil
      tree_for_string_literal766 = nil
      tree_for_EQ769 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 696:4: ( 'UPDATE' | keyUPSERT ( 'ALL' )? )? cell_assignment ( order_by_clause )? EQ sql_expression
        # at line 696:4: ( 'UPDATE' | keyUPSERT ( 'ALL' )? )?
        alt_199 = 3
        look_199_0 = @input.peek( 1 )

        if ( look_199_0 == T__132 )
          alt_199 = 1
        elsif ( look_199_0 == ID )
          look_199_2 = @input.peek( 2 )

          if ( look_199_2.between?( ID, DOUBLEQUOTED_STRING ) || look_199_2 == T__100 || look_199_2 == T__119 )
            alt_199 = 2
          end
        end
        case alt_199
        when 1
          # at line 696:6: 'UPDATE'
          string_literal764 = match( T__132, TOKENS_FOLLOWING_T__132_IN_model_rules_expr_4471 )
          if @state.backtracking == 0

            tree_for_string_literal764 = @adaptor.create_with_payload( string_literal764 )
            @adaptor.add_child( root_0, tree_for_string_literal764 )

          end

        when 2
          # at line 696:17: keyUPSERT ( 'ALL' )?
          @state.following.push( TOKENS_FOLLOWING_keyUPSERT_IN_model_rules_expr_4475 )
          keyUPSERT765 = keyUPSERT
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyUPSERT765.tree )
          end
          # at line 696:27: ( 'ALL' )?
          alt_198 = 2
          look_198_0 = @input.peek( 1 )

          if ( look_198_0 == T__119 )
            alt_198 = 1
          end
          case alt_198
          when 1
            # at line 696:29: 'ALL'
            string_literal766 = match( T__119, TOKENS_FOLLOWING_T__119_IN_model_rules_expr_4479 )
            if @state.backtracking == 0

              tree_for_string_literal766 = @adaptor.create_with_payload( string_literal766 )
              @adaptor.add_child( root_0, tree_for_string_literal766 )

            end

          end

        end
        @state.following.push( TOKENS_FOLLOWING_cell_assignment_IN_model_rules_expr_4487 )
        cell_assignment767 = cell_assignment
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, cell_assignment767.tree )
        end
        # at line 696:57: ( order_by_clause )?
        alt_200 = 2
        look_200_0 = @input.peek( 1 )

        if ( look_200_0 == T__133 )
          alt_200 = 1
        end
        case alt_200
        when 1
          # at line 696:59: order_by_clause
          @state.following.push( TOKENS_FOLLOWING_order_by_clause_IN_model_rules_expr_4491 )
          order_by_clause768 = order_by_clause
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, order_by_clause768.tree )
          end

        end
        __EQ769__ = match( EQ, TOKENS_FOLLOWING_EQ_IN_model_rules_expr_4496 )
        if @state.backtracking == 0

          tree_for_EQ769 = @adaptor.create_with_payload( __EQ769__ )
          @adaptor.add_child( root_0, tree_for_EQ769 )

        end
        @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_model_rules_expr_4498 )
        sql_expression770 = sql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_expression770.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 118 )
        memoize( __method__, model_rules_expr_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CellAssignmentReturnValue = define_return_scope 

    # 
    # parser rule cell_assignment
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 698:1: cell_assignment : measure_column LBRACK ( multi_column_for_loop | cell_assignment_exprs ) RBRACK ;
    # 
    def cell_assignment
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 119 )
      return_value = CellAssignmentReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      cell_assignment_start_index = @input.index

      root_0 = nil
      __LBRACK772__ = nil
      __RBRACK775__ = nil
      measure_column771 = nil
      multi_column_for_loop773 = nil
      cell_assignment_exprs774 = nil

      tree_for_LBRACK772 = nil
      tree_for_RBRACK775 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 699:4: measure_column LBRACK ( multi_column_for_loop | cell_assignment_exprs ) RBRACK
        @state.following.push( TOKENS_FOLLOWING_measure_column_IN_cell_assignment_4508 )
        measure_column771 = measure_column
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, measure_column771.tree )
        end
        __LBRACK772__ = match( LBRACK, TOKENS_FOLLOWING_LBRACK_IN_cell_assignment_4510 )
        if @state.backtracking == 0

          tree_for_LBRACK772 = @adaptor.create_with_payload( __LBRACK772__ )
          @adaptor.add_child( root_0, tree_for_LBRACK772 )

        end
        # at line 699:26: ( multi_column_for_loop | cell_assignment_exprs )
        alt_201 = 2
        look_201_0 = @input.peek( 1 )

        if ( look_201_0 == T__112 )
          look_201_1 = @input.peek( 2 )

          if ( look_201_1 == LPAREN )
            alt_201 = 1
          elsif ( look_201_1.between?( ID, DOUBLEQUOTED_STRING ) || look_201_1 == T__100 )
            alt_201 = 2
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 201, 1 )
          end
        elsif ( look_201_0 == LPAREN || look_201_0.between?( PLUS, QUOTED_STRING ) || look_201_0.between?( ID, DOUBLEQUOTED_STRING ) || look_201_0.between?( T__57, T__58 ) || look_201_0 == T__100 || look_201_0.between?( T__110, T__111 ) || look_201_0.between?( T__116, T__117 ) || look_201_0.between?( T__140, T__142 ) || look_201_0 == T__144 || look_201_0 == T__146 )
          alt_201 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 201, 0 )
        end
        case alt_201
        when 1
          # at line 699:28: multi_column_for_loop
          @state.following.push( TOKENS_FOLLOWING_multi_column_for_loop_IN_cell_assignment_4514 )
          multi_column_for_loop773 = multi_column_for_loop
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, multi_column_for_loop773.tree )
          end

        when 2
          # at line 699:52: cell_assignment_exprs
          @state.following.push( TOKENS_FOLLOWING_cell_assignment_exprs_IN_cell_assignment_4518 )
          cell_assignment_exprs774 = cell_assignment_exprs
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, cell_assignment_exprs774.tree )
          end

        end
        __RBRACK775__ = match( RBRACK, TOKENS_FOLLOWING_RBRACK_IN_cell_assignment_4522 )
        if @state.backtracking == 0

          tree_for_RBRACK775 = @adaptor.create_with_payload( __RBRACK775__ )
          @adaptor.add_child( root_0, tree_for_RBRACK775 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 119 )
        memoize( __method__, cell_assignment_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CellAssignmentExprsReturnValue = define_return_scope 

    # 
    # parser rule cell_assignment_exprs
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 701:1: cell_assignment_exprs : cell_assignment_expr ( COMMA cell_assignment_expr )* ;
    # 
    def cell_assignment_exprs
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 120 )
      return_value = CellAssignmentExprsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      cell_assignment_exprs_start_index = @input.index

      root_0 = nil
      __COMMA777__ = nil
      cell_assignment_expr776 = nil
      cell_assignment_expr778 = nil

      tree_for_COMMA777 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 702:4: cell_assignment_expr ( COMMA cell_assignment_expr )*
        @state.following.push( TOKENS_FOLLOWING_cell_assignment_expr_IN_cell_assignment_exprs_4532 )
        cell_assignment_expr776 = cell_assignment_expr
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, cell_assignment_expr776.tree )
        end
        # at line 702:25: ( COMMA cell_assignment_expr )*
        while true # decision 202
          alt_202 = 2
          look_202_0 = @input.peek( 1 )

          if ( look_202_0 == COMMA )
            alt_202 = 1

          end
          case alt_202
          when 1
            # at line 702:27: COMMA cell_assignment_expr
            __COMMA777__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_cell_assignment_exprs_4536 )
            if @state.backtracking == 0

              tree_for_COMMA777 = @adaptor.create_with_payload( __COMMA777__ )
              @adaptor.add_child( root_0, tree_for_COMMA777 )

            end
            @state.following.push( TOKENS_FOLLOWING_cell_assignment_expr_IN_cell_assignment_exprs_4538 )
            cell_assignment_expr778 = cell_assignment_expr
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, cell_assignment_expr778.tree )
            end

          else
            break # out of loop for decision 202
          end
        end # loop for decision 202
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 120 )
        memoize( __method__, cell_assignment_exprs_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CellAssignmentExprReturnValue = define_return_scope 

    # 
    # parser rule cell_assignment_expr
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 704:1: cell_assignment_expr : ( sql_condition | sql_expression | single_column_for_loop );
    # 
    def cell_assignment_expr
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 121 )
      return_value = CellAssignmentExprReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      cell_assignment_expr_start_index = @input.index

      root_0 = nil
      sql_condition779 = nil
      sql_expression780 = nil
      single_column_for_loop781 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 705:2: ( sql_condition | sql_expression | single_column_for_loop )
        alt_203 = 3
        alt_203 = @dfa203.predict( @input )
        case alt_203
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 705:4: sql_condition
          @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_cell_assignment_expr_4551 )
          sql_condition779 = sql_condition
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_condition779.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 705:20: sql_expression
          @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_cell_assignment_expr_4555 )
          sql_expression780 = sql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expression780.tree )
          end

        when 3
          root_0 = @adaptor.create_flat_list


          # at line 705:37: single_column_for_loop
          @state.following.push( TOKENS_FOLLOWING_single_column_for_loop_IN_cell_assignment_expr_4559 )
          single_column_for_loop781 = single_column_for_loop
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, single_column_for_loop781.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 121 )
        memoize( __method__, cell_assignment_expr_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    MeasureColumnReturnValue = define_return_scope 

    # 
    # parser rule measure_column
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 707:1: measure_column : column_name ;
    # 
    def measure_column
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 122 )
      return_value = MeasureColumnReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      measure_column_start_index = @input.index

      root_0 = nil
      column_name782 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 708:4: column_name
        @state.following.push( TOKENS_FOLLOWING_column_name_IN_measure_column_4569 )
        column_name782 = column_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, column_name782.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 122 )
        memoize( __method__, measure_column_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SingleColumnForLoopReturnValue = define_return_scope 

    # 
    # parser rule single_column_for_loop
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 710:1: single_column_for_loop : 'FOR' column_name ( 'IN' LPAREN ( literals | subquery ) RPAREN | ( 'LIKE' pattern )? 'FROM' literal 'TO' literal ( keyINCREMENT | keyDECREMENT ) literal ) ;
    # 
    def single_column_for_loop
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 123 )
      return_value = SingleColumnForLoopReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      single_column_for_loop_start_index = @input.index

      root_0 = nil
      string_literal783 = nil
      string_literal785 = nil
      __LPAREN786__ = nil
      __RPAREN789__ = nil
      string_literal790 = nil
      string_literal792 = nil
      string_literal794 = nil
      column_name784 = nil
      literals787 = nil
      subquery788 = nil
      pattern791 = nil
      literal793 = nil
      literal795 = nil
      keyINCREMENT796 = nil
      keyDECREMENT797 = nil
      literal798 = nil

      tree_for_string_literal783 = nil
      tree_for_string_literal785 = nil
      tree_for_LPAREN786 = nil
      tree_for_RPAREN789 = nil
      tree_for_string_literal790 = nil
      tree_for_string_literal792 = nil
      tree_for_string_literal794 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 711:4: 'FOR' column_name ( 'IN' LPAREN ( literals | subquery ) RPAREN | ( 'LIKE' pattern )? 'FROM' literal 'TO' literal ( keyINCREMENT | keyDECREMENT ) literal )
        string_literal783 = match( T__112, TOKENS_FOLLOWING_T__112_IN_single_column_for_loop_4579 )
        if @state.backtracking == 0

          tree_for_string_literal783 = @adaptor.create_with_payload( string_literal783 )
          @adaptor.add_child( root_0, tree_for_string_literal783 )

        end
        @state.following.push( TOKENS_FOLLOWING_column_name_IN_single_column_for_loop_4581 )
        column_name784 = column_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, column_name784.tree )
        end
        # at line 712:3: ( 'IN' LPAREN ( literals | subquery ) RPAREN | ( 'LIKE' pattern )? 'FROM' literal 'TO' literal ( keyINCREMENT | keyDECREMENT ) literal )
        alt_207 = 2
        look_207_0 = @input.peek( 1 )

        if ( look_207_0 == T__102 )
          alt_207 = 1
        elsif ( look_207_0 == T__121 || look_207_0 == T__134 )
          alt_207 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 207, 0 )
        end
        case alt_207
        when 1
          # at line 712:5: 'IN' LPAREN ( literals | subquery ) RPAREN
          string_literal785 = match( T__102, TOKENS_FOLLOWING_T__102_IN_single_column_for_loop_4587 )
          if @state.backtracking == 0

            tree_for_string_literal785 = @adaptor.create_with_payload( string_literal785 )
            @adaptor.add_child( root_0, tree_for_string_literal785 )

          end
          __LPAREN786__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_single_column_for_loop_4589 )
          if @state.backtracking == 0

            tree_for_LPAREN786 = @adaptor.create_with_payload( __LPAREN786__ )
            @adaptor.add_child( root_0, tree_for_LPAREN786 )

          end
          # at line 712:17: ( literals | subquery )
          alt_204 = 2
          look_204_0 = @input.peek( 1 )

          if ( look_204_0.between?( PLUS, QUOTED_STRING ) )
            alt_204 = 1
          elsif ( look_204_0 == LPAREN )
            alt_204 = 2
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 204, 0 )
          end
          case alt_204
          when 1
            # at line 712:19: literals
            @state.following.push( TOKENS_FOLLOWING_literals_IN_single_column_for_loop_4593 )
            literals787 = literals
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, literals787.tree )
            end

          when 2
            # at line 712:30: subquery
            @state.following.push( TOKENS_FOLLOWING_subquery_IN_single_column_for_loop_4597 )
            subquery788 = subquery
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, subquery788.tree )
            end

          end
          __RPAREN789__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_single_column_for_loop_4601 )
          if @state.backtracking == 0

            tree_for_RPAREN789 = @adaptor.create_with_payload( __RPAREN789__ )
            @adaptor.add_child( root_0, tree_for_RPAREN789 )

          end

        when 2
          # at line 713:5: ( 'LIKE' pattern )? 'FROM' literal 'TO' literal ( keyINCREMENT | keyDECREMENT ) literal
          # at line 713:5: ( 'LIKE' pattern )?
          alt_205 = 2
          look_205_0 = @input.peek( 1 )

          if ( look_205_0 == T__134 )
            alt_205 = 1
          end
          case alt_205
          when 1
            # at line 713:7: 'LIKE' pattern
            string_literal790 = match( T__134, TOKENS_FOLLOWING_T__134_IN_single_column_for_loop_4609 )
            if @state.backtracking == 0

              tree_for_string_literal790 = @adaptor.create_with_payload( string_literal790 )
              @adaptor.add_child( root_0, tree_for_string_literal790 )

            end
            @state.following.push( TOKENS_FOLLOWING_pattern_IN_single_column_for_loop_4611 )
            pattern791 = pattern
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, pattern791.tree )
            end

          end
          string_literal792 = match( T__121, TOKENS_FOLLOWING_T__121_IN_single_column_for_loop_4616 )
          if @state.backtracking == 0

            tree_for_string_literal792 = @adaptor.create_with_payload( string_literal792 )
            @adaptor.add_child( root_0, tree_for_string_literal792 )

          end
          @state.following.push( TOKENS_FOLLOWING_literal_IN_single_column_for_loop_4618 )
          literal793 = literal
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, literal793.tree )
          end
          string_literal794 = match( T__77, TOKENS_FOLLOWING_T__77_IN_single_column_for_loop_4620 )
          if @state.backtracking == 0

            tree_for_string_literal794 = @adaptor.create_with_payload( string_literal794 )
            @adaptor.add_child( root_0, tree_for_string_literal794 )

          end
          @state.following.push( TOKENS_FOLLOWING_literal_IN_single_column_for_loop_4622 )
          literal795 = literal
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, literal795.tree )
          end
          # at line 713:53: ( keyINCREMENT | keyDECREMENT )
          alt_206 = 2
          look_206_0 = @input.peek( 1 )

          if ( look_206_0 == ID )
            look_206_1 = @input.peek( 2 )

            if ( ( syntactic_predicate?( :synpred335_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("INCREMENT") ) ) )
              alt_206 = 1
            elsif ( ( self.input.look(1).text.upcase == ("DECREMENT") ) )
              alt_206 = 2
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 206, 1 )
            end
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 206, 0 )
          end
          case alt_206
          when 1
            # at line 713:55: keyINCREMENT
            @state.following.push( TOKENS_FOLLOWING_keyINCREMENT_IN_single_column_for_loop_4626 )
            keyINCREMENT796 = keyINCREMENT
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyINCREMENT796.tree )
            end

          when 2
            # at line 713:70: keyDECREMENT
            @state.following.push( TOKENS_FOLLOWING_keyDECREMENT_IN_single_column_for_loop_4630 )
            keyDECREMENT797 = keyDECREMENT
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyDECREMENT797.tree )
            end

          end
          @state.following.push( TOKENS_FOLLOWING_literal_IN_single_column_for_loop_4634 )
          literal798 = literal
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, literal798.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 123 )
        memoize( __method__, single_column_for_loop_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    LiteralReturnValue = define_return_scope 

    # 
    # parser rule literal
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 716:1: literal : ( ( PLUS | MINUS )? NUMBER | QUOTED_STRING );
    # 
    def literal
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 124 )
      return_value = LiteralReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      literal_start_index = @input.index

      root_0 = nil
      set799 = nil
      __NUMBER800__ = nil
      __QUOTED_STRING801__ = nil

      tree_for_set799 = nil
      tree_for_NUMBER800 = nil
      tree_for_QUOTED_STRING801 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 717:2: ( ( PLUS | MINUS )? NUMBER | QUOTED_STRING )
        alt_209 = 2
        look_209_0 = @input.peek( 1 )

        if ( look_209_0.between?( PLUS, NUMBER ) )
          alt_209 = 1
        elsif ( look_209_0 == QUOTED_STRING )
          alt_209 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 209, 0 )
        end
        case alt_209
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 717:4: ( PLUS | MINUS )? NUMBER
          # at line 717:4: ( PLUS | MINUS )?
          alt_208 = 2
          look_208_0 = @input.peek( 1 )

          if ( look_208_0.between?( PLUS, MINUS ) )
            alt_208 = 1
          end
          case alt_208
          when 1
            # at line 
            set799 = @input.look
            if @input.peek( 1 ).between?( PLUS, MINUS )
              @input.consume
              if @state.backtracking == 0
                @adaptor.add_child( root_0, @adaptor.create_with_payload( set799 ) )
              end
              @state.error_recovery = false
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              mse = MismatchedSet( nil )
              raise mse
            end



          end
          __NUMBER800__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_literal_4659 )
          if @state.backtracking == 0

            tree_for_NUMBER800 = @adaptor.create_with_payload( __NUMBER800__ )
            @adaptor.add_child( root_0, tree_for_NUMBER800 )

          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 718:4: QUOTED_STRING
          __QUOTED_STRING801__ = match( QUOTED_STRING, TOKENS_FOLLOWING_QUOTED_STRING_IN_literal_4664 )
          if @state.backtracking == 0

            tree_for_QUOTED_STRING801 = @adaptor.create_with_payload( __QUOTED_STRING801__ )
            @adaptor.add_child( root_0, tree_for_QUOTED_STRING801 )

          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 124 )
        memoize( __method__, literal_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    LiteralsReturnValue = define_return_scope 

    # 
    # parser rule literals
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 720:1: literals : literal ( COMMA literal )* ;
    # 
    def literals
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 125 )
      return_value = LiteralsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      literals_start_index = @input.index

      root_0 = nil
      __COMMA803__ = nil
      literal802 = nil
      literal804 = nil

      tree_for_COMMA803 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 721:4: literal ( COMMA literal )*
        @state.following.push( TOKENS_FOLLOWING_literal_IN_literals_4674 )
        literal802 = literal
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, literal802.tree )
        end
        # at line 721:12: ( COMMA literal )*
        while true # decision 210
          alt_210 = 2
          look_210_0 = @input.peek( 1 )

          if ( look_210_0 == COMMA )
            alt_210 = 1

          end
          case alt_210
          when 1
            # at line 721:14: COMMA literal
            __COMMA803__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_literals_4678 )
            if @state.backtracking == 0

              tree_for_COMMA803 = @adaptor.create_with_payload( __COMMA803__ )
              @adaptor.add_child( root_0, tree_for_COMMA803 )

            end
            @state.following.push( TOKENS_FOLLOWING_literal_IN_literals_4680 )
            literal804 = literal
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, literal804.tree )
            end

          else
            break # out of loop for decision 210
          end
        end # loop for decision 210
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 125 )
        memoize( __method__, literals_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    BracketLiteralsReturnValue = define_return_scope 

    # 
    # parser rule bracket_literals
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 723:1: bracket_literals : LPAREN literals RPAREN ;
    # 
    def bracket_literals
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 126 )
      return_value = BracketLiteralsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      bracket_literals_start_index = @input.index

      root_0 = nil
      __LPAREN805__ = nil
      __RPAREN807__ = nil
      literals806 = nil

      tree_for_LPAREN805 = nil
      tree_for_RPAREN807 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 724:4: LPAREN literals RPAREN
        __LPAREN805__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_bracket_literals_4693 )
        if @state.backtracking == 0

          tree_for_LPAREN805 = @adaptor.create_with_payload( __LPAREN805__ )
          @adaptor.add_child( root_0, tree_for_LPAREN805 )

        end
        @state.following.push( TOKENS_FOLLOWING_literals_IN_bracket_literals_4695 )
        literals806 = literals
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, literals806.tree )
        end
        __RPAREN807__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_bracket_literals_4697 )
        if @state.backtracking == 0

          tree_for_RPAREN807 = @adaptor.create_with_payload( __RPAREN807__ )
          @adaptor.add_child( root_0, tree_for_RPAREN807 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 126 )
        memoize( __method__, bracket_literals_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    BracketLiteralsListReturnValue = define_return_scope 

    # 
    # parser rule bracket_literals_list
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 726:1: bracket_literals_list : bracket_literals ( COMMA bracket_literals )* ;
    # 
    def bracket_literals_list
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 127 )
      return_value = BracketLiteralsListReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      bracket_literals_list_start_index = @input.index

      root_0 = nil
      __COMMA809__ = nil
      bracket_literals808 = nil
      bracket_literals810 = nil

      tree_for_COMMA809 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 727:4: bracket_literals ( COMMA bracket_literals )*
        @state.following.push( TOKENS_FOLLOWING_bracket_literals_IN_bracket_literals_list_4707 )
        bracket_literals808 = bracket_literals
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, bracket_literals808.tree )
        end
        # at line 727:21: ( COMMA bracket_literals )*
        while true # decision 211
          alt_211 = 2
          look_211_0 = @input.peek( 1 )

          if ( look_211_0 == COMMA )
            alt_211 = 1

          end
          case alt_211
          when 1
            # at line 727:23: COMMA bracket_literals
            __COMMA809__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_bracket_literals_list_4711 )
            if @state.backtracking == 0

              tree_for_COMMA809 = @adaptor.create_with_payload( __COMMA809__ )
              @adaptor.add_child( root_0, tree_for_COMMA809 )

            end
            @state.following.push( TOKENS_FOLLOWING_bracket_literals_IN_bracket_literals_list_4713 )
            bracket_literals810 = bracket_literals
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, bracket_literals810.tree )
            end

          else
            break # out of loop for decision 211
          end
        end # loop for decision 211
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 127 )
        memoize( __method__, bracket_literals_list_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    PatternReturnValue = define_return_scope 

    # 
    # parser rule pattern
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 729:1: pattern : QUOTED_STRING ;
    # 
    def pattern
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 128 )
      return_value = PatternReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      pattern_start_index = @input.index

      root_0 = nil
      __QUOTED_STRING811__ = nil

      tree_for_QUOTED_STRING811 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 730:4: QUOTED_STRING
        __QUOTED_STRING811__ = match( QUOTED_STRING, TOKENS_FOLLOWING_QUOTED_STRING_IN_pattern_4726 )
        if @state.backtracking == 0

          tree_for_QUOTED_STRING811 = @adaptor.create_with_payload( __QUOTED_STRING811__ )
          @adaptor.add_child( root_0, tree_for_QUOTED_STRING811 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 128 )
        memoize( __method__, pattern_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    MultiColumnForLoopReturnValue = define_return_scope 

    # 
    # parser rule multi_column_for_loop
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 732:1: multi_column_for_loop : 'FOR' LPAREN column_specs RPAREN 'IN' LPAREN ( bracket_literals_list | subquery ) RPAREN ;
    # 
    def multi_column_for_loop
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 129 )
      return_value = MultiColumnForLoopReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      multi_column_for_loop_start_index = @input.index

      root_0 = nil
      string_literal812 = nil
      __LPAREN813__ = nil
      __RPAREN815__ = nil
      string_literal816 = nil
      __LPAREN817__ = nil
      __RPAREN820__ = nil
      column_specs814 = nil
      bracket_literals_list818 = nil
      subquery819 = nil

      tree_for_string_literal812 = nil
      tree_for_LPAREN813 = nil
      tree_for_RPAREN815 = nil
      tree_for_string_literal816 = nil
      tree_for_LPAREN817 = nil
      tree_for_RPAREN820 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 733:4: 'FOR' LPAREN column_specs RPAREN 'IN' LPAREN ( bracket_literals_list | subquery ) RPAREN
        string_literal812 = match( T__112, TOKENS_FOLLOWING_T__112_IN_multi_column_for_loop_4736 )
        if @state.backtracking == 0

          tree_for_string_literal812 = @adaptor.create_with_payload( string_literal812 )
          @adaptor.add_child( root_0, tree_for_string_literal812 )

        end
        __LPAREN813__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_multi_column_for_loop_4738 )
        if @state.backtracking == 0

          tree_for_LPAREN813 = @adaptor.create_with_payload( __LPAREN813__ )
          @adaptor.add_child( root_0, tree_for_LPAREN813 )

        end
        @state.following.push( TOKENS_FOLLOWING_column_specs_IN_multi_column_for_loop_4740 )
        column_specs814 = column_specs
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, column_specs814.tree )
        end
        __RPAREN815__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_multi_column_for_loop_4742 )
        if @state.backtracking == 0

          tree_for_RPAREN815 = @adaptor.create_with_payload( __RPAREN815__ )
          @adaptor.add_child( root_0, tree_for_RPAREN815 )

        end
        string_literal816 = match( T__102, TOKENS_FOLLOWING_T__102_IN_multi_column_for_loop_4744 )
        if @state.backtracking == 0

          tree_for_string_literal816 = @adaptor.create_with_payload( string_literal816 )
          @adaptor.add_child( root_0, tree_for_string_literal816 )

        end
        __LPAREN817__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_multi_column_for_loop_4746 )
        if @state.backtracking == 0

          tree_for_LPAREN817 = @adaptor.create_with_payload( __LPAREN817__ )
          @adaptor.add_child( root_0, tree_for_LPAREN817 )

        end
        # at line 733:49: ( bracket_literals_list | subquery )
        alt_212 = 2
        look_212_0 = @input.peek( 1 )

        if ( look_212_0 == LPAREN )
          look_212_1 = @input.peek( 2 )

          if ( look_212_1.between?( PLUS, QUOTED_STRING ) )
            alt_212 = 1
          elsif ( look_212_1 == T__116 )
            alt_212 = 2
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 212, 1 )
          end
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 212, 0 )
        end
        case alt_212
        when 1
          # at line 733:51: bracket_literals_list
          @state.following.push( TOKENS_FOLLOWING_bracket_literals_list_IN_multi_column_for_loop_4750 )
          bracket_literals_list818 = bracket_literals_list
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, bracket_literals_list818.tree )
          end

        when 2
          # at line 733:75: subquery
          @state.following.push( TOKENS_FOLLOWING_subquery_IN_multi_column_for_loop_4754 )
          subquery819 = subquery
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, subquery819.tree )
          end

        end
        __RPAREN820__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_multi_column_for_loop_4758 )
        if @state.backtracking == 0

          tree_for_RPAREN820 = @adaptor.create_with_payload( __RPAREN820__ )
          @adaptor.add_child( root_0, tree_for_RPAREN820 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 129 )
        memoize( __method__, multi_column_for_loop_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    OrderByClauseReturnValue = define_return_scope 

    # 
    # parser rule order_by_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 735:1: order_by_clause : 'ORDER' ( keySIBLINGS )? 'BY' order_by_exprs ;
    # 
    def order_by_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 130 )
      return_value = OrderByClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      order_by_clause_start_index = @input.index

      root_0 = nil
      string_literal821 = nil
      string_literal823 = nil
      keySIBLINGS822 = nil
      order_by_exprs824 = nil

      tree_for_string_literal821 = nil
      tree_for_string_literal823 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 736:4: 'ORDER' ( keySIBLINGS )? 'BY' order_by_exprs
        string_literal821 = match( T__133, TOKENS_FOLLOWING_T__133_IN_order_by_clause_4768 )
        if @state.backtracking == 0

          tree_for_string_literal821 = @adaptor.create_with_payload( string_literal821 )
          @adaptor.add_child( root_0, tree_for_string_literal821 )

        end
        # at line 736:12: ( keySIBLINGS )?
        alt_213 = 2
        look_213_0 = @input.peek( 1 )

        if ( look_213_0 == ID )
          alt_213 = 1
        end
        case alt_213
        when 1
          # at line 736:14: keySIBLINGS
          @state.following.push( TOKENS_FOLLOWING_keySIBLINGS_IN_order_by_clause_4772 )
          keySIBLINGS822 = keySIBLINGS
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keySIBLINGS822.tree )
          end

        end
        string_literal823 = match( T__108, TOKENS_FOLLOWING_T__108_IN_order_by_clause_4777 )
        if @state.backtracking == 0

          tree_for_string_literal823 = @adaptor.create_with_payload( string_literal823 )
          @adaptor.add_child( root_0, tree_for_string_literal823 )

        end
        @state.following.push( TOKENS_FOLLOWING_order_by_exprs_IN_order_by_clause_4779 )
        order_by_exprs824 = order_by_exprs
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, order_by_exprs824.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 130 )
        memoize( __method__, order_by_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    OrderByExprsReturnValue = define_return_scope 

    # 
    # parser rule order_by_exprs
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 738:1: order_by_exprs : order_by_expr ( COMMA order_by_expr )* ;
    # 
    def order_by_exprs
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 131 )
      return_value = OrderByExprsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      order_by_exprs_start_index = @input.index

      root_0 = nil
      __COMMA826__ = nil
      order_by_expr825 = nil
      order_by_expr827 = nil

      tree_for_COMMA826 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 739:4: order_by_expr ( COMMA order_by_expr )*
        @state.following.push( TOKENS_FOLLOWING_order_by_expr_IN_order_by_exprs_4789 )
        order_by_expr825 = order_by_expr
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, order_by_expr825.tree )
        end
        # at line 739:18: ( COMMA order_by_expr )*
        while true # decision 214
          alt_214 = 2
          look_214_0 = @input.peek( 1 )

          if ( look_214_0 == COMMA )
            look_214_2 = @input.peek( 2 )

            if ( syntactic_predicate?( :synpred343_Plsql ) )
              alt_214 = 1

            end

          end
          case alt_214
          when 1
            # at line 739:20: COMMA order_by_expr
            __COMMA826__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_order_by_exprs_4793 )
            if @state.backtracking == 0

              tree_for_COMMA826 = @adaptor.create_with_payload( __COMMA826__ )
              @adaptor.add_child( root_0, tree_for_COMMA826 )

            end
            @state.following.push( TOKENS_FOLLOWING_order_by_expr_IN_order_by_exprs_4795 )
            order_by_expr827 = order_by_expr
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, order_by_expr827.tree )
            end

          else
            break # out of loop for decision 214
          end
        end # loop for decision 214
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 131 )
        memoize( __method__, order_by_exprs_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    OrderByExprReturnValue = define_return_scope 

    # 
    # parser rule order_by_expr
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 741:1: order_by_expr : ( sql_expression ) ( 'ASC' | 'DESC' )? ( keyNULLS keyFIRST | keyNULLS keyLAST )? ;
    # 
    def order_by_expr
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 132 )
      return_value = OrderByExprReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      order_by_expr_start_index = @input.index

      root_0 = nil
      set829 = nil
      sql_expression828 = nil
      keyNULLS830 = nil
      keyFIRST831 = nil
      keyNULLS832 = nil
      keyLAST833 = nil

      tree_for_set829 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 742:4: ( sql_expression ) ( 'ASC' | 'DESC' )? ( keyNULLS keyFIRST | keyNULLS keyLAST )?
        # at line 742:4: ( sql_expression )
        # at line 742:6: sql_expression
        @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_order_by_expr_4810 )
        sql_expression828 = sql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_expression828.tree )
        end

        # at line 746:3: ( 'ASC' | 'DESC' )?
        alt_215 = 2
        look_215_0 = @input.peek( 1 )

        if ( look_215_0.between?( T__135, T__136 ) )
          alt_215 = 1
        end
        case alt_215
        when 1
          # at line 
          set829 = @input.look
          if @input.peek( 1 ).between?( T__135, T__136 )
            @input.consume
            if @state.backtracking == 0
              @adaptor.add_child( root_0, @adaptor.create_with_payload( set829 ) )
            end
            @state.error_recovery = false
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            mse = MismatchedSet( nil )
            raise mse
          end



        end
        # at line 746:23: ( keyNULLS keyFIRST | keyNULLS keyLAST )?
        alt_216 = 3
        look_216_0 = @input.peek( 1 )

        if ( look_216_0 == ID )
          look_216_1 = @input.peek( 2 )

          if ( ( syntactic_predicate?( :synpred346_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("NULLS") ) ) )
            alt_216 = 1
          elsif ( ( syntactic_predicate?( :synpred347_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("NULLS") ) ) )
            alt_216 = 2
          end
        end
        case alt_216
        when 1
          # at line 746:25: keyNULLS keyFIRST
          @state.following.push( TOKENS_FOLLOWING_keyNULLS_IN_order_by_expr_4833 )
          keyNULLS830 = keyNULLS
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyNULLS830.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_keyFIRST_IN_order_by_expr_4835 )
          keyFIRST831 = keyFIRST
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyFIRST831.tree )
          end

        when 2
          # at line 746:45: keyNULLS keyLAST
          @state.following.push( TOKENS_FOLLOWING_keyNULLS_IN_order_by_expr_4839 )
          keyNULLS832 = keyNULLS
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyNULLS832.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_keyLAST_IN_order_by_expr_4841 )
          keyLAST833 = keyLAST
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyLAST833.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 132 )
        memoize( __method__, order_by_expr_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ForUpdateClauseReturnValue = define_return_scope 

    # 
    # parser rule for_update_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 748:1: for_update_clause : 'FOR' 'UPDATE' ( 'OF' column_specs )? ( keyWAIT integer | 'NOWAIT' )? ;
    # 
    def for_update_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 133 )
      return_value = ForUpdateClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      for_update_clause_start_index = @input.index

      root_0 = nil
      string_literal834 = nil
      string_literal835 = nil
      string_literal836 = nil
      string_literal840 = nil
      column_specs837 = nil
      keyWAIT838 = nil
      integer839 = nil

      tree_for_string_literal834 = nil
      tree_for_string_literal835 = nil
      tree_for_string_literal836 = nil
      tree_for_string_literal840 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 749:4: 'FOR' 'UPDATE' ( 'OF' column_specs )? ( keyWAIT integer | 'NOWAIT' )?
        string_literal834 = match( T__112, TOKENS_FOLLOWING_T__112_IN_for_update_clause_4854 )
        if @state.backtracking == 0

          tree_for_string_literal834 = @adaptor.create_with_payload( string_literal834 )
          @adaptor.add_child( root_0, tree_for_string_literal834 )

        end
        string_literal835 = match( T__132, TOKENS_FOLLOWING_T__132_IN_for_update_clause_4856 )
        if @state.backtracking == 0

          tree_for_string_literal835 = @adaptor.create_with_payload( string_literal835 )
          @adaptor.add_child( root_0, tree_for_string_literal835 )

        end
        # at line 749:19: ( 'OF' column_specs )?
        alt_217 = 2
        look_217_0 = @input.peek( 1 )

        if ( look_217_0 == T__106 )
          alt_217 = 1
        end
        case alt_217
        when 1
          # at line 749:21: 'OF' column_specs
          string_literal836 = match( T__106, TOKENS_FOLLOWING_T__106_IN_for_update_clause_4860 )
          if @state.backtracking == 0

            tree_for_string_literal836 = @adaptor.create_with_payload( string_literal836 )
            @adaptor.add_child( root_0, tree_for_string_literal836 )

          end
          @state.following.push( TOKENS_FOLLOWING_column_specs_IN_for_update_clause_4862 )
          column_specs837 = column_specs
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, column_specs837.tree )
          end

        end
        # at line 749:42: ( keyWAIT integer | 'NOWAIT' )?
        alt_218 = 3
        look_218_0 = @input.peek( 1 )

        if ( look_218_0 == ID )
          alt_218 = 1
        elsif ( look_218_0 == T__137 )
          alt_218 = 2
        end
        case alt_218
        when 1
          # at line 749:44: keyWAIT integer
          @state.following.push( TOKENS_FOLLOWING_keyWAIT_IN_for_update_clause_4869 )
          keyWAIT838 = keyWAIT
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyWAIT838.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_integer_IN_for_update_clause_4871 )
          integer839 = integer
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, integer839.tree )
          end

        when 2
          # at line 749:62: 'NOWAIT'
          string_literal840 = match( T__137, TOKENS_FOLLOWING_T__137_IN_for_update_clause_4875 )
          if @state.backtracking == 0

            tree_for_string_literal840 = @adaptor.create_with_payload( string_literal840 )
            @adaptor.add_child( root_0, tree_for_string_literal840 )

          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 133 )
        memoize( __method__, for_update_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    WhereConditionWholeReturnValue = define_return_scope 

    # 
    # parser rule where_condition_whole
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 752:1: where_condition_whole : 'WHERE' sql_condition ;
    # 
    def where_condition_whole
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 134 )
      return_value = WhereConditionWholeReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      where_condition_whole_start_index = @input.index

      root_0 = nil
      string_literal841 = nil
      sql_condition842 = nil

      tree_for_string_literal841 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 753:4: 'WHERE' sql_condition
        string_literal841 = match( T__127, TOKENS_FOLLOWING_T__127_IN_where_condition_whole_4889 )
        if @state.backtracking == 0

          tree_for_string_literal841 = @adaptor.create_with_payload( string_literal841 )
          @adaptor.add_child( root_0, tree_for_string_literal841 )

        end
        @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_where_condition_whole_4891 )
        sql_condition842 = sql_condition
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_condition842.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 134 )
        memoize( __method__, where_condition_whole_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    WhereConditionReturnValue = define_return_scope 

    # 
    # parser rule where_condition
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 756:1: where_condition : sql_condition ;
    # 
    def where_condition
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 135 )
      return_value = WhereConditionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      where_condition_start_index = @input.index

      root_0 = nil
      sql_condition843 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 757:4: sql_condition
        @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_where_condition_4902 )
        sql_condition843 = sql_condition
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_condition843.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 135 )
        memoize( __method__, where_condition_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    DisplayedColumnReturnValue = define_return_scope 

    # 
    # parser rule displayed_column
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 760:1: displayed_column : ( ( column_spec DOT ASTERISK ) | sql_expression ) ( objalias )? ;
    # 
    def displayed_column
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 136 )
      return_value = DisplayedColumnReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      displayed_column_start_index = @input.index

      root_0 = nil
      __DOT845__ = nil
      __ASTERISK846__ = nil
      column_spec844 = nil
      sql_expression847 = nil
      objalias848 = nil

      tree_for_DOT845 = nil
      tree_for_ASTERISK846 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 761:4: ( ( column_spec DOT ASTERISK ) | sql_expression ) ( objalias )?
        # at line 761:4: ( ( column_spec DOT ASTERISK ) | sql_expression )
        alt_219 = 2
        alt_219 = @dfa219.predict( @input )
        case alt_219
        when 1
          # at line 761:6: ( column_spec DOT ASTERISK )
          # at line 761:6: ( column_spec DOT ASTERISK )
          # at line 761:7: column_spec DOT ASTERISK
          @state.following.push( TOKENS_FOLLOWING_column_spec_IN_displayed_column_4916 )
          column_spec844 = column_spec
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, column_spec844.tree )
          end
          __DOT845__ = match( DOT, TOKENS_FOLLOWING_DOT_IN_displayed_column_4918 )
          if @state.backtracking == 0

            tree_for_DOT845 = @adaptor.create_with_payload( __DOT845__ )
            @adaptor.add_child( root_0, tree_for_DOT845 )

          end
          __ASTERISK846__ = match( ASTERISK, TOKENS_FOLLOWING_ASTERISK_IN_displayed_column_4920 )
          if @state.backtracking == 0

            tree_for_ASTERISK846 = @adaptor.create_with_payload( __ASTERISK846__ )
            @adaptor.add_child( root_0, tree_for_ASTERISK846 )

          end

          # syntactic predicate action gate test
          if @state.backtracking == 0
            # --> action
             @columns << ( column_spec844 && @input.to_s( column_spec844.start, column_spec844.stop ) ) + '.*' unless @skip 
            # <-- action
          end

        when 2
          # at line 762:5: sql_expression
          @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_displayed_column_4929 )
          sql_expression847 = sql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expression847.tree )
          end

        end
        # at line 764:3: ( objalias )?
        alt_220 = 2
        look_220_0 = @input.peek( 1 )

        if ( look_220_0 == DOUBLEQUOTED_STRING || look_220_0 == T__53 || look_220_0 == T__100 )
          alt_220 = 1
        elsif ( look_220_0 == ID )
          look_220_2 = @input.peek( 2 )

          if ( look_220_2 == ID )
            look_220_4 = @input.peek( 3 )

            if ( look_220_4 == ID )
              alt_220 = 1
            end
          elsif ( look_220_2 == EOF || look_220_2 == COMMA || look_220_2.between?( T__120, T__121 ) )
            alt_220 = 1
          end
        end
        case alt_220
        when 1
          # at line 764:5: objalias
          @state.following.push( TOKENS_FOLLOWING_objalias_IN_displayed_column_4939 )
          objalias848 = objalias
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, objalias848.tree )
          end
          # syntactic predicate action gate test
          if @state.backtracking == 0
            # --> action
             @last_alias = ( objalias848.nil? ? nil : objalias848.value ) 
            # <-- action
          end

        end
        # syntactic predicate action gate test
        if @state.backtracking == 0
          # --> action
           
                unless @skip
                  if @last_alias
                    @columns << @last_alias unless @skip 
                  elsif @last_expr
                    @columns << @last_expr
                  end
                  @last_expr = nil
                  @last_alias = nil
                end
              
          # <-- action
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 136 )
        memoize( __method__, displayed_column_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SchemaNameReturnValue = define_return_scope 

    # 
    # parser rule schema_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 778:1: schema_name : sql_identifier ;
    # 
    def schema_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 137 )
      return_value = SchemaNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      schema_name_start_index = @input.index

      root_0 = nil
      sql_identifier849 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 779:4: sql_identifier
        @state.following.push( TOKENS_FOLLOWING_sql_identifier_IN_schema_name_4962 )
        sql_identifier849 = sql_identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_identifier849.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 137 )
        memoize( __method__, schema_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    TableNameReturnValue = define_return_scope 

    # 
    # parser rule table_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 782:1: table_name : sql_identifier ;
    # 
    def table_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 138 )
      return_value = TableNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      table_name_start_index = @input.index

      root_0 = nil
      sql_identifier850 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 783:4: sql_identifier
        @state.following.push( TOKENS_FOLLOWING_sql_identifier_IN_table_name_4973 )
        sql_identifier850 = sql_identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_identifier850.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 138 )
        memoize( __method__, table_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    NestedExpressionsReturnValue = define_return_scope 

    # 
    # parser rule nested_expressions
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 786:1: nested_expressions : nested_expression ( COMMA nested_expression )* ;
    # 
    def nested_expressions
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 139 )
      return_value = NestedExpressionsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      nested_expressions_start_index = @input.index

      root_0 = nil
      __COMMA852__ = nil
      nested_expression851 = nil
      nested_expression853 = nil

      tree_for_COMMA852 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 787:4: nested_expression ( COMMA nested_expression )*
        @state.following.push( TOKENS_FOLLOWING_nested_expression_IN_nested_expressions_4984 )
        nested_expression851 = nested_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, nested_expression851.tree )
        end
        # at line 787:22: ( COMMA nested_expression )*
        while true # decision 221
          alt_221 = 2
          look_221_0 = @input.peek( 1 )

          if ( look_221_0 == COMMA )
            alt_221 = 1

          end
          case alt_221
          when 1
            # at line 787:24: COMMA nested_expression
            __COMMA852__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_nested_expressions_4988 )
            if @state.backtracking == 0

              tree_for_COMMA852 = @adaptor.create_with_payload( __COMMA852__ )
              @adaptor.add_child( root_0, tree_for_COMMA852 )

            end
            @state.following.push( TOKENS_FOLLOWING_nested_expression_IN_nested_expressions_4990 )
            nested_expression853 = nested_expression
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, nested_expression853.tree )
            end

          else
            break # out of loop for decision 221
          end
        end # loop for decision 221
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 139 )
        memoize( __method__, nested_expressions_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    NestedExpressionReturnValue = define_return_scope 

    # 
    # parser rule nested_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 790:1: nested_expression : ({...}? sql_expression | {...}? plsql_expression );
    # 
    def nested_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 140 )
      return_value = NestedExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      nested_expression_start_index = @input.index

      root_0 = nil
      sql_expression854 = nil
      plsql_expression855 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 791:2: ({...}? sql_expression | {...}? plsql_expression )
        alt_222 = 2
        alt_222 = @dfa222.predict( @input )
        case alt_222
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 791:4: {...}? sql_expression
          unless ( (   @is_sql  ) )
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise FailedPredicate( "nested_expression", "  @is_sql " )
          end
          @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_nested_expression_5006 )
          sql_expression854 = sql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expression854.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 792:4: {...}? plsql_expression
          unless ( (  !@is_sql  ) )
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise FailedPredicate( "nested_expression", " !@is_sql " )
          end
          @state.following.push( TOKENS_FOLLOWING_plsql_expression_IN_nested_expression_5013 )
          plsql_expression855 = plsql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, plsql_expression855.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 140 )
        memoize( __method__, nested_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    PlsqlConditionReturnValue = define_return_scope 

    # 
    # parser rule plsql_condition
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 794:1: plsql_condition : expr_bool ;
    # 
    def plsql_condition
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 141 )
      return_value = PlsqlConditionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      plsql_condition_start_index = @input.index

      root_0 = nil
      expr_bool856 = nil

      # - - - - @init action - - - -
       @is_sql = false; 

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 796:4: expr_bool
        @state.following.push( TOKENS_FOLLOWING_expr_bool_IN_plsql_condition_5030 )
        expr_bool856 = expr_bool
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, expr_bool856.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 141 )
        memoize( __method__, plsql_condition_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    PlsqlExpressionsReturnValue = define_return_scope 

    # 
    # parser rule plsql_expressions
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 799:1: plsql_expressions : plsql_expression ( COMMA plsql_expression )* ;
    # 
    def plsql_expressions
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 142 )
      return_value = PlsqlExpressionsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      plsql_expressions_start_index = @input.index

      root_0 = nil
      __COMMA858__ = nil
      plsql_expression857 = nil
      plsql_expression859 = nil

      tree_for_COMMA858 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 800:4: plsql_expression ( COMMA plsql_expression )*
        @state.following.push( TOKENS_FOLLOWING_plsql_expression_IN_plsql_expressions_5041 )
        plsql_expression857 = plsql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, plsql_expression857.tree )
        end
        # at line 800:21: ( COMMA plsql_expression )*
        while true # decision 223
          alt_223 = 2
          look_223_0 = @input.peek( 1 )

          if ( look_223_0 == COMMA )
            alt_223 = 1

          end
          case alt_223
          when 1
            # at line 800:23: COMMA plsql_expression
            __COMMA858__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_plsql_expressions_5045 )
            if @state.backtracking == 0

              tree_for_COMMA858 = @adaptor.create_with_payload( __COMMA858__ )
              @adaptor.add_child( root_0, tree_for_COMMA858 )

            end
            @state.following.push( TOKENS_FOLLOWING_plsql_expression_IN_plsql_expressions_5047 )
            plsql_expression859 = plsql_expression
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, plsql_expression859.tree )
            end

          else
            break # out of loop for decision 223
          end
        end # loop for decision 223
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 142 )
        memoize( __method__, plsql_expressions_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    PlsqlExpressionReturnValue = define_return_scope 

    # 
    # parser rule plsql_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 803:1: plsql_expression : expr_bool ;
    # 
    def plsql_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 143 )
      return_value = PlsqlExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      plsql_expression_start_index = @input.index

      root_0 = nil
      expr_bool860 = nil

      # - - - - @init action - - - -
       @is_sql = false; 

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 805:4: expr_bool
        @state.following.push( TOKENS_FOLLOWING_expr_bool_IN_plsql_expression_5068 )
        expr_bool860 = expr_bool
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, expr_bool860.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 143 )
        memoize( __method__, plsql_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExprBoolReturnValue = define_return_scope 

    # 
    # parser rule expr_bool
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 809:1: expr_bool : expr_or ( 'OR' expr_or )* ;
    # 
    def expr_bool
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 144 )
      return_value = ExprBoolReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      expr_bool_start_index = @input.index

      root_0 = nil
      string_literal862 = nil
      expr_or861 = nil
      expr_or863 = nil

      tree_for_string_literal862 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 810:4: expr_or ( 'OR' expr_or )*
        @state.following.push( TOKENS_FOLLOWING_expr_or_IN_expr_bool_5080 )
        expr_or861 = expr_or
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, expr_or861.tree )
        end
        # at line 810:12: ( 'OR' expr_or )*
        while true # decision 224
          alt_224 = 2
          look_224_0 = @input.peek( 1 )

          if ( look_224_0 == T__51 )
            look_224_2 = @input.peek( 2 )

            if ( syntactic_predicate?( :synpred356_Plsql ) )
              alt_224 = 1

            end

          end
          case alt_224
          when 1
            # at line 810:14: 'OR' expr_or
            string_literal862 = match( T__51, TOKENS_FOLLOWING_T__51_IN_expr_bool_5084 )
            if @state.backtracking == 0

              tree_for_string_literal862 = @adaptor.create_with_payload( string_literal862 )
              @adaptor.add_child( root_0, tree_for_string_literal862 )

            end
            @state.following.push( TOKENS_FOLLOWING_expr_or_IN_expr_bool_5086 )
            expr_or863 = expr_or
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, expr_or863.tree )
            end

          else
            break # out of loop for decision 224
          end
        end # loop for decision 224
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 144 )
        memoize( __method__, expr_bool_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExprOrReturnValue = define_return_scope 

    # 
    # parser rule expr_or
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 812:1: expr_or : expr_and ( 'AND' expr_and )* ;
    # 
    def expr_or
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 145 )
      return_value = ExprOrReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      expr_or_start_index = @input.index

      root_0 = nil
      string_literal865 = nil
      expr_and864 = nil
      expr_and866 = nil

      tree_for_string_literal865 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 813:4: expr_and ( 'AND' expr_and )*
        @state.following.push( TOKENS_FOLLOWING_expr_and_IN_expr_or_5099 )
        expr_and864 = expr_and
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, expr_and864.tree )
        end
        # at line 813:13: ( 'AND' expr_and )*
        while true # decision 225
          alt_225 = 2
          look_225_0 = @input.peek( 1 )

          if ( look_225_0 == T__138 )
            look_225_2 = @input.peek( 2 )

            if ( syntactic_predicate?( :synpred357_Plsql ) )
              alt_225 = 1

            end

          end
          case alt_225
          when 1
            # at line 813:15: 'AND' expr_and
            string_literal865 = match( T__138, TOKENS_FOLLOWING_T__138_IN_expr_or_5103 )
            if @state.backtracking == 0

              tree_for_string_literal865 = @adaptor.create_with_payload( string_literal865 )
              @adaptor.add_child( root_0, tree_for_string_literal865 )

            end
            @state.following.push( TOKENS_FOLLOWING_expr_and_IN_expr_or_5105 )
            expr_and866 = expr_and
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, expr_and866.tree )
            end

          else
            break # out of loop for decision 225
          end
        end # loop for decision 225
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 145 )
        memoize( __method__, expr_or_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExprAndReturnValue = define_return_scope 

    # 
    # parser rule expr_and
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 815:1: expr_and : ( 'NOT' )? expr_not ;
    # 
    def expr_and
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 146 )
      return_value = ExprAndReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      expr_and_start_index = @input.index

      root_0 = nil
      string_literal867 = nil
      expr_not868 = nil

      tree_for_string_literal867 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 816:4: ( 'NOT' )? expr_not
        # at line 816:4: ( 'NOT' )?
        alt_226 = 2
        look_226_0 = @input.peek( 1 )

        if ( look_226_0 == T__57 )
          alt_226 = 1
        end
        case alt_226
        when 1
          # at line 816:6: 'NOT'
          string_literal867 = match( T__57, TOKENS_FOLLOWING_T__57_IN_expr_and_5120 )
          if @state.backtracking == 0

            tree_for_string_literal867 = @adaptor.create_with_payload( string_literal867 )
            @adaptor.add_child( root_0, tree_for_string_literal867 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_expr_not_IN_expr_and_5125 )
        expr_not868 = expr_not
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, expr_not868.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 146 )
        memoize( __method__, expr_and_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExprNotReturnValue = define_return_scope 

    # 
    # parser rule expr_not
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 818:1: expr_not : expr_add ( relational_op expr_add | FOUND_ATTR | NOTFOUND_ATTR | ISOPEN_ATTR | ROWCOUNT_ATTR | BULK_ROWCOUNT_ATTR | 'IS' ( 'NOT' )? 'NULL' | ( 'NOT' )? 'LIKE' expr_add | ( 'NOT' )? 'BETWEEN' expr_add 'AND' expr_add | ( 'NOT' )? 'IN' LPAREN nested_expressions RPAREN )* ;
    # 
    def expr_not
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 147 )
      return_value = ExprNotReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      expr_not_start_index = @input.index

      root_0 = nil
      __FOUND_ATTR872__ = nil
      __NOTFOUND_ATTR873__ = nil
      __ISOPEN_ATTR874__ = nil
      __ROWCOUNT_ATTR875__ = nil
      __BULK_ROWCOUNT_ATTR876__ = nil
      string_literal877 = nil
      string_literal878 = nil
      string_literal879 = nil
      string_literal880 = nil
      string_literal881 = nil
      string_literal883 = nil
      string_literal884 = nil
      string_literal886 = nil
      string_literal888 = nil
      string_literal889 = nil
      __LPAREN890__ = nil
      __RPAREN892__ = nil
      expr_add869 = nil
      relational_op870 = nil
      expr_add871 = nil
      expr_add882 = nil
      expr_add885 = nil
      expr_add887 = nil
      nested_expressions891 = nil

      tree_for_FOUND_ATTR872 = nil
      tree_for_NOTFOUND_ATTR873 = nil
      tree_for_ISOPEN_ATTR874 = nil
      tree_for_ROWCOUNT_ATTR875 = nil
      tree_for_BULK_ROWCOUNT_ATTR876 = nil
      tree_for_string_literal877 = nil
      tree_for_string_literal878 = nil
      tree_for_string_literal879 = nil
      tree_for_string_literal880 = nil
      tree_for_string_literal881 = nil
      tree_for_string_literal883 = nil
      tree_for_string_literal884 = nil
      tree_for_string_literal886 = nil
      tree_for_string_literal888 = nil
      tree_for_string_literal889 = nil
      tree_for_LPAREN890 = nil
      tree_for_RPAREN892 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 819:4: expr_add ( relational_op expr_add | FOUND_ATTR | NOTFOUND_ATTR | ISOPEN_ATTR | ROWCOUNT_ATTR | BULK_ROWCOUNT_ATTR | 'IS' ( 'NOT' )? 'NULL' | ( 'NOT' )? 'LIKE' expr_add | ( 'NOT' )? 'BETWEEN' expr_add 'AND' expr_add | ( 'NOT' )? 'IN' LPAREN nested_expressions RPAREN )*
        @state.following.push( TOKENS_FOLLOWING_expr_add_IN_expr_not_5135 )
        expr_add869 = expr_add
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, expr_add869.tree )
        end
        # at line 820:3: ( relational_op expr_add | FOUND_ATTR | NOTFOUND_ATTR | ISOPEN_ATTR | ROWCOUNT_ATTR | BULK_ROWCOUNT_ATTR | 'IS' ( 'NOT' )? 'NULL' | ( 'NOT' )? 'LIKE' expr_add | ( 'NOT' )? 'BETWEEN' expr_add 'AND' expr_add | ( 'NOT' )? 'IN' LPAREN nested_expressions RPAREN )*
        while true # decision 231
          alt_231 = 11
          alt_231 = @dfa231.predict( @input )
          case alt_231
          when 1
            # at line 820:5: relational_op expr_add
            @state.following.push( TOKENS_FOLLOWING_relational_op_IN_expr_not_5142 )
            relational_op870 = relational_op
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, relational_op870.tree )
            end
            @state.following.push( TOKENS_FOLLOWING_expr_add_IN_expr_not_5144 )
            expr_add871 = expr_add
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, expr_add871.tree )
            end

          when 2
            # at line 821:5: FOUND_ATTR
            __FOUND_ATTR872__ = match( FOUND_ATTR, TOKENS_FOLLOWING_FOUND_ATTR_IN_expr_not_5150 )
            if @state.backtracking == 0

              tree_for_FOUND_ATTR872 = @adaptor.create_with_payload( __FOUND_ATTR872__ )
              @adaptor.add_child( root_0, tree_for_FOUND_ATTR872 )

            end

          when 3
            # at line 821:18: NOTFOUND_ATTR
            __NOTFOUND_ATTR873__ = match( NOTFOUND_ATTR, TOKENS_FOLLOWING_NOTFOUND_ATTR_IN_expr_not_5154 )
            if @state.backtracking == 0

              tree_for_NOTFOUND_ATTR873 = @adaptor.create_with_payload( __NOTFOUND_ATTR873__ )
              @adaptor.add_child( root_0, tree_for_NOTFOUND_ATTR873 )

            end

          when 4
            # at line 821:34: ISOPEN_ATTR
            __ISOPEN_ATTR874__ = match( ISOPEN_ATTR, TOKENS_FOLLOWING_ISOPEN_ATTR_IN_expr_not_5158 )
            if @state.backtracking == 0

              tree_for_ISOPEN_ATTR874 = @adaptor.create_with_payload( __ISOPEN_ATTR874__ )
              @adaptor.add_child( root_0, tree_for_ISOPEN_ATTR874 )

            end

          when 5
            # at line 821:48: ROWCOUNT_ATTR
            __ROWCOUNT_ATTR875__ = match( ROWCOUNT_ATTR, TOKENS_FOLLOWING_ROWCOUNT_ATTR_IN_expr_not_5162 )
            if @state.backtracking == 0

              tree_for_ROWCOUNT_ATTR875 = @adaptor.create_with_payload( __ROWCOUNT_ATTR875__ )
              @adaptor.add_child( root_0, tree_for_ROWCOUNT_ATTR875 )

            end

          when 6
            # at line 821:64: BULK_ROWCOUNT_ATTR
            __BULK_ROWCOUNT_ATTR876__ = match( BULK_ROWCOUNT_ATTR, TOKENS_FOLLOWING_BULK_ROWCOUNT_ATTR_IN_expr_not_5166 )
            if @state.backtracking == 0

              tree_for_BULK_ROWCOUNT_ATTR876 = @adaptor.create_with_payload( __BULK_ROWCOUNT_ATTR876__ )
              @adaptor.add_child( root_0, tree_for_BULK_ROWCOUNT_ATTR876 )

            end

          when 7
            # at line 822:5: 'IS' ( 'NOT' )? 'NULL'
            string_literal877 = match( T__52, TOKENS_FOLLOWING_T__52_IN_expr_not_5172 )
            if @state.backtracking == 0

              tree_for_string_literal877 = @adaptor.create_with_payload( string_literal877 )
              @adaptor.add_child( root_0, tree_for_string_literal877 )

            end
            # at line 822:10: ( 'NOT' )?
            alt_227 = 2
            look_227_0 = @input.peek( 1 )

            if ( look_227_0 == T__57 )
              alt_227 = 1
            end
            case alt_227
            when 1
              # at line 822:12: 'NOT'
              string_literal878 = match( T__57, TOKENS_FOLLOWING_T__57_IN_expr_not_5176 )
              if @state.backtracking == 0

                tree_for_string_literal878 = @adaptor.create_with_payload( string_literal878 )
                @adaptor.add_child( root_0, tree_for_string_literal878 )

              end

            end
            string_literal879 = match( T__58, TOKENS_FOLLOWING_T__58_IN_expr_not_5181 )
            if @state.backtracking == 0

              tree_for_string_literal879 = @adaptor.create_with_payload( string_literal879 )
              @adaptor.add_child( root_0, tree_for_string_literal879 )

            end

          when 8
            # at line 823:5: ( 'NOT' )? 'LIKE' expr_add
            # at line 823:5: ( 'NOT' )?
            alt_228 = 2
            look_228_0 = @input.peek( 1 )

            if ( look_228_0 == T__57 )
              alt_228 = 1
            end
            case alt_228
            when 1
              # at line 823:7: 'NOT'
              string_literal880 = match( T__57, TOKENS_FOLLOWING_T__57_IN_expr_not_5189 )
              if @state.backtracking == 0

                tree_for_string_literal880 = @adaptor.create_with_payload( string_literal880 )
                @adaptor.add_child( root_0, tree_for_string_literal880 )

              end

            end
            string_literal881 = match( T__134, TOKENS_FOLLOWING_T__134_IN_expr_not_5194 )
            if @state.backtracking == 0

              tree_for_string_literal881 = @adaptor.create_with_payload( string_literal881 )
              @adaptor.add_child( root_0, tree_for_string_literal881 )

            end
            @state.following.push( TOKENS_FOLLOWING_expr_add_IN_expr_not_5196 )
            expr_add882 = expr_add
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, expr_add882.tree )
            end

          when 9
            # at line 824:5: ( 'NOT' )? 'BETWEEN' expr_add 'AND' expr_add
            # at line 824:5: ( 'NOT' )?
            alt_229 = 2
            look_229_0 = @input.peek( 1 )

            if ( look_229_0 == T__57 )
              alt_229 = 1
            end
            case alt_229
            when 1
              # at line 824:7: 'NOT'
              string_literal883 = match( T__57, TOKENS_FOLLOWING_T__57_IN_expr_not_5204 )
              if @state.backtracking == 0

                tree_for_string_literal883 = @adaptor.create_with_payload( string_literal883 )
                @adaptor.add_child( root_0, tree_for_string_literal883 )

              end

            end
            string_literal884 = match( T__139, TOKENS_FOLLOWING_T__139_IN_expr_not_5209 )
            if @state.backtracking == 0

              tree_for_string_literal884 = @adaptor.create_with_payload( string_literal884 )
              @adaptor.add_child( root_0, tree_for_string_literal884 )

            end
            @state.following.push( TOKENS_FOLLOWING_expr_add_IN_expr_not_5211 )
            expr_add885 = expr_add
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, expr_add885.tree )
            end
            string_literal886 = match( T__138, TOKENS_FOLLOWING_T__138_IN_expr_not_5213 )
            if @state.backtracking == 0

              tree_for_string_literal886 = @adaptor.create_with_payload( string_literal886 )
              @adaptor.add_child( root_0, tree_for_string_literal886 )

            end
            @state.following.push( TOKENS_FOLLOWING_expr_add_IN_expr_not_5215 )
            expr_add887 = expr_add
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, expr_add887.tree )
            end

          when 10
            # at line 825:5: ( 'NOT' )? 'IN' LPAREN nested_expressions RPAREN
            # at line 825:5: ( 'NOT' )?
            alt_230 = 2
            look_230_0 = @input.peek( 1 )

            if ( look_230_0 == T__57 )
              alt_230 = 1
            end
            case alt_230
            when 1
              # at line 825:7: 'NOT'
              string_literal888 = match( T__57, TOKENS_FOLLOWING_T__57_IN_expr_not_5223 )
              if @state.backtracking == 0

                tree_for_string_literal888 = @adaptor.create_with_payload( string_literal888 )
                @adaptor.add_child( root_0, tree_for_string_literal888 )

              end

            end
            string_literal889 = match( T__102, TOKENS_FOLLOWING_T__102_IN_expr_not_5228 )
            if @state.backtracking == 0

              tree_for_string_literal889 = @adaptor.create_with_payload( string_literal889 )
              @adaptor.add_child( root_0, tree_for_string_literal889 )

            end
            __LPAREN890__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_expr_not_5230 )
            if @state.backtracking == 0

              tree_for_LPAREN890 = @adaptor.create_with_payload( __LPAREN890__ )
              @adaptor.add_child( root_0, tree_for_LPAREN890 )

            end
            @state.following.push( TOKENS_FOLLOWING_nested_expressions_IN_expr_not_5232 )
            nested_expressions891 = nested_expressions
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, nested_expressions891.tree )
            end
            __RPAREN892__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_expr_not_5234 )
            if @state.backtracking == 0

              tree_for_RPAREN892 = @adaptor.create_with_payload( __RPAREN892__ )
              @adaptor.add_child( root_0, tree_for_RPAREN892 )

            end

          else
            break # out of loop for decision 231
          end
        end # loop for decision 231
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 147 )
        memoize( __method__, expr_not_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    BooleanLiteralReturnValue = define_return_scope 

    # 
    # parser rule boolean_literal
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 829:1: boolean_literal : ( 'TRUE' | 'FALSE' );
    # 
    def boolean_literal
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 148 )
      return_value = BooleanLiteralReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      boolean_literal_start_index = @input.index

      root_0 = nil
      set893 = nil

      tree_for_set893 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 
        set893 = @input.look
        if @input.peek( 1 ).between?( T__110, T__111 )
          @input.consume
          if @state.backtracking == 0
            @adaptor.add_child( root_0, @adaptor.create_with_payload( set893 ) )
          end
          @state.error_recovery = false
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          mse = MismatchedSet( nil )
          raise mse
        end


        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 148 )
        memoize( __method__, boolean_literal_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SqlExpressionsReturnValue = define_return_scope 

    # 
    # parser rule sql_expressions
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 833:1: sql_expressions : sql_expression ( COMMA sql_expression )* ;
    # 
    def sql_expressions
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 149 )
      return_value = SqlExpressionsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      sql_expressions_start_index = @input.index

      root_0 = nil
      __COMMA895__ = nil
      sql_expression894 = nil
      sql_expression896 = nil

      tree_for_COMMA895 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 834:4: sql_expression ( COMMA sql_expression )*
        @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_sql_expressions_5265 )
        sql_expression894 = sql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_expression894.tree )
        end
        # at line 834:19: ( COMMA sql_expression )*
        while true # decision 232
          alt_232 = 2
          look_232_0 = @input.peek( 1 )

          if ( look_232_0 == COMMA )
            look_232_2 = @input.peek( 2 )

            if ( syntactic_predicate?( :synpred374_Plsql ) )
              alt_232 = 1

            end

          end
          case alt_232
          when 1
            # at line 834:21: COMMA sql_expression
            __COMMA895__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_sql_expressions_5269 )
            if @state.backtracking == 0

              tree_for_COMMA895 = @adaptor.create_with_payload( __COMMA895__ )
              @adaptor.add_child( root_0, tree_for_COMMA895 )

            end
            @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_sql_expressions_5271 )
            sql_expression896 = sql_expression
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, sql_expression896.tree )
            end

          else
            break # out of loop for decision 232
          end
        end # loop for decision 232
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 149 )
        memoize( __method__, sql_expressions_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SqlExpressionReturnValue = define_return_scope 

    # 
    # parser rule sql_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 836:1: sql_expression : expr_add ;
    # 
    def sql_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 150 )
      return_value = SqlExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      sql_expression_start_index = @input.index

      root_0 = nil
      expr_add897 = nil

      # - - - - @init action - - - -
       @is_sql = true; 

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 838:4: expr_add
        @state.following.push( TOKENS_FOLLOWING_expr_add_IN_sql_expression_5291 )
        expr_add897 = expr_add
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, expr_add897.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 150 )
        memoize( __method__, sql_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExprAddReturnValue = define_return_scope 

    # 
    # parser rule expr_add
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 840:1: expr_add : expr_mul ( ( PLUS | MINUS | DOUBLEVERTBAR ) expr_mul )* ;
    # 
    def expr_add
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 151 )
      return_value = ExprAddReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      expr_add_start_index = @input.index

      root_0 = nil
      set899 = nil
      expr_mul898 = nil
      expr_mul900 = nil

      tree_for_set899 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 841:4: expr_mul ( ( PLUS | MINUS | DOUBLEVERTBAR ) expr_mul )*
        @state.following.push( TOKENS_FOLLOWING_expr_mul_IN_expr_add_5301 )
        expr_mul898 = expr_mul
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, expr_mul898.tree )
        end
        # at line 841:13: ( ( PLUS | MINUS | DOUBLEVERTBAR ) expr_mul )*
        while true # decision 233
          alt_233 = 2
          look_233_0 = @input.peek( 1 )

          if ( look_233_0.between?( PLUS, MINUS ) )
            look_233_2 = @input.peek( 2 )

            if ( syntactic_predicate?( :synpred377_Plsql ) )
              alt_233 = 1

            end
          elsif ( look_233_0 == DOUBLEVERTBAR )
            look_233_3 = @input.peek( 2 )

            if ( syntactic_predicate?( :synpred377_Plsql ) )
              alt_233 = 1

            end

          end
          case alt_233
          when 1
            # at line 841:15: ( PLUS | MINUS | DOUBLEVERTBAR ) expr_mul
            set899 = @input.look
            if @input.peek( 1 ).between?( PLUS, MINUS ) || @input.peek(1) == DOUBLEVERTBAR
              @input.consume
              if @state.backtracking == 0
                @adaptor.add_child( root_0, @adaptor.create_with_payload( set899 ) )
              end
              @state.error_recovery = false
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              mse = MismatchedSet( nil )
              raise mse
            end


            @state.following.push( TOKENS_FOLLOWING_expr_mul_IN_expr_add_5319 )
            expr_mul900 = expr_mul
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, expr_mul900.tree )
            end

          else
            break # out of loop for decision 233
          end
        end # loop for decision 233
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 151 )
        memoize( __method__, expr_add_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExprMulReturnValue = define_return_scope 

    # 
    # parser rule expr_mul
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 843:1: expr_mul : expr_sign ( ( ASTERISK | DIVIDE ) expr_sign )* ;
    # 
    def expr_mul
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 152 )
      return_value = ExprMulReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      expr_mul_start_index = @input.index

      root_0 = nil
      set902 = nil
      expr_sign901 = nil
      expr_sign903 = nil

      tree_for_set902 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 844:4: expr_sign ( ( ASTERISK | DIVIDE ) expr_sign )*
        @state.following.push( TOKENS_FOLLOWING_expr_sign_IN_expr_mul_5332 )
        expr_sign901 = expr_sign
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, expr_sign901.tree )
        end
        # at line 844:14: ( ( ASTERISK | DIVIDE ) expr_sign )*
        while true # decision 234
          alt_234 = 2
          look_234_0 = @input.peek( 1 )

          if ( look_234_0 == ASTERISK || look_234_0 == DIVIDE )
            look_234_2 = @input.peek( 2 )

            if ( syntactic_predicate?( :synpred379_Plsql ) )
              alt_234 = 1

            end

          end
          case alt_234
          when 1
            # at line 844:16: ( ASTERISK | DIVIDE ) expr_sign
            set902 = @input.look
            if @input.peek(1) == ASTERISK || @input.peek(1) == DIVIDE
              @input.consume
              if @state.backtracking == 0
                @adaptor.add_child( root_0, @adaptor.create_with_payload( set902 ) )
              end
              @state.error_recovery = false
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              mse = MismatchedSet( nil )
              raise mse
            end


            @state.following.push( TOKENS_FOLLOWING_expr_sign_IN_expr_mul_5346 )
            expr_sign903 = expr_sign
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, expr_sign903.tree )
            end

          else
            break # out of loop for decision 234
          end
        end # loop for decision 234
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 152 )
        memoize( __method__, expr_mul_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExprSignReturnValue = define_return_scope 

    # 
    # parser rule expr_sign
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 846:1: expr_sign : ( PLUS | MINUS )? expr_pow ;
    # 
    def expr_sign
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 153 )
      return_value = ExprSignReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      expr_sign_start_index = @input.index

      root_0 = nil
      set904 = nil
      expr_pow905 = nil

      tree_for_set904 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 847:4: ( PLUS | MINUS )? expr_pow
        # at line 847:4: ( PLUS | MINUS )?
        alt_235 = 2
        look_235_0 = @input.peek( 1 )

        if ( look_235_0.between?( PLUS, MINUS ) )
          alt_235 = 1
        end
        case alt_235
        when 1
          # at line 
          set904 = @input.look
          if @input.peek( 1 ).between?( PLUS, MINUS )
            @input.consume
            if @state.backtracking == 0
              @adaptor.add_child( root_0, @adaptor.create_with_payload( set904 ) )
            end
            @state.error_recovery = false
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            mse = MismatchedSet( nil )
            raise mse
          end



        end
        @state.following.push( TOKENS_FOLLOWING_expr_pow_IN_expr_sign_5370 )
        expr_pow905 = expr_pow
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, expr_pow905.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 153 )
        memoize( __method__, expr_sign_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExprPowReturnValue = define_return_scope 

    # 
    # parser rule expr_pow
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 849:1: expr_pow : expr_expr ( EXPONENT expr_expr )* ;
    # 
    def expr_pow
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 154 )
      return_value = ExprPowReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      expr_pow_start_index = @input.index

      root_0 = nil
      __EXPONENT907__ = nil
      expr_expr906 = nil
      expr_expr908 = nil

      tree_for_EXPONENT907 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 850:4: expr_expr ( EXPONENT expr_expr )*
        @state.following.push( TOKENS_FOLLOWING_expr_expr_IN_expr_pow_5380 )
        expr_expr906 = expr_expr
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, expr_expr906.tree )
        end
        # at line 850:14: ( EXPONENT expr_expr )*
        while true # decision 236
          alt_236 = 2
          look_236_0 = @input.peek( 1 )

          if ( look_236_0 == EXPONENT )
            look_236_2 = @input.peek( 2 )

            if ( syntactic_predicate?( :synpred382_Plsql ) )
              alt_236 = 1

            end

          end
          case alt_236
          when 1
            # at line 850:16: EXPONENT expr_expr
            __EXPONENT907__ = match( EXPONENT, TOKENS_FOLLOWING_EXPONENT_IN_expr_pow_5384 )
            if @state.backtracking == 0

              tree_for_EXPONENT907 = @adaptor.create_with_payload( __EXPONENT907__ )
              @adaptor.add_child( root_0, tree_for_EXPONENT907 )

            end
            @state.following.push( TOKENS_FOLLOWING_expr_expr_IN_expr_pow_5386 )
            expr_expr908 = expr_expr
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, expr_expr908.tree )
            end

          else
            break # out of loop for decision 236
          end
        end # loop for decision 236
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 154 )
        memoize( __method__, expr_pow_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExprExprReturnValue = define_return_scope 

    # 
    # parser rule expr_expr
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 852:1: expr_expr : ( ( expr_paren )=> expr_paren | ( function_expression )=> function_expression | ( case_expression )=> case_expression | ( cursor_expression )=> cursor_expression | ( simple_expression )=> simple_expression | ( select_expression )=> select_expression );
    # 
    def expr_expr
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 155 )
      return_value = ExprExprReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      expr_expr_start_index = @input.index

      root_0 = nil
      expr_paren909 = nil
      function_expression910 = nil
      case_expression911 = nil
      cursor_expression912 = nil
      simple_expression913 = nil
      select_expression914 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 853:2: ( ( expr_paren )=> expr_paren | ( function_expression )=> function_expression | ( case_expression )=> case_expression | ( cursor_expression )=> cursor_expression | ( simple_expression )=> simple_expression | ( select_expression )=> select_expression )
        alt_237 = 6
        alt_237 = @dfa237.predict( @input )
        case alt_237
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 853:4: ( expr_paren )=> expr_paren
          @state.following.push( TOKENS_FOLLOWING_expr_paren_IN_expr_expr_5407 )
          expr_paren909 = expr_paren
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, expr_paren909.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 854:4: ( function_expression )=> function_expression
          @state.following.push( TOKENS_FOLLOWING_function_expression_IN_expr_expr_5420 )
          function_expression910 = function_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, function_expression910.tree )
          end
          # syntactic predicate action gate test
          if @state.backtracking == 0
            # --> action
             
                  unless @skip 
                    next_part = @input.look(1).nil? ? '' : @input.look(1).text
                    @last_expr = ( function_expression910 && @input.to_s( function_expression910.start, function_expression910.stop ) ).split('.').last if next_part != '('
                  end
                
            # <-- action
          end

        when 3
          root_0 = @adaptor.create_flat_list


          # at line 861:4: ( case_expression )=> case_expression
          @state.following.push( TOKENS_FOLLOWING_case_expression_IN_expr_expr_5440 )
          case_expression911 = case_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, case_expression911.tree )
          end

        when 4
          root_0 = @adaptor.create_flat_list


          # at line 862:4: ( cursor_expression )=> cursor_expression
          @state.following.push( TOKENS_FOLLOWING_cursor_expression_IN_expr_expr_5453 )
          cursor_expression912 = cursor_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, cursor_expression912.tree )
          end

        when 5
          root_0 = @adaptor.create_flat_list


          # at line 863:4: ( simple_expression )=> simple_expression
          @state.following.push( TOKENS_FOLLOWING_simple_expression_IN_expr_expr_5466 )
          simple_expression913 = simple_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, simple_expression913.tree )
          end

        when 6
          root_0 = @adaptor.create_flat_list


          # at line 864:4: ( select_expression )=> select_expression
          @state.following.push( TOKENS_FOLLOWING_select_expression_IN_expr_expr_5479 )
          select_expression914 = select_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, select_expression914.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 155 )
        memoize( __method__, expr_expr_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SimpleExpressionReturnValue = define_return_scope 

    # 
    # parser rule simple_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 866:1: simple_expression : ( boolean_literal | 'SQL' ( FOUND_ATTR | NOTFOUND_ATTR | ISOPEN_ATTR | ROWCOUNT_ATTR | BULK_ROWCOUNT_ATTR ) | ( column_spec )=> column_spec | QUOTED_STRING | NUMBER | 'NULL' );
    # 
    def simple_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 156 )
      return_value = SimpleExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      simple_expression_start_index = @input.index

      root_0 = nil
      string_literal916 = nil
      set917 = nil
      __QUOTED_STRING919__ = nil
      __NUMBER920__ = nil
      string_literal921 = nil
      boolean_literal915 = nil
      column_spec918 = nil

      tree_for_string_literal916 = nil
      tree_for_set917 = nil
      tree_for_QUOTED_STRING919 = nil
      tree_for_NUMBER920 = nil
      tree_for_string_literal921 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 867:2: ( boolean_literal | 'SQL' ( FOUND_ATTR | NOTFOUND_ATTR | ISOPEN_ATTR | ROWCOUNT_ATTR | BULK_ROWCOUNT_ATTR ) | ( column_spec )=> column_spec | QUOTED_STRING | NUMBER | 'NULL' )
        alt_238 = 6
        look_238_0 = @input.peek( 1 )

        if ( look_238_0.between?( T__110, T__111 ) )
          alt_238 = 1
        elsif ( look_238_0 == T__140 )
          alt_238 = 2
        elsif ( look_238_0.between?( ID, DOUBLEQUOTED_STRING ) ) and ( syntactic_predicate?( :synpred395_Plsql ) )
          alt_238 = 3
        elsif ( look_238_0 == T__100 ) and ( syntactic_predicate?( :synpred395_Plsql ) )
          alt_238 = 3
        elsif ( look_238_0 == QUOTED_STRING )
          alt_238 = 4
        elsif ( look_238_0 == NUMBER )
          alt_238 = 5
        elsif ( look_238_0 == T__58 )
          alt_238 = 6
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 238, 0 )
        end
        case alt_238
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 867:4: boolean_literal
          @state.following.push( TOKENS_FOLLOWING_boolean_literal_IN_simple_expression_5490 )
          boolean_literal915 = boolean_literal
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, boolean_literal915.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 868:4: 'SQL' ( FOUND_ATTR | NOTFOUND_ATTR | ISOPEN_ATTR | ROWCOUNT_ATTR | BULK_ROWCOUNT_ATTR )
          string_literal916 = match( T__140, TOKENS_FOLLOWING_T__140_IN_simple_expression_5495 )
          if @state.backtracking == 0

            tree_for_string_literal916 = @adaptor.create_with_payload( string_literal916 )
            @adaptor.add_child( root_0, tree_for_string_literal916 )

          end
          set917 = @input.look
          if @input.peek( 1 ).between?( FOUND_ATTR, BULK_ROWCOUNT_ATTR )
            @input.consume
            if @state.backtracking == 0
              @adaptor.add_child( root_0, @adaptor.create_with_payload( set917 ) )
            end
            @state.error_recovery = false
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            mse = MismatchedSet( nil )
            raise mse
          end



        when 3
          root_0 = @adaptor.create_flat_list


          # at line 869:4: ( column_spec )=> column_spec
          @state.following.push( TOKENS_FOLLOWING_column_spec_IN_simple_expression_5530 )
          column_spec918 = column_spec
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, column_spec918.tree )
          end

        when 4
          root_0 = @adaptor.create_flat_list


          # at line 870:4: QUOTED_STRING
          __QUOTED_STRING919__ = match( QUOTED_STRING, TOKENS_FOLLOWING_QUOTED_STRING_IN_simple_expression_5536 )
          if @state.backtracking == 0

            tree_for_QUOTED_STRING919 = @adaptor.create_with_payload( __QUOTED_STRING919__ )
            @adaptor.add_child( root_0, tree_for_QUOTED_STRING919 )

          end

        when 5
          root_0 = @adaptor.create_flat_list


          # at line 871:4: NUMBER
          __NUMBER920__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_simple_expression_5541 )
          if @state.backtracking == 0

            tree_for_NUMBER920 = @adaptor.create_with_payload( __NUMBER920__ )
            @adaptor.add_child( root_0, tree_for_NUMBER920 )

          end

        when 6
          root_0 = @adaptor.create_flat_list


          # at line 872:4: 'NULL'
          string_literal921 = match( T__58, TOKENS_FOLLOWING_T__58_IN_simple_expression_5546 )
          if @state.backtracking == 0

            tree_for_string_literal921 = @adaptor.create_with_payload( string_literal921 )
            @adaptor.add_child( root_0, tree_for_string_literal921 )

          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 156 )
        memoize( __method__, simple_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CompoundExpressionReturnValue = define_return_scope 

    # 
    # parser rule compound_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 874:1: compound_expression : expr_prior ;
    # 
    def compound_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 157 )
      return_value = CompoundExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      compound_expression_start_index = @input.index

      root_0 = nil
      expr_prior922 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 877:4: expr_prior
        @state.following.push( TOKENS_FOLLOWING_expr_prior_IN_compound_expression_5558 )
        expr_prior922 = expr_prior
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, expr_prior922.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 157 )
        memoize( __method__, compound_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExprParenReturnValue = define_return_scope 

    # 
    # parser rule expr_paren
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 881:1: expr_paren : LPAREN nested_expression RPAREN ;
    # 
    def expr_paren
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 158 )
      return_value = ExprParenReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      expr_paren_start_index = @input.index

      root_0 = nil
      __LPAREN923__ = nil
      __RPAREN925__ = nil
      nested_expression924 = nil

      tree_for_LPAREN923 = nil
      tree_for_RPAREN925 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 882:4: LPAREN nested_expression RPAREN
        __LPAREN923__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_expr_paren_5570 )
        if @state.backtracking == 0

          tree_for_LPAREN923 = @adaptor.create_with_payload( __LPAREN923__ )
          @adaptor.add_child( root_0, tree_for_LPAREN923 )

        end
        # syntactic predicate action gate test
        if @state.backtracking == 0
          # --> action
           @skip = true 
          # <-- action
        end
        @state.following.push( TOKENS_FOLLOWING_nested_expression_IN_expr_paren_5574 )
        nested_expression924 = nested_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, nested_expression924.tree )
        end
        __RPAREN925__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_expr_paren_5576 )
        if @state.backtracking == 0

          tree_for_RPAREN925 = @adaptor.create_with_payload( __RPAREN925__ )
          @adaptor.add_child( root_0, tree_for_RPAREN925 )

        end
        # syntactic predicate action gate test
        if @state.backtracking == 0
          # --> action
           @skip = false 
          # <-- action
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 158 )
        memoize( __method__, expr_paren_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExprPriorReturnValue = define_return_scope 

    # 
    # parser rule expr_prior
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 884:1: expr_prior : 'PRIOR' expr_add ;
    # 
    def expr_prior
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 159 )
      return_value = ExprPriorReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      expr_prior_start_index = @input.index

      root_0 = nil
      string_literal926 = nil
      expr_add927 = nil

      tree_for_string_literal926 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 885:4: 'PRIOR' expr_add
        string_literal926 = match( T__141, TOKENS_FOLLOWING_T__141_IN_expr_prior_5588 )
        if @state.backtracking == 0

          tree_for_string_literal926 = @adaptor.create_with_payload( string_literal926 )
          @adaptor.add_child( root_0, tree_for_string_literal926 )

        end
        @state.following.push( TOKENS_FOLLOWING_expr_add_IN_expr_prior_5590 )
        expr_add927 = expr_add
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, expr_add927.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 159 )
        memoize( __method__, expr_prior_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CaseExpressionReturnValue = define_return_scope 

    # 
    # parser rule case_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 887:1: case_expression : 'CASE' ( simple_case_expression | searched_case_expression ) ( else_case_expression )? 'END' ;
    # 
    def case_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 160 )
      return_value = CaseExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      case_expression_start_index = @input.index

      root_0 = nil
      string_literal928 = nil
      string_literal932 = nil
      simple_case_expression929 = nil
      searched_case_expression930 = nil
      else_case_expression931 = nil

      tree_for_string_literal928 = nil
      tree_for_string_literal932 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 888:4: 'CASE' ( simple_case_expression | searched_case_expression ) ( else_case_expression )? 'END'
        string_literal928 = match( T__142, TOKENS_FOLLOWING_T__142_IN_case_expression_5600 )
        if @state.backtracking == 0

          tree_for_string_literal928 = @adaptor.create_with_payload( string_literal928 )
          @adaptor.add_child( root_0, tree_for_string_literal928 )

        end
        # at line 888:11: ( simple_case_expression | searched_case_expression )
        alt_239 = 2
        look_239_0 = @input.peek( 1 )

        if ( look_239_0 == LPAREN || look_239_0.between?( PLUS, QUOTED_STRING ) || look_239_0.between?( ID, DOUBLEQUOTED_STRING ) || look_239_0.between?( T__57, T__58 ) || look_239_0 == T__100 || look_239_0.between?( T__110, T__111 ) || look_239_0.between?( T__116, T__117 ) || look_239_0 == T__140 || look_239_0 == T__142 )
          alt_239 = 1
        elsif ( look_239_0 == T__63 )
          alt_239 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 239, 0 )
        end
        case alt_239
        when 1
          # at line 888:13: simple_case_expression
          @state.following.push( TOKENS_FOLLOWING_simple_case_expression_IN_case_expression_5604 )
          simple_case_expression929 = simple_case_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, simple_case_expression929.tree )
          end

        when 2
          # at line 888:38: searched_case_expression
          @state.following.push( TOKENS_FOLLOWING_searched_case_expression_IN_case_expression_5608 )
          searched_case_expression930 = searched_case_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, searched_case_expression930.tree )
          end

        end
        # at line 888:65: ( else_case_expression )?
        alt_240 = 2
        look_240_0 = @input.peek( 1 )

        if ( look_240_0 == T__115 )
          alt_240 = 1
        end
        case alt_240
        when 1
          # at line 888:67: else_case_expression
          @state.following.push( TOKENS_FOLLOWING_else_case_expression_IN_case_expression_5614 )
          else_case_expression931 = else_case_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, else_case_expression931.tree )
          end

        end
        string_literal932 = match( T__54, TOKENS_FOLLOWING_T__54_IN_case_expression_5619 )
        if @state.backtracking == 0

          tree_for_string_literal932 = @adaptor.create_with_payload( string_literal932 )
          @adaptor.add_child( root_0, tree_for_string_literal932 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 160 )
        memoize( __method__, case_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SimpleCaseExpressionReturnValue = define_return_scope 

    # 
    # parser rule simple_case_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 890:1: simple_case_expression : nested_expression ( 'WHEN' nested_expression 'THEN' nested_expression )+ ;
    # 
    def simple_case_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 161 )
      return_value = SimpleCaseExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      simple_case_expression_start_index = @input.index

      root_0 = nil
      string_literal934 = nil
      string_literal936 = nil
      nested_expression933 = nil
      nested_expression935 = nil
      nested_expression937 = nil

      tree_for_string_literal934 = nil
      tree_for_string_literal936 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 891:4: nested_expression ( 'WHEN' nested_expression 'THEN' nested_expression )+
        @state.following.push( TOKENS_FOLLOWING_nested_expression_IN_simple_case_expression_5629 )
        nested_expression933 = nested_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, nested_expression933.tree )
        end
        # at file 891:22: ( 'WHEN' nested_expression 'THEN' nested_expression )+
        match_count_241 = 0
        while true
          alt_241 = 2
          look_241_0 = @input.peek( 1 )

          if ( look_241_0 == T__63 )
            alt_241 = 1

          end
          case alt_241
          when 1
            # at line 891:24: 'WHEN' nested_expression 'THEN' nested_expression
            string_literal934 = match( T__63, TOKENS_FOLLOWING_T__63_IN_simple_case_expression_5633 )
            if @state.backtracking == 0

              tree_for_string_literal934 = @adaptor.create_with_payload( string_literal934 )
              @adaptor.add_child( root_0, tree_for_string_literal934 )

            end
            @state.following.push( TOKENS_FOLLOWING_nested_expression_IN_simple_case_expression_5635 )
            nested_expression935 = nested_expression
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, nested_expression935.tree )
            end
            string_literal936 = match( T__109, TOKENS_FOLLOWING_T__109_IN_simple_case_expression_5637 )
            if @state.backtracking == 0

              tree_for_string_literal936 = @adaptor.create_with_payload( string_literal936 )
              @adaptor.add_child( root_0, tree_for_string_literal936 )

            end
            @state.following.push( TOKENS_FOLLOWING_nested_expression_IN_simple_case_expression_5639 )
            nested_expression937 = nested_expression
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, nested_expression937.tree )
            end

          else
            match_count_241 > 0 and break
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            eee = EarlyExit(241)


            raise eee
          end
          match_count_241 += 1
        end

        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 161 )
        memoize( __method__, simple_case_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SearchedCaseExpressionReturnValue = define_return_scope 

    # 
    # parser rule searched_case_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 893:1: searched_case_expression : ( 'WHEN' nested_condition 'THEN' nested_expression )+ ;
    # 
    def searched_case_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 162 )
      return_value = SearchedCaseExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      searched_case_expression_start_index = @input.index

      root_0 = nil
      string_literal938 = nil
      string_literal940 = nil
      nested_condition939 = nil
      nested_expression941 = nil

      tree_for_string_literal938 = nil
      tree_for_string_literal940 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 894:4: ( 'WHEN' nested_condition 'THEN' nested_expression )+
        # at file 894:4: ( 'WHEN' nested_condition 'THEN' nested_expression )+
        match_count_242 = 0
        while true
          alt_242 = 2
          look_242_0 = @input.peek( 1 )

          if ( look_242_0 == T__63 )
            alt_242 = 1

          end
          case alt_242
          when 1
            # at line 894:6: 'WHEN' nested_condition 'THEN' nested_expression
            string_literal938 = match( T__63, TOKENS_FOLLOWING_T__63_IN_searched_case_expression_5654 )
            if @state.backtracking == 0

              tree_for_string_literal938 = @adaptor.create_with_payload( string_literal938 )
              @adaptor.add_child( root_0, tree_for_string_literal938 )

            end
            @state.following.push( TOKENS_FOLLOWING_nested_condition_IN_searched_case_expression_5656 )
            nested_condition939 = nested_condition
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, nested_condition939.tree )
            end
            string_literal940 = match( T__109, TOKENS_FOLLOWING_T__109_IN_searched_case_expression_5658 )
            if @state.backtracking == 0

              tree_for_string_literal940 = @adaptor.create_with_payload( string_literal940 )
              @adaptor.add_child( root_0, tree_for_string_literal940 )

            end
            @state.following.push( TOKENS_FOLLOWING_nested_expression_IN_searched_case_expression_5660 )
            nested_expression941 = nested_expression
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, nested_expression941.tree )
            end

          else
            match_count_242 > 0 and break
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            eee = EarlyExit(242)


            raise eee
          end
          match_count_242 += 1
        end

        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 162 )
        memoize( __method__, searched_case_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ElseCaseExpressionReturnValue = define_return_scope 

    # 
    # parser rule else_case_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 896:1: else_case_expression : 'ELSE' nested_expression ;
    # 
    def else_case_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 163 )
      return_value = ElseCaseExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      else_case_expression_start_index = @input.index

      root_0 = nil
      string_literal942 = nil
      nested_expression943 = nil

      tree_for_string_literal942 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 897:4: 'ELSE' nested_expression
        string_literal942 = match( T__115, TOKENS_FOLLOWING_T__115_IN_else_case_expression_5673 )
        if @state.backtracking == 0

          tree_for_string_literal942 = @adaptor.create_with_payload( string_literal942 )
          @adaptor.add_child( root_0, tree_for_string_literal942 )

        end
        @state.following.push( TOKENS_FOLLOWING_nested_expression_IN_else_case_expression_5675 )
        nested_expression943 = nested_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, nested_expression943.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 163 )
        memoize( __method__, else_case_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CaseStatementReturnValue = define_return_scope 

    # 
    # parser rule case_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 899:1: case_statement : ( label_name )? 'CASE' ( simple_case_statement | searched_case_statement ) ( else_case_statement )? 'END' 'CASE' ( label_name )? ;
    # 
    def case_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 164 )
      return_value = CaseStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      case_statement_start_index = @input.index

      root_0 = nil
      string_literal945 = nil
      string_literal949 = nil
      string_literal950 = nil
      label_name944 = nil
      simple_case_statement946 = nil
      searched_case_statement947 = nil
      else_case_statement948 = nil
      label_name951 = nil

      tree_for_string_literal945 = nil
      tree_for_string_literal949 = nil
      tree_for_string_literal950 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 900:4: ( label_name )? 'CASE' ( simple_case_statement | searched_case_statement ) ( else_case_statement )? 'END' 'CASE' ( label_name )?
        # at line 900:4: ( label_name )?
        alt_243 = 2
        look_243_0 = @input.peek( 1 )

        if ( look_243_0.between?( ID, DOUBLEQUOTED_STRING ) )
          alt_243 = 1
        end
        case alt_243
        when 1
          # at line 900:6: label_name
          @state.following.push( TOKENS_FOLLOWING_label_name_IN_case_statement_5687 )
          label_name944 = label_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, label_name944.tree )
          end

        end
        string_literal945 = match( T__142, TOKENS_FOLLOWING_T__142_IN_case_statement_5692 )
        if @state.backtracking == 0

          tree_for_string_literal945 = @adaptor.create_with_payload( string_literal945 )
          root_0 = @adaptor.become_root( tree_for_string_literal945, root_0 )

        end
        # at line 900:28: ( simple_case_statement | searched_case_statement )
        alt_244 = 2
        look_244_0 = @input.peek( 1 )

        if ( look_244_0 == LPAREN || look_244_0.between?( PLUS, QUOTED_STRING ) || look_244_0.between?( ID, DOUBLEQUOTED_STRING ) || look_244_0.between?( T__57, T__58 ) || look_244_0 == T__100 || look_244_0.between?( T__110, T__111 ) || look_244_0.between?( T__116, T__117 ) || look_244_0 == T__140 || look_244_0 == T__142 )
          alt_244 = 1
        elsif ( look_244_0 == T__63 )
          alt_244 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 244, 0 )
        end
        case alt_244
        when 1
          # at line 900:30: simple_case_statement
          @state.following.push( TOKENS_FOLLOWING_simple_case_statement_IN_case_statement_5697 )
          simple_case_statement946 = simple_case_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, simple_case_statement946.tree )
          end

        when 2
          # at line 900:54: searched_case_statement
          @state.following.push( TOKENS_FOLLOWING_searched_case_statement_IN_case_statement_5701 )
          searched_case_statement947 = searched_case_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, searched_case_statement947.tree )
          end

        end
        # at line 900:80: ( else_case_statement )?
        alt_245 = 2
        look_245_0 = @input.peek( 1 )

        if ( look_245_0 == T__115 )
          alt_245 = 1
        end
        case alt_245
        when 1
          # at line 900:82: else_case_statement
          @state.following.push( TOKENS_FOLLOWING_else_case_statement_IN_case_statement_5707 )
          else_case_statement948 = else_case_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, else_case_statement948.tree )
          end

        end
        string_literal949 = match( T__54, TOKENS_FOLLOWING_T__54_IN_case_statement_5712 )
        if @state.backtracking == 0

          tree_for_string_literal949 = @adaptor.create_with_payload( string_literal949 )
          @adaptor.add_child( root_0, tree_for_string_literal949 )

        end
        string_literal950 = match( T__142, TOKENS_FOLLOWING_T__142_IN_case_statement_5714 )
        if @state.backtracking == 0

          tree_for_string_literal950 = @adaptor.create_with_payload( string_literal950 )
          @adaptor.add_child( root_0, tree_for_string_literal950 )

        end
        # at line 900:118: ( label_name )?
        alt_246 = 2
        look_246_0 = @input.peek( 1 )

        if ( look_246_0.between?( ID, DOUBLEQUOTED_STRING ) )
          alt_246 = 1
        end
        case alt_246
        when 1
          # at line 900:120: label_name
          @state.following.push( TOKENS_FOLLOWING_label_name_IN_case_statement_5718 )
          label_name951 = label_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, label_name951.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 164 )
        memoize( __method__, case_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SimpleCaseStatementReturnValue = define_return_scope 

    # 
    # parser rule simple_case_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 902:1: simple_case_statement : plsql_expression ( 'WHEN' plsql_expression 'THEN' seq_of_statements )+ ;
    # 
    def simple_case_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 165 )
      return_value = SimpleCaseStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      simple_case_statement_start_index = @input.index

      root_0 = nil
      string_literal953 = nil
      string_literal955 = nil
      plsql_expression952 = nil
      plsql_expression954 = nil
      seq_of_statements956 = nil

      tree_for_string_literal953 = nil
      tree_for_string_literal955 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 903:4: plsql_expression ( 'WHEN' plsql_expression 'THEN' seq_of_statements )+
        @state.following.push( TOKENS_FOLLOWING_plsql_expression_IN_simple_case_statement_5731 )
        plsql_expression952 = plsql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, plsql_expression952.tree )
        end
        # at file 903:21: ( 'WHEN' plsql_expression 'THEN' seq_of_statements )+
        match_count_247 = 0
        while true
          alt_247 = 2
          look_247_0 = @input.peek( 1 )

          if ( look_247_0 == T__63 )
            alt_247 = 1

          end
          case alt_247
          when 1
            # at line 903:23: 'WHEN' plsql_expression 'THEN' seq_of_statements
            string_literal953 = match( T__63, TOKENS_FOLLOWING_T__63_IN_simple_case_statement_5735 )
            if @state.backtracking == 0

              tree_for_string_literal953 = @adaptor.create_with_payload( string_literal953 )
              @adaptor.add_child( root_0, tree_for_string_literal953 )

            end
            @state.following.push( TOKENS_FOLLOWING_plsql_expression_IN_simple_case_statement_5737 )
            plsql_expression954 = plsql_expression
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, plsql_expression954.tree )
            end
            string_literal955 = match( T__109, TOKENS_FOLLOWING_T__109_IN_simple_case_statement_5739 )
            if @state.backtracking == 0

              tree_for_string_literal955 = @adaptor.create_with_payload( string_literal955 )
              @adaptor.add_child( root_0, tree_for_string_literal955 )

            end
            @state.following.push( TOKENS_FOLLOWING_seq_of_statements_IN_simple_case_statement_5741 )
            seq_of_statements956 = seq_of_statements
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, seq_of_statements956.tree )
            end

          else
            match_count_247 > 0 and break
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            eee = EarlyExit(247)


            raise eee
          end
          match_count_247 += 1
        end

        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 165 )
        memoize( __method__, simple_case_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SearchedCaseStatementReturnValue = define_return_scope 

    # 
    # parser rule searched_case_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 905:1: searched_case_statement : ( 'WHEN' plsql_expression 'THEN' seq_of_statements )+ ;
    # 
    def searched_case_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 166 )
      return_value = SearchedCaseStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      searched_case_statement_start_index = @input.index

      root_0 = nil
      string_literal957 = nil
      string_literal959 = nil
      plsql_expression958 = nil
      seq_of_statements960 = nil

      tree_for_string_literal957 = nil
      tree_for_string_literal959 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 906:4: ( 'WHEN' plsql_expression 'THEN' seq_of_statements )+
        # at file 906:4: ( 'WHEN' plsql_expression 'THEN' seq_of_statements )+
        match_count_248 = 0
        while true
          alt_248 = 2
          look_248_0 = @input.peek( 1 )

          if ( look_248_0 == T__63 )
            alt_248 = 1

          end
          case alt_248
          when 1
            # at line 906:6: 'WHEN' plsql_expression 'THEN' seq_of_statements
            string_literal957 = match( T__63, TOKENS_FOLLOWING_T__63_IN_searched_case_statement_5756 )
            if @state.backtracking == 0

              tree_for_string_literal957 = @adaptor.create_with_payload( string_literal957 )
              @adaptor.add_child( root_0, tree_for_string_literal957 )

            end
            @state.following.push( TOKENS_FOLLOWING_plsql_expression_IN_searched_case_statement_5758 )
            plsql_expression958 = plsql_expression
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, plsql_expression958.tree )
            end
            string_literal959 = match( T__109, TOKENS_FOLLOWING_T__109_IN_searched_case_statement_5760 )
            if @state.backtracking == 0

              tree_for_string_literal959 = @adaptor.create_with_payload( string_literal959 )
              @adaptor.add_child( root_0, tree_for_string_literal959 )

            end
            @state.following.push( TOKENS_FOLLOWING_seq_of_statements_IN_searched_case_statement_5762 )
            seq_of_statements960 = seq_of_statements
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, seq_of_statements960.tree )
            end

          else
            match_count_248 > 0 and break
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            eee = EarlyExit(248)


            raise eee
          end
          match_count_248 += 1
        end

        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 166 )
        memoize( __method__, searched_case_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ElseCaseStatementReturnValue = define_return_scope 

    # 
    # parser rule else_case_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 908:1: else_case_statement : 'ELSE' seq_of_statements ;
    # 
    def else_case_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 167 )
      return_value = ElseCaseStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      else_case_statement_start_index = @input.index

      root_0 = nil
      string_literal961 = nil
      seq_of_statements962 = nil

      tree_for_string_literal961 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 909:4: 'ELSE' seq_of_statements
        string_literal961 = match( T__115, TOKENS_FOLLOWING_T__115_IN_else_case_statement_5775 )
        if @state.backtracking == 0

          tree_for_string_literal961 = @adaptor.create_with_payload( string_literal961 )
          @adaptor.add_child( root_0, tree_for_string_literal961 )

        end
        @state.following.push( TOKENS_FOLLOWING_seq_of_statements_IN_else_case_statement_5777 )
        seq_of_statements962 = seq_of_statements
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, seq_of_statements962.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 167 )
        memoize( __method__, else_case_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CursorExpressionReturnValue = define_return_scope 

    # 
    # parser rule cursor_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 911:1: cursor_expression : keyCURSOR LPAREN subquery RPAREN ;
    # 
    def cursor_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 168 )
      return_value = CursorExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      cursor_expression_start_index = @input.index

      root_0 = nil
      __LPAREN964__ = nil
      __RPAREN966__ = nil
      keyCURSOR963 = nil
      subquery965 = nil

      tree_for_LPAREN964 = nil
      tree_for_RPAREN966 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 912:4: keyCURSOR LPAREN subquery RPAREN
        @state.following.push( TOKENS_FOLLOWING_keyCURSOR_IN_cursor_expression_5787 )
        keyCURSOR963 = keyCURSOR
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyCURSOR963.tree )
        end
        __LPAREN964__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_cursor_expression_5789 )
        if @state.backtracking == 0

          tree_for_LPAREN964 = @adaptor.create_with_payload( __LPAREN964__ )
          @adaptor.add_child( root_0, tree_for_LPAREN964 )

        end
        @state.following.push( TOKENS_FOLLOWING_subquery_IN_cursor_expression_5791 )
        subquery965 = subquery
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, subquery965.tree )
        end
        __RPAREN966__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_cursor_expression_5793 )
        if @state.backtracking == 0

          tree_for_RPAREN966 = @adaptor.create_with_payload( __RPAREN966__ )
          @adaptor.add_child( root_0, tree_for_RPAREN966 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 168 )
        memoize( __method__, cursor_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    DatetimeExpressionReturnValue = define_return_scope 

    # 
    # parser rule datetime_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 914:1: datetime_expression : sql_expression 'AT' ( keyLOCAL | keyTIME keyZONE ( keyDBTIMEZONE | keySESSIONTIMEZONE | sql_expression ) ) ;
    # 
    def datetime_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 169 )
      return_value = DatetimeExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      datetime_expression_start_index = @input.index

      root_0 = nil
      string_literal968 = nil
      sql_expression967 = nil
      keyLOCAL969 = nil
      keyTIME970 = nil
      keyZONE971 = nil
      keyDBTIMEZONE972 = nil
      keySESSIONTIMEZONE973 = nil
      sql_expression974 = nil

      tree_for_string_literal968 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 915:4: sql_expression 'AT' ( keyLOCAL | keyTIME keyZONE ( keyDBTIMEZONE | keySESSIONTIMEZONE | sql_expression ) )
        @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_datetime_expression_5803 )
        sql_expression967 = sql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_expression967.tree )
        end
        string_literal968 = match( T__143, TOKENS_FOLLOWING_T__143_IN_datetime_expression_5805 )
        if @state.backtracking == 0

          tree_for_string_literal968 = @adaptor.create_with_payload( string_literal968 )
          @adaptor.add_child( root_0, tree_for_string_literal968 )

        end
        # at line 916:3: ( keyLOCAL | keyTIME keyZONE ( keyDBTIMEZONE | keySESSIONTIMEZONE | sql_expression ) )
        alt_250 = 2
        look_250_0 = @input.peek( 1 )

        if ( look_250_0 == ID )
          look_250_1 = @input.peek( 2 )

          if ( look_250_1 == EOF )
            alt_250 = 1
          elsif ( look_250_1 == ID )
            alt_250 = 2
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 250, 1 )
          end
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 250, 0 )
        end
        case alt_250
        when 1
          # at line 916:5: keyLOCAL
          @state.following.push( TOKENS_FOLLOWING_keyLOCAL_IN_datetime_expression_5811 )
          keyLOCAL969 = keyLOCAL
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyLOCAL969.tree )
          end

        when 2
          # at line 917:5: keyTIME keyZONE ( keyDBTIMEZONE | keySESSIONTIMEZONE | sql_expression )
          @state.following.push( TOKENS_FOLLOWING_keyTIME_IN_datetime_expression_5817 )
          keyTIME970 = keyTIME
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyTIME970.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_keyZONE_IN_datetime_expression_5819 )
          keyZONE971 = keyZONE
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyZONE971.tree )
          end
          # at line 917:21: ( keyDBTIMEZONE | keySESSIONTIMEZONE | sql_expression )
          alt_249 = 3
          look_249_0 = @input.peek( 1 )

          if ( look_249_0 == ID )
            look_249_1 = @input.peek( 2 )

            if ( ( syntactic_predicate?( :synpred409_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("DBTIMEZONE") ) ) )
              alt_249 = 1
            elsif ( ( syntactic_predicate?( :synpred410_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("SESSIONTIMEZONE") ) ) )
              alt_249 = 2
            elsif ( true )
              alt_249 = 3
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 249, 1 )
            end
          elsif ( look_249_0 == LPAREN || look_249_0.between?( PLUS, QUOTED_STRING ) || look_249_0 == DOUBLEQUOTED_STRING || look_249_0 == T__58 || look_249_0 == T__100 || look_249_0.between?( T__110, T__111 ) || look_249_0.between?( T__116, T__117 ) || look_249_0 == T__140 || look_249_0 == T__142 )
            alt_249 = 3
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 249, 0 )
          end
          case alt_249
          when 1
            # at line 917:23: keyDBTIMEZONE
            @state.following.push( TOKENS_FOLLOWING_keyDBTIMEZONE_IN_datetime_expression_5823 )
            keyDBTIMEZONE972 = keyDBTIMEZONE
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyDBTIMEZONE972.tree )
            end

          when 2
            # at line 917:39: keySESSIONTIMEZONE
            @state.following.push( TOKENS_FOLLOWING_keySESSIONTIMEZONE_IN_datetime_expression_5827 )
            keySESSIONTIMEZONE973 = keySESSIONTIMEZONE
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keySESSIONTIMEZONE973.tree )
            end

          when 3
            # at line 917:60: sql_expression
            @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_datetime_expression_5831 )
            sql_expression974 = sql_expression
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, sql_expression974.tree )
            end

          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 169 )
        memoize( __method__, datetime_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    FunctionExpressionReturnValue = define_return_scope 

    # 
    # parser rule function_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 920:1: function_expression : ( function_call ( DOT nested_expression )? | {...}? ( keyCOUNT LPAREN ( ASTERISK | nested_expression ) RPAREN | 'DISTINCT' ( LPAREN nested_expression RPAREN | nested_expression ) ) );
    # 
    def function_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 170 )
      return_value = FunctionExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      function_expression_start_index = @input.index

      root_0 = nil
      __DOT976__ = nil
      __LPAREN979__ = nil
      __ASTERISK980__ = nil
      __RPAREN982__ = nil
      string_literal983 = nil
      __LPAREN984__ = nil
      __RPAREN986__ = nil
      function_call975 = nil
      nested_expression977 = nil
      keyCOUNT978 = nil
      nested_expression981 = nil
      nested_expression985 = nil
      nested_expression987 = nil

      tree_for_DOT976 = nil
      tree_for_LPAREN979 = nil
      tree_for_ASTERISK980 = nil
      tree_for_RPAREN982 = nil
      tree_for_string_literal983 = nil
      tree_for_LPAREN984 = nil
      tree_for_RPAREN986 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 921:2: ( function_call ( DOT nested_expression )? | {...}? ( keyCOUNT LPAREN ( ASTERISK | nested_expression ) RPAREN | 'DISTINCT' ( LPAREN nested_expression RPAREN | nested_expression ) ) )
        alt_255 = 2
        case look_255 = @input.peek( 1 )
        when ID then look_255_1 = @input.peek( 2 )

        if ( syntactic_predicate?( :synpred412_Plsql ) )
          alt_255 = 1
        elsif ( ( (  @is_sql  ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) )
          alt_255 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 255, 1 )
        end
        when DOUBLEQUOTED_STRING, T__100 then alt_255 = 1
        when T__117 then alt_255 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 255, 0 )
        end
        case alt_255
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 921:4: function_call ( DOT nested_expression )?
          @state.following.push( TOKENS_FOLLOWING_function_call_IN_function_expression_5847 )
          function_call975 = function_call
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, function_call975.tree )
          end
          # at line 921:18: ( DOT nested_expression )?
          alt_251 = 2
          look_251_0 = @input.peek( 1 )

          if ( look_251_0 == DOT )
            alt_251 = 1
          end
          case alt_251
          when 1
            # at line 921:20: DOT nested_expression
            __DOT976__ = match( DOT, TOKENS_FOLLOWING_DOT_IN_function_expression_5851 )
            if @state.backtracking == 0

              tree_for_DOT976 = @adaptor.create_with_payload( __DOT976__ )
              @adaptor.add_child( root_0, tree_for_DOT976 )

            end
            @state.following.push( TOKENS_FOLLOWING_nested_expression_IN_function_expression_5853 )
            nested_expression977 = nested_expression
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, nested_expression977.tree )
            end

          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 922:4: {...}? ( keyCOUNT LPAREN ( ASTERISK | nested_expression ) RPAREN | 'DISTINCT' ( LPAREN nested_expression RPAREN | nested_expression ) )
          unless ( (  @is_sql  ) )
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise FailedPredicate( "function_expression", " @is_sql " )
          end
          # at line 923:3: ( keyCOUNT LPAREN ( ASTERISK | nested_expression ) RPAREN | 'DISTINCT' ( LPAREN nested_expression RPAREN | nested_expression ) )
          alt_254 = 2
          look_254_0 = @input.peek( 1 )

          if ( look_254_0 == ID )
            alt_254 = 1
          elsif ( look_254_0 == T__117 )
            alt_254 = 2
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 254, 0 )
          end
          case alt_254
          when 1
            # at line 923:5: keyCOUNT LPAREN ( ASTERISK | nested_expression ) RPAREN
            @state.following.push( TOKENS_FOLLOWING_keyCOUNT_IN_function_expression_5867 )
            keyCOUNT978 = keyCOUNT
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyCOUNT978.tree )
            end
            __LPAREN979__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_function_expression_5869 )
            if @state.backtracking == 0

              tree_for_LPAREN979 = @adaptor.create_with_payload( __LPAREN979__ )
              @adaptor.add_child( root_0, tree_for_LPAREN979 )

            end
            # at line 923:21: ( ASTERISK | nested_expression )
            alt_252 = 2
            look_252_0 = @input.peek( 1 )

            if ( look_252_0 == ASTERISK )
              alt_252 = 1
            elsif ( look_252_0 == LPAREN || look_252_0.between?( PLUS, QUOTED_STRING ) || look_252_0.between?( ID, DOUBLEQUOTED_STRING ) || look_252_0.between?( T__57, T__58 ) || look_252_0 == T__100 || look_252_0.between?( T__110, T__111 ) || look_252_0.between?( T__116, T__117 ) || look_252_0 == T__140 || look_252_0 == T__142 )
              alt_252 = 2
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 252, 0 )
            end
            case alt_252
            when 1
              # at line 923:23: ASTERISK
              __ASTERISK980__ = match( ASTERISK, TOKENS_FOLLOWING_ASTERISK_IN_function_expression_5873 )
              if @state.backtracking == 0

                tree_for_ASTERISK980 = @adaptor.create_with_payload( __ASTERISK980__ )
                @adaptor.add_child( root_0, tree_for_ASTERISK980 )

              end

            when 2
              # at line 923:34: nested_expression
              @state.following.push( TOKENS_FOLLOWING_nested_expression_IN_function_expression_5877 )
              nested_expression981 = nested_expression
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, nested_expression981.tree )
              end

            end
            __RPAREN982__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_function_expression_5881 )
            if @state.backtracking == 0

              tree_for_RPAREN982 = @adaptor.create_with_payload( __RPAREN982__ )
              @adaptor.add_child( root_0, tree_for_RPAREN982 )

            end

          when 2
            # at line 924:5: 'DISTINCT' ( LPAREN nested_expression RPAREN | nested_expression )
            string_literal983 = match( T__117, TOKENS_FOLLOWING_T__117_IN_function_expression_5887 )
            if @state.backtracking == 0

              tree_for_string_literal983 = @adaptor.create_with_payload( string_literal983 )
              @adaptor.add_child( root_0, tree_for_string_literal983 )

            end
            # at line 924:16: ( LPAREN nested_expression RPAREN | nested_expression )
            alt_253 = 2
            alt_253 = @dfa253.predict( @input )
            case alt_253
            when 1
              # at line 924:18: LPAREN nested_expression RPAREN
              __LPAREN984__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_function_expression_5891 )
              if @state.backtracking == 0

                tree_for_LPAREN984 = @adaptor.create_with_payload( __LPAREN984__ )
                @adaptor.add_child( root_0, tree_for_LPAREN984 )

              end
              @state.following.push( TOKENS_FOLLOWING_nested_expression_IN_function_expression_5893 )
              nested_expression985 = nested_expression
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, nested_expression985.tree )
              end
              __RPAREN986__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_function_expression_5895 )
              if @state.backtracking == 0

                tree_for_RPAREN986 = @adaptor.create_with_payload( __RPAREN986__ )
                @adaptor.add_child( root_0, tree_for_RPAREN986 )

              end

            when 2
              # at line 924:52: nested_expression
              @state.following.push( TOKENS_FOLLOWING_nested_expression_IN_function_expression_5899 )
              nested_expression987 = nested_expression
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, nested_expression987.tree )
              end

            end

          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 170 )
        memoize( __method__, function_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SpecialExpressionReturnValue = define_return_scope 

    # 
    # parser rule special_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 927:1: special_expression : {...}? ( keyCOUNT LPAREN ( ASTERISK | nested_expression ) RPAREN | 'DISTINCT' LPAREN nested_expression RPAREN ) ;
    # 
    def special_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 171 )
      return_value = SpecialExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      special_expression_start_index = @input.index

      root_0 = nil
      __LPAREN989__ = nil
      __ASTERISK990__ = nil
      __RPAREN992__ = nil
      string_literal993 = nil
      __LPAREN994__ = nil
      __RPAREN996__ = nil
      keyCOUNT988 = nil
      nested_expression991 = nil
      nested_expression995 = nil

      tree_for_LPAREN989 = nil
      tree_for_ASTERISK990 = nil
      tree_for_RPAREN992 = nil
      tree_for_string_literal993 = nil
      tree_for_LPAREN994 = nil
      tree_for_RPAREN996 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 928:4: {...}? ( keyCOUNT LPAREN ( ASTERISK | nested_expression ) RPAREN | 'DISTINCT' LPAREN nested_expression RPAREN )
        unless ( (  @is_sql  ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "special_expression", " @is_sql " )
        end
        # at line 929:3: ( keyCOUNT LPAREN ( ASTERISK | nested_expression ) RPAREN | 'DISTINCT' LPAREN nested_expression RPAREN )
        alt_257 = 2
        look_257_0 = @input.peek( 1 )

        if ( look_257_0 == ID )
          alt_257 = 1
        elsif ( look_257_0 == T__117 )
          alt_257 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 257, 0 )
        end
        case alt_257
        when 1
          # at line 929:5: keyCOUNT LPAREN ( ASTERISK | nested_expression ) RPAREN
          @state.following.push( TOKENS_FOLLOWING_keyCOUNT_IN_special_expression_5921 )
          keyCOUNT988 = keyCOUNT
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyCOUNT988.tree )
          end
          __LPAREN989__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_special_expression_5923 )
          if @state.backtracking == 0

            tree_for_LPAREN989 = @adaptor.create_with_payload( __LPAREN989__ )
            @adaptor.add_child( root_0, tree_for_LPAREN989 )

          end
          # at line 929:21: ( ASTERISK | nested_expression )
          alt_256 = 2
          look_256_0 = @input.peek( 1 )

          if ( look_256_0 == ASTERISK )
            alt_256 = 1
          elsif ( look_256_0 == LPAREN || look_256_0.between?( PLUS, QUOTED_STRING ) || look_256_0.between?( ID, DOUBLEQUOTED_STRING ) || look_256_0.between?( T__57, T__58 ) || look_256_0 == T__100 || look_256_0.between?( T__110, T__111 ) || look_256_0.between?( T__116, T__117 ) || look_256_0 == T__140 || look_256_0 == T__142 )
            alt_256 = 2
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 256, 0 )
          end
          case alt_256
          when 1
            # at line 929:23: ASTERISK
            __ASTERISK990__ = match( ASTERISK, TOKENS_FOLLOWING_ASTERISK_IN_special_expression_5927 )
            if @state.backtracking == 0

              tree_for_ASTERISK990 = @adaptor.create_with_payload( __ASTERISK990__ )
              @adaptor.add_child( root_0, tree_for_ASTERISK990 )

            end

          when 2
            # at line 929:34: nested_expression
            @state.following.push( TOKENS_FOLLOWING_nested_expression_IN_special_expression_5931 )
            nested_expression991 = nested_expression
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, nested_expression991.tree )
            end

          end
          __RPAREN992__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_special_expression_5935 )
          if @state.backtracking == 0

            tree_for_RPAREN992 = @adaptor.create_with_payload( __RPAREN992__ )
            @adaptor.add_child( root_0, tree_for_RPAREN992 )

          end

        when 2
          # at line 930:5: 'DISTINCT' LPAREN nested_expression RPAREN
          string_literal993 = match( T__117, TOKENS_FOLLOWING_T__117_IN_special_expression_5941 )
          if @state.backtracking == 0

            tree_for_string_literal993 = @adaptor.create_with_payload( string_literal993 )
            @adaptor.add_child( root_0, tree_for_string_literal993 )

          end
          __LPAREN994__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_special_expression_5943 )
          if @state.backtracking == 0

            tree_for_LPAREN994 = @adaptor.create_with_payload( __LPAREN994__ )
            @adaptor.add_child( root_0, tree_for_LPAREN994 )

          end
          @state.following.push( TOKENS_FOLLOWING_nested_expression_IN_special_expression_5945 )
          nested_expression995 = nested_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, nested_expression995.tree )
          end
          __RPAREN996__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_special_expression_5947 )
          if @state.backtracking == 0

            tree_for_RPAREN996 = @adaptor.create_with_payload( __RPAREN996__ )
            @adaptor.add_child( root_0, tree_for_RPAREN996 )

          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 171 )
        memoize( __method__, special_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    IntervalExpressionReturnValue = define_return_scope 

    # 
    # parser rule interval_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 933:1: interval_expression : sql_expression ( keyDAY ( LPAREN leading_field_precision RPAREN )? 'TO' keySECOND ( LPAREN fractional_second_precision RPAREN )? | keyYEAR ( LPAREN leading_field_precision RPAREN )? 'TO' keyMONTH ) ;
    # 
    def interval_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 172 )
      return_value = IntervalExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      interval_expression_start_index = @input.index

      root_0 = nil
      __LPAREN999__ = nil
      __RPAREN1001__ = nil
      string_literal1002 = nil
      __LPAREN1004__ = nil
      __RPAREN1006__ = nil
      __LPAREN1008__ = nil
      __RPAREN1010__ = nil
      string_literal1011 = nil
      sql_expression997 = nil
      keyDAY998 = nil
      leading_field_precision1000 = nil
      keySECOND1003 = nil
      fractional_second_precision1005 = nil
      keyYEAR1007 = nil
      leading_field_precision1009 = nil
      keyMONTH1012 = nil

      tree_for_LPAREN999 = nil
      tree_for_RPAREN1001 = nil
      tree_for_string_literal1002 = nil
      tree_for_LPAREN1004 = nil
      tree_for_RPAREN1006 = nil
      tree_for_LPAREN1008 = nil
      tree_for_RPAREN1010 = nil
      tree_for_string_literal1011 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 934:4: sql_expression ( keyDAY ( LPAREN leading_field_precision RPAREN )? 'TO' keySECOND ( LPAREN fractional_second_precision RPAREN )? | keyYEAR ( LPAREN leading_field_precision RPAREN )? 'TO' keyMONTH )
        @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_interval_expression_5961 )
        sql_expression997 = sql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_expression997.tree )
        end
        # at line 935:3: ( keyDAY ( LPAREN leading_field_precision RPAREN )? 'TO' keySECOND ( LPAREN fractional_second_precision RPAREN )? | keyYEAR ( LPAREN leading_field_precision RPAREN )? 'TO' keyMONTH )
        alt_261 = 2
        look_261_0 = @input.peek( 1 )

        if ( look_261_0 == ID )
          look_261_1 = @input.peek( 2 )

          if ( look_261_1 == LPAREN )
            look_261_2 = @input.peek( 3 )

            if ( look_261_2 == NUMBER )
              look_261_4 = @input.peek( 4 )

              if ( look_261_4 == RPAREN )
                look_261_6 = @input.peek( 5 )

                if ( look_261_6 == T__77 )
                  look_261_3 = @input.peek( 6 )

                  if ( look_261_3 == ID )
                    look_261_5 = @input.peek( 7 )

                    if ( ( syntactic_predicate?( :synpred420_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("DAY") ) ) )
                      alt_261 = 1
                    elsif ( ( self.input.look(1).text.upcase == ("YEAR") ) )
                      alt_261 = 2
                    else
                      @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

                      raise NoViableAlternative( "", 261, 5 )
                    end
                  else
                    @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

                    raise NoViableAlternative( "", 261, 3 )
                  end
                else
                  @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

                  raise NoViableAlternative( "", 261, 6 )
                end
              else
                @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

                raise NoViableAlternative( "", 261, 4 )
              end
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 261, 2 )
            end
          elsif ( look_261_1 == T__77 )
            look_261_3 = @input.peek( 3 )

            if ( look_261_3 == ID )
              look_261_5 = @input.peek( 4 )

              if ( ( syntactic_predicate?( :synpred420_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("DAY") ) ) )
                alt_261 = 1
              elsif ( ( self.input.look(1).text.upcase == ("YEAR") ) )
                alt_261 = 2
              else
                @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

                raise NoViableAlternative( "", 261, 5 )
              end
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 261, 3 )
            end
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 261, 1 )
          end
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 261, 0 )
        end
        case alt_261
        when 1
          # at line 935:5: keyDAY ( LPAREN leading_field_precision RPAREN )? 'TO' keySECOND ( LPAREN fractional_second_precision RPAREN )?
          @state.following.push( TOKENS_FOLLOWING_keyDAY_IN_interval_expression_5967 )
          keyDAY998 = keyDAY
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyDAY998.tree )
          end
          # at line 935:12: ( LPAREN leading_field_precision RPAREN )?
          alt_258 = 2
          look_258_0 = @input.peek( 1 )

          if ( look_258_0 == LPAREN )
            alt_258 = 1
          end
          case alt_258
          when 1
            # at line 935:14: LPAREN leading_field_precision RPAREN
            __LPAREN999__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_interval_expression_5971 )
            if @state.backtracking == 0

              tree_for_LPAREN999 = @adaptor.create_with_payload( __LPAREN999__ )
              @adaptor.add_child( root_0, tree_for_LPAREN999 )

            end
            @state.following.push( TOKENS_FOLLOWING_leading_field_precision_IN_interval_expression_5973 )
            leading_field_precision1000 = leading_field_precision
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, leading_field_precision1000.tree )
            end
            __RPAREN1001__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_interval_expression_5975 )
            if @state.backtracking == 0

              tree_for_RPAREN1001 = @adaptor.create_with_payload( __RPAREN1001__ )
              @adaptor.add_child( root_0, tree_for_RPAREN1001 )

            end

          end
          string_literal1002 = match( T__77, TOKENS_FOLLOWING_T__77_IN_interval_expression_5980 )
          if @state.backtracking == 0

            tree_for_string_literal1002 = @adaptor.create_with_payload( string_literal1002 )
            @adaptor.add_child( root_0, tree_for_string_literal1002 )

          end
          @state.following.push( TOKENS_FOLLOWING_keySECOND_IN_interval_expression_5982 )
          keySECOND1003 = keySECOND
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keySECOND1003.tree )
          end
          # at line 935:70: ( LPAREN fractional_second_precision RPAREN )?
          alt_259 = 2
          look_259_0 = @input.peek( 1 )

          if ( look_259_0 == LPAREN )
            alt_259 = 1
          end
          case alt_259
          when 1
            # at line 935:72: LPAREN fractional_second_precision RPAREN
            __LPAREN1004__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_interval_expression_5986 )
            if @state.backtracking == 0

              tree_for_LPAREN1004 = @adaptor.create_with_payload( __LPAREN1004__ )
              @adaptor.add_child( root_0, tree_for_LPAREN1004 )

            end
            @state.following.push( TOKENS_FOLLOWING_fractional_second_precision_IN_interval_expression_5988 )
            fractional_second_precision1005 = fractional_second_precision
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, fractional_second_precision1005.tree )
            end
            __RPAREN1006__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_interval_expression_5990 )
            if @state.backtracking == 0

              tree_for_RPAREN1006 = @adaptor.create_with_payload( __RPAREN1006__ )
              @adaptor.add_child( root_0, tree_for_RPAREN1006 )

            end

          end

        when 2
          # at line 936:5: keyYEAR ( LPAREN leading_field_precision RPAREN )? 'TO' keyMONTH
          @state.following.push( TOKENS_FOLLOWING_keyYEAR_IN_interval_expression_5999 )
          keyYEAR1007 = keyYEAR
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyYEAR1007.tree )
          end
          # at line 936:13: ( LPAREN leading_field_precision RPAREN )?
          alt_260 = 2
          look_260_0 = @input.peek( 1 )

          if ( look_260_0 == LPAREN )
            alt_260 = 1
          end
          case alt_260
          when 1
            # at line 936:15: LPAREN leading_field_precision RPAREN
            __LPAREN1008__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_interval_expression_6003 )
            if @state.backtracking == 0

              tree_for_LPAREN1008 = @adaptor.create_with_payload( __LPAREN1008__ )
              @adaptor.add_child( root_0, tree_for_LPAREN1008 )

            end
            @state.following.push( TOKENS_FOLLOWING_leading_field_precision_IN_interval_expression_6005 )
            leading_field_precision1009 = leading_field_precision
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, leading_field_precision1009.tree )
            end
            __RPAREN1010__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_interval_expression_6007 )
            if @state.backtracking == 0

              tree_for_RPAREN1010 = @adaptor.create_with_payload( __RPAREN1010__ )
              @adaptor.add_child( root_0, tree_for_RPAREN1010 )

            end

          end
          string_literal1011 = match( T__77, TOKENS_FOLLOWING_T__77_IN_interval_expression_6012 )
          if @state.backtracking == 0

            tree_for_string_literal1011 = @adaptor.create_with_payload( string_literal1011 )
            @adaptor.add_child( root_0, tree_for_string_literal1011 )

          end
          @state.following.push( TOKENS_FOLLOWING_keyMONTH_IN_interval_expression_6014 )
          keyMONTH1012 = keyMONTH
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyMONTH1012.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 172 )
        memoize( __method__, interval_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    LeadingFieldPrecisionReturnValue = define_return_scope 

    # 
    # parser rule leading_field_precision
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 939:1: leading_field_precision : integer ;
    # 
    def leading_field_precision
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 173 )
      return_value = LeadingFieldPrecisionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      leading_field_precision_start_index = @input.index

      root_0 = nil
      integer1013 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 940:4: integer
        @state.following.push( TOKENS_FOLLOWING_integer_IN_leading_field_precision_6028 )
        integer1013 = integer
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, integer1013.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 173 )
        memoize( __method__, leading_field_precision_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    FractionalSecondPrecisionReturnValue = define_return_scope 

    # 
    # parser rule fractional_second_precision
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 942:1: fractional_second_precision : integer ;
    # 
    def fractional_second_precision
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 174 )
      return_value = FractionalSecondPrecisionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      fractional_second_precision_start_index = @input.index

      root_0 = nil
      integer1014 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 943:4: integer
        @state.following.push( TOKENS_FOLLOWING_integer_IN_fractional_second_precision_6039 )
        integer1014 = integer
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, integer1014.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 174 )
        memoize( __method__, fractional_second_precision_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ObjectAccessExpressionReturnValue = define_return_scope 

    # 
    # parser rule object_access_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 945:1: object_access_expression : ;
    # 
    def object_access_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 175 )
      return_value = ObjectAccessExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      object_access_expression_start_index = @input.index

      root_0 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 947:2: 
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 175 )
        memoize( __method__, object_access_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ScalarSubqueryExpressionReturnValue = define_return_scope 

    # 
    # parser rule scalar_subquery_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 948:1: scalar_subquery_expression : ;
    # 
    def scalar_subquery_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 176 )
      return_value = ScalarSubqueryExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      scalar_subquery_expression_start_index = @input.index

      root_0 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 950:2: 
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 176 )
        memoize( __method__, scalar_subquery_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ModelExpressionReturnValue = define_return_scope 

    # 
    # parser rule model_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 951:1: model_expression : ;
    # 
    def model_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 177 )
      return_value = ModelExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      model_expression_start_index = @input.index

      root_0 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 953:2: 
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 177 )
        memoize( __method__, model_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    TypeConstructorExpressionReturnValue = define_return_scope 

    # 
    # parser rule type_constructor_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 954:1: type_constructor_expression : ;
    # 
    def type_constructor_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 178 )
      return_value = TypeConstructorExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      type_constructor_expression_start_index = @input.index

      root_0 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 956:2: 
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 178 )
        memoize( __method__, type_constructor_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    VariableExpressionReturnValue = define_return_scope 

    # 
    # parser rule variable_expression
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 957:1: variable_expression : ;
    # 
    def variable_expression
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 179 )
      return_value = VariableExpressionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      variable_expression_start_index = @input.index

      root_0 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 959:2: 
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 179 )
        memoize( __method__, variable_expression_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SequenceNameReturnValue = define_return_scope 

    # 
    # parser rule sequence_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 960:1: sequence_name : identifier ;
    # 
    def sequence_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 180 )
      return_value = SequenceNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      sequence_name_start_index = @input.index

      root_0 = nil
      identifier1015 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 961:4: identifier
        @state.following.push( TOKENS_FOLLOWING_identifier_IN_sequence_name_6090 )
        identifier1015 = identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, identifier1015.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 180 )
        memoize( __method__, sequence_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    IntegerReturnValue = define_return_scope 

    # 
    # parser rule integer
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 963:1: integer : NUMBER ;
    # 
    def integer
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 181 )
      return_value = IntegerReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      integer_start_index = @input.index

      root_0 = nil
      __NUMBER1016__ = nil

      tree_for_NUMBER1016 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 964:4: NUMBER
        __NUMBER1016__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_integer_6100 )
        if @state.backtracking == 0

          tree_for_NUMBER1016 = @adaptor.create_with_payload( __NUMBER1016__ )
          @adaptor.add_child( root_0, tree_for_NUMBER1016 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 181 )
        memoize( __method__, integer_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ObjaliasReturnValue = define_return_scope :value

    # 
    # parser rule objalias
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 968:1: objalias returns [ value ] : ( 'AS' )? sql_identifier ;
    # 
    def objalias
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 182 )
      return_value = ObjaliasReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      objalias_start_index = @input.index

      root_0 = nil
      string_literal1017 = nil
      sql_identifier1018 = nil

      tree_for_string_literal1017 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 969:4: ( 'AS' )? sql_identifier
        # at line 969:4: ( 'AS' )?
        alt_262 = 2
        look_262_0 = @input.peek( 1 )

        if ( look_262_0 == T__53 )
          alt_262 = 1
        end
        case alt_262
        when 1
          # at line 969:6: 'AS'
          string_literal1017 = match( T__53, TOKENS_FOLLOWING_T__53_IN_objalias_6118 )
          if @state.backtracking == 0

            tree_for_string_literal1017 = @adaptor.create_with_payload( string_literal1017 )
            @adaptor.add_child( root_0, tree_for_string_literal1017 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_sql_identifier_IN_objalias_6123 )
        sql_identifier1018 = sql_identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_identifier1018.tree )
        end
        # syntactic predicate action gate test
        if @state.backtracking == 0
          # --> action
           return_value.value = ( sql_identifier1018 && @input.to_s( sql_identifier1018.start, sql_identifier1018.stop ) ) 
          # <-- action
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 182 )
        memoize( __method__, objalias_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ColumnSpecsReturnValue = define_return_scope 

    # 
    # parser rule column_specs
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 972:1: column_specs : column_spec ( COMMA column_spec )* ;
    # 
    def column_specs
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 183 )
      return_value = ColumnSpecsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      column_specs_start_index = @input.index

      root_0 = nil
      __COMMA1020__ = nil
      column_spec1019 = nil
      column_spec1021 = nil

      tree_for_COMMA1020 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 973:4: column_spec ( COMMA column_spec )*
        @state.following.push( TOKENS_FOLLOWING_column_spec_IN_column_specs_6136 )
        column_spec1019 = column_spec
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, column_spec1019.tree )
        end
        # at line 973:16: ( COMMA column_spec )*
        while true # decision 263
          alt_263 = 2
          look_263_0 = @input.peek( 1 )

          if ( look_263_0 == COMMA )
            alt_263 = 1

          end
          case alt_263
          when 1
            # at line 973:18: COMMA column_spec
            __COMMA1020__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_column_specs_6140 )
            if @state.backtracking == 0

              tree_for_COMMA1020 = @adaptor.create_with_payload( __COMMA1020__ )
              @adaptor.add_child( root_0, tree_for_COMMA1020 )

            end
            @state.following.push( TOKENS_FOLLOWING_column_spec_IN_column_specs_6142 )
            column_spec1021 = column_spec
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, column_spec1021.tree )
            end

          else
            break # out of loop for decision 263
          end
        end # loop for decision 263
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 183 )
        memoize( __method__, column_specs_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ColumnSpecReturnValue = define_return_scope 

    # 
    # parser rule column_spec
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 976:1: column_spec : sql_identifier ( DOT sql_identifier ( DOT sql_identifier )? )? ;
    # 
    def column_spec
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 184 )
      return_value = ColumnSpecReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      column_spec_start_index = @input.index

      root_0 = nil
      __DOT1023__ = nil
      __DOT1025__ = nil
      sql_identifier1022 = nil
      sql_identifier1024 = nil
      sql_identifier1026 = nil

      tree_for_DOT1023 = nil
      tree_for_DOT1025 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 977:4: sql_identifier ( DOT sql_identifier ( DOT sql_identifier )? )?
        @state.following.push( TOKENS_FOLLOWING_sql_identifier_IN_column_spec_6156 )
        sql_identifier1022 = sql_identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_identifier1022.tree )
        end
        # at line 977:19: ( DOT sql_identifier ( DOT sql_identifier )? )?
        alt_265 = 2
        look_265_0 = @input.peek( 1 )

        if ( look_265_0 == DOT )
          look_265_1 = @input.peek( 2 )

          if ( look_265_1.between?( ID, DOUBLEQUOTED_STRING ) || look_265_1 == T__100 )
            alt_265 = 1
          end
        end
        case alt_265
        when 1
          # at line 977:21: DOT sql_identifier ( DOT sql_identifier )?
          __DOT1023__ = match( DOT, TOKENS_FOLLOWING_DOT_IN_column_spec_6160 )
          if @state.backtracking == 0

            tree_for_DOT1023 = @adaptor.create_with_payload( __DOT1023__ )
            @adaptor.add_child( root_0, tree_for_DOT1023 )

          end
          @state.following.push( TOKENS_FOLLOWING_sql_identifier_IN_column_spec_6162 )
          sql_identifier1024 = sql_identifier
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_identifier1024.tree )
          end
          # at line 977:40: ( DOT sql_identifier )?
          alt_264 = 2
          look_264_0 = @input.peek( 1 )

          if ( look_264_0 == DOT )
            look_264_1 = @input.peek( 2 )

            if ( look_264_1.between?( ID, DOUBLEQUOTED_STRING ) || look_264_1 == T__100 )
              alt_264 = 1
            end
          end
          case alt_264
          when 1
            # at line 977:42: DOT sql_identifier
            __DOT1025__ = match( DOT, TOKENS_FOLLOWING_DOT_IN_column_spec_6166 )
            if @state.backtracking == 0

              tree_for_DOT1025 = @adaptor.create_with_payload( __DOT1025__ )
              @adaptor.add_child( root_0, tree_for_DOT1025 )

            end
            @state.following.push( TOKENS_FOLLOWING_sql_identifier_IN_column_spec_6168 )
            sql_identifier1026 = sql_identifier
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, sql_identifier1026.tree )
            end

          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 184 )
        memoize( __method__, column_spec_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ColumnNameReturnValue = define_return_scope 

    # 
    # parser rule column_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 980:1: column_name : sql_identifier ;
    # 
    def column_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 185 )
      return_value = ColumnNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      column_name_start_index = @input.index

      root_0 = nil
      sql_identifier1027 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 981:4: sql_identifier
        @state.following.push( TOKENS_FOLLOWING_sql_identifier_IN_column_name_6185 )
        sql_identifier1027 = sql_identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_identifier1027.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 185 )
        memoize( __method__, column_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    NestedTableReturnValue = define_return_scope 

    # 
    # parser rule nested_table
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 983:1: nested_table : sql_identifier ;
    # 
    def nested_table
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 186 )
      return_value = NestedTableReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      nested_table_start_index = @input.index

      root_0 = nil
      sql_identifier1028 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 984:4: sql_identifier
        @state.following.push( TOKENS_FOLLOWING_sql_identifier_IN_nested_table_6195 )
        sql_identifier1028 = sql_identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_identifier1028.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 186 )
        memoize( __method__, nested_table_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    NestedTableColumnNameReturnValue = define_return_scope 

    # 
    # parser rule nested_table_column_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 986:1: nested_table_column_name : ( schema_name DOT )? table_name DOT nested_table DOT column_name ;
    # 
    def nested_table_column_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 187 )
      return_value = NestedTableColumnNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      nested_table_column_name_start_index = @input.index

      root_0 = nil
      __DOT1030__ = nil
      __DOT1032__ = nil
      __DOT1034__ = nil
      schema_name1029 = nil
      table_name1031 = nil
      nested_table1033 = nil
      column_name1035 = nil

      tree_for_DOT1030 = nil
      tree_for_DOT1032 = nil
      tree_for_DOT1034 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 987:4: ( schema_name DOT )? table_name DOT nested_table DOT column_name
        # at line 987:4: ( schema_name DOT )?
        alt_266 = 2
        alt_266 = @dfa266.predict( @input )
        case alt_266
        when 1
          # at line 987:6: schema_name DOT
          @state.following.push( TOKENS_FOLLOWING_schema_name_IN_nested_table_column_name_6207 )
          schema_name1029 = schema_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, schema_name1029.tree )
          end
          __DOT1030__ = match( DOT, TOKENS_FOLLOWING_DOT_IN_nested_table_column_name_6209 )
          if @state.backtracking == 0

            tree_for_DOT1030 = @adaptor.create_with_payload( __DOT1030__ )
            @adaptor.add_child( root_0, tree_for_DOT1030 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_table_name_IN_nested_table_column_name_6214 )
        table_name1031 = table_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, table_name1031.tree )
        end
        __DOT1032__ = match( DOT, TOKENS_FOLLOWING_DOT_IN_nested_table_column_name_6216 )
        if @state.backtracking == 0

          tree_for_DOT1032 = @adaptor.create_with_payload( __DOT1032__ )
          @adaptor.add_child( root_0, tree_for_DOT1032 )

        end
        @state.following.push( TOKENS_FOLLOWING_nested_table_IN_nested_table_column_name_6218 )
        nested_table1033 = nested_table
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, nested_table1033.tree )
        end
        __DOT1034__ = match( DOT, TOKENS_FOLLOWING_DOT_IN_nested_table_column_name_6220 )
        if @state.backtracking == 0

          tree_for_DOT1034 = @adaptor.create_with_payload( __DOT1034__ )
          @adaptor.add_child( root_0, tree_for_DOT1034 )

        end
        @state.following.push( TOKENS_FOLLOWING_column_name_IN_nested_table_column_name_6222 )
        column_name1035 = column_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, column_name1035.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 187 )
        memoize( __method__, nested_table_column_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    UserDefinedFunctionReturnValue = define_return_scope 

    # 
    # parser rule user_defined_function
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 990:1: user_defined_function : sql_identifier ( DOT sql_identifier )* ( DOT ( 'EXISTS' | 'PRIOR' | 'DELETE' ) )? ;
    # 
    def user_defined_function
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 188 )
      return_value = UserDefinedFunctionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      user_defined_function_start_index = @input.index

      root_0 = nil
      __DOT1037__ = nil
      __DOT1039__ = nil
      set1040 = nil
      sql_identifier1036 = nil
      sql_identifier1038 = nil

      tree_for_DOT1037 = nil
      tree_for_DOT1039 = nil
      tree_for_set1040 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 991:4: sql_identifier ( DOT sql_identifier )* ( DOT ( 'EXISTS' | 'PRIOR' | 'DELETE' ) )?
        @state.following.push( TOKENS_FOLLOWING_sql_identifier_IN_user_defined_function_6233 )
        sql_identifier1036 = sql_identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_identifier1036.tree )
        end
        # at line 991:19: ( DOT sql_identifier )*
        while true # decision 267
          alt_267 = 2
          look_267_0 = @input.peek( 1 )

          if ( look_267_0 == DOT )
            case look_267 = @input.peek( 2 )
            when ID then look_267_3 = @input.peek( 3 )

            if ( syntactic_predicate?( :synpred427_Plsql ) )
              alt_267 = 1

            end
            when T__100 then look_267_4 = @input.peek( 3 )

            if ( syntactic_predicate?( :synpred427_Plsql ) )
              alt_267 = 1

            end
            when DOUBLEQUOTED_STRING then look_267_5 = @input.peek( 3 )

            if ( syntactic_predicate?( :synpred427_Plsql ) )
              alt_267 = 1

            end
            end

          end
          case alt_267
          when 1
            # at line 991:21: DOT sql_identifier
            __DOT1037__ = match( DOT, TOKENS_FOLLOWING_DOT_IN_user_defined_function_6237 )
            if @state.backtracking == 0

              tree_for_DOT1037 = @adaptor.create_with_payload( __DOT1037__ )
              @adaptor.add_child( root_0, tree_for_DOT1037 )

            end
            @state.following.push( TOKENS_FOLLOWING_sql_identifier_IN_user_defined_function_6239 )
            sql_identifier1038 = sql_identifier
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, sql_identifier1038.tree )
            end

          else
            break # out of loop for decision 267
          end
        end # loop for decision 267
        # at line 991:43: ( DOT ( 'EXISTS' | 'PRIOR' | 'DELETE' ) )?
        alt_268 = 2
        look_268_0 = @input.peek( 1 )

        if ( look_268_0 == DOT )
          look_268_1 = @input.peek( 2 )

          if ( look_268_1 == T__141 || look_268_1.between?( T__144, T__145 ) )
            alt_268 = 1
          end
        end
        case alt_268
        when 1
          # at line 991:45: DOT ( 'EXISTS' | 'PRIOR' | 'DELETE' )
          __DOT1039__ = match( DOT, TOKENS_FOLLOWING_DOT_IN_user_defined_function_6246 )
          if @state.backtracking == 0

            tree_for_DOT1039 = @adaptor.create_with_payload( __DOT1039__ )
            @adaptor.add_child( root_0, tree_for_DOT1039 )

          end
          set1040 = @input.look
          if @input.peek(1) == T__141 || @input.peek( 1 ).between?( T__144, T__145 )
            @input.consume
            if @state.backtracking == 0
              @adaptor.add_child( root_0, @adaptor.create_with_payload( set1040 ) )
            end
            @state.error_recovery = false
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            mse = MismatchedSet( nil )
            raise mse
          end



        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 188 )
        memoize( __method__, user_defined_function_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SelectedTableReturnValue = define_return_scope 

    # 
    # parser rule selected_table
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 994:1: selected_table : ( table_spec | ( 'TABLE' | keyTHE )? subquery ) ( objalias )? ;
    # 
    def selected_table
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 189 )
      return_value = SelectedTableReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      selected_table_start_index = @input.index

      root_0 = nil
      string_literal1042 = nil
      table_spec1041 = nil
      keyTHE1043 = nil
      subquery1044 = nil
      objalias1045 = nil

      tree_for_string_literal1042 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 995:4: ( table_spec | ( 'TABLE' | keyTHE )? subquery ) ( objalias )?
        # at line 995:4: ( table_spec | ( 'TABLE' | keyTHE )? subquery )
        alt_270 = 2
        case look_270 = @input.peek( 1 )
        when ID then look_270_1 = @input.peek( 2 )

        if ( syntactic_predicate?( :synpred431_Plsql ) )
          alt_270 = 1
        elsif ( ( self.input.look(1).text.upcase == ("THE") ) )
          alt_270 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 270, 1 )
        end
        when DOUBLEQUOTED_STRING, T__100 then alt_270 = 1
        when LPAREN, T__105 then alt_270 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 270, 0 )
        end
        case alt_270
        when 1
          # at line 995:6: table_spec
          @state.following.push( TOKENS_FOLLOWING_table_spec_IN_selected_table_6277 )
          table_spec1041 = table_spec
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, table_spec1041.tree )
          end

        when 2
          # at line 995:19: ( 'TABLE' | keyTHE )? subquery
          # at line 995:19: ( 'TABLE' | keyTHE )?
          alt_269 = 3
          look_269_0 = @input.peek( 1 )

          if ( look_269_0 == T__105 )
            alt_269 = 1
          elsif ( look_269_0 == ID )
            alt_269 = 2
          end
          case alt_269
          when 1
            # at line 995:21: 'TABLE'
            string_literal1042 = match( T__105, TOKENS_FOLLOWING_T__105_IN_selected_table_6283 )
            if @state.backtracking == 0

              tree_for_string_literal1042 = @adaptor.create_with_payload( string_literal1042 )
              @adaptor.add_child( root_0, tree_for_string_literal1042 )

            end

          when 2
            # at line 995:31: keyTHE
            @state.following.push( TOKENS_FOLLOWING_keyTHE_IN_selected_table_6287 )
            keyTHE1043 = keyTHE
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyTHE1043.tree )
            end

          end
          @state.following.push( TOKENS_FOLLOWING_subquery_IN_selected_table_6292 )
          subquery1044 = subquery
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, subquery1044.tree )
          end

        end
        # at line 995:52: ( objalias )?
        alt_271 = 2
        case look_271 = @input.peek( 1 )
        when T__53 then look_271_1 = @input.peek( 2 )

        if ( look_271_1.between?( ID, DOUBLEQUOTED_STRING ) )
          look_271_6 = @input.peek( 3 )

          if ( syntactic_predicate?( :synpred434_Plsql ) )
            alt_271 = 1
          end
        elsif ( look_271_1 == T__100 )
          look_271_7 = @input.peek( 3 )

          if ( syntactic_predicate?( :synpred434_Plsql ) )
            alt_271 = 1
          end
        end
        when ID then look_271_2 = @input.peek( 2 )

        if ( syntactic_predicate?( :synpred434_Plsql ) )
          alt_271 = 1
        end
        when T__100 then look_271_3 = @input.peek( 2 )

        if ( syntactic_predicate?( :synpred434_Plsql ) )
          alt_271 = 1
        end
        when DOUBLEQUOTED_STRING then look_271_5 = @input.peek( 2 )

        if ( syntactic_predicate?( :synpred434_Plsql ) )
          alt_271 = 1
        end
        end
        case alt_271
        when 1
          # at line 995:54: objalias
          @state.following.push( TOKENS_FOLLOWING_objalias_IN_selected_table_6298 )
          objalias1045 = objalias
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, objalias1045.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 189 )
        memoize( __method__, selected_table_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    TableSpecReturnValue = define_return_scope 

    # 
    # parser rule table_spec
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 998:1: table_spec : ( schema_name DOT )? table_name ( AT_SIGN link_name )? ;
    # 
    def table_spec
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 190 )
      return_value = TableSpecReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      table_spec_start_index = @input.index

      root_0 = nil
      __DOT1047__ = nil
      __AT_SIGN1049__ = nil
      schema_name1046 = nil
      table_name1048 = nil
      link_name1050 = nil

      tree_for_DOT1047 = nil
      tree_for_AT_SIGN1049 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 999:4: ( schema_name DOT )? table_name ( AT_SIGN link_name )?
        # at line 999:4: ( schema_name DOT )?
        alt_272 = 2
        look_272_0 = @input.peek( 1 )

        if ( look_272_0.between?( ID, DOUBLEQUOTED_STRING ) )
          look_272_1 = @input.peek( 2 )

          if ( look_272_1 == DOT )
            alt_272 = 1
          end
        elsif ( look_272_0 == T__100 )
          look_272_2 = @input.peek( 2 )

          if ( look_272_2 == DOT )
            alt_272 = 1
          end
        end
        case alt_272
        when 1
          # at line 999:6: schema_name DOT
          @state.following.push( TOKENS_FOLLOWING_schema_name_IN_table_spec_6314 )
          schema_name1046 = schema_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, schema_name1046.tree )
          end
          __DOT1047__ = match( DOT, TOKENS_FOLLOWING_DOT_IN_table_spec_6316 )
          if @state.backtracking == 0

            tree_for_DOT1047 = @adaptor.create_with_payload( __DOT1047__ )
            @adaptor.add_child( root_0, tree_for_DOT1047 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_table_name_IN_table_spec_6321 )
        table_name1048 = table_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, table_name1048.tree )
        end
        # at line 999:36: ( AT_SIGN link_name )?
        alt_273 = 2
        look_273_0 = @input.peek( 1 )

        if ( look_273_0 == AT_SIGN )
          alt_273 = 1
        end
        case alt_273
        when 1
          # at line 999:38: AT_SIGN link_name
          __AT_SIGN1049__ = match( AT_SIGN, TOKENS_FOLLOWING_AT_SIGN_IN_table_spec_6325 )
          if @state.backtracking == 0

            tree_for_AT_SIGN1049 = @adaptor.create_with_payload( __AT_SIGN1049__ )
            @adaptor.add_child( root_0, tree_for_AT_SIGN1049 )

          end
          @state.following.push( TOKENS_FOLLOWING_link_name_IN_table_spec_6327 )
          link_name1050 = link_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, link_name1050.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 190 )
        memoize( __method__, table_spec_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    TableAliasReturnValue = define_return_scope 

    # 
    # parser rule table_alias
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1002:1: table_alias : ( schema_name DOT )? table_name ( AT_SIGN link_name )? ( objalias )? ;
    # 
    def table_alias
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 191 )
      return_value = TableAliasReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      table_alias_start_index = @input.index

      root_0 = nil
      __DOT1052__ = nil
      __AT_SIGN1054__ = nil
      schema_name1051 = nil
      table_name1053 = nil
      link_name1055 = nil
      objalias1056 = nil

      tree_for_DOT1052 = nil
      tree_for_AT_SIGN1054 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1003:4: ( schema_name DOT )? table_name ( AT_SIGN link_name )? ( objalias )?
        # at line 1003:4: ( schema_name DOT )?
        alt_274 = 2
        look_274_0 = @input.peek( 1 )

        if ( look_274_0.between?( ID, DOUBLEQUOTED_STRING ) )
          look_274_1 = @input.peek( 2 )

          if ( look_274_1 == DOT )
            alt_274 = 1
          end
        elsif ( look_274_0 == T__100 )
          look_274_2 = @input.peek( 2 )

          if ( look_274_2 == DOT )
            alt_274 = 1
          end
        end
        case alt_274
        when 1
          # at line 1003:6: schema_name DOT
          @state.following.push( TOKENS_FOLLOWING_schema_name_IN_table_alias_6343 )
          schema_name1051 = schema_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, schema_name1051.tree )
          end
          __DOT1052__ = match( DOT, TOKENS_FOLLOWING_DOT_IN_table_alias_6345 )
          if @state.backtracking == 0

            tree_for_DOT1052 = @adaptor.create_with_payload( __DOT1052__ )
            @adaptor.add_child( root_0, tree_for_DOT1052 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_table_name_IN_table_alias_6350 )
        table_name1053 = table_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, table_name1053.tree )
        end
        # at line 1003:36: ( AT_SIGN link_name )?
        alt_275 = 2
        look_275_0 = @input.peek( 1 )

        if ( look_275_0 == AT_SIGN )
          alt_275 = 1
        end
        case alt_275
        when 1
          # at line 1003:38: AT_SIGN link_name
          __AT_SIGN1054__ = match( AT_SIGN, TOKENS_FOLLOWING_AT_SIGN_IN_table_alias_6354 )
          if @state.backtracking == 0

            tree_for_AT_SIGN1054 = @adaptor.create_with_payload( __AT_SIGN1054__ )
            @adaptor.add_child( root_0, tree_for_AT_SIGN1054 )

          end
          @state.following.push( TOKENS_FOLLOWING_link_name_IN_table_alias_6356 )
          link_name1055 = link_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, link_name1055.tree )
          end

        end
        # at line 1003:59: ( objalias )?
        alt_276 = 2
        look_276_0 = @input.peek( 1 )

        if ( look_276_0.between?( ID, DOUBLEQUOTED_STRING ) || look_276_0 == T__53 || look_276_0 == T__100 )
          alt_276 = 1
        end
        case alt_276
        when 1
          # at line 1003:61: objalias
          @state.following.push( TOKENS_FOLLOWING_objalias_IN_table_alias_6363 )
          objalias1056 = objalias
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, objalias1056.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 191 )
        memoize( __method__, table_alias_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    LinkNameReturnValue = define_return_scope 

    # 
    # parser rule link_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1006:1: link_name : sql_identifier ;
    # 
    def link_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 192 )
      return_value = LinkNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      link_name_start_index = @input.index

      root_0 = nil
      sql_identifier1057 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1007:4: sql_identifier
        @state.following.push( TOKENS_FOLLOWING_sql_identifier_IN_link_name_6377 )
        sql_identifier1057 = sql_identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_identifier1057.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 192 )
        memoize( __method__, link_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    NestedConditionReturnValue = define_return_scope 

    # 
    # parser rule nested_condition
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1009:1: nested_condition : ({...}? condition_or | {...}? expr_bool );
    # 
    def nested_condition
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 193 )
      return_value = NestedConditionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      nested_condition_start_index = @input.index

      root_0 = nil
      condition_or1058 = nil
      expr_bool1059 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 1010:2: ({...}? condition_or | {...}? expr_bool )
        alt_277 = 2
        alt_277 = @dfa277.predict( @input )
        case alt_277
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 1010:4: {...}? condition_or
          unless ( (   @is_sql  ) )
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise FailedPredicate( "nested_condition", "  @is_sql " )
          end
          @state.following.push( TOKENS_FOLLOWING_condition_or_IN_nested_condition_6389 )
          condition_or1058 = condition_or
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_or1058.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 1011:4: {...}? expr_bool
          unless ( (  !@is_sql  ) )
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise FailedPredicate( "nested_condition", " !@is_sql " )
          end
          @state.following.push( TOKENS_FOLLOWING_expr_bool_IN_nested_condition_6396 )
          expr_bool1059 = expr_bool
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, expr_bool1059.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 193 )
        memoize( __method__, nested_condition_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SqlConditionReturnValue = define_return_scope 

    # 
    # parser rule sql_condition
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1013:1: sql_condition : condition_or ;
    # 
    def sql_condition
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 194 )
      return_value = SqlConditionReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      sql_condition_start_index = @input.index

      root_0 = nil
      condition_or1060 = nil

      # - - - - @init action - - - -
       @is_sql = true; 

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1015:4: condition_or
        @state.following.push( TOKENS_FOLLOWING_condition_or_IN_sql_condition_6413 )
        condition_or1060 = condition_or
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, condition_or1060.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 194 )
        memoize( __method__, sql_condition_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionParenReturnValue = define_return_scope 

    # 
    # parser rule condition_paren
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1018:1: condition_paren : LPAREN sql_condition RPAREN ;
    # 
    def condition_paren
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 195 )
      return_value = ConditionParenReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_paren_start_index = @input.index

      root_0 = nil
      __LPAREN1061__ = nil
      __RPAREN1063__ = nil
      sql_condition1062 = nil

      tree_for_LPAREN1061 = nil
      tree_for_RPAREN1063 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1019:4: LPAREN sql_condition RPAREN
        __LPAREN1061__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_condition_paren_6424 )
        if @state.backtracking == 0

          tree_for_LPAREN1061 = @adaptor.create_with_payload( __LPAREN1061__ )
          @adaptor.add_child( root_0, tree_for_LPAREN1061 )

        end
        @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_condition_paren_6426 )
        sql_condition1062 = sql_condition
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_condition1062.tree )
        end
        __RPAREN1063__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_condition_paren_6428 )
        if @state.backtracking == 0

          tree_for_RPAREN1063 = @adaptor.create_with_payload( __RPAREN1063__ )
          @adaptor.add_child( root_0, tree_for_RPAREN1063 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 195 )
        memoize( __method__, condition_paren_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionOrReturnValue = define_return_scope 

    # 
    # parser rule condition_or
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1021:1: condition_or : condition_and ( 'OR' condition_and )* ;
    # 
    def condition_or
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 196 )
      return_value = ConditionOrReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_or_start_index = @input.index

      root_0 = nil
      string_literal1065 = nil
      condition_and1064 = nil
      condition_and1066 = nil

      tree_for_string_literal1065 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1022:4: condition_and ( 'OR' condition_and )*
        @state.following.push( TOKENS_FOLLOWING_condition_and_IN_condition_or_6438 )
        condition_and1064 = condition_and
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, condition_and1064.tree )
        end
        # at line 1022:18: ( 'OR' condition_and )*
        while true # decision 278
          alt_278 = 2
          look_278_0 = @input.peek( 1 )

          if ( look_278_0 == T__51 )
            look_278_2 = @input.peek( 2 )

            if ( syntactic_predicate?( :synpred441_Plsql ) )
              alt_278 = 1

            end

          end
          case alt_278
          when 1
            # at line 1022:20: 'OR' condition_and
            string_literal1065 = match( T__51, TOKENS_FOLLOWING_T__51_IN_condition_or_6442 )
            if @state.backtracking == 0

              tree_for_string_literal1065 = @adaptor.create_with_payload( string_literal1065 )
              @adaptor.add_child( root_0, tree_for_string_literal1065 )

            end
            @state.following.push( TOKENS_FOLLOWING_condition_and_IN_condition_or_6444 )
            condition_and1066 = condition_and
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, condition_and1066.tree )
            end

          else
            break # out of loop for decision 278
          end
        end # loop for decision 278
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 196 )
        memoize( __method__, condition_or_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionAndReturnValue = define_return_scope 

    # 
    # parser rule condition_and
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1024:1: condition_and : condition_not ( 'AND' condition_not )* ;
    # 
    def condition_and
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 197 )
      return_value = ConditionAndReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_and_start_index = @input.index

      root_0 = nil
      string_literal1068 = nil
      condition_not1067 = nil
      condition_not1069 = nil

      tree_for_string_literal1068 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1025:4: condition_not ( 'AND' condition_not )*
        @state.following.push( TOKENS_FOLLOWING_condition_not_IN_condition_and_6457 )
        condition_not1067 = condition_not
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, condition_not1067.tree )
        end
        # at line 1025:18: ( 'AND' condition_not )*
        while true # decision 279
          alt_279 = 2
          look_279_0 = @input.peek( 1 )

          if ( look_279_0 == T__138 )
            look_279_2 = @input.peek( 2 )

            if ( syntactic_predicate?( :synpred442_Plsql ) )
              alt_279 = 1

            end

          end
          case alt_279
          when 1
            # at line 1025:20: 'AND' condition_not
            string_literal1068 = match( T__138, TOKENS_FOLLOWING_T__138_IN_condition_and_6461 )
            if @state.backtracking == 0

              tree_for_string_literal1068 = @adaptor.create_with_payload( string_literal1068 )
              @adaptor.add_child( root_0, tree_for_string_literal1068 )

            end
            @state.following.push( TOKENS_FOLLOWING_condition_not_IN_condition_and_6463 )
            condition_not1069 = condition_not
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, condition_not1069.tree )
            end

          else
            break # out of loop for decision 279
          end
        end # loop for decision 279
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 197 )
        memoize( __method__, condition_and_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionNotReturnValue = define_return_scope 

    # 
    # parser rule condition_not
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1027:1: condition_not : ( 'NOT' condition_expr | condition_expr );
    # 
    def condition_not
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 198 )
      return_value = ConditionNotReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_not_start_index = @input.index

      root_0 = nil
      string_literal1070 = nil
      condition_expr1071 = nil
      condition_expr1072 = nil

      tree_for_string_literal1070 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 1028:2: ( 'NOT' condition_expr | condition_expr )
        alt_280 = 2
        look_280_0 = @input.peek( 1 )

        if ( look_280_0 == T__57 )
          alt_280 = 1
        elsif ( look_280_0 == LPAREN || look_280_0.between?( PLUS, QUOTED_STRING ) || look_280_0.between?( ID, DOUBLEQUOTED_STRING ) || look_280_0 == T__58 || look_280_0 == T__100 || look_280_0.between?( T__110, T__111 ) || look_280_0.between?( T__116, T__117 ) || look_280_0.between?( T__140, T__142 ) || look_280_0 == T__144 || look_280_0 == T__146 )
          alt_280 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 280, 0 )
        end
        case alt_280
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 1028:4: 'NOT' condition_expr
          string_literal1070 = match( T__57, TOKENS_FOLLOWING_T__57_IN_condition_not_6476 )
          if @state.backtracking == 0

            tree_for_string_literal1070 = @adaptor.create_with_payload( string_literal1070 )
            @adaptor.add_child( root_0, tree_for_string_literal1070 )

          end
          @state.following.push( TOKENS_FOLLOWING_condition_expr_IN_condition_not_6478 )
          condition_expr1071 = condition_expr
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_expr1071.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 1029:4: condition_expr
          @state.following.push( TOKENS_FOLLOWING_condition_expr_IN_condition_not_6483 )
          condition_expr1072 = condition_expr
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_expr1072.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 198 )
        memoize( __method__, condition_not_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionExprReturnValue = define_return_scope 

    # 
    # parser rule condition_expr
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1031:1: condition_expr : ( condition_exists | condition_is | condition_comparison | condition_group_comparison | condition_in | condition_is_a_set | condition_is_any | condition_is_empty | condition_is_of_type | condition_is_present | condition_like | condition_memeber | condition_between | condition_regexp_like | condition_submultiset | condition_equals_path | condition_under_path | condition_paren );
    # 
    def condition_expr
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 199 )
      return_value = ConditionExprReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_expr_start_index = @input.index

      root_0 = nil
      condition_exists1073 = nil
      condition_is1074 = nil
      condition_comparison1075 = nil
      condition_group_comparison1076 = nil
      condition_in1077 = nil
      condition_is_a_set1078 = nil
      condition_is_any1079 = nil
      condition_is_empty1080 = nil
      condition_is_of_type1081 = nil
      condition_is_present1082 = nil
      condition_like1083 = nil
      condition_memeber1084 = nil
      condition_between1085 = nil
      condition_regexp_like1086 = nil
      condition_submultiset1087 = nil
      condition_equals_path1088 = nil
      condition_under_path1089 = nil
      condition_paren1090 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 1032:2: ( condition_exists | condition_is | condition_comparison | condition_group_comparison | condition_in | condition_is_a_set | condition_is_any | condition_is_empty | condition_is_of_type | condition_is_present | condition_like | condition_memeber | condition_between | condition_regexp_like | condition_submultiset | condition_equals_path | condition_under_path | condition_paren )
        alt_281 = 18
        alt_281 = @dfa281.predict( @input )
        case alt_281
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 1032:4: condition_exists
          @state.following.push( TOKENS_FOLLOWING_condition_exists_IN_condition_expr_6493 )
          condition_exists1073 = condition_exists
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_exists1073.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 1033:4: condition_is
          @state.following.push( TOKENS_FOLLOWING_condition_is_IN_condition_expr_6498 )
          condition_is1074 = condition_is
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_is1074.tree )
          end

        when 3
          root_0 = @adaptor.create_flat_list


          # at line 1034:4: condition_comparison
          @state.following.push( TOKENS_FOLLOWING_condition_comparison_IN_condition_expr_6503 )
          condition_comparison1075 = condition_comparison
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_comparison1075.tree )
          end

        when 4
          root_0 = @adaptor.create_flat_list


          # at line 1035:4: condition_group_comparison
          @state.following.push( TOKENS_FOLLOWING_condition_group_comparison_IN_condition_expr_6508 )
          condition_group_comparison1076 = condition_group_comparison
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_group_comparison1076.tree )
          end

        when 5
          root_0 = @adaptor.create_flat_list


          # at line 1036:4: condition_in
          @state.following.push( TOKENS_FOLLOWING_condition_in_IN_condition_expr_6513 )
          condition_in1077 = condition_in
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_in1077.tree )
          end

        when 6
          root_0 = @adaptor.create_flat_list


          # at line 1037:4: condition_is_a_set
          @state.following.push( TOKENS_FOLLOWING_condition_is_a_set_IN_condition_expr_6518 )
          condition_is_a_set1078 = condition_is_a_set
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_is_a_set1078.tree )
          end

        when 7
          root_0 = @adaptor.create_flat_list


          # at line 1038:4: condition_is_any
          @state.following.push( TOKENS_FOLLOWING_condition_is_any_IN_condition_expr_6523 )
          condition_is_any1079 = condition_is_any
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_is_any1079.tree )
          end

        when 8
          root_0 = @adaptor.create_flat_list


          # at line 1039:4: condition_is_empty
          @state.following.push( TOKENS_FOLLOWING_condition_is_empty_IN_condition_expr_6528 )
          condition_is_empty1080 = condition_is_empty
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_is_empty1080.tree )
          end

        when 9
          root_0 = @adaptor.create_flat_list


          # at line 1040:4: condition_is_of_type
          @state.following.push( TOKENS_FOLLOWING_condition_is_of_type_IN_condition_expr_6533 )
          condition_is_of_type1081 = condition_is_of_type
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_is_of_type1081.tree )
          end

        when 10
          root_0 = @adaptor.create_flat_list


          # at line 1041:4: condition_is_present
          @state.following.push( TOKENS_FOLLOWING_condition_is_present_IN_condition_expr_6538 )
          condition_is_present1082 = condition_is_present
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_is_present1082.tree )
          end

        when 11
          root_0 = @adaptor.create_flat_list


          # at line 1042:4: condition_like
          @state.following.push( TOKENS_FOLLOWING_condition_like_IN_condition_expr_6543 )
          condition_like1083 = condition_like
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_like1083.tree )
          end

        when 12
          root_0 = @adaptor.create_flat_list


          # at line 1043:4: condition_memeber
          @state.following.push( TOKENS_FOLLOWING_condition_memeber_IN_condition_expr_6548 )
          condition_memeber1084 = condition_memeber
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_memeber1084.tree )
          end

        when 13
          root_0 = @adaptor.create_flat_list


          # at line 1044:4: condition_between
          @state.following.push( TOKENS_FOLLOWING_condition_between_IN_condition_expr_6553 )
          condition_between1085 = condition_between
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_between1085.tree )
          end

        when 14
          root_0 = @adaptor.create_flat_list


          # at line 1045:4: condition_regexp_like
          @state.following.push( TOKENS_FOLLOWING_condition_regexp_like_IN_condition_expr_6558 )
          condition_regexp_like1086 = condition_regexp_like
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_regexp_like1086.tree )
          end

        when 15
          root_0 = @adaptor.create_flat_list


          # at line 1046:4: condition_submultiset
          @state.following.push( TOKENS_FOLLOWING_condition_submultiset_IN_condition_expr_6563 )
          condition_submultiset1087 = condition_submultiset
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_submultiset1087.tree )
          end

        when 16
          root_0 = @adaptor.create_flat_list


          # at line 1047:4: condition_equals_path
          @state.following.push( TOKENS_FOLLOWING_condition_equals_path_IN_condition_expr_6568 )
          condition_equals_path1088 = condition_equals_path
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_equals_path1088.tree )
          end

        when 17
          root_0 = @adaptor.create_flat_list


          # at line 1048:4: condition_under_path
          @state.following.push( TOKENS_FOLLOWING_condition_under_path_IN_condition_expr_6573 )
          condition_under_path1089 = condition_under_path
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_under_path1089.tree )
          end

        when 18
          root_0 = @adaptor.create_flat_list


          # at line 1049:4: condition_paren
          @state.following.push( TOKENS_FOLLOWING_condition_paren_IN_condition_expr_6578 )
          condition_paren1090 = condition_paren
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, condition_paren1090.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 199 )
        memoize( __method__, condition_expr_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionExistsReturnValue = define_return_scope 

    # 
    # parser rule condition_exists
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1051:1: condition_exists : 'EXISTS' LPAREN select_command RPAREN ;
    # 
    def condition_exists
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 200 )
      return_value = ConditionExistsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_exists_start_index = @input.index

      root_0 = nil
      string_literal1091 = nil
      __LPAREN1092__ = nil
      __RPAREN1094__ = nil
      select_command1093 = nil

      tree_for_string_literal1091 = nil
      tree_for_LPAREN1092 = nil
      tree_for_RPAREN1094 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1052:4: 'EXISTS' LPAREN select_command RPAREN
        string_literal1091 = match( T__144, TOKENS_FOLLOWING_T__144_IN_condition_exists_6588 )
        if @state.backtracking == 0

          tree_for_string_literal1091 = @adaptor.create_with_payload( string_literal1091 )
          @adaptor.add_child( root_0, tree_for_string_literal1091 )

        end
        __LPAREN1092__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_condition_exists_6590 )
        if @state.backtracking == 0

          tree_for_LPAREN1092 = @adaptor.create_with_payload( __LPAREN1092__ )
          @adaptor.add_child( root_0, tree_for_LPAREN1092 )

        end
        @state.following.push( TOKENS_FOLLOWING_select_command_IN_condition_exists_6592 )
        select_command1093 = select_command
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, select_command1093.tree )
        end
        __RPAREN1094__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_condition_exists_6594 )
        if @state.backtracking == 0

          tree_for_RPAREN1094 = @adaptor.create_with_payload( __RPAREN1094__ )
          @adaptor.add_child( root_0, tree_for_RPAREN1094 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 200 )
        memoize( __method__, condition_exists_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionIsReturnValue = define_return_scope 

    # 
    # parser rule condition_is
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1054:1: condition_is : sql_expression 'IS' ( 'NOT' )? ( keyNAN | keyINFINITE | 'NULL' ) ;
    # 
    def condition_is
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 201 )
      return_value = ConditionIsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_is_start_index = @input.index

      root_0 = nil
      string_literal1096 = nil
      string_literal1097 = nil
      string_literal1100 = nil
      sql_expression1095 = nil
      keyNAN1098 = nil
      keyINFINITE1099 = nil

      tree_for_string_literal1096 = nil
      tree_for_string_literal1097 = nil
      tree_for_string_literal1100 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1055:4: sql_expression 'IS' ( 'NOT' )? ( keyNAN | keyINFINITE | 'NULL' )
        @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_condition_is_6604 )
        sql_expression1095 = sql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_expression1095.tree )
        end
        string_literal1096 = match( T__52, TOKENS_FOLLOWING_T__52_IN_condition_is_6606 )
        if @state.backtracking == 0

          tree_for_string_literal1096 = @adaptor.create_with_payload( string_literal1096 )
          @adaptor.add_child( root_0, tree_for_string_literal1096 )

        end
        # at line 1055:24: ( 'NOT' )?
        alt_282 = 2
        look_282_0 = @input.peek( 1 )

        if ( look_282_0 == T__57 )
          alt_282 = 1
        end
        case alt_282
        when 1
          # at line 1055:26: 'NOT'
          string_literal1097 = match( T__57, TOKENS_FOLLOWING_T__57_IN_condition_is_6610 )
          if @state.backtracking == 0

            tree_for_string_literal1097 = @adaptor.create_with_payload( string_literal1097 )
            @adaptor.add_child( root_0, tree_for_string_literal1097 )

          end

        end
        # at line 1055:35: ( keyNAN | keyINFINITE | 'NULL' )
        alt_283 = 3
        look_283_0 = @input.peek( 1 )

        if ( look_283_0 == ID )
          look_283_1 = @input.peek( 2 )

          if ( ( syntactic_predicate?( :synpred462_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("NAN") ) ) )
            alt_283 = 1
          elsif ( ( syntactic_predicate?( :synpred463_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("INFINITE") ) ) )
            alt_283 = 2
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 283, 1 )
          end
        elsif ( look_283_0 == T__58 )
          alt_283 = 3
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 283, 0 )
        end
        case alt_283
        when 1
          # at line 1055:37: keyNAN
          @state.following.push( TOKENS_FOLLOWING_keyNAN_IN_condition_is_6617 )
          keyNAN1098 = keyNAN
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyNAN1098.tree )
          end

        when 2
          # at line 1055:46: keyINFINITE
          @state.following.push( TOKENS_FOLLOWING_keyINFINITE_IN_condition_is_6621 )
          keyINFINITE1099 = keyINFINITE
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyINFINITE1099.tree )
          end

        when 3
          # at line 1055:60: 'NULL'
          string_literal1100 = match( T__58, TOKENS_FOLLOWING_T__58_IN_condition_is_6625 )
          if @state.backtracking == 0

            tree_for_string_literal1100 = @adaptor.create_with_payload( string_literal1100 )
            @adaptor.add_child( root_0, tree_for_string_literal1100 )

          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 201 )
        memoize( __method__, condition_is_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionComparisonReturnValue = define_return_scope 

    # 
    # parser rule condition_comparison
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1057:1: condition_comparison : ( LPAREN sql_expressions RPAREN ( outer_join_sign )? ( EQ | NOT_EQ ) LPAREN select_command RPAREN ( outer_join_sign )? | ( 'PRIOR' )? sql_expression ( outer_join_sign )? ( EQ | NOT_EQ | GTH | GEQ | LTH | LEQ ) ( 'PRIOR' )? ( sql_expression | LPAREN select_command RPAREN ) ( outer_join_sign )? );
    # 
    def condition_comparison
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 202 )
      return_value = ConditionComparisonReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_comparison_start_index = @input.index

      root_0 = nil
      __LPAREN1101__ = nil
      __RPAREN1103__ = nil
      set1105 = nil
      __LPAREN1106__ = nil
      __RPAREN1108__ = nil
      string_literal1110 = nil
      set1113 = nil
      string_literal1114 = nil
      __LPAREN1116__ = nil
      __RPAREN1118__ = nil
      sql_expressions1102 = nil
      outer_join_sign1104 = nil
      select_command1107 = nil
      outer_join_sign1109 = nil
      sql_expression1111 = nil
      outer_join_sign1112 = nil
      sql_expression1115 = nil
      select_command1117 = nil
      outer_join_sign1119 = nil

      tree_for_LPAREN1101 = nil
      tree_for_RPAREN1103 = nil
      tree_for_set1105 = nil
      tree_for_LPAREN1106 = nil
      tree_for_RPAREN1108 = nil
      tree_for_string_literal1110 = nil
      tree_for_set1113 = nil
      tree_for_string_literal1114 = nil
      tree_for_LPAREN1116 = nil
      tree_for_RPAREN1118 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 1058:2: ( LPAREN sql_expressions RPAREN ( outer_join_sign )? ( EQ | NOT_EQ ) LPAREN select_command RPAREN ( outer_join_sign )? | ( 'PRIOR' )? sql_expression ( outer_join_sign )? ( EQ | NOT_EQ | GTH | GEQ | LTH | LEQ ) ( 'PRIOR' )? ( sql_expression | LPAREN select_command RPAREN ) ( outer_join_sign )? )
        alt_291 = 2
        alt_291 = @dfa291.predict( @input )
        case alt_291
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 1058:4: LPAREN sql_expressions RPAREN ( outer_join_sign )? ( EQ | NOT_EQ ) LPAREN select_command RPAREN ( outer_join_sign )?
          __LPAREN1101__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_condition_comparison_6637 )
          if @state.backtracking == 0

            tree_for_LPAREN1101 = @adaptor.create_with_payload( __LPAREN1101__ )
            @adaptor.add_child( root_0, tree_for_LPAREN1101 )

          end
          @state.following.push( TOKENS_FOLLOWING_sql_expressions_IN_condition_comparison_6639 )
          sql_expressions1102 = sql_expressions
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expressions1102.tree )
          end
          __RPAREN1103__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_condition_comparison_6641 )
          if @state.backtracking == 0

            tree_for_RPAREN1103 = @adaptor.create_with_payload( __RPAREN1103__ )
            @adaptor.add_child( root_0, tree_for_RPAREN1103 )

          end
          # at line 1058:34: ( outer_join_sign )?
          alt_284 = 2
          look_284_0 = @input.peek( 1 )

          if ( look_284_0 == LPAREN )
            alt_284 = 1
          end
          case alt_284
          when 1
            # at line 1058:36: outer_join_sign
            @state.following.push( TOKENS_FOLLOWING_outer_join_sign_IN_condition_comparison_6645 )
            outer_join_sign1104 = outer_join_sign
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, outer_join_sign1104.tree )
            end

          end
          set1105 = @input.look
          if @input.peek(1) == EQ || @input.peek(1) == NOT_EQ
            @input.consume
            if @state.backtracking == 0
              @adaptor.add_child( root_0, @adaptor.create_with_payload( set1105 ) )
            end
            @state.error_recovery = false
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            mse = MismatchedSet( nil )
            raise mse
          end


          __LPAREN1106__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_condition_comparison_6660 )
          if @state.backtracking == 0

            tree_for_LPAREN1106 = @adaptor.create_with_payload( __LPAREN1106__ )
            @adaptor.add_child( root_0, tree_for_LPAREN1106 )

          end
          @state.following.push( TOKENS_FOLLOWING_select_command_IN_condition_comparison_6662 )
          select_command1107 = select_command
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, select_command1107.tree )
          end
          __RPAREN1108__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_condition_comparison_6664 )
          if @state.backtracking == 0

            tree_for_RPAREN1108 = @adaptor.create_with_payload( __RPAREN1108__ )
            @adaptor.add_child( root_0, tree_for_RPAREN1108 )

          end
          # at line 1058:100: ( outer_join_sign )?
          alt_285 = 2
          look_285_0 = @input.peek( 1 )

          if ( look_285_0 == LPAREN )
            look_285_1 = @input.peek( 2 )

            if ( look_285_1 == PLUS )
              look_285_3 = @input.peek( 3 )

              if ( look_285_3 == RPAREN )
                look_285_4 = @input.peek( 4 )

                if ( syntactic_predicate?( :synpred466_Plsql ) )
                  alt_285 = 1
                end
              end
            end
          end
          case alt_285
          when 1
            # at line 1058:102: outer_join_sign
            @state.following.push( TOKENS_FOLLOWING_outer_join_sign_IN_condition_comparison_6668 )
            outer_join_sign1109 = outer_join_sign
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, outer_join_sign1109.tree )
            end

          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 1059:4: ( 'PRIOR' )? sql_expression ( outer_join_sign )? ( EQ | NOT_EQ | GTH | GEQ | LTH | LEQ ) ( 'PRIOR' )? ( sql_expression | LPAREN select_command RPAREN ) ( outer_join_sign )?
          # at line 1059:4: ( 'PRIOR' )?
          alt_286 = 2
          look_286_0 = @input.peek( 1 )

          if ( look_286_0 == T__141 )
            alt_286 = 1
          end
          case alt_286
          when 1
            # at line 1059:6: 'PRIOR'
            string_literal1110 = match( T__141, TOKENS_FOLLOWING_T__141_IN_condition_comparison_6678 )
            if @state.backtracking == 0

              tree_for_string_literal1110 = @adaptor.create_with_payload( string_literal1110 )
              @adaptor.add_child( root_0, tree_for_string_literal1110 )

            end

          end
          @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_condition_comparison_6683 )
          sql_expression1111 = sql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expression1111.tree )
          end
          # at line 1059:32: ( outer_join_sign )?
          alt_287 = 2
          look_287_0 = @input.peek( 1 )

          if ( look_287_0 == LPAREN )
            alt_287 = 1
          end
          case alt_287
          when 1
            # at line 1059:34: outer_join_sign
            @state.following.push( TOKENS_FOLLOWING_outer_join_sign_IN_condition_comparison_6687 )
            outer_join_sign1112 = outer_join_sign
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, outer_join_sign1112.tree )
            end

          end
          set1113 = @input.look
          if @input.peek(1) == EQ || @input.peek( 1 ).between?( NOT_EQ, LEQ )
            @input.consume
            if @state.backtracking == 0
              @adaptor.add_child( root_0, @adaptor.create_with_payload( set1113 ) )
            end
            @state.error_recovery = false
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            mse = MismatchedSet( nil )
            raise mse
          end


          # at line 1059:93: ( 'PRIOR' )?
          alt_288 = 2
          look_288_0 = @input.peek( 1 )

          if ( look_288_0 == T__141 )
            alt_288 = 1
          end
          case alt_288
          when 1
            # at line 1059:95: 'PRIOR'
            string_literal1114 = match( T__141, TOKENS_FOLLOWING_T__141_IN_condition_comparison_6720 )
            if @state.backtracking == 0

              tree_for_string_literal1114 = @adaptor.create_with_payload( string_literal1114 )
              @adaptor.add_child( root_0, tree_for_string_literal1114 )

            end

          end
          # at line 1059:106: ( sql_expression | LPAREN select_command RPAREN )
          alt_289 = 2
          alt_289 = @dfa289.predict( @input )
          case alt_289
          when 1
            # at line 1059:108: sql_expression
            @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_condition_comparison_6727 )
            sql_expression1115 = sql_expression
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, sql_expression1115.tree )
            end

          when 2
            # at line 1059:125: LPAREN select_command RPAREN
            __LPAREN1116__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_condition_comparison_6731 )
            if @state.backtracking == 0

              tree_for_LPAREN1116 = @adaptor.create_with_payload( __LPAREN1116__ )
              @adaptor.add_child( root_0, tree_for_LPAREN1116 )

            end
            @state.following.push( TOKENS_FOLLOWING_select_command_IN_condition_comparison_6733 )
            select_command1117 = select_command
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, select_command1117.tree )
            end
            __RPAREN1118__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_condition_comparison_6735 )
            if @state.backtracking == 0

              tree_for_RPAREN1118 = @adaptor.create_with_payload( __RPAREN1118__ )
              @adaptor.add_child( root_0, tree_for_RPAREN1118 )

            end

          end
          # at line 1059:156: ( outer_join_sign )?
          alt_290 = 2
          look_290_0 = @input.peek( 1 )

          if ( look_290_0 == LPAREN )
            look_290_1 = @input.peek( 2 )

            if ( syntactic_predicate?( :synpred477_Plsql ) )
              alt_290 = 1
            end
          end
          case alt_290
          when 1
            # at line 1059:158: outer_join_sign
            @state.following.push( TOKENS_FOLLOWING_outer_join_sign_IN_condition_comparison_6741 )
            outer_join_sign1119 = outer_join_sign
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, outer_join_sign1119.tree )
            end

          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 202 )
        memoize( __method__, condition_comparison_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionGroupComparisonReturnValue = define_return_scope 

    # 
    # parser rule condition_group_comparison
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1061:1: condition_group_comparison : ( LPAREN sql_expressions RPAREN ( EQ | NOT_EQ ) ( 'ANY' | keySOME | 'ALL' ) LPAREN ( grouping_expression_list | select_command ) RPAREN | sql_expression ( EQ | NOT_EQ | GTH | GEQ | LTH | LEQ ) ( 'ANY' | keySOME | 'ALL' ) LPAREN ( sql_expressions | select_command ) RPAREN );
    # 
    def condition_group_comparison
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 203 )
      return_value = ConditionGroupComparisonReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_group_comparison_start_index = @input.index

      root_0 = nil
      __LPAREN1120__ = nil
      __RPAREN1122__ = nil
      set1123 = nil
      string_literal1124 = nil
      string_literal1126 = nil
      __LPAREN1127__ = nil
      __RPAREN1130__ = nil
      set1132 = nil
      string_literal1133 = nil
      string_literal1135 = nil
      __LPAREN1136__ = nil
      __RPAREN1139__ = nil
      sql_expressions1121 = nil
      keySOME1125 = nil
      grouping_expression_list1128 = nil
      select_command1129 = nil
      sql_expression1131 = nil
      keySOME1134 = nil
      sql_expressions1137 = nil
      select_command1138 = nil

      tree_for_LPAREN1120 = nil
      tree_for_RPAREN1122 = nil
      tree_for_set1123 = nil
      tree_for_string_literal1124 = nil
      tree_for_string_literal1126 = nil
      tree_for_LPAREN1127 = nil
      tree_for_RPAREN1130 = nil
      tree_for_set1132 = nil
      tree_for_string_literal1133 = nil
      tree_for_string_literal1135 = nil
      tree_for_LPAREN1136 = nil
      tree_for_RPAREN1139 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 1062:2: ( LPAREN sql_expressions RPAREN ( EQ | NOT_EQ ) ( 'ANY' | keySOME | 'ALL' ) LPAREN ( grouping_expression_list | select_command ) RPAREN | sql_expression ( EQ | NOT_EQ | GTH | GEQ | LTH | LEQ ) ( 'ANY' | keySOME | 'ALL' ) LPAREN ( sql_expressions | select_command ) RPAREN )
        alt_296 = 2
        alt_296 = @dfa296.predict( @input )
        case alt_296
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 1062:4: LPAREN sql_expressions RPAREN ( EQ | NOT_EQ ) ( 'ANY' | keySOME | 'ALL' ) LPAREN ( grouping_expression_list | select_command ) RPAREN
          __LPAREN1120__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_condition_group_comparison_6754 )
          if @state.backtracking == 0

            tree_for_LPAREN1120 = @adaptor.create_with_payload( __LPAREN1120__ )
            @adaptor.add_child( root_0, tree_for_LPAREN1120 )

          end
          @state.following.push( TOKENS_FOLLOWING_sql_expressions_IN_condition_group_comparison_6756 )
          sql_expressions1121 = sql_expressions
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expressions1121.tree )
          end
          __RPAREN1122__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_condition_group_comparison_6758 )
          if @state.backtracking == 0

            tree_for_RPAREN1122 = @adaptor.create_with_payload( __RPAREN1122__ )
            @adaptor.add_child( root_0, tree_for_RPAREN1122 )

          end
          set1123 = @input.look
          if @input.peek(1) == EQ || @input.peek(1) == NOT_EQ
            @input.consume
            if @state.backtracking == 0
              @adaptor.add_child( root_0, @adaptor.create_with_payload( set1123 ) )
            end
            @state.error_recovery = false
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            mse = MismatchedSet( nil )
            raise mse
          end


          # at line 1062:50: ( 'ANY' | keySOME | 'ALL' )
          alt_292 = 3
          case look_292 = @input.peek( 1 )
          when T__146 then alt_292 = 1
          when ID then alt_292 = 2
          when T__119 then alt_292 = 3
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 292, 0 )
          end
          case alt_292
          when 1
            # at line 1062:52: 'ANY'
            string_literal1124 = match( T__146, TOKENS_FOLLOWING_T__146_IN_condition_group_comparison_6772 )
            if @state.backtracking == 0

              tree_for_string_literal1124 = @adaptor.create_with_payload( string_literal1124 )
              @adaptor.add_child( root_0, tree_for_string_literal1124 )

            end

          when 2
            # at line 1062:60: keySOME
            @state.following.push( TOKENS_FOLLOWING_keySOME_IN_condition_group_comparison_6776 )
            keySOME1125 = keySOME
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keySOME1125.tree )
            end

          when 3
            # at line 1062:70: 'ALL'
            string_literal1126 = match( T__119, TOKENS_FOLLOWING_T__119_IN_condition_group_comparison_6780 )
            if @state.backtracking == 0

              tree_for_string_literal1126 = @adaptor.create_with_payload( string_literal1126 )
              @adaptor.add_child( root_0, tree_for_string_literal1126 )

            end

          end
          __LPAREN1127__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_condition_group_comparison_6784 )
          if @state.backtracking == 0

            tree_for_LPAREN1127 = @adaptor.create_with_payload( __LPAREN1127__ )
            @adaptor.add_child( root_0, tree_for_LPAREN1127 )

          end
          # at line 1062:85: ( grouping_expression_list | select_command )
          alt_293 = 2
          alt_293 = @dfa293.predict( @input )
          case alt_293
          when 1
            # at line 1062:87: grouping_expression_list
            @state.following.push( TOKENS_FOLLOWING_grouping_expression_list_IN_condition_group_comparison_6788 )
            grouping_expression_list1128 = grouping_expression_list
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, grouping_expression_list1128.tree )
            end

          when 2
            # at line 1062:114: select_command
            @state.following.push( TOKENS_FOLLOWING_select_command_IN_condition_group_comparison_6792 )
            select_command1129 = select_command
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, select_command1129.tree )
            end

          end
          __RPAREN1130__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_condition_group_comparison_6796 )
          if @state.backtracking == 0

            tree_for_RPAREN1130 = @adaptor.create_with_payload( __RPAREN1130__ )
            @adaptor.add_child( root_0, tree_for_RPAREN1130 )

          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 1063:4: sql_expression ( EQ | NOT_EQ | GTH | GEQ | LTH | LEQ ) ( 'ANY' | keySOME | 'ALL' ) LPAREN ( sql_expressions | select_command ) RPAREN
          @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_condition_group_comparison_6801 )
          sql_expression1131 = sql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expression1131.tree )
          end
          set1132 = @input.look
          if @input.peek(1) == EQ || @input.peek( 1 ).between?( NOT_EQ, LEQ )
            @input.consume
            if @state.backtracking == 0
              @adaptor.add_child( root_0, @adaptor.create_with_payload( set1132 ) )
            end
            @state.error_recovery = false
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            mse = MismatchedSet( nil )
            raise mse
          end


          # at line 1063:59: ( 'ANY' | keySOME | 'ALL' )
          alt_294 = 3
          case look_294 = @input.peek( 1 )
          when T__146 then alt_294 = 1
          when ID then alt_294 = 2
          when T__119 then alt_294 = 3
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 294, 0 )
          end
          case alt_294
          when 1
            # at line 1063:61: 'ANY'
            string_literal1133 = match( T__146, TOKENS_FOLLOWING_T__146_IN_condition_group_comparison_6831 )
            if @state.backtracking == 0

              tree_for_string_literal1133 = @adaptor.create_with_payload( string_literal1133 )
              @adaptor.add_child( root_0, tree_for_string_literal1133 )

            end

          when 2
            # at line 1063:69: keySOME
            @state.following.push( TOKENS_FOLLOWING_keySOME_IN_condition_group_comparison_6835 )
            keySOME1134 = keySOME
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keySOME1134.tree )
            end

          when 3
            # at line 1063:79: 'ALL'
            string_literal1135 = match( T__119, TOKENS_FOLLOWING_T__119_IN_condition_group_comparison_6839 )
            if @state.backtracking == 0

              tree_for_string_literal1135 = @adaptor.create_with_payload( string_literal1135 )
              @adaptor.add_child( root_0, tree_for_string_literal1135 )

            end

          end
          __LPAREN1136__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_condition_group_comparison_6843 )
          if @state.backtracking == 0

            tree_for_LPAREN1136 = @adaptor.create_with_payload( __LPAREN1136__ )
            @adaptor.add_child( root_0, tree_for_LPAREN1136 )

          end
          # at line 1063:94: ( sql_expressions | select_command )
          alt_295 = 2
          alt_295 = @dfa295.predict( @input )
          case alt_295
          when 1
            # at line 1063:96: sql_expressions
            @state.following.push( TOKENS_FOLLOWING_sql_expressions_IN_condition_group_comparison_6847 )
            sql_expressions1137 = sql_expressions
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, sql_expressions1137.tree )
            end

          when 2
            # at line 1063:114: select_command
            @state.following.push( TOKENS_FOLLOWING_select_command_IN_condition_group_comparison_6851 )
            select_command1138 = select_command
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, select_command1138.tree )
            end

          end
          __RPAREN1139__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_condition_group_comparison_6855 )
          if @state.backtracking == 0

            tree_for_RPAREN1139 = @adaptor.create_with_payload( __RPAREN1139__ )
            @adaptor.add_child( root_0, tree_for_RPAREN1139 )

          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 203 )
        memoize( __method__, condition_group_comparison_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionInReturnValue = define_return_scope 

    # 
    # parser rule condition_in
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1065:1: condition_in : ( LPAREN sql_expressions RPAREN ( 'NOT' )? 'IN' LPAREN ( grouping_expression_list | select_command ) RPAREN | sql_expression ( 'NOT' )? 'IN' LPAREN ( expression_list | select_command ) RPAREN );
    # 
    def condition_in
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 204 )
      return_value = ConditionInReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_in_start_index = @input.index

      root_0 = nil
      __LPAREN1140__ = nil
      __RPAREN1142__ = nil
      string_literal1143 = nil
      string_literal1144 = nil
      __LPAREN1145__ = nil
      __RPAREN1148__ = nil
      string_literal1150 = nil
      string_literal1151 = nil
      __LPAREN1152__ = nil
      __RPAREN1155__ = nil
      sql_expressions1141 = nil
      grouping_expression_list1146 = nil
      select_command1147 = nil
      sql_expression1149 = nil
      expression_list1153 = nil
      select_command1154 = nil

      tree_for_LPAREN1140 = nil
      tree_for_RPAREN1142 = nil
      tree_for_string_literal1143 = nil
      tree_for_string_literal1144 = nil
      tree_for_LPAREN1145 = nil
      tree_for_RPAREN1148 = nil
      tree_for_string_literal1150 = nil
      tree_for_string_literal1151 = nil
      tree_for_LPAREN1152 = nil
      tree_for_RPAREN1155 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 1066:2: ( LPAREN sql_expressions RPAREN ( 'NOT' )? 'IN' LPAREN ( grouping_expression_list | select_command ) RPAREN | sql_expression ( 'NOT' )? 'IN' LPAREN ( expression_list | select_command ) RPAREN )
        alt_301 = 2
        alt_301 = @dfa301.predict( @input )
        case alt_301
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 1066:4: LPAREN sql_expressions RPAREN ( 'NOT' )? 'IN' LPAREN ( grouping_expression_list | select_command ) RPAREN
          __LPAREN1140__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_condition_in_6865 )
          if @state.backtracking == 0

            tree_for_LPAREN1140 = @adaptor.create_with_payload( __LPAREN1140__ )
            @adaptor.add_child( root_0, tree_for_LPAREN1140 )

          end
          @state.following.push( TOKENS_FOLLOWING_sql_expressions_IN_condition_in_6867 )
          sql_expressions1141 = sql_expressions
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expressions1141.tree )
          end
          __RPAREN1142__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_condition_in_6869 )
          if @state.backtracking == 0

            tree_for_RPAREN1142 = @adaptor.create_with_payload( __RPAREN1142__ )
            @adaptor.add_child( root_0, tree_for_RPAREN1142 )

          end
          # at line 1066:34: ( 'NOT' )?
          alt_297 = 2
          look_297_0 = @input.peek( 1 )

          if ( look_297_0 == T__57 )
            alt_297 = 1
          end
          case alt_297
          when 1
            # at line 1066:36: 'NOT'
            string_literal1143 = match( T__57, TOKENS_FOLLOWING_T__57_IN_condition_in_6873 )
            if @state.backtracking == 0

              tree_for_string_literal1143 = @adaptor.create_with_payload( string_literal1143 )
              @adaptor.add_child( root_0, tree_for_string_literal1143 )

            end

          end
          string_literal1144 = match( T__102, TOKENS_FOLLOWING_T__102_IN_condition_in_6878 )
          if @state.backtracking == 0

            tree_for_string_literal1144 = @adaptor.create_with_payload( string_literal1144 )
            @adaptor.add_child( root_0, tree_for_string_literal1144 )

          end
          __LPAREN1145__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_condition_in_6880 )
          if @state.backtracking == 0

            tree_for_LPAREN1145 = @adaptor.create_with_payload( __LPAREN1145__ )
            @adaptor.add_child( root_0, tree_for_LPAREN1145 )

          end
          # at line 1066:57: ( grouping_expression_list | select_command )
          alt_298 = 2
          alt_298 = @dfa298.predict( @input )
          case alt_298
          when 1
            # at line 1066:59: grouping_expression_list
            @state.following.push( TOKENS_FOLLOWING_grouping_expression_list_IN_condition_in_6884 )
            grouping_expression_list1146 = grouping_expression_list
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, grouping_expression_list1146.tree )
            end

          when 2
            # at line 1066:86: select_command
            @state.following.push( TOKENS_FOLLOWING_select_command_IN_condition_in_6888 )
            select_command1147 = select_command
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, select_command1147.tree )
            end

          end
          __RPAREN1148__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_condition_in_6892 )
          if @state.backtracking == 0

            tree_for_RPAREN1148 = @adaptor.create_with_payload( __RPAREN1148__ )
            @adaptor.add_child( root_0, tree_for_RPAREN1148 )

          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 1067:4: sql_expression ( 'NOT' )? 'IN' LPAREN ( expression_list | select_command ) RPAREN
          @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_condition_in_6897 )
          sql_expression1149 = sql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expression1149.tree )
          end
          # at line 1067:19: ( 'NOT' )?
          alt_299 = 2
          look_299_0 = @input.peek( 1 )

          if ( look_299_0 == T__57 )
            alt_299 = 1
          end
          case alt_299
          when 1
            # at line 1067:21: 'NOT'
            string_literal1150 = match( T__57, TOKENS_FOLLOWING_T__57_IN_condition_in_6901 )
            if @state.backtracking == 0

              tree_for_string_literal1150 = @adaptor.create_with_payload( string_literal1150 )
              @adaptor.add_child( root_0, tree_for_string_literal1150 )

            end

          end
          string_literal1151 = match( T__102, TOKENS_FOLLOWING_T__102_IN_condition_in_6906 )
          if @state.backtracking == 0

            tree_for_string_literal1151 = @adaptor.create_with_payload( string_literal1151 )
            @adaptor.add_child( root_0, tree_for_string_literal1151 )

          end
          __LPAREN1152__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_condition_in_6908 )
          if @state.backtracking == 0

            tree_for_LPAREN1152 = @adaptor.create_with_payload( __LPAREN1152__ )
            @adaptor.add_child( root_0, tree_for_LPAREN1152 )

          end
          # at line 1067:42: ( expression_list | select_command )
          alt_300 = 2
          alt_300 = @dfa300.predict( @input )
          case alt_300
          when 1
            # at line 1067:44: expression_list
            @state.following.push( TOKENS_FOLLOWING_expression_list_IN_condition_in_6912 )
            expression_list1153 = expression_list
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, expression_list1153.tree )
            end

          when 2
            # at line 1067:62: select_command
            @state.following.push( TOKENS_FOLLOWING_select_command_IN_condition_in_6916 )
            select_command1154 = select_command
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, select_command1154.tree )
            end

          end
          __RPAREN1155__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_condition_in_6920 )
          if @state.backtracking == 0

            tree_for_RPAREN1155 = @adaptor.create_with_payload( __RPAREN1155__ )
            @adaptor.add_child( root_0, tree_for_RPAREN1155 )

          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 204 )
        memoize( __method__, condition_in_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionIsASetReturnValue = define_return_scope 

    # 
    # parser rule condition_is_a_set
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1069:1: condition_is_a_set : nested_table_column_name 'IS' ( 'NOT' )? keyA 'SET' ;
    # 
    def condition_is_a_set
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 205 )
      return_value = ConditionIsASetReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_is_a_set_start_index = @input.index

      root_0 = nil
      string_literal1157 = nil
      string_literal1158 = nil
      string_literal1160 = nil
      nested_table_column_name1156 = nil
      keyA1159 = nil

      tree_for_string_literal1157 = nil
      tree_for_string_literal1158 = nil
      tree_for_string_literal1160 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1070:4: nested_table_column_name 'IS' ( 'NOT' )? keyA 'SET'
        @state.following.push( TOKENS_FOLLOWING_nested_table_column_name_IN_condition_is_a_set_6930 )
        nested_table_column_name1156 = nested_table_column_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, nested_table_column_name1156.tree )
        end
        string_literal1157 = match( T__52, TOKENS_FOLLOWING_T__52_IN_condition_is_a_set_6932 )
        if @state.backtracking == 0

          tree_for_string_literal1157 = @adaptor.create_with_payload( string_literal1157 )
          @adaptor.add_child( root_0, tree_for_string_literal1157 )

        end
        # at line 1070:34: ( 'NOT' )?
        alt_302 = 2
        look_302_0 = @input.peek( 1 )

        if ( look_302_0 == T__57 )
          alt_302 = 1
        end
        case alt_302
        when 1
          # at line 1070:36: 'NOT'
          string_literal1158 = match( T__57, TOKENS_FOLLOWING_T__57_IN_condition_is_a_set_6936 )
          if @state.backtracking == 0

            tree_for_string_literal1158 = @adaptor.create_with_payload( string_literal1158 )
            @adaptor.add_child( root_0, tree_for_string_literal1158 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_keyA_IN_condition_is_a_set_6941 )
        keyA1159 = keyA
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyA1159.tree )
        end
        string_literal1160 = match( T__87, TOKENS_FOLLOWING_T__87_IN_condition_is_a_set_6943 )
        if @state.backtracking == 0

          tree_for_string_literal1160 = @adaptor.create_with_payload( string_literal1160 )
          @adaptor.add_child( root_0, tree_for_string_literal1160 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 205 )
        memoize( __method__, condition_is_a_set_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionIsAnyReturnValue = define_return_scope 

    # 
    # parser rule condition_is_any
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1072:1: condition_is_any : ( column_name 'IS' )? 'ANY' ;
    # 
    def condition_is_any
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 206 )
      return_value = ConditionIsAnyReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_is_any_start_index = @input.index

      root_0 = nil
      string_literal1162 = nil
      string_literal1163 = nil
      column_name1161 = nil

      tree_for_string_literal1162 = nil
      tree_for_string_literal1163 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1073:4: ( column_name 'IS' )? 'ANY'
        # at line 1073:4: ( column_name 'IS' )?
        alt_303 = 2
        look_303_0 = @input.peek( 1 )

        if ( look_303_0.between?( ID, DOUBLEQUOTED_STRING ) || look_303_0 == T__100 )
          alt_303 = 1
        end
        case alt_303
        when 1
          # at line 1073:6: column_name 'IS'
          @state.following.push( TOKENS_FOLLOWING_column_name_IN_condition_is_any_6955 )
          column_name1161 = column_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, column_name1161.tree )
          end
          string_literal1162 = match( T__52, TOKENS_FOLLOWING_T__52_IN_condition_is_any_6957 )
          if @state.backtracking == 0

            tree_for_string_literal1162 = @adaptor.create_with_payload( string_literal1162 )
            @adaptor.add_child( root_0, tree_for_string_literal1162 )

          end

        end
        string_literal1163 = match( T__146, TOKENS_FOLLOWING_T__146_IN_condition_is_any_6962 )
        if @state.backtracking == 0

          tree_for_string_literal1163 = @adaptor.create_with_payload( string_literal1163 )
          @adaptor.add_child( root_0, tree_for_string_literal1163 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 206 )
        memoize( __method__, condition_is_any_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionIsEmptyReturnValue = define_return_scope 

    # 
    # parser rule condition_is_empty
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1075:1: condition_is_empty : nested_table_column_name 'IS' ( 'NOT' )? keyEMPTY ;
    # 
    def condition_is_empty
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 207 )
      return_value = ConditionIsEmptyReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_is_empty_start_index = @input.index

      root_0 = nil
      string_literal1165 = nil
      string_literal1166 = nil
      nested_table_column_name1164 = nil
      keyEMPTY1167 = nil

      tree_for_string_literal1165 = nil
      tree_for_string_literal1166 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1076:4: nested_table_column_name 'IS' ( 'NOT' )? keyEMPTY
        @state.following.push( TOKENS_FOLLOWING_nested_table_column_name_IN_condition_is_empty_6972 )
        nested_table_column_name1164 = nested_table_column_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, nested_table_column_name1164.tree )
        end
        string_literal1165 = match( T__52, TOKENS_FOLLOWING_T__52_IN_condition_is_empty_6974 )
        if @state.backtracking == 0

          tree_for_string_literal1165 = @adaptor.create_with_payload( string_literal1165 )
          @adaptor.add_child( root_0, tree_for_string_literal1165 )

        end
        # at line 1076:34: ( 'NOT' )?
        alt_304 = 2
        look_304_0 = @input.peek( 1 )

        if ( look_304_0 == T__57 )
          alt_304 = 1
        end
        case alt_304
        when 1
          # at line 1076:36: 'NOT'
          string_literal1166 = match( T__57, TOKENS_FOLLOWING_T__57_IN_condition_is_empty_6978 )
          if @state.backtracking == 0

            tree_for_string_literal1166 = @adaptor.create_with_payload( string_literal1166 )
            @adaptor.add_child( root_0, tree_for_string_literal1166 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_keyEMPTY_IN_condition_is_empty_6983 )
        keyEMPTY1167 = keyEMPTY
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyEMPTY1167.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 207 )
        memoize( __method__, condition_is_empty_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionIsOfTypeReturnValue = define_return_scope 

    # 
    # parser rule condition_is_of_type
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1078:1: condition_is_of_type : sql_expression 'IS' ( 'NOT' )? 'OF' ( keyTYPE )? LPAREN type_name RPAREN ;
    # 
    def condition_is_of_type
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 208 )
      return_value = ConditionIsOfTypeReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_is_of_type_start_index = @input.index

      root_0 = nil
      string_literal1169 = nil
      string_literal1170 = nil
      string_literal1171 = nil
      __LPAREN1173__ = nil
      __RPAREN1175__ = nil
      sql_expression1168 = nil
      keyTYPE1172 = nil
      type_name1174 = nil

      tree_for_string_literal1169 = nil
      tree_for_string_literal1170 = nil
      tree_for_string_literal1171 = nil
      tree_for_LPAREN1173 = nil
      tree_for_RPAREN1175 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1079:4: sql_expression 'IS' ( 'NOT' )? 'OF' ( keyTYPE )? LPAREN type_name RPAREN
        @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_condition_is_of_type_6993 )
        sql_expression1168 = sql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_expression1168.tree )
        end
        string_literal1169 = match( T__52, TOKENS_FOLLOWING_T__52_IN_condition_is_of_type_6995 )
        if @state.backtracking == 0

          tree_for_string_literal1169 = @adaptor.create_with_payload( string_literal1169 )
          @adaptor.add_child( root_0, tree_for_string_literal1169 )

        end
        # at line 1079:24: ( 'NOT' )?
        alt_305 = 2
        look_305_0 = @input.peek( 1 )

        if ( look_305_0 == T__57 )
          alt_305 = 1
        end
        case alt_305
        when 1
          # at line 1079:26: 'NOT'
          string_literal1170 = match( T__57, TOKENS_FOLLOWING_T__57_IN_condition_is_of_type_6999 )
          if @state.backtracking == 0

            tree_for_string_literal1170 = @adaptor.create_with_payload( string_literal1170 )
            @adaptor.add_child( root_0, tree_for_string_literal1170 )

          end

        end
        string_literal1171 = match( T__106, TOKENS_FOLLOWING_T__106_IN_condition_is_of_type_7004 )
        if @state.backtracking == 0

          tree_for_string_literal1171 = @adaptor.create_with_payload( string_literal1171 )
          @adaptor.add_child( root_0, tree_for_string_literal1171 )

        end
        # at line 1079:40: ( keyTYPE )?
        alt_306 = 2
        look_306_0 = @input.peek( 1 )

        if ( look_306_0 == ID )
          alt_306 = 1
        end
        case alt_306
        when 1
          # at line 1079:42: keyTYPE
          @state.following.push( TOKENS_FOLLOWING_keyTYPE_IN_condition_is_of_type_7008 )
          keyTYPE1172 = keyTYPE
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyTYPE1172.tree )
          end

        end
        __LPAREN1173__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_condition_is_of_type_7013 )
        if @state.backtracking == 0

          tree_for_LPAREN1173 = @adaptor.create_with_payload( __LPAREN1173__ )
          @adaptor.add_child( root_0, tree_for_LPAREN1173 )

        end
        @state.following.push( TOKENS_FOLLOWING_type_name_IN_condition_is_of_type_7015 )
        type_name1174 = type_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, type_name1174.tree )
        end
        __RPAREN1175__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_condition_is_of_type_7017 )
        if @state.backtracking == 0

          tree_for_RPAREN1175 = @adaptor.create_with_payload( __RPAREN1175__ )
          @adaptor.add_child( root_0, tree_for_RPAREN1175 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 208 )
        memoize( __method__, condition_is_of_type_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionIsOfTypeNamesReturnValue = define_return_scope 

    # 
    # parser rule condition_is_of_type_names
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1081:1: condition_is_of_type_names : condition_is_of_type_name ( COMMA condition_is_of_type_name )* ;
    # 
    def condition_is_of_type_names
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 209 )
      return_value = ConditionIsOfTypeNamesReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_is_of_type_names_start_index = @input.index

      root_0 = nil
      __COMMA1177__ = nil
      condition_is_of_type_name1176 = nil
      condition_is_of_type_name1178 = nil

      tree_for_COMMA1177 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1082:4: condition_is_of_type_name ( COMMA condition_is_of_type_name )*
        @state.following.push( TOKENS_FOLLOWING_condition_is_of_type_name_IN_condition_is_of_type_names_7027 )
        condition_is_of_type_name1176 = condition_is_of_type_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, condition_is_of_type_name1176.tree )
        end
        # at line 1082:30: ( COMMA condition_is_of_type_name )*
        while true # decision 307
          alt_307 = 2
          look_307_0 = @input.peek( 1 )

          if ( look_307_0 == COMMA )
            alt_307 = 1

          end
          case alt_307
          when 1
            # at line 1082:32: COMMA condition_is_of_type_name
            __COMMA1177__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_condition_is_of_type_names_7031 )
            if @state.backtracking == 0

              tree_for_COMMA1177 = @adaptor.create_with_payload( __COMMA1177__ )
              @adaptor.add_child( root_0, tree_for_COMMA1177 )

            end
            @state.following.push( TOKENS_FOLLOWING_condition_is_of_type_name_IN_condition_is_of_type_names_7033 )
            condition_is_of_type_name1178 = condition_is_of_type_name
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, condition_is_of_type_name1178.tree )
            end

          else
            break # out of loop for decision 307
          end
        end # loop for decision 307
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 209 )
        memoize( __method__, condition_is_of_type_names_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionIsOfTypeNameReturnValue = define_return_scope 

    # 
    # parser rule condition_is_of_type_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1084:1: condition_is_of_type_name : ( keyONLY )? type_name ;
    # 
    def condition_is_of_type_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 210 )
      return_value = ConditionIsOfTypeNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_is_of_type_name_start_index = @input.index

      root_0 = nil
      keyONLY1179 = nil
      type_name1180 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1085:4: ( keyONLY )? type_name
        # at line 1085:4: ( keyONLY )?
        alt_308 = 2
        look_308_0 = @input.peek( 1 )

        if ( look_308_0 == ID )
          look_308_1 = @input.peek( 2 )

          if ( look_308_1.between?( ID, DOUBLEQUOTED_STRING ) )
            alt_308 = 1
          end
        end
        case alt_308
        when 1
          # at line 1085:6: keyONLY
          @state.following.push( TOKENS_FOLLOWING_keyONLY_IN_condition_is_of_type_name_7048 )
          keyONLY1179 = keyONLY
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyONLY1179.tree )
          end

        end
        @state.following.push( TOKENS_FOLLOWING_type_name_IN_condition_is_of_type_name_7053 )
        type_name1180 = type_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, type_name1180.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 210 )
        memoize( __method__, condition_is_of_type_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionIsPresentReturnValue = define_return_scope 

    # 
    # parser rule condition_is_present
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1087:1: condition_is_present : cell_reference 'IS' keyPRESENT ;
    # 
    def condition_is_present
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 211 )
      return_value = ConditionIsPresentReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_is_present_start_index = @input.index

      root_0 = nil
      string_literal1182 = nil
      cell_reference1181 = nil
      keyPRESENT1183 = nil

      tree_for_string_literal1182 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1088:4: cell_reference 'IS' keyPRESENT
        @state.following.push( TOKENS_FOLLOWING_cell_reference_IN_condition_is_present_7063 )
        cell_reference1181 = cell_reference
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, cell_reference1181.tree )
        end
        string_literal1182 = match( T__52, TOKENS_FOLLOWING_T__52_IN_condition_is_present_7065 )
        if @state.backtracking == 0

          tree_for_string_literal1182 = @adaptor.create_with_payload( string_literal1182 )
          @adaptor.add_child( root_0, tree_for_string_literal1182 )

        end
        @state.following.push( TOKENS_FOLLOWING_keyPRESENT_IN_condition_is_present_7067 )
        keyPRESENT1183 = keyPRESENT
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyPRESENT1183.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 211 )
        memoize( __method__, condition_is_present_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionLikeReturnValue = define_return_scope 

    # 
    # parser rule condition_like
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1090:1: condition_like : sql_expression ( 'NOT' )? ( 'LIKE' | keyLIKEC | keyLIKE2 | keyLIKE4 ) sql_expression ( keyESCAPE sql_expression )? ;
    # 
    def condition_like
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 212 )
      return_value = ConditionLikeReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_like_start_index = @input.index

      root_0 = nil
      string_literal1185 = nil
      string_literal1186 = nil
      sql_expression1184 = nil
      keyLIKEC1187 = nil
      keyLIKE21188 = nil
      keyLIKE41189 = nil
      sql_expression1190 = nil
      keyESCAPE1191 = nil
      sql_expression1192 = nil

      tree_for_string_literal1185 = nil
      tree_for_string_literal1186 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1091:4: sql_expression ( 'NOT' )? ( 'LIKE' | keyLIKEC | keyLIKE2 | keyLIKE4 ) sql_expression ( keyESCAPE sql_expression )?
        @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_condition_like_7077 )
        sql_expression1184 = sql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_expression1184.tree )
        end
        # at line 1091:19: ( 'NOT' )?
        alt_309 = 2
        look_309_0 = @input.peek( 1 )

        if ( look_309_0 == T__57 )
          alt_309 = 1
        end
        case alt_309
        when 1
          # at line 1091:21: 'NOT'
          string_literal1185 = match( T__57, TOKENS_FOLLOWING_T__57_IN_condition_like_7081 )
          if @state.backtracking == 0

            tree_for_string_literal1185 = @adaptor.create_with_payload( string_literal1185 )
            @adaptor.add_child( root_0, tree_for_string_literal1185 )

          end

        end
        # at line 1091:30: ( 'LIKE' | keyLIKEC | keyLIKE2 | keyLIKE4 )
        alt_310 = 4
        look_310_0 = @input.peek( 1 )

        if ( look_310_0 == T__134 )
          alt_310 = 1
        elsif ( look_310_0 == ID )
          look_310_2 = @input.peek( 2 )

          if ( ( syntactic_predicate?( :synpred505_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("LIKEC") ) ) )
            alt_310 = 2
          elsif ( ( syntactic_predicate?( :synpred506_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("LIKE2") ) ) )
            alt_310 = 3
          elsif ( ( self.input.look(1).text.upcase == ("LIKE4") ) )
            alt_310 = 4
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 310, 2 )
          end
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 310, 0 )
        end
        case alt_310
        when 1
          # at line 1091:32: 'LIKE'
          string_literal1186 = match( T__134, TOKENS_FOLLOWING_T__134_IN_condition_like_7088 )
          if @state.backtracking == 0

            tree_for_string_literal1186 = @adaptor.create_with_payload( string_literal1186 )
            @adaptor.add_child( root_0, tree_for_string_literal1186 )

          end

        when 2
          # at line 1091:41: keyLIKEC
          @state.following.push( TOKENS_FOLLOWING_keyLIKEC_IN_condition_like_7092 )
          keyLIKEC1187 = keyLIKEC
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyLIKEC1187.tree )
          end

        when 3
          # at line 1091:52: keyLIKE2
          @state.following.push( TOKENS_FOLLOWING_keyLIKE2_IN_condition_like_7096 )
          keyLIKE21188 = keyLIKE2
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyLIKE21188.tree )
          end

        when 4
          # at line 1091:63: keyLIKE4
          @state.following.push( TOKENS_FOLLOWING_keyLIKE4_IN_condition_like_7100 )
          keyLIKE41189 = keyLIKE4
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyLIKE41189.tree )
          end

        end
        @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_condition_like_7104 )
        sql_expression1190 = sql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_expression1190.tree )
        end
        # at line 1091:89: ( keyESCAPE sql_expression )?
        alt_311 = 2
        look_311_0 = @input.peek( 1 )

        if ( look_311_0 == ID )
          look_311_1 = @input.peek( 2 )

          if ( ( syntactic_predicate?( :synpred507_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("ESCAPE") ) ) )
            alt_311 = 1
          end
        end
        case alt_311
        when 1
          # at line 1091:91: keyESCAPE sql_expression
          @state.following.push( TOKENS_FOLLOWING_keyESCAPE_IN_condition_like_7108 )
          keyESCAPE1191 = keyESCAPE
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyESCAPE1191.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_condition_like_7110 )
          sql_expression1192 = sql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expression1192.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 212 )
        memoize( __method__, condition_like_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionMemeberReturnValue = define_return_scope 

    # 
    # parser rule condition_memeber
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1093:1: condition_memeber : sql_expression ( 'NOT' )? keyMEMBER ( 'OF' )? nested_table_column_name ;
    # 
    def condition_memeber
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 213 )
      return_value = ConditionMemeberReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_memeber_start_index = @input.index

      root_0 = nil
      string_literal1194 = nil
      string_literal1196 = nil
      sql_expression1193 = nil
      keyMEMBER1195 = nil
      nested_table_column_name1197 = nil

      tree_for_string_literal1194 = nil
      tree_for_string_literal1196 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1094:4: sql_expression ( 'NOT' )? keyMEMBER ( 'OF' )? nested_table_column_name
        @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_condition_memeber_7123 )
        sql_expression1193 = sql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_expression1193.tree )
        end
        # at line 1094:19: ( 'NOT' )?
        alt_312 = 2
        look_312_0 = @input.peek( 1 )

        if ( look_312_0 == T__57 )
          alt_312 = 1
        end
        case alt_312
        when 1
          # at line 1094:21: 'NOT'
          string_literal1194 = match( T__57, TOKENS_FOLLOWING_T__57_IN_condition_memeber_7127 )
          if @state.backtracking == 0

            tree_for_string_literal1194 = @adaptor.create_with_payload( string_literal1194 )
            @adaptor.add_child( root_0, tree_for_string_literal1194 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_keyMEMBER_IN_condition_memeber_7132 )
        keyMEMBER1195 = keyMEMBER
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyMEMBER1195.tree )
        end
        # at line 1094:40: ( 'OF' )?
        alt_313 = 2
        look_313_0 = @input.peek( 1 )

        if ( look_313_0 == T__106 )
          alt_313 = 1
        end
        case alt_313
        when 1
          # at line 1094:42: 'OF'
          string_literal1196 = match( T__106, TOKENS_FOLLOWING_T__106_IN_condition_memeber_7136 )
          if @state.backtracking == 0

            tree_for_string_literal1196 = @adaptor.create_with_payload( string_literal1196 )
            @adaptor.add_child( root_0, tree_for_string_literal1196 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_nested_table_column_name_IN_condition_memeber_7141 )
        nested_table_column_name1197 = nested_table_column_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, nested_table_column_name1197.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 213 )
        memoize( __method__, condition_memeber_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionBetweenReturnValue = define_return_scope 

    # 
    # parser rule condition_between
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1096:1: condition_between : sql_expression ( 'NOT' )? 'BETWEEN' sql_expression 'AND' sql_expression ;
    # 
    def condition_between
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 214 )
      return_value = ConditionBetweenReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_between_start_index = @input.index

      root_0 = nil
      string_literal1199 = nil
      string_literal1200 = nil
      string_literal1202 = nil
      sql_expression1198 = nil
      sql_expression1201 = nil
      sql_expression1203 = nil

      tree_for_string_literal1199 = nil
      tree_for_string_literal1200 = nil
      tree_for_string_literal1202 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1097:4: sql_expression ( 'NOT' )? 'BETWEEN' sql_expression 'AND' sql_expression
        @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_condition_between_7151 )
        sql_expression1198 = sql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_expression1198.tree )
        end
        # at line 1097:19: ( 'NOT' )?
        alt_314 = 2
        look_314_0 = @input.peek( 1 )

        if ( look_314_0 == T__57 )
          alt_314 = 1
        end
        case alt_314
        when 1
          # at line 1097:21: 'NOT'
          string_literal1199 = match( T__57, TOKENS_FOLLOWING_T__57_IN_condition_between_7155 )
          if @state.backtracking == 0

            tree_for_string_literal1199 = @adaptor.create_with_payload( string_literal1199 )
            @adaptor.add_child( root_0, tree_for_string_literal1199 )

          end

        end
        string_literal1200 = match( T__139, TOKENS_FOLLOWING_T__139_IN_condition_between_7160 )
        if @state.backtracking == 0

          tree_for_string_literal1200 = @adaptor.create_with_payload( string_literal1200 )
          @adaptor.add_child( root_0, tree_for_string_literal1200 )

        end
        @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_condition_between_7162 )
        sql_expression1201 = sql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_expression1201.tree )
        end
        string_literal1202 = match( T__138, TOKENS_FOLLOWING_T__138_IN_condition_between_7164 )
        if @state.backtracking == 0

          tree_for_string_literal1202 = @adaptor.create_with_payload( string_literal1202 )
          @adaptor.add_child( root_0, tree_for_string_literal1202 )

        end
        @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_condition_between_7166 )
        sql_expression1203 = sql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_expression1203.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 214 )
        memoize( __method__, condition_between_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionRegexpLikeReturnValue = define_return_scope 

    # 
    # parser rule condition_regexp_like
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1099:1: condition_regexp_like : keyREGEXP_LIKE LPAREN call_parameters RPAREN ;
    # 
    def condition_regexp_like
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 215 )
      return_value = ConditionRegexpLikeReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_regexp_like_start_index = @input.index

      root_0 = nil
      __LPAREN1205__ = nil
      __RPAREN1207__ = nil
      keyREGEXP_LIKE1204 = nil
      call_parameters1206 = nil

      tree_for_LPAREN1205 = nil
      tree_for_RPAREN1207 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1100:4: keyREGEXP_LIKE LPAREN call_parameters RPAREN
        @state.following.push( TOKENS_FOLLOWING_keyREGEXP_LIKE_IN_condition_regexp_like_7176 )
        keyREGEXP_LIKE1204 = keyREGEXP_LIKE
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyREGEXP_LIKE1204.tree )
        end
        __LPAREN1205__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_condition_regexp_like_7178 )
        if @state.backtracking == 0

          tree_for_LPAREN1205 = @adaptor.create_with_payload( __LPAREN1205__ )
          @adaptor.add_child( root_0, tree_for_LPAREN1205 )

        end
        @state.following.push( TOKENS_FOLLOWING_call_parameters_IN_condition_regexp_like_7180 )
        call_parameters1206 = call_parameters
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, call_parameters1206.tree )
        end
        __RPAREN1207__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_condition_regexp_like_7182 )
        if @state.backtracking == 0

          tree_for_RPAREN1207 = @adaptor.create_with_payload( __RPAREN1207__ )
          @adaptor.add_child( root_0, tree_for_RPAREN1207 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 215 )
        memoize( __method__, condition_regexp_like_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionSubmultisetReturnValue = define_return_scope 

    # 
    # parser rule condition_submultiset
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1102:1: condition_submultiset : nested_table_column_name ( 'NOT' )? keySUBMULTISET ( 'OF' )? nested_table_column_name ;
    # 
    def condition_submultiset
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 216 )
      return_value = ConditionSubmultisetReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_submultiset_start_index = @input.index

      root_0 = nil
      string_literal1209 = nil
      string_literal1211 = nil
      nested_table_column_name1208 = nil
      keySUBMULTISET1210 = nil
      nested_table_column_name1212 = nil

      tree_for_string_literal1209 = nil
      tree_for_string_literal1211 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1103:4: nested_table_column_name ( 'NOT' )? keySUBMULTISET ( 'OF' )? nested_table_column_name
        @state.following.push( TOKENS_FOLLOWING_nested_table_column_name_IN_condition_submultiset_7192 )
        nested_table_column_name1208 = nested_table_column_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, nested_table_column_name1208.tree )
        end
        # at line 1103:29: ( 'NOT' )?
        alt_315 = 2
        look_315_0 = @input.peek( 1 )

        if ( look_315_0 == T__57 )
          alt_315 = 1
        end
        case alt_315
        when 1
          # at line 1103:31: 'NOT'
          string_literal1209 = match( T__57, TOKENS_FOLLOWING_T__57_IN_condition_submultiset_7196 )
          if @state.backtracking == 0

            tree_for_string_literal1209 = @adaptor.create_with_payload( string_literal1209 )
            @adaptor.add_child( root_0, tree_for_string_literal1209 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_keySUBMULTISET_IN_condition_submultiset_7201 )
        keySUBMULTISET1210 = keySUBMULTISET
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keySUBMULTISET1210.tree )
        end
        # at line 1103:55: ( 'OF' )?
        alt_316 = 2
        look_316_0 = @input.peek( 1 )

        if ( look_316_0 == T__106 )
          alt_316 = 1
        end
        case alt_316
        when 1
          # at line 1103:57: 'OF'
          string_literal1211 = match( T__106, TOKENS_FOLLOWING_T__106_IN_condition_submultiset_7205 )
          if @state.backtracking == 0

            tree_for_string_literal1211 = @adaptor.create_with_payload( string_literal1211 )
            @adaptor.add_child( root_0, tree_for_string_literal1211 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_nested_table_column_name_IN_condition_submultiset_7210 )
        nested_table_column_name1212 = nested_table_column_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, nested_table_column_name1212.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 216 )
        memoize( __method__, condition_submultiset_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionEqualsPathReturnValue = define_return_scope 

    # 
    # parser rule condition_equals_path
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1105:1: condition_equals_path : keyEQUALS_PATH LPAREN column_name COMMA path_string ( COMMA correlation_integer )? RPAREN ;
    # 
    def condition_equals_path
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 217 )
      return_value = ConditionEqualsPathReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_equals_path_start_index = @input.index

      root_0 = nil
      __LPAREN1214__ = nil
      __COMMA1216__ = nil
      __COMMA1218__ = nil
      __RPAREN1220__ = nil
      keyEQUALS_PATH1213 = nil
      column_name1215 = nil
      path_string1217 = nil
      correlation_integer1219 = nil

      tree_for_LPAREN1214 = nil
      tree_for_COMMA1216 = nil
      tree_for_COMMA1218 = nil
      tree_for_RPAREN1220 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1106:4: keyEQUALS_PATH LPAREN column_name COMMA path_string ( COMMA correlation_integer )? RPAREN
        @state.following.push( TOKENS_FOLLOWING_keyEQUALS_PATH_IN_condition_equals_path_7220 )
        keyEQUALS_PATH1213 = keyEQUALS_PATH
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyEQUALS_PATH1213.tree )
        end
        __LPAREN1214__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_condition_equals_path_7222 )
        if @state.backtracking == 0

          tree_for_LPAREN1214 = @adaptor.create_with_payload( __LPAREN1214__ )
          @adaptor.add_child( root_0, tree_for_LPAREN1214 )

        end
        @state.following.push( TOKENS_FOLLOWING_column_name_IN_condition_equals_path_7224 )
        column_name1215 = column_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, column_name1215.tree )
        end
        __COMMA1216__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_condition_equals_path_7226 )
        if @state.backtracking == 0

          tree_for_COMMA1216 = @adaptor.create_with_payload( __COMMA1216__ )
          @adaptor.add_child( root_0, tree_for_COMMA1216 )

        end
        @state.following.push( TOKENS_FOLLOWING_path_string_IN_condition_equals_path_7228 )
        path_string1217 = path_string
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, path_string1217.tree )
        end
        # at line 1106:56: ( COMMA correlation_integer )?
        alt_317 = 2
        look_317_0 = @input.peek( 1 )

        if ( look_317_0 == COMMA )
          alt_317 = 1
        end
        case alt_317
        when 1
          # at line 1106:58: COMMA correlation_integer
          __COMMA1218__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_condition_equals_path_7232 )
          if @state.backtracking == 0

            tree_for_COMMA1218 = @adaptor.create_with_payload( __COMMA1218__ )
            @adaptor.add_child( root_0, tree_for_COMMA1218 )

          end
          @state.following.push( TOKENS_FOLLOWING_correlation_integer_IN_condition_equals_path_7234 )
          correlation_integer1219 = correlation_integer
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, correlation_integer1219.tree )
          end

        end
        __RPAREN1220__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_condition_equals_path_7239 )
        if @state.backtracking == 0

          tree_for_RPAREN1220 = @adaptor.create_with_payload( __RPAREN1220__ )
          @adaptor.add_child( root_0, tree_for_RPAREN1220 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 217 )
        memoize( __method__, condition_equals_path_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConditionUnderPathReturnValue = define_return_scope 

    # 
    # parser rule condition_under_path
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1108:1: condition_under_path : keyUNDER_PATH LPAREN column_name ( COMMA levels )? COMMA path_string ( COMMA correlation_integer )? RPAREN ;
    # 
    def condition_under_path
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 218 )
      return_value = ConditionUnderPathReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      condition_under_path_start_index = @input.index

      root_0 = nil
      __LPAREN1222__ = nil
      __COMMA1224__ = nil
      __COMMA1226__ = nil
      __COMMA1228__ = nil
      __RPAREN1230__ = nil
      keyUNDER_PATH1221 = nil
      column_name1223 = nil
      levels1225 = nil
      path_string1227 = nil
      correlation_integer1229 = nil

      tree_for_LPAREN1222 = nil
      tree_for_COMMA1224 = nil
      tree_for_COMMA1226 = nil
      tree_for_COMMA1228 = nil
      tree_for_RPAREN1230 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1109:4: keyUNDER_PATH LPAREN column_name ( COMMA levels )? COMMA path_string ( COMMA correlation_integer )? RPAREN
        @state.following.push( TOKENS_FOLLOWING_keyUNDER_PATH_IN_condition_under_path_7249 )
        keyUNDER_PATH1221 = keyUNDER_PATH
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyUNDER_PATH1221.tree )
        end
        __LPAREN1222__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_condition_under_path_7251 )
        if @state.backtracking == 0

          tree_for_LPAREN1222 = @adaptor.create_with_payload( __LPAREN1222__ )
          @adaptor.add_child( root_0, tree_for_LPAREN1222 )

        end
        @state.following.push( TOKENS_FOLLOWING_column_name_IN_condition_under_path_7253 )
        column_name1223 = column_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, column_name1223.tree )
        end
        # at line 1109:37: ( COMMA levels )?
        alt_318 = 2
        look_318_0 = @input.peek( 1 )

        if ( look_318_0 == COMMA )
          look_318_1 = @input.peek( 2 )

          if ( look_318_1 == NUMBER )
            alt_318 = 1
          end
        end
        case alt_318
        when 1
          # at line 1109:39: COMMA levels
          __COMMA1224__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_condition_under_path_7257 )
          if @state.backtracking == 0

            tree_for_COMMA1224 = @adaptor.create_with_payload( __COMMA1224__ )
            @adaptor.add_child( root_0, tree_for_COMMA1224 )

          end
          @state.following.push( TOKENS_FOLLOWING_levels_IN_condition_under_path_7259 )
          levels1225 = levels
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, levels1225.tree )
          end

        end
        __COMMA1226__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_condition_under_path_7264 )
        if @state.backtracking == 0

          tree_for_COMMA1226 = @adaptor.create_with_payload( __COMMA1226__ )
          @adaptor.add_child( root_0, tree_for_COMMA1226 )

        end
        @state.following.push( TOKENS_FOLLOWING_path_string_IN_condition_under_path_7266 )
        path_string1227 = path_string
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, path_string1227.tree )
        end
        # at line 1109:73: ( COMMA correlation_integer )?
        alt_319 = 2
        look_319_0 = @input.peek( 1 )

        if ( look_319_0 == COMMA )
          alt_319 = 1
        end
        case alt_319
        when 1
          # at line 1109:75: COMMA correlation_integer
          __COMMA1228__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_condition_under_path_7270 )
          if @state.backtracking == 0

            tree_for_COMMA1228 = @adaptor.create_with_payload( __COMMA1228__ )
            @adaptor.add_child( root_0, tree_for_COMMA1228 )

          end
          @state.following.push( TOKENS_FOLLOWING_correlation_integer_IN_condition_under_path_7272 )
          correlation_integer1229 = correlation_integer
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, correlation_integer1229.tree )
          end

        end
        __RPAREN1230__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_condition_under_path_7277 )
        if @state.backtracking == 0

          tree_for_RPAREN1230 = @adaptor.create_with_payload( __RPAREN1230__ )
          @adaptor.add_child( root_0, tree_for_RPAREN1230 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 218 )
        memoize( __method__, condition_under_path_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    LevelsReturnValue = define_return_scope 

    # 
    # parser rule levels
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1111:1: levels : integer ;
    # 
    def levels
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 219 )
      return_value = LevelsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      levels_start_index = @input.index

      root_0 = nil
      integer1231 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1112:4: integer
        @state.following.push( TOKENS_FOLLOWING_integer_IN_levels_7287 )
        integer1231 = integer
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, integer1231.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 219 )
        memoize( __method__, levels_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CorrelationIntegerReturnValue = define_return_scope 

    # 
    # parser rule correlation_integer
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1114:1: correlation_integer : integer ;
    # 
    def correlation_integer
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 220 )
      return_value = CorrelationIntegerReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      correlation_integer_start_index = @input.index

      root_0 = nil
      integer1232 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1115:4: integer
        @state.following.push( TOKENS_FOLLOWING_integer_IN_correlation_integer_7297 )
        integer1232 = integer
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, integer1232.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 220 )
        memoize( __method__, correlation_integer_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    PathStringReturnValue = define_return_scope 

    # 
    # parser rule path_string
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1117:1: path_string : QUOTED_STRING ;
    # 
    def path_string
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 221 )
      return_value = PathStringReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      path_string_start_index = @input.index

      root_0 = nil
      __QUOTED_STRING1233__ = nil

      tree_for_QUOTED_STRING1233 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1118:4: QUOTED_STRING
        __QUOTED_STRING1233__ = match( QUOTED_STRING, TOKENS_FOLLOWING_QUOTED_STRING_IN_path_string_7307 )
        if @state.backtracking == 0

          tree_for_QUOTED_STRING1233 = @adaptor.create_with_payload( __QUOTED_STRING1233__ )
          @adaptor.add_child( root_0, tree_for_QUOTED_STRING1233 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 221 )
        memoize( __method__, path_string_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    GroupingExpressionListReturnValue = define_return_scope 

    # 
    # parser rule grouping_expression_list
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1120:1: grouping_expression_list : expression_list ( COMMA expression_list )* ;
    # 
    def grouping_expression_list
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 222 )
      return_value = GroupingExpressionListReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      grouping_expression_list_start_index = @input.index

      root_0 = nil
      __COMMA1235__ = nil
      expression_list1234 = nil
      expression_list1236 = nil

      tree_for_COMMA1235 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1121:4: expression_list ( COMMA expression_list )*
        @state.following.push( TOKENS_FOLLOWING_expression_list_IN_grouping_expression_list_7317 )
        expression_list1234 = expression_list
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, expression_list1234.tree )
        end
        # at line 1121:20: ( COMMA expression_list )*
        while true # decision 320
          alt_320 = 2
          look_320_0 = @input.peek( 1 )

          if ( look_320_0 == COMMA )
            look_320_1 = @input.peek( 2 )

            if ( syntactic_predicate?( :synpred516_Plsql ) )
              alt_320 = 1

            end

          end
          case alt_320
          when 1
            # at line 1121:22: COMMA expression_list
            __COMMA1235__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_grouping_expression_list_7321 )
            if @state.backtracking == 0

              tree_for_COMMA1235 = @adaptor.create_with_payload( __COMMA1235__ )
              @adaptor.add_child( root_0, tree_for_COMMA1235 )

            end
            @state.following.push( TOKENS_FOLLOWING_expression_list_IN_grouping_expression_list_7323 )
            expression_list1236 = expression_list
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, expression_list1236.tree )
            end

          else
            break # out of loop for decision 320
          end
        end # loop for decision 320
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 222 )
        memoize( __method__, grouping_expression_list_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExpressionListReturnValue = define_return_scope 

    # 
    # parser rule expression_list
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1123:1: expression_list : ( LPAREN sql_expressions RPAREN | sql_expressions );
    # 
    def expression_list
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 223 )
      return_value = ExpressionListReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      expression_list_start_index = @input.index

      root_0 = nil
      __LPAREN1237__ = nil
      __RPAREN1239__ = nil
      sql_expressions1238 = nil
      sql_expressions1240 = nil

      tree_for_LPAREN1237 = nil
      tree_for_RPAREN1239 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 1124:2: ( LPAREN sql_expressions RPAREN | sql_expressions )
        alt_321 = 2
        alt_321 = @dfa321.predict( @input )
        case alt_321
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 1124:4: LPAREN sql_expressions RPAREN
          __LPAREN1237__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_expression_list_7336 )
          if @state.backtracking == 0

            tree_for_LPAREN1237 = @adaptor.create_with_payload( __LPAREN1237__ )
            @adaptor.add_child( root_0, tree_for_LPAREN1237 )

          end
          @state.following.push( TOKENS_FOLLOWING_sql_expressions_IN_expression_list_7338 )
          sql_expressions1238 = sql_expressions
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expressions1238.tree )
          end
          __RPAREN1239__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_expression_list_7340 )
          if @state.backtracking == 0

            tree_for_RPAREN1239 = @adaptor.create_with_payload( __RPAREN1239__ )
            @adaptor.add_child( root_0, tree_for_RPAREN1239 )

          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 1125:4: sql_expressions
          @state.following.push( TOKENS_FOLLOWING_sql_expressions_IN_expression_list_7345 )
          sql_expressions1240 = sql_expressions
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expressions1240.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 223 )
        memoize( __method__, expression_list_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CellReferenceReturnValue = define_return_scope 

    # 
    # parser rule cell_reference
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1127:1: cell_reference : sql_identifier ;
    # 
    def cell_reference
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 224 )
      return_value = CellReferenceReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      cell_reference_start_index = @input.index

      root_0 = nil
      sql_identifier1241 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1128:4: sql_identifier
        @state.following.push( TOKENS_FOLLOWING_sql_identifier_IN_cell_reference_7355 )
        sql_identifier1241 = sql_identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_identifier1241.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 224 )
        memoize( __method__, cell_reference_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CallParametersReturnValue = define_return_scope 

    # 
    # parser rule call_parameters
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1130:1: call_parameters : call_parameter ( COMMA call_parameter )* ;
    # 
    def call_parameters
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 225 )
      return_value = CallParametersReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      call_parameters_start_index = @input.index

      root_0 = nil
      __COMMA1243__ = nil
      call_parameter1242 = nil
      call_parameter1244 = nil

      tree_for_COMMA1243 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1131:4: call_parameter ( COMMA call_parameter )*
        @state.following.push( TOKENS_FOLLOWING_call_parameter_IN_call_parameters_7365 )
        call_parameter1242 = call_parameter
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, call_parameter1242.tree )
        end
        # at line 1131:19: ( COMMA call_parameter )*
        while true # decision 322
          alt_322 = 2
          look_322_0 = @input.peek( 1 )

          if ( look_322_0 == COMMA )
            alt_322 = 1

          end
          case alt_322
          when 1
            # at line 1131:21: COMMA call_parameter
            __COMMA1243__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_call_parameters_7369 )
            if @state.backtracking == 0

              tree_for_COMMA1243 = @adaptor.create_with_payload( __COMMA1243__ )
              @adaptor.add_child( root_0, tree_for_COMMA1243 )

            end
            @state.following.push( TOKENS_FOLLOWING_call_parameter_IN_call_parameters_7371 )
            call_parameter1244 = call_parameter
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, call_parameter1244.tree )
            end

          else
            break # out of loop for decision 322
          end
        end # loop for decision 322
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 225 )
        memoize( __method__, call_parameters_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CallParameterReturnValue = define_return_scope 

    # 
    # parser rule call_parameter
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1133:1: call_parameter : ( parameter_name ARROW )? nested_expression ;
    # 
    def call_parameter
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 226 )
      return_value = CallParameterReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      call_parameter_start_index = @input.index

      root_0 = nil
      __ARROW1246__ = nil
      parameter_name1245 = nil
      nested_expression1247 = nil

      tree_for_ARROW1246 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1134:4: ( parameter_name ARROW )? nested_expression
        # at line 1134:4: ( parameter_name ARROW )?
        alt_323 = 2
        look_323_0 = @input.peek( 1 )

        if ( look_323_0 == ID )
          look_323_1 = @input.peek( 2 )

          if ( look_323_1 == ARROW )
            alt_323 = 1
          end
        elsif ( look_323_0 == DOUBLEQUOTED_STRING )
          look_323_3 = @input.peek( 2 )

          if ( look_323_3 == ARROW )
            alt_323 = 1
          end
        end
        case alt_323
        when 1
          # at line 1134:6: parameter_name ARROW
          @state.following.push( TOKENS_FOLLOWING_parameter_name_IN_call_parameter_7386 )
          parameter_name1245 = parameter_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, parameter_name1245.tree )
          end
          __ARROW1246__ = match( ARROW, TOKENS_FOLLOWING_ARROW_IN_call_parameter_7388 )
          if @state.backtracking == 0

            tree_for_ARROW1246 = @adaptor.create_with_payload( __ARROW1246__ )
            @adaptor.add_child( root_0, tree_for_ARROW1246 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_nested_expression_IN_call_parameter_7393 )
        nested_expression1247 = nested_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, nested_expression1247.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 226 )
        memoize( __method__, call_parameter_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    RelationalOpReturnValue = define_return_scope 

    # 
    # parser rule relational_op
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1137:1: relational_op : ( EQ | LTH | GTH | NOT_EQ | LEQ | GEQ );
    # 
    def relational_op
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 227 )
      return_value = RelationalOpReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      relational_op_start_index = @input.index

      root_0 = nil
      set1248 = nil

      tree_for_set1248 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 
        set1248 = @input.look
        if @input.peek(1) == EQ || @input.peek( 1 ).between?( NOT_EQ, LEQ )
          @input.consume
          if @state.backtracking == 0
            @adaptor.add_child( root_0, @adaptor.create_with_payload( set1248 ) )
          end
          @state.error_recovery = false
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          mse = MismatchedSet( nil )
          raise mse
        end


        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 227 )
        memoize( __method__, relational_op_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ExpSetReturnValue = define_return_scope 

    # 
    # parser rule exp_set
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1141:1: exp_set : ( ( sql_expression )=> sql_expression | subquery );
    # 
    def exp_set
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 228 )
      return_value = ExpSetReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      exp_set_start_index = @input.index

      root_0 = nil
      sql_expression1249 = nil
      subquery1250 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 1142:2: ( ( sql_expression )=> sql_expression | subquery )
        alt_324 = 2
        alt_324 = @dfa324.predict( @input )
        case alt_324
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 1142:4: ( sql_expression )=> sql_expression
          @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_exp_set_7443 )
          sql_expression1249 = sql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expression1249.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 1143:4: subquery
          @state.following.push( TOKENS_FOLLOWING_subquery_IN_exp_set_7448 )
          subquery1250 = subquery
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, subquery1250.tree )
          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 228 )
        memoize( __method__, exp_set_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SubqueryReturnValue = define_return_scope 

    # 
    # parser rule subquery
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1146:1: subquery : LPAREN select_command RPAREN ;
    # 
    def subquery
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 229 )
      return_value = SubqueryReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      subquery_start_index = @input.index

      root_0 = nil
      __LPAREN1251__ = nil
      __RPAREN1253__ = nil
      select_command1252 = nil

      tree_for_LPAREN1251 = nil
      tree_for_RPAREN1253 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1147:4: LPAREN select_command RPAREN
        __LPAREN1251__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_subquery_7460 )
        if @state.backtracking == 0

          tree_for_LPAREN1251 = @adaptor.create_with_payload( __LPAREN1251__ )
          @adaptor.add_child( root_0, tree_for_LPAREN1251 )

        end
        @state.following.push( TOKENS_FOLLOWING_select_command_IN_subquery_7462 )
        select_command1252 = select_command
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, select_command1252.tree )
        end
        __RPAREN1253__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_subquery_7464 )
        if @state.backtracking == 0

          tree_for_RPAREN1253 = @adaptor.create_with_payload( __RPAREN1253__ )
          @adaptor.add_child( root_0, tree_for_RPAREN1253 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 229 )
        memoize( __method__, subquery_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ConnectClauseReturnValue = define_return_scope 

    # 
    # parser rule connect_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1150:1: connect_clause : ( 'START' 'WITH' sql_condition )? 'CONNECT' 'BY' ( 'PRIOR' sql_expression relational_op sql_expression | sql_expression relational_op sql_expression 'PRIOR' ) ( ( ( 'PRIOR' )? sql_condition )=> ( 'PRIOR' )? sql_condition | sql_expression relational_op ( 'PRIOR' )? sql_expression ( 'AND' sql_condition )? ) ( 'START' 'WITH' sql_condition )? ;
    # 
    def connect_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 230 )
      return_value = ConnectClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      connect_clause_start_index = @input.index

      root_0 = nil
      string_literal1254 = nil
      string_literal1255 = nil
      string_literal1257 = nil
      string_literal1258 = nil
      string_literal1259 = nil
      string_literal1266 = nil
      string_literal1267 = nil
      string_literal1271 = nil
      string_literal1273 = nil
      string_literal1275 = nil
      string_literal1276 = nil
      sql_condition1256 = nil
      sql_expression1260 = nil
      relational_op1261 = nil
      sql_expression1262 = nil
      sql_expression1263 = nil
      relational_op1264 = nil
      sql_expression1265 = nil
      sql_condition1268 = nil
      sql_expression1269 = nil
      relational_op1270 = nil
      sql_expression1272 = nil
      sql_condition1274 = nil
      sql_condition1277 = nil

      tree_for_string_literal1254 = nil
      tree_for_string_literal1255 = nil
      tree_for_string_literal1257 = nil
      tree_for_string_literal1258 = nil
      tree_for_string_literal1259 = nil
      tree_for_string_literal1266 = nil
      tree_for_string_literal1267 = nil
      tree_for_string_literal1271 = nil
      tree_for_string_literal1273 = nil
      tree_for_string_literal1275 = nil
      tree_for_string_literal1276 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1151:4: ( 'START' 'WITH' sql_condition )? 'CONNECT' 'BY' ( 'PRIOR' sql_expression relational_op sql_expression | sql_expression relational_op sql_expression 'PRIOR' ) ( ( ( 'PRIOR' )? sql_condition )=> ( 'PRIOR' )? sql_condition | sql_expression relational_op ( 'PRIOR' )? sql_expression ( 'AND' sql_condition )? ) ( 'START' 'WITH' sql_condition )?
        # at line 1151:4: ( 'START' 'WITH' sql_condition )?
        alt_325 = 2
        look_325_0 = @input.peek( 1 )

        if ( look_325_0 == T__128 )
          alt_325 = 1
        end
        case alt_325
        when 1
          # at line 1151:6: 'START' 'WITH' sql_condition
          string_literal1254 = match( T__128, TOKENS_FOLLOWING_T__128_IN_connect_clause_7478 )
          if @state.backtracking == 0

            tree_for_string_literal1254 = @adaptor.create_with_payload( string_literal1254 )
            @adaptor.add_child( root_0, tree_for_string_literal1254 )

          end
          string_literal1255 = match( T__78, TOKENS_FOLLOWING_T__78_IN_connect_clause_7480 )
          if @state.backtracking == 0

            tree_for_string_literal1255 = @adaptor.create_with_payload( string_literal1255 )
            @adaptor.add_child( root_0, tree_for_string_literal1255 )

          end
          @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_connect_clause_7482 )
          sql_condition1256 = sql_condition
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_condition1256.tree )
          end

        end
        string_literal1257 = match( T__129, TOKENS_FOLLOWING_T__129_IN_connect_clause_7489 )
        if @state.backtracking == 0

          tree_for_string_literal1257 = @adaptor.create_with_payload( string_literal1257 )
          @adaptor.add_child( root_0, tree_for_string_literal1257 )

        end
        string_literal1258 = match( T__108, TOKENS_FOLLOWING_T__108_IN_connect_clause_7491 )
        if @state.backtracking == 0

          tree_for_string_literal1258 = @adaptor.create_with_payload( string_literal1258 )
          @adaptor.add_child( root_0, tree_for_string_literal1258 )

        end
        # at line 1153:3: ( 'PRIOR' sql_expression relational_op sql_expression | sql_expression relational_op sql_expression 'PRIOR' )
        alt_326 = 2
        look_326_0 = @input.peek( 1 )

        if ( look_326_0 == T__141 )
          alt_326 = 1
        elsif ( look_326_0 == LPAREN || look_326_0.between?( PLUS, QUOTED_STRING ) || look_326_0.between?( ID, DOUBLEQUOTED_STRING ) || look_326_0 == T__58 || look_326_0 == T__100 || look_326_0.between?( T__110, T__111 ) || look_326_0.between?( T__116, T__117 ) || look_326_0 == T__140 || look_326_0 == T__142 )
          alt_326 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 326, 0 )
        end
        case alt_326
        when 1
          # at line 1153:5: 'PRIOR' sql_expression relational_op sql_expression
          string_literal1259 = match( T__141, TOKENS_FOLLOWING_T__141_IN_connect_clause_7498 )
          if @state.backtracking == 0

            tree_for_string_literal1259 = @adaptor.create_with_payload( string_literal1259 )
            @adaptor.add_child( root_0, tree_for_string_literal1259 )

          end
          @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_connect_clause_7500 )
          sql_expression1260 = sql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expression1260.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_relational_op_IN_connect_clause_7502 )
          relational_op1261 = relational_op
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, relational_op1261.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_connect_clause_7504 )
          sql_expression1262 = sql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expression1262.tree )
          end

        when 2
          # at line 1154:5: sql_expression relational_op sql_expression 'PRIOR'
          @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_connect_clause_7510 )
          sql_expression1263 = sql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expression1263.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_relational_op_IN_connect_clause_7512 )
          relational_op1264 = relational_op
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, relational_op1264.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_connect_clause_7514 )
          sql_expression1265 = sql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expression1265.tree )
          end
          string_literal1266 = match( T__141, TOKENS_FOLLOWING_T__141_IN_connect_clause_7516 )
          if @state.backtracking == 0

            tree_for_string_literal1266 = @adaptor.create_with_payload( string_literal1266 )
            @adaptor.add_child( root_0, tree_for_string_literal1266 )

          end

        end
        # at line 1156:3: ( ( ( 'PRIOR' )? sql_condition )=> ( 'PRIOR' )? sql_condition | sql_expression relational_op ( 'PRIOR' )? sql_expression ( 'AND' sql_condition )? )
        alt_330 = 2
        alt_330 = @dfa330.predict( @input )
        case alt_330
        when 1
          # at line 1156:5: ( ( 'PRIOR' )? sql_condition )=> ( 'PRIOR' )? sql_condition
          # at line 1156:39: ( 'PRIOR' )?
          alt_327 = 2
          look_327_0 = @input.peek( 1 )

          if ( look_327_0 == T__141 )
            look_327_1 = @input.peek( 2 )

            if ( syntactic_predicate?( :synpred530_Plsql ) )
              alt_327 = 1
            end
          end
          case alt_327
          when 1
            # at line 1156:40: 'PRIOR'
            string_literal1267 = match( T__141, TOKENS_FOLLOWING_T__141_IN_connect_clause_7542 )
            if @state.backtracking == 0

              tree_for_string_literal1267 = @adaptor.create_with_payload( string_literal1267 )
              @adaptor.add_child( root_0, tree_for_string_literal1267 )

            end

          end
          @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_connect_clause_7546 )
          sql_condition1268 = sql_condition
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_condition1268.tree )
          end

        when 2
          # at line 1157:5: sql_expression relational_op ( 'PRIOR' )? sql_expression ( 'AND' sql_condition )?
          @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_connect_clause_7552 )
          sql_expression1269 = sql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expression1269.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_relational_op_IN_connect_clause_7554 )
          relational_op1270 = relational_op
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, relational_op1270.tree )
          end
          # at line 1157:34: ( 'PRIOR' )?
          alt_328 = 2
          look_328_0 = @input.peek( 1 )

          if ( look_328_0 == T__141 )
            alt_328 = 1
          end
          case alt_328
          when 1
            # at line 1157:36: 'PRIOR'
            string_literal1271 = match( T__141, TOKENS_FOLLOWING_T__141_IN_connect_clause_7558 )
            if @state.backtracking == 0

              tree_for_string_literal1271 = @adaptor.create_with_payload( string_literal1271 )
              @adaptor.add_child( root_0, tree_for_string_literal1271 )

            end

          end
          @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_connect_clause_7563 )
          sql_expression1272 = sql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expression1272.tree )
          end
          # at line 1157:62: ( 'AND' sql_condition )?
          alt_329 = 2
          look_329_0 = @input.peek( 1 )

          if ( look_329_0 == T__138 )
            alt_329 = 1
          end
          case alt_329
          when 1
            # at line 1157:64: 'AND' sql_condition
            string_literal1273 = match( T__138, TOKENS_FOLLOWING_T__138_IN_connect_clause_7567 )
            if @state.backtracking == 0

              tree_for_string_literal1273 = @adaptor.create_with_payload( string_literal1273 )
              @adaptor.add_child( root_0, tree_for_string_literal1273 )

            end
            @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_connect_clause_7569 )
            sql_condition1274 = sql_condition
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, sql_condition1274.tree )
            end

          end

        end
        # at line 1159:3: ( 'START' 'WITH' sql_condition )?
        alt_331 = 2
        look_331_0 = @input.peek( 1 )

        if ( look_331_0 == T__128 )
          alt_331 = 1
        end
        case alt_331
        when 1
          # at line 1159:5: 'START' 'WITH' sql_condition
          string_literal1275 = match( T__128, TOKENS_FOLLOWING_T__128_IN_connect_clause_7582 )
          if @state.backtracking == 0

            tree_for_string_literal1275 = @adaptor.create_with_payload( string_literal1275 )
            @adaptor.add_child( root_0, tree_for_string_literal1275 )

          end
          string_literal1276 = match( T__78, TOKENS_FOLLOWING_T__78_IN_connect_clause_7584 )
          if @state.backtracking == 0

            tree_for_string_literal1276 = @adaptor.create_with_payload( string_literal1276 )
            @adaptor.add_child( root_0, tree_for_string_literal1276 )

          end
          @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_connect_clause_7586 )
          sql_condition1277 = sql_condition
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_condition1277.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 230 )
        memoize( __method__, connect_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    GroupClauseReturnValue = define_return_scope 

    # 
    # parser rule group_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1162:1: group_clause : 'GROUP' 'BY' sql_expression ( COMMA sql_expression )* ( 'HAVING' sql_condition )? ;
    # 
    def group_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 231 )
      return_value = GroupClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      group_clause_start_index = @input.index

      root_0 = nil
      string_literal1278 = nil
      string_literal1279 = nil
      __COMMA1281__ = nil
      string_literal1283 = nil
      sql_expression1280 = nil
      sql_expression1282 = nil
      sql_condition1284 = nil

      tree_for_string_literal1278 = nil
      tree_for_string_literal1279 = nil
      tree_for_COMMA1281 = nil
      tree_for_string_literal1283 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1163:4: 'GROUP' 'BY' sql_expression ( COMMA sql_expression )* ( 'HAVING' sql_condition )?
        string_literal1278 = match( T__130, TOKENS_FOLLOWING_T__130_IN_group_clause_7600 )
        if @state.backtracking == 0

          tree_for_string_literal1278 = @adaptor.create_with_payload( string_literal1278 )
          @adaptor.add_child( root_0, tree_for_string_literal1278 )

        end
        string_literal1279 = match( T__108, TOKENS_FOLLOWING_T__108_IN_group_clause_7602 )
        if @state.backtracking == 0

          tree_for_string_literal1279 = @adaptor.create_with_payload( string_literal1279 )
          @adaptor.add_child( root_0, tree_for_string_literal1279 )

        end
        @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_group_clause_7604 )
        sql_expression1280 = sql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_expression1280.tree )
        end
        # at line 1163:32: ( COMMA sql_expression )*
        while true # decision 332
          alt_332 = 2
          look_332_0 = @input.peek( 1 )

          if ( look_332_0 == COMMA )
            alt_332 = 1

          end
          case alt_332
          when 1
            # at line 1163:34: COMMA sql_expression
            __COMMA1281__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_group_clause_7608 )
            if @state.backtracking == 0

              tree_for_COMMA1281 = @adaptor.create_with_payload( __COMMA1281__ )
              @adaptor.add_child( root_0, tree_for_COMMA1281 )

            end
            @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_group_clause_7610 )
            sql_expression1282 = sql_expression
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, sql_expression1282.tree )
            end

          else
            break # out of loop for decision 332
          end
        end # loop for decision 332
        # at line 1163:58: ( 'HAVING' sql_condition )?
        alt_333 = 2
        look_333_0 = @input.peek( 1 )

        if ( look_333_0 == T__122 )
          alt_333 = 1
        end
        case alt_333
        when 1
          # at line 1163:60: 'HAVING' sql_condition
          string_literal1283 = match( T__122, TOKENS_FOLLOWING_T__122_IN_group_clause_7617 )
          if @state.backtracking == 0

            tree_for_string_literal1283 = @adaptor.create_with_payload( string_literal1283 )
            @adaptor.add_child( root_0, tree_for_string_literal1283 )

          end
          @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_group_clause_7619 )
          sql_condition1284 = sql_condition
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_condition1284.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 231 )
        memoize( __method__, group_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SetClauseReturnValue = define_return_scope 

    # 
    # parser rule set_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1166:1: set_clause : ( ( 'UNION' 'ALL' ) | 'INTERSECT' | 'MINUS' ) select_command ;
    # 
    def set_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 232 )
      return_value = SetClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      set_clause_start_index = @input.index

      root_0 = nil
      string_literal1285 = nil
      string_literal1286 = nil
      string_literal1287 = nil
      string_literal1288 = nil
      select_command1289 = nil

      tree_for_string_literal1285 = nil
      tree_for_string_literal1286 = nil
      tree_for_string_literal1287 = nil
      tree_for_string_literal1288 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1167:4: ( ( 'UNION' 'ALL' ) | 'INTERSECT' | 'MINUS' ) select_command
        # at line 1167:4: ( ( 'UNION' 'ALL' ) | 'INTERSECT' | 'MINUS' )
        alt_334 = 3
        case look_334 = @input.peek( 1 )
        when T__123 then alt_334 = 1
        when T__124 then alt_334 = 2
        when T__125 then alt_334 = 3
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 334, 0 )
        end
        case alt_334
        when 1
          # at line 1167:6: ( 'UNION' 'ALL' )
          # at line 1167:6: ( 'UNION' 'ALL' )
          # at line 1167:8: 'UNION' 'ALL'
          string_literal1285 = match( T__123, TOKENS_FOLLOWING_T__123_IN_set_clause_7637 )
          if @state.backtracking == 0

            tree_for_string_literal1285 = @adaptor.create_with_payload( string_literal1285 )
            @adaptor.add_child( root_0, tree_for_string_literal1285 )

          end
          string_literal1286 = match( T__119, TOKENS_FOLLOWING_T__119_IN_set_clause_7639 )
          if @state.backtracking == 0

            tree_for_string_literal1286 = @adaptor.create_with_payload( string_literal1286 )
            @adaptor.add_child( root_0, tree_for_string_literal1286 )

          end


        when 2
          # at line 1167:26: 'INTERSECT'
          string_literal1287 = match( T__124, TOKENS_FOLLOWING_T__124_IN_set_clause_7645 )
          if @state.backtracking == 0

            tree_for_string_literal1287 = @adaptor.create_with_payload( string_literal1287 )
            @adaptor.add_child( root_0, tree_for_string_literal1287 )

          end

        when 3
          # at line 1167:40: 'MINUS'
          string_literal1288 = match( T__125, TOKENS_FOLLOWING_T__125_IN_set_clause_7649 )
          if @state.backtracking == 0

            tree_for_string_literal1288 = @adaptor.create_with_payload( string_literal1288 )
            @adaptor.add_child( root_0, tree_for_string_literal1288 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_select_command_IN_set_clause_7653 )
        select_command1289 = select_command
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, select_command1289.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 232 )
        memoize( __method__, set_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    OrderClauseReturnValue = define_return_scope 

    # 
    # parser rule order_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1170:1: order_clause : 'ORDER' 'BY' sorted_def ( COMMA sorted_def )* ;
    # 
    def order_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 233 )
      return_value = OrderClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      order_clause_start_index = @input.index

      root_0 = nil
      string_literal1290 = nil
      string_literal1291 = nil
      __COMMA1293__ = nil
      sorted_def1292 = nil
      sorted_def1294 = nil

      tree_for_string_literal1290 = nil
      tree_for_string_literal1291 = nil
      tree_for_COMMA1293 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1171:4: 'ORDER' 'BY' sorted_def ( COMMA sorted_def )*
        string_literal1290 = match( T__133, TOKENS_FOLLOWING_T__133_IN_order_clause_7665 )
        if @state.backtracking == 0

          tree_for_string_literal1290 = @adaptor.create_with_payload( string_literal1290 )
          @adaptor.add_child( root_0, tree_for_string_literal1290 )

        end
        string_literal1291 = match( T__108, TOKENS_FOLLOWING_T__108_IN_order_clause_7667 )
        if @state.backtracking == 0

          tree_for_string_literal1291 = @adaptor.create_with_payload( string_literal1291 )
          @adaptor.add_child( root_0, tree_for_string_literal1291 )

        end
        @state.following.push( TOKENS_FOLLOWING_sorted_def_IN_order_clause_7669 )
        sorted_def1292 = sorted_def
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sorted_def1292.tree )
        end
        # at line 1171:28: ( COMMA sorted_def )*
        while true # decision 335
          alt_335 = 2
          look_335_0 = @input.peek( 1 )

          if ( look_335_0 == COMMA )
            alt_335 = 1

          end
          case alt_335
          when 1
            # at line 1171:30: COMMA sorted_def
            __COMMA1293__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_order_clause_7673 )
            if @state.backtracking == 0

              tree_for_COMMA1293 = @adaptor.create_with_payload( __COMMA1293__ )
              @adaptor.add_child( root_0, tree_for_COMMA1293 )

            end
            @state.following.push( TOKENS_FOLLOWING_sorted_def_IN_order_clause_7675 )
            sorted_def1294 = sorted_def
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, sorted_def1294.tree )
            end

          else
            break # out of loop for decision 335
          end
        end # loop for decision 335
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 233 )
        memoize( __method__, order_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SortedDefReturnValue = define_return_scope 

    # 
    # parser rule sorted_def
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1174:1: sorted_def : ( ( sql_expression )=> sql_expression | ( NUMBER )=> NUMBER ) ( 'ASC' | 'DESC' )? ;
    # 
    def sorted_def
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 234 )
      return_value = SortedDefReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      sorted_def_start_index = @input.index

      root_0 = nil
      __NUMBER1296__ = nil
      set1297 = nil
      sql_expression1295 = nil

      tree_for_NUMBER1296 = nil
      tree_for_set1297 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1175:4: ( ( sql_expression )=> sql_expression | ( NUMBER )=> NUMBER ) ( 'ASC' | 'DESC' )?
        # at line 1175:4: ( ( sql_expression )=> sql_expression | ( NUMBER )=> NUMBER )
        alt_336 = 2
        alt_336 = @dfa336.predict( @input )
        case alt_336
        when 1
          # at line 1175:6: ( sql_expression )=> sql_expression
          @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_sorted_def_7699 )
          sql_expression1295 = sql_expression
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, sql_expression1295.tree )
          end

        when 2
          # at line 1175:45: ( NUMBER )=> NUMBER
          __NUMBER1296__ = match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_sorted_def_7711 )
          if @state.backtracking == 0

            tree_for_NUMBER1296 = @adaptor.create_with_payload( __NUMBER1296__ )
            @adaptor.add_child( root_0, tree_for_NUMBER1296 )

          end

        end
        # at line 1175:68: ( 'ASC' | 'DESC' )?
        alt_337 = 2
        look_337_0 = @input.peek( 1 )

        if ( look_337_0.between?( T__135, T__136 ) )
          alt_337 = 1
        end
        case alt_337
        when 1
          # at line 
          set1297 = @input.look
          if @input.peek( 1 ).between?( T__135, T__136 )
            @input.consume
            if @state.backtracking == 0
              @adaptor.add_child( root_0, @adaptor.create_with_payload( set1297 ) )
            end
            @state.error_recovery = false
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            mse = MismatchedSet( nil )
            raise mse
          end



        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 234 )
        memoize( __method__, sorted_def_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    UpdateClauseReturnValue = define_return_scope 

    # 
    # parser rule update_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1178:1: update_clause : 'FOR' 'UPDATE' ( 'OF' column_name ( COMMA column_name )* )? ( 'NOWAIT' )? ;
    # 
    def update_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 235 )
      return_value = UpdateClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      update_clause_start_index = @input.index

      root_0 = nil
      string_literal1298 = nil
      string_literal1299 = nil
      string_literal1300 = nil
      __COMMA1302__ = nil
      string_literal1304 = nil
      column_name1301 = nil
      column_name1303 = nil

      tree_for_string_literal1298 = nil
      tree_for_string_literal1299 = nil
      tree_for_string_literal1300 = nil
      tree_for_COMMA1302 = nil
      tree_for_string_literal1304 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1179:4: 'FOR' 'UPDATE' ( 'OF' column_name ( COMMA column_name )* )? ( 'NOWAIT' )?
        string_literal1298 = match( T__112, TOKENS_FOLLOWING_T__112_IN_update_clause_7735 )
        if @state.backtracking == 0

          tree_for_string_literal1298 = @adaptor.create_with_payload( string_literal1298 )
          @adaptor.add_child( root_0, tree_for_string_literal1298 )

        end
        string_literal1299 = match( T__132, TOKENS_FOLLOWING_T__132_IN_update_clause_7737 )
        if @state.backtracking == 0

          tree_for_string_literal1299 = @adaptor.create_with_payload( string_literal1299 )
          @adaptor.add_child( root_0, tree_for_string_literal1299 )

        end
        # at line 1179:19: ( 'OF' column_name ( COMMA column_name )* )?
        alt_339 = 2
        look_339_0 = @input.peek( 1 )

        if ( look_339_0 == T__106 )
          alt_339 = 1
        end
        case alt_339
        when 1
          # at line 1179:21: 'OF' column_name ( COMMA column_name )*
          string_literal1300 = match( T__106, TOKENS_FOLLOWING_T__106_IN_update_clause_7741 )
          if @state.backtracking == 0

            tree_for_string_literal1300 = @adaptor.create_with_payload( string_literal1300 )
            @adaptor.add_child( root_0, tree_for_string_literal1300 )

          end
          @state.following.push( TOKENS_FOLLOWING_column_name_IN_update_clause_7743 )
          column_name1301 = column_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, column_name1301.tree )
          end
          # at line 1179:38: ( COMMA column_name )*
          while true # decision 338
            alt_338 = 2
            look_338_0 = @input.peek( 1 )

            if ( look_338_0 == COMMA )
              alt_338 = 1

            end
            case alt_338
            when 1
              # at line 1179:40: COMMA column_name
              __COMMA1302__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_update_clause_7747 )
              if @state.backtracking == 0

                tree_for_COMMA1302 = @adaptor.create_with_payload( __COMMA1302__ )
                @adaptor.add_child( root_0, tree_for_COMMA1302 )

              end
              @state.following.push( TOKENS_FOLLOWING_column_name_IN_update_clause_7749 )
              column_name1303 = column_name
              @state.following.pop
              if @state.backtracking == 0
                @adaptor.add_child( root_0, column_name1303.tree )
              end

            else
              break # out of loop for decision 338
            end
          end # loop for decision 338

        end
        # at line 1179:64: ( 'NOWAIT' )?
        alt_340 = 2
        look_340_0 = @input.peek( 1 )

        if ( look_340_0 == T__137 )
          alt_340 = 1
        end
        case alt_340
        when 1
          # at line 1179:66: 'NOWAIT'
          string_literal1304 = match( T__137, TOKENS_FOLLOWING_T__137_IN_update_clause_7759 )
          if @state.backtracking == 0

            tree_for_string_literal1304 = @adaptor.create_with_payload( string_literal1304 )
            @adaptor.add_child( root_0, tree_for_string_literal1304 )

          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 235 )
        memoize( __method__, update_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    InsertCommandReturnValue = define_return_scope 

    # 
    # parser rule insert_command
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1182:1: insert_command : 'INSERT' 'INTO' table_reference_list ( LPAREN column_specs RPAREN )? ( 'VALUES' LPAREN plsql_expressions RPAREN | select_statement ) ( returning_clause )? ;
    # 
    def insert_command
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 236 )
      return_value = InsertCommandReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      insert_command_start_index = @input.index

      root_0 = nil
      string_literal1305 = nil
      string_literal1306 = nil
      __LPAREN1308__ = nil
      __RPAREN1310__ = nil
      string_literal1311 = nil
      __LPAREN1312__ = nil
      __RPAREN1314__ = nil
      table_reference_list1307 = nil
      column_specs1309 = nil
      plsql_expressions1313 = nil
      select_statement1315 = nil
      returning_clause1316 = nil

      tree_for_string_literal1305 = nil
      tree_for_string_literal1306 = nil
      tree_for_LPAREN1308 = nil
      tree_for_RPAREN1310 = nil
      tree_for_string_literal1311 = nil
      tree_for_LPAREN1312 = nil
      tree_for_RPAREN1314 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1183:4: 'INSERT' 'INTO' table_reference_list ( LPAREN column_specs RPAREN )? ( 'VALUES' LPAREN plsql_expressions RPAREN | select_statement ) ( returning_clause )?
        string_literal1305 = match( T__147, TOKENS_FOLLOWING_T__147_IN_insert_command_7773 )
        if @state.backtracking == 0

          tree_for_string_literal1305 = @adaptor.create_with_payload( string_literal1305 )
          @adaptor.add_child( root_0, tree_for_string_literal1305 )

        end
        string_literal1306 = match( T__120, TOKENS_FOLLOWING_T__120_IN_insert_command_7775 )
        if @state.backtracking == 0

          tree_for_string_literal1306 = @adaptor.create_with_payload( string_literal1306 )
          @adaptor.add_child( root_0, tree_for_string_literal1306 )

        end
        @state.following.push( TOKENS_FOLLOWING_table_reference_list_IN_insert_command_7777 )
        table_reference_list1307 = table_reference_list
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, table_reference_list1307.tree )
        end
        # at line 1184:3: ( LPAREN column_specs RPAREN )?
        alt_341 = 2
        look_341_0 = @input.peek( 1 )

        if ( look_341_0 == LPAREN )
          alt_341 = 1
        end
        case alt_341
        when 1
          # at line 1184:5: LPAREN column_specs RPAREN
          __LPAREN1308__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_insert_command_7783 )
          if @state.backtracking == 0

            tree_for_LPAREN1308 = @adaptor.create_with_payload( __LPAREN1308__ )
            @adaptor.add_child( root_0, tree_for_LPAREN1308 )

          end
          @state.following.push( TOKENS_FOLLOWING_column_specs_IN_insert_command_7785 )
          column_specs1309 = column_specs
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, column_specs1309.tree )
          end
          __RPAREN1310__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_insert_command_7787 )
          if @state.backtracking == 0

            tree_for_RPAREN1310 = @adaptor.create_with_payload( __RPAREN1310__ )
            @adaptor.add_child( root_0, tree_for_RPAREN1310 )

          end

        end
        # at line 1185:3: ( 'VALUES' LPAREN plsql_expressions RPAREN | select_statement )
        alt_342 = 2
        look_342_0 = @input.peek( 1 )

        if ( look_342_0 == T__148 )
          alt_342 = 1
        elsif ( look_342_0 == T__116 )
          alt_342 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 342, 0 )
        end
        case alt_342
        when 1
          # at line 1185:5: 'VALUES' LPAREN plsql_expressions RPAREN
          string_literal1311 = match( T__148, TOKENS_FOLLOWING_T__148_IN_insert_command_7796 )
          if @state.backtracking == 0

            tree_for_string_literal1311 = @adaptor.create_with_payload( string_literal1311 )
            @adaptor.add_child( root_0, tree_for_string_literal1311 )

          end
          __LPAREN1312__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_insert_command_7798 )
          if @state.backtracking == 0

            tree_for_LPAREN1312 = @adaptor.create_with_payload( __LPAREN1312__ )
            @adaptor.add_child( root_0, tree_for_LPAREN1312 )

          end
          @state.following.push( TOKENS_FOLLOWING_plsql_expressions_IN_insert_command_7800 )
          plsql_expressions1313 = plsql_expressions
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, plsql_expressions1313.tree )
          end
          __RPAREN1314__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_insert_command_7802 )
          if @state.backtracking == 0

            tree_for_RPAREN1314 = @adaptor.create_with_payload( __RPAREN1314__ )
            @adaptor.add_child( root_0, tree_for_RPAREN1314 )

          end

        when 2
          # at line 1186:5: select_statement
          @state.following.push( TOKENS_FOLLOWING_select_statement_IN_insert_command_7808 )
          select_statement1315 = select_statement
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, select_statement1315.tree )
          end

        end
        # at line 1188:3: ( returning_clause )?
        alt_343 = 2
        look_343_0 = @input.peek( 1 )

        if ( look_343_0.between?( T__164, T__165 ) )
          alt_343 = 1
        end
        case alt_343
        when 1
          # at line 1188:5: returning_clause
          @state.following.push( TOKENS_FOLLOWING_returning_clause_IN_insert_command_7818 )
          returning_clause1316 = returning_clause
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, returning_clause1316.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 236 )
        memoize( __method__, insert_command_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    UpdateCommandReturnValue = define_return_scope 

    # 
    # parser rule update_command
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1191:1: update_command : 'UPDATE' selected_table 'SET' ( update_nested_column_specs | update_column_specs ) ( 'WHERE' ( keyCURRENT_OF cursor_name | sql_condition ) )? ( returning_clause )? ;
    # 
    def update_command
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 237 )
      return_value = UpdateCommandReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      update_command_start_index = @input.index

      root_0 = nil
      string_literal1317 = nil
      string_literal1319 = nil
      string_literal1322 = nil
      selected_table1318 = nil
      update_nested_column_specs1320 = nil
      update_column_specs1321 = nil
      keyCURRENT_OF1323 = nil
      cursor_name1324 = nil
      sql_condition1325 = nil
      returning_clause1326 = nil

      tree_for_string_literal1317 = nil
      tree_for_string_literal1319 = nil
      tree_for_string_literal1322 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1192:4: 'UPDATE' selected_table 'SET' ( update_nested_column_specs | update_column_specs ) ( 'WHERE' ( keyCURRENT_OF cursor_name | sql_condition ) )? ( returning_clause )?
        string_literal1317 = match( T__132, TOKENS_FOLLOWING_T__132_IN_update_command_7832 )
        if @state.backtracking == 0

          tree_for_string_literal1317 = @adaptor.create_with_payload( string_literal1317 )
          @adaptor.add_child( root_0, tree_for_string_literal1317 )

        end
        @state.following.push( TOKENS_FOLLOWING_selected_table_IN_update_command_7834 )
        selected_table1318 = selected_table
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, selected_table1318.tree )
        end
        string_literal1319 = match( T__87, TOKENS_FOLLOWING_T__87_IN_update_command_7838 )
        if @state.backtracking == 0

          tree_for_string_literal1319 = @adaptor.create_with_payload( string_literal1319 )
          @adaptor.add_child( root_0, tree_for_string_literal1319 )

        end
        # at line 1194:3: ( update_nested_column_specs | update_column_specs )
        alt_344 = 2
        look_344_0 = @input.peek( 1 )

        if ( look_344_0 == LPAREN )
          alt_344 = 1
        elsif ( look_344_0.between?( ID, DOUBLEQUOTED_STRING ) || look_344_0 == T__100 )
          alt_344 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 344, 0 )
        end
        case alt_344
        when 1
          # at line 1194:5: update_nested_column_specs
          @state.following.push( TOKENS_FOLLOWING_update_nested_column_specs_IN_update_command_7845 )
          update_nested_column_specs1320 = update_nested_column_specs
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, update_nested_column_specs1320.tree )
          end

        when 2
          # at line 1195:5: update_column_specs
          @state.following.push( TOKENS_FOLLOWING_update_column_specs_IN_update_command_7851 )
          update_column_specs1321 = update_column_specs
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, update_column_specs1321.tree )
          end

        end
        # at line 1197:3: ( 'WHERE' ( keyCURRENT_OF cursor_name | sql_condition ) )?
        alt_346 = 2
        look_346_0 = @input.peek( 1 )

        if ( look_346_0 == T__127 )
          alt_346 = 1
        end
        case alt_346
        when 1
          # at line 1197:5: 'WHERE' ( keyCURRENT_OF cursor_name | sql_condition )
          string_literal1322 = match( T__127, TOKENS_FOLLOWING_T__127_IN_update_command_7861 )
          if @state.backtracking == 0

            tree_for_string_literal1322 = @adaptor.create_with_payload( string_literal1322 )
            @adaptor.add_child( root_0, tree_for_string_literal1322 )

          end
          # at line 1198:4: ( keyCURRENT_OF cursor_name | sql_condition )
          alt_345 = 2
          look_345_0 = @input.peek( 1 )

          if ( look_345_0 == ID )
            case look_345 = @input.peek( 2 )
            when DOT, LPAREN, PLUS, MINUS, ASTERISK, EQ, DOUBLEVERTBAR, DIVIDE, EXPONENT, NOT_EQ, GTH, GEQ, LTH, LEQ, T__52, T__57, T__102, T__134, T__139 then alt_345 = 2
            when ID then look_345_3 = @input.peek( 3 )

            if ( look_345_3 == LPAREN || look_345_3.between?( PLUS, QUOTED_STRING ) || look_345_3.between?( ID, DOUBLEQUOTED_STRING ) || look_345_3 == T__58 || look_345_3 == T__100 || look_345_3 == T__106 || look_345_3.between?( T__110, T__111 ) || look_345_3.between?( T__116, T__117 ) || look_345_3 == T__140 || look_345_3 == T__142 )
              alt_345 = 2
            elsif ( look_345_3 == EOF || look_345_3 == SEMI || look_345_3.between?( T__164, T__165 ) )
              alt_345 = 1
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 345, 3 )
            end
            when DOUBLEQUOTED_STRING then alt_345 = 1
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 345, 1 )
            end
          elsif ( look_345_0 == LPAREN || look_345_0.between?( PLUS, QUOTED_STRING ) || look_345_0 == DOUBLEQUOTED_STRING || look_345_0.between?( T__57, T__58 ) || look_345_0 == T__100 || look_345_0.between?( T__110, T__111 ) || look_345_0.between?( T__116, T__117 ) || look_345_0.between?( T__140, T__142 ) || look_345_0 == T__144 || look_345_0 == T__146 )
            alt_345 = 2
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 345, 0 )
          end
          case alt_345
          when 1
            # at line 1198:6: keyCURRENT_OF cursor_name
            @state.following.push( TOKENS_FOLLOWING_keyCURRENT_OF_IN_update_command_7868 )
            keyCURRENT_OF1323 = keyCURRENT_OF
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyCURRENT_OF1323.tree )
            end
            @state.following.push( TOKENS_FOLLOWING_cursor_name_IN_update_command_7870 )
            cursor_name1324 = cursor_name
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, cursor_name1324.tree )
            end

          when 2
            # at line 1199:6: sql_condition
            @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_update_command_7877 )
            sql_condition1325 = sql_condition
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, sql_condition1325.tree )
            end

          end

        end
        # at line 1202:3: ( returning_clause )?
        alt_347 = 2
        look_347_0 = @input.peek( 1 )

        if ( look_347_0.between?( T__164, T__165 ) )
          alt_347 = 1
        end
        case alt_347
        when 1
          # at line 1202:5: returning_clause
          @state.following.push( TOKENS_FOLLOWING_returning_clause_IN_update_command_7893 )
          returning_clause1326 = returning_clause
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, returning_clause1326.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 237 )
        memoize( __method__, update_command_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    UpdateColumnSpecsReturnValue = define_return_scope 

    # 
    # parser rule update_column_specs
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1205:1: update_column_specs : update_column_spec ( COMMA update_column_spec )* ;
    # 
    def update_column_specs
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 238 )
      return_value = UpdateColumnSpecsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      update_column_specs_start_index = @input.index

      root_0 = nil
      __COMMA1328__ = nil
      update_column_spec1327 = nil
      update_column_spec1329 = nil

      tree_for_COMMA1328 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1206:4: update_column_spec ( COMMA update_column_spec )*
        @state.following.push( TOKENS_FOLLOWING_update_column_spec_IN_update_column_specs_7907 )
        update_column_spec1327 = update_column_spec
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, update_column_spec1327.tree )
        end
        # at line 1206:23: ( COMMA update_column_spec )*
        while true # decision 348
          alt_348 = 2
          look_348_0 = @input.peek( 1 )

          if ( look_348_0 == COMMA )
            alt_348 = 1

          end
          case alt_348
          when 1
            # at line 1206:25: COMMA update_column_spec
            __COMMA1328__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_update_column_specs_7911 )
            if @state.backtracking == 0

              tree_for_COMMA1328 = @adaptor.create_with_payload( __COMMA1328__ )
              @adaptor.add_child( root_0, tree_for_COMMA1328 )

            end
            @state.following.push( TOKENS_FOLLOWING_update_column_spec_IN_update_column_specs_7913 )
            update_column_spec1329 = update_column_spec
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, update_column_spec1329.tree )
            end

          else
            break # out of loop for decision 348
          end
        end # loop for decision 348
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 238 )
        memoize( __method__, update_column_specs_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    UpdateColumnSpecReturnValue = define_return_scope 

    # 
    # parser rule update_column_spec
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1209:1: update_column_spec : column_spec EQ sql_expression ;
    # 
    def update_column_spec
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 239 )
      return_value = UpdateColumnSpecReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      update_column_spec_start_index = @input.index

      root_0 = nil
      __EQ1331__ = nil
      column_spec1330 = nil
      sql_expression1332 = nil

      tree_for_EQ1331 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1210:4: column_spec EQ sql_expression
        @state.following.push( TOKENS_FOLLOWING_column_spec_IN_update_column_spec_7927 )
        column_spec1330 = column_spec
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, column_spec1330.tree )
        end
        __EQ1331__ = match( EQ, TOKENS_FOLLOWING_EQ_IN_update_column_spec_7929 )
        if @state.backtracking == 0

          tree_for_EQ1331 = @adaptor.create_with_payload( __EQ1331__ )
          @adaptor.add_child( root_0, tree_for_EQ1331 )

        end
        @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_update_column_spec_7931 )
        sql_expression1332 = sql_expression
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, sql_expression1332.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 239 )
        memoize( __method__, update_column_spec_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    UpdateNestedColumnSpecsReturnValue = define_return_scope 

    # 
    # parser rule update_nested_column_specs
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1213:1: update_nested_column_specs : update_nested_column_spec ( COMMA update_nested_column_spec )* ;
    # 
    def update_nested_column_specs
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 240 )
      return_value = UpdateNestedColumnSpecsReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      update_nested_column_specs_start_index = @input.index

      root_0 = nil
      __COMMA1334__ = nil
      update_nested_column_spec1333 = nil
      update_nested_column_spec1335 = nil

      tree_for_COMMA1334 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1214:4: update_nested_column_spec ( COMMA update_nested_column_spec )*
        @state.following.push( TOKENS_FOLLOWING_update_nested_column_spec_IN_update_nested_column_specs_7942 )
        update_nested_column_spec1333 = update_nested_column_spec
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, update_nested_column_spec1333.tree )
        end
        # at line 1214:30: ( COMMA update_nested_column_spec )*
        while true # decision 349
          alt_349 = 2
          look_349_0 = @input.peek( 1 )

          if ( look_349_0 == COMMA )
            alt_349 = 1

          end
          case alt_349
          when 1
            # at line 1214:32: COMMA update_nested_column_spec
            __COMMA1334__ = match( COMMA, TOKENS_FOLLOWING_COMMA_IN_update_nested_column_specs_7946 )
            if @state.backtracking == 0

              tree_for_COMMA1334 = @adaptor.create_with_payload( __COMMA1334__ )
              @adaptor.add_child( root_0, tree_for_COMMA1334 )

            end
            @state.following.push( TOKENS_FOLLOWING_update_nested_column_spec_IN_update_nested_column_specs_7948 )
            update_nested_column_spec1335 = update_nested_column_spec
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, update_nested_column_spec1335.tree )
            end

          else
            break # out of loop for decision 349
          end
        end # loop for decision 349
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 240 )
        memoize( __method__, update_nested_column_specs_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    UpdateNestedColumnSpecReturnValue = define_return_scope 

    # 
    # parser rule update_nested_column_spec
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1217:1: update_nested_column_spec : LPAREN column_specs RPAREN EQ subquery ;
    # 
    def update_nested_column_spec
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 241 )
      return_value = UpdateNestedColumnSpecReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      update_nested_column_spec_start_index = @input.index

      root_0 = nil
      __LPAREN1336__ = nil
      __RPAREN1338__ = nil
      __EQ1339__ = nil
      column_specs1337 = nil
      subquery1340 = nil

      tree_for_LPAREN1336 = nil
      tree_for_RPAREN1338 = nil
      tree_for_EQ1339 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1218:4: LPAREN column_specs RPAREN EQ subquery
        __LPAREN1336__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_update_nested_column_spec_7962 )
        if @state.backtracking == 0

          tree_for_LPAREN1336 = @adaptor.create_with_payload( __LPAREN1336__ )
          @adaptor.add_child( root_0, tree_for_LPAREN1336 )

        end
        @state.following.push( TOKENS_FOLLOWING_column_specs_IN_update_nested_column_spec_7964 )
        column_specs1337 = column_specs
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, column_specs1337.tree )
        end
        __RPAREN1338__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_update_nested_column_spec_7966 )
        if @state.backtracking == 0

          tree_for_RPAREN1338 = @adaptor.create_with_payload( __RPAREN1338__ )
          @adaptor.add_child( root_0, tree_for_RPAREN1338 )

        end
        __EQ1339__ = match( EQ, TOKENS_FOLLOWING_EQ_IN_update_nested_column_spec_7968 )
        if @state.backtracking == 0

          tree_for_EQ1339 = @adaptor.create_with_payload( __EQ1339__ )
          @adaptor.add_child( root_0, tree_for_EQ1339 )

        end
        @state.following.push( TOKENS_FOLLOWING_subquery_IN_update_nested_column_spec_7970 )
        subquery1340 = subquery
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, subquery1340.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 241 )
        memoize( __method__, update_nested_column_spec_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    DeleteCommandReturnValue = define_return_scope 

    # 
    # parser rule delete_command
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1221:1: delete_command : 'DELETE' ( 'FROM' )? selected_table ( 'WHERE' ( keyCURRENT_OF cursor_name | sql_condition ) )? ( returning_clause )? ;
    # 
    def delete_command
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 242 )
      return_value = DeleteCommandReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      delete_command_start_index = @input.index

      root_0 = nil
      string_literal1341 = nil
      string_literal1342 = nil
      string_literal1344 = nil
      selected_table1343 = nil
      keyCURRENT_OF1345 = nil
      cursor_name1346 = nil
      sql_condition1347 = nil
      returning_clause1348 = nil

      tree_for_string_literal1341 = nil
      tree_for_string_literal1342 = nil
      tree_for_string_literal1344 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1222:4: 'DELETE' ( 'FROM' )? selected_table ( 'WHERE' ( keyCURRENT_OF cursor_name | sql_condition ) )? ( returning_clause )?
        string_literal1341 = match( T__145, TOKENS_FOLLOWING_T__145_IN_delete_command_7981 )
        if @state.backtracking == 0

          tree_for_string_literal1341 = @adaptor.create_with_payload( string_literal1341 )
          @adaptor.add_child( root_0, tree_for_string_literal1341 )

        end
        # at line 1222:13: ( 'FROM' )?
        alt_350 = 2
        look_350_0 = @input.peek( 1 )

        if ( look_350_0 == T__121 )
          alt_350 = 1
        end
        case alt_350
        when 1
          # at line 1222:15: 'FROM'
          string_literal1342 = match( T__121, TOKENS_FOLLOWING_T__121_IN_delete_command_7985 )
          if @state.backtracking == 0

            tree_for_string_literal1342 = @adaptor.create_with_payload( string_literal1342 )
            @adaptor.add_child( root_0, tree_for_string_literal1342 )

          end

        end
        @state.following.push( TOKENS_FOLLOWING_selected_table_IN_delete_command_7990 )
        selected_table1343 = selected_table
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, selected_table1343.tree )
        end
        # at line 1223:3: ( 'WHERE' ( keyCURRENT_OF cursor_name | sql_condition ) )?
        alt_352 = 2
        look_352_0 = @input.peek( 1 )

        if ( look_352_0 == T__127 )
          alt_352 = 1
        end
        case alt_352
        when 1
          # at line 1223:5: 'WHERE' ( keyCURRENT_OF cursor_name | sql_condition )
          string_literal1344 = match( T__127, TOKENS_FOLLOWING_T__127_IN_delete_command_7996 )
          if @state.backtracking == 0

            tree_for_string_literal1344 = @adaptor.create_with_payload( string_literal1344 )
            @adaptor.add_child( root_0, tree_for_string_literal1344 )

          end
          # at line 1224:4: ( keyCURRENT_OF cursor_name | sql_condition )
          alt_351 = 2
          look_351_0 = @input.peek( 1 )

          if ( look_351_0 == ID )
            case look_351 = @input.peek( 2 )
            when DOT, LPAREN, PLUS, MINUS, ASTERISK, EQ, DOUBLEVERTBAR, DIVIDE, EXPONENT, NOT_EQ, GTH, GEQ, LTH, LEQ, T__52, T__57, T__102, T__134, T__139 then alt_351 = 2
            when ID then look_351_3 = @input.peek( 3 )

            if ( look_351_3 == LPAREN || look_351_3.between?( PLUS, QUOTED_STRING ) || look_351_3.between?( ID, DOUBLEQUOTED_STRING ) || look_351_3 == T__58 || look_351_3 == T__100 || look_351_3 == T__106 || look_351_3.between?( T__110, T__111 ) || look_351_3.between?( T__116, T__117 ) || look_351_3 == T__140 || look_351_3 == T__142 )
              alt_351 = 2
            elsif ( look_351_3 == EOF || look_351_3 == SEMI || look_351_3.between?( T__164, T__165 ) )
              alt_351 = 1
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 351, 3 )
            end
            when DOUBLEQUOTED_STRING then alt_351 = 1
            else
              @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

              raise NoViableAlternative( "", 351, 1 )
            end
          elsif ( look_351_0 == LPAREN || look_351_0.between?( PLUS, QUOTED_STRING ) || look_351_0 == DOUBLEQUOTED_STRING || look_351_0.between?( T__57, T__58 ) || look_351_0 == T__100 || look_351_0.between?( T__110, T__111 ) || look_351_0.between?( T__116, T__117 ) || look_351_0.between?( T__140, T__142 ) || look_351_0 == T__144 || look_351_0 == T__146 )
            alt_351 = 2
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 351, 0 )
          end
          case alt_351
          when 1
            # at line 1224:6: keyCURRENT_OF cursor_name
            @state.following.push( TOKENS_FOLLOWING_keyCURRENT_OF_IN_delete_command_8003 )
            keyCURRENT_OF1345 = keyCURRENT_OF
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, keyCURRENT_OF1345.tree )
            end
            @state.following.push( TOKENS_FOLLOWING_cursor_name_IN_delete_command_8005 )
            cursor_name1346 = cursor_name
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, cursor_name1346.tree )
            end

          when 2
            # at line 1225:6: sql_condition
            @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_delete_command_8012 )
            sql_condition1347 = sql_condition
            @state.following.pop
            if @state.backtracking == 0
              @adaptor.add_child( root_0, sql_condition1347.tree )
            end

          end

        end
        # at line 1228:3: ( returning_clause )?
        alt_353 = 2
        look_353_0 = @input.peek( 1 )

        if ( look_353_0.between?( T__164, T__165 ) )
          alt_353 = 1
        end
        case alt_353
        when 1
          # at line 1228:5: returning_clause
          @state.following.push( TOKENS_FOLLOWING_returning_clause_IN_delete_command_8028 )
          returning_clause1348 = returning_clause
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, returning_clause1348.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 242 )
        memoize( __method__, delete_command_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    ReturningClauseReturnValue = define_return_scope 

    # 
    # parser rule returning_clause
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1231:1: returning_clause : ( keyRETURN | keyRETURNING ) select_list ( keyBULK keyCOLLECT )? 'INTO' lvalues ;
    # 
    def returning_clause
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 243 )
      return_value = ReturningClauseReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      returning_clause_start_index = @input.index

      root_0 = nil
      string_literal1354 = nil
      keyRETURN1349 = nil
      keyRETURNING1350 = nil
      select_list1351 = nil
      keyBULK1352 = nil
      keyCOLLECT1353 = nil
      lvalues1355 = nil

      tree_for_string_literal1354 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1232:4: ( keyRETURN | keyRETURNING ) select_list ( keyBULK keyCOLLECT )? 'INTO' lvalues
        # at line 1232:4: ( keyRETURN | keyRETURNING )
        alt_354 = 2
        look_354_0 = @input.peek( 1 )

        if ( look_354_0 == T__164 )
          alt_354 = 1
        elsif ( look_354_0 == T__165 )
          alt_354 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 354, 0 )
        end
        case alt_354
        when 1
          # at line 1232:6: keyRETURN
          @state.following.push( TOKENS_FOLLOWING_keyRETURN_IN_returning_clause_8044 )
          keyRETURN1349 = keyRETURN
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyRETURN1349.tree )
          end

        when 2
          # at line 1232:18: keyRETURNING
          @state.following.push( TOKENS_FOLLOWING_keyRETURNING_IN_returning_clause_8048 )
          keyRETURNING1350 = keyRETURNING
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyRETURNING1350.tree )
          end

        end
        @state.following.push( TOKENS_FOLLOWING_select_list_IN_returning_clause_8052 )
        select_list1351 = select_list
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, select_list1351.tree )
        end
        # at line 1232:45: ( keyBULK keyCOLLECT )?
        alt_355 = 2
        look_355_0 = @input.peek( 1 )

        if ( look_355_0 == ID )
          alt_355 = 1
        end
        case alt_355
        when 1
          # at line 1232:47: keyBULK keyCOLLECT
          @state.following.push( TOKENS_FOLLOWING_keyBULK_IN_returning_clause_8056 )
          keyBULK1352 = keyBULK
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyBULK1352.tree )
          end
          @state.following.push( TOKENS_FOLLOWING_keyCOLLECT_IN_returning_clause_8058 )
          keyCOLLECT1353 = keyCOLLECT
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyCOLLECT1353.tree )
          end

        end
        string_literal1354 = match( T__120, TOKENS_FOLLOWING_T__120_IN_returning_clause_8063 )
        if @state.backtracking == 0

          tree_for_string_literal1354 = @adaptor.create_with_payload( string_literal1354 )
          @adaptor.add_child( root_0, tree_for_string_literal1354 )

        end
        @state.following.push( TOKENS_FOLLOWING_lvalues_IN_returning_clause_8065 )
        lvalues1355 = lvalues
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, lvalues1355.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 243 )
        memoize( __method__, returning_clause_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SetTransactionCommandReturnValue = define_return_scope 

    # 
    # parser rule set_transaction_command
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1235:1: set_transaction_command : 'SET' keyTRANSACTION keyREAD keyONLY ;
    # 
    def set_transaction_command
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 244 )
      return_value = SetTransactionCommandReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      set_transaction_command_start_index = @input.index

      root_0 = nil
      string_literal1356 = nil
      keyTRANSACTION1357 = nil
      keyREAD1358 = nil
      keyONLY1359 = nil

      tree_for_string_literal1356 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1236:4: 'SET' keyTRANSACTION keyREAD keyONLY
        string_literal1356 = match( T__87, TOKENS_FOLLOWING_T__87_IN_set_transaction_command_8076 )
        if @state.backtracking == 0

          tree_for_string_literal1356 = @adaptor.create_with_payload( string_literal1356 )
          @adaptor.add_child( root_0, tree_for_string_literal1356 )

        end
        @state.following.push( TOKENS_FOLLOWING_keyTRANSACTION_IN_set_transaction_command_8078 )
        keyTRANSACTION1357 = keyTRANSACTION
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyTRANSACTION1357.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_keyREAD_IN_set_transaction_command_8080 )
        keyREAD1358 = keyREAD
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyREAD1358.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_keyONLY_IN_set_transaction_command_8082 )
        keyONLY1359 = keyONLY
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyONLY1359.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 244 )
        memoize( __method__, set_transaction_command_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    CloseStatementReturnValue = define_return_scope 

    # 
    # parser rule close_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1239:1: close_statement : keyCLOSE cursor_name ;
    # 
    def close_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 245 )
      return_value = CloseStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      close_statement_start_index = @input.index

      root_0 = nil
      keyCLOSE1360 = nil
      cursor_name1361 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1240:4: keyCLOSE cursor_name
        @state.following.push( TOKENS_FOLLOWING_keyCLOSE_IN_close_statement_8093 )
        keyCLOSE1360 = keyCLOSE
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyCLOSE1360.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_cursor_name_IN_close_statement_8095 )
        cursor_name1361 = cursor_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, cursor_name1361.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 245 )
        memoize( __method__, close_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    FetchStatementReturnValue = define_return_scope 

    # 
    # parser rule fetch_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1243:1: fetch_statement : 'FETCH' cursor_name 'INTO' ( variable_names | record_name ) ;
    # 
    def fetch_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 246 )
      return_value = FetchStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      fetch_statement_start_index = @input.index

      root_0 = nil
      string_literal1362 = nil
      string_literal1364 = nil
      cursor_name1363 = nil
      variable_names1365 = nil
      record_name1366 = nil

      tree_for_string_literal1362 = nil
      tree_for_string_literal1364 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1244:4: 'FETCH' cursor_name 'INTO' ( variable_names | record_name )
        string_literal1362 = match( T__149, TOKENS_FOLLOWING_T__149_IN_fetch_statement_8106 )
        if @state.backtracking == 0

          tree_for_string_literal1362 = @adaptor.create_with_payload( string_literal1362 )
          @adaptor.add_child( root_0, tree_for_string_literal1362 )

        end
        @state.following.push( TOKENS_FOLLOWING_cursor_name_IN_fetch_statement_8108 )
        cursor_name1363 = cursor_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, cursor_name1363.tree )
        end
        string_literal1364 = match( T__120, TOKENS_FOLLOWING_T__120_IN_fetch_statement_8110 )
        if @state.backtracking == 0

          tree_for_string_literal1364 = @adaptor.create_with_payload( string_literal1364 )
          @adaptor.add_child( root_0, tree_for_string_literal1364 )

        end
        # at line 1245:3: ( variable_names | record_name )
        alt_356 = 2
        look_356_0 = @input.peek( 1 )

        if ( look_356_0.between?( ID, DOUBLEQUOTED_STRING ) )
          look_356_1 = @input.peek( 2 )

          if ( syntactic_predicate?( :synpred561_Plsql ) )
            alt_356 = 1
          elsif ( true )
            alt_356 = 2
          else
            @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

            raise NoViableAlternative( "", 356, 1 )
          end
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 356, 0 )
        end
        case alt_356
        when 1
          # at line 1245:5: variable_names
          @state.following.push( TOKENS_FOLLOWING_variable_names_IN_fetch_statement_8117 )
          variable_names1365 = variable_names
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, variable_names1365.tree )
          end

        when 2
          # at line 1246:5: record_name
          @state.following.push( TOKENS_FOLLOWING_record_name_IN_fetch_statement_8123 )
          record_name1366 = record_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, record_name1366.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 246 )
        memoize( __method__, fetch_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    LockTableStatementReturnValue = define_return_scope 

    # 
    # parser rule lock_table_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1250:1: lock_table_statement : 'LOCK' 'TABLE' table_reference_list 'IN' lock_mode 'MODE' ( 'NOWAIT' )? ;
    # 
    def lock_table_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 247 )
      return_value = LockTableStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      lock_table_statement_start_index = @input.index

      root_0 = nil
      string_literal1367 = nil
      string_literal1368 = nil
      string_literal1370 = nil
      string_literal1372 = nil
      string_literal1373 = nil
      table_reference_list1369 = nil
      lock_mode1371 = nil

      tree_for_string_literal1367 = nil
      tree_for_string_literal1368 = nil
      tree_for_string_literal1370 = nil
      tree_for_string_literal1372 = nil
      tree_for_string_literal1373 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1251:4: 'LOCK' 'TABLE' table_reference_list 'IN' lock_mode 'MODE' ( 'NOWAIT' )?
        string_literal1367 = match( T__150, TOKENS_FOLLOWING_T__150_IN_lock_table_statement_8138 )
        if @state.backtracking == 0

          tree_for_string_literal1367 = @adaptor.create_with_payload( string_literal1367 )
          @adaptor.add_child( root_0, tree_for_string_literal1367 )

        end
        string_literal1368 = match( T__105, TOKENS_FOLLOWING_T__105_IN_lock_table_statement_8140 )
        if @state.backtracking == 0

          tree_for_string_literal1368 = @adaptor.create_with_payload( string_literal1368 )
          @adaptor.add_child( root_0, tree_for_string_literal1368 )

        end
        @state.following.push( TOKENS_FOLLOWING_table_reference_list_IN_lock_table_statement_8142 )
        table_reference_list1369 = table_reference_list
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, table_reference_list1369.tree )
        end
        string_literal1370 = match( T__102, TOKENS_FOLLOWING_T__102_IN_lock_table_statement_8146 )
        if @state.backtracking == 0

          tree_for_string_literal1370 = @adaptor.create_with_payload( string_literal1370 )
          @adaptor.add_child( root_0, tree_for_string_literal1370 )

        end
        @state.following.push( TOKENS_FOLLOWING_lock_mode_IN_lock_table_statement_8148 )
        lock_mode1371 = lock_mode
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, lock_mode1371.tree )
        end
        string_literal1372 = match( T__151, TOKENS_FOLLOWING_T__151_IN_lock_table_statement_8150 )
        if @state.backtracking == 0

          tree_for_string_literal1372 = @adaptor.create_with_payload( string_literal1372 )
          @adaptor.add_child( root_0, tree_for_string_literal1372 )

        end
        # at line 1252:25: ( 'NOWAIT' )?
        alt_357 = 2
        look_357_0 = @input.peek( 1 )

        if ( look_357_0 == T__137 )
          alt_357 = 1
        end
        case alt_357
        when 1
          # at line 1252:27: 'NOWAIT'
          string_literal1373 = match( T__137, TOKENS_FOLLOWING_T__137_IN_lock_table_statement_8154 )
          if @state.backtracking == 0

            tree_for_string_literal1373 = @adaptor.create_with_payload( string_literal1373 )
            @adaptor.add_child( root_0, tree_for_string_literal1373 )

          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 247 )
        memoize( __method__, lock_table_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    LockModeReturnValue = define_return_scope 

    # 
    # parser rule lock_mode
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1255:1: lock_mode : ( 'ROW' 'SHARE' | 'ROW' 'EXCLUSIVE' | 'SHARE' 'UPDATE' | 'SHARE' | 'SHARE' 'ROW' 'EXCLUSIVE' | 'EXCLUSIVE' );
    # 
    def lock_mode
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 248 )
      return_value = LockModeReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      lock_mode_start_index = @input.index

      root_0 = nil
      string_literal1374 = nil
      string_literal1375 = nil
      string_literal1376 = nil
      string_literal1377 = nil
      string_literal1378 = nil
      string_literal1379 = nil
      string_literal1380 = nil
      string_literal1381 = nil
      string_literal1382 = nil
      string_literal1383 = nil
      string_literal1384 = nil

      tree_for_string_literal1374 = nil
      tree_for_string_literal1375 = nil
      tree_for_string_literal1376 = nil
      tree_for_string_literal1377 = nil
      tree_for_string_literal1378 = nil
      tree_for_string_literal1379 = nil
      tree_for_string_literal1380 = nil
      tree_for_string_literal1381 = nil
      tree_for_string_literal1382 = nil
      tree_for_string_literal1383 = nil
      tree_for_string_literal1384 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 1256:2: ( 'ROW' 'SHARE' | 'ROW' 'EXCLUSIVE' | 'SHARE' 'UPDATE' | 'SHARE' | 'SHARE' 'ROW' 'EXCLUSIVE' | 'EXCLUSIVE' )
        alt_358 = 6
        case look_358 = @input.peek( 1 )
        when T__152 then look_358_1 = @input.peek( 2 )

        if ( look_358_1 == T__153 )
          alt_358 = 1
        elsif ( look_358_1 == T__154 )
          alt_358 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 358, 1 )
        end
        when T__153 then case look_358 = @input.peek( 2 )
        when T__132 then alt_358 = 3
        when T__152 then alt_358 = 5
        when T__151 then alt_358 = 4
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 358, 2 )
        end
        when T__154 then alt_358 = 6
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 358, 0 )
        end
        case alt_358
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 1256:4: 'ROW' 'SHARE'
          string_literal1374 = match( T__152, TOKENS_FOLLOWING_T__152_IN_lock_mode_8168 )
          if @state.backtracking == 0

            tree_for_string_literal1374 = @adaptor.create_with_payload( string_literal1374 )
            @adaptor.add_child( root_0, tree_for_string_literal1374 )

          end
          string_literal1375 = match( T__153, TOKENS_FOLLOWING_T__153_IN_lock_mode_8170 )
          if @state.backtracking == 0

            tree_for_string_literal1375 = @adaptor.create_with_payload( string_literal1375 )
            @adaptor.add_child( root_0, tree_for_string_literal1375 )

          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 1257:4: 'ROW' 'EXCLUSIVE'
          string_literal1376 = match( T__152, TOKENS_FOLLOWING_T__152_IN_lock_mode_8175 )
          if @state.backtracking == 0

            tree_for_string_literal1376 = @adaptor.create_with_payload( string_literal1376 )
            @adaptor.add_child( root_0, tree_for_string_literal1376 )

          end
          string_literal1377 = match( T__154, TOKENS_FOLLOWING_T__154_IN_lock_mode_8177 )
          if @state.backtracking == 0

            tree_for_string_literal1377 = @adaptor.create_with_payload( string_literal1377 )
            @adaptor.add_child( root_0, tree_for_string_literal1377 )

          end

        when 3
          root_0 = @adaptor.create_flat_list


          # at line 1258:4: 'SHARE' 'UPDATE'
          string_literal1378 = match( T__153, TOKENS_FOLLOWING_T__153_IN_lock_mode_8182 )
          if @state.backtracking == 0

            tree_for_string_literal1378 = @adaptor.create_with_payload( string_literal1378 )
            @adaptor.add_child( root_0, tree_for_string_literal1378 )

          end
          string_literal1379 = match( T__132, TOKENS_FOLLOWING_T__132_IN_lock_mode_8184 )
          if @state.backtracking == 0

            tree_for_string_literal1379 = @adaptor.create_with_payload( string_literal1379 )
            @adaptor.add_child( root_0, tree_for_string_literal1379 )

          end

        when 4
          root_0 = @adaptor.create_flat_list


          # at line 1259:4: 'SHARE'
          string_literal1380 = match( T__153, TOKENS_FOLLOWING_T__153_IN_lock_mode_8189 )
          if @state.backtracking == 0

            tree_for_string_literal1380 = @adaptor.create_with_payload( string_literal1380 )
            @adaptor.add_child( root_0, tree_for_string_literal1380 )

          end

        when 5
          root_0 = @adaptor.create_flat_list


          # at line 1260:4: 'SHARE' 'ROW' 'EXCLUSIVE'
          string_literal1381 = match( T__153, TOKENS_FOLLOWING_T__153_IN_lock_mode_8194 )
          if @state.backtracking == 0

            tree_for_string_literal1381 = @adaptor.create_with_payload( string_literal1381 )
            @adaptor.add_child( root_0, tree_for_string_literal1381 )

          end
          string_literal1382 = match( T__152, TOKENS_FOLLOWING_T__152_IN_lock_mode_8196 )
          if @state.backtracking == 0

            tree_for_string_literal1382 = @adaptor.create_with_payload( string_literal1382 )
            @adaptor.add_child( root_0, tree_for_string_literal1382 )

          end
          string_literal1383 = match( T__154, TOKENS_FOLLOWING_T__154_IN_lock_mode_8198 )
          if @state.backtracking == 0

            tree_for_string_literal1383 = @adaptor.create_with_payload( string_literal1383 )
            @adaptor.add_child( root_0, tree_for_string_literal1383 )

          end

        when 6
          root_0 = @adaptor.create_flat_list


          # at line 1261:4: 'EXCLUSIVE'
          string_literal1384 = match( T__154, TOKENS_FOLLOWING_T__154_IN_lock_mode_8203 )
          if @state.backtracking == 0

            tree_for_string_literal1384 = @adaptor.create_with_payload( string_literal1384 )
            @adaptor.add_child( root_0, tree_for_string_literal1384 )

          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 248 )
        memoize( __method__, lock_mode_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    OpenStatementReturnValue = define_return_scope 

    # 
    # parser rule open_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1264:1: open_statement : keyOPEN cursor_name ( LPAREN plsql_expressions RPAREN )? ;
    # 
    def open_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 249 )
      return_value = OpenStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      open_statement_start_index = @input.index

      root_0 = nil
      __LPAREN1387__ = nil
      __RPAREN1389__ = nil
      keyOPEN1385 = nil
      cursor_name1386 = nil
      plsql_expressions1388 = nil

      tree_for_LPAREN1387 = nil
      tree_for_RPAREN1389 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1265:4: keyOPEN cursor_name ( LPAREN plsql_expressions RPAREN )?
        @state.following.push( TOKENS_FOLLOWING_keyOPEN_IN_open_statement_8214 )
        keyOPEN1385 = keyOPEN
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyOPEN1385.tree )
        end
        @state.following.push( TOKENS_FOLLOWING_cursor_name_IN_open_statement_8216 )
        cursor_name1386 = cursor_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, cursor_name1386.tree )
        end
        # at line 1265:24: ( LPAREN plsql_expressions RPAREN )?
        alt_359 = 2
        look_359_0 = @input.peek( 1 )

        if ( look_359_0 == LPAREN )
          alt_359 = 1
        end
        case alt_359
        when 1
          # at line 1265:26: LPAREN plsql_expressions RPAREN
          __LPAREN1387__ = match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_open_statement_8220 )
          if @state.backtracking == 0

            tree_for_LPAREN1387 = @adaptor.create_with_payload( __LPAREN1387__ )
            @adaptor.add_child( root_0, tree_for_LPAREN1387 )

          end
          @state.following.push( TOKENS_FOLLOWING_plsql_expressions_IN_open_statement_8222 )
          plsql_expressions1388 = plsql_expressions
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, plsql_expressions1388.tree )
          end
          __RPAREN1389__ = match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_open_statement_8224 )
          if @state.backtracking == 0

            tree_for_RPAREN1389 = @adaptor.create_with_payload( __RPAREN1389__ )
            @adaptor.add_child( root_0, tree_for_RPAREN1389 )

          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 249 )
        memoize( __method__, open_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    RollbackStatementReturnValue = define_return_scope 

    # 
    # parser rule rollback_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1268:1: rollback_statement : keyROLLBACK ( keyWORK )? ( 'TO' ( 'SAVEPOINT' )? savepoint_name )? ( 'COMMENT' quoted_string )? ;
    # 
    def rollback_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 250 )
      return_value = RollbackStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      rollback_statement_start_index = @input.index

      root_0 = nil
      string_literal1392 = nil
      string_literal1393 = nil
      string_literal1395 = nil
      keyROLLBACK1390 = nil
      keyWORK1391 = nil
      savepoint_name1394 = nil
      quoted_string1396 = nil

      tree_for_string_literal1392 = nil
      tree_for_string_literal1393 = nil
      tree_for_string_literal1395 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1269:4: keyROLLBACK ( keyWORK )? ( 'TO' ( 'SAVEPOINT' )? savepoint_name )? ( 'COMMENT' quoted_string )?
        @state.following.push( TOKENS_FOLLOWING_keyROLLBACK_IN_rollback_statement_8238 )
        keyROLLBACK1390 = keyROLLBACK
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, keyROLLBACK1390.tree )
        end
        # at line 1269:16: ( keyWORK )?
        alt_360 = 2
        look_360_0 = @input.peek( 1 )

        if ( look_360_0 == ID )
          alt_360 = 1
        end
        case alt_360
        when 1
          # at line 1269:18: keyWORK
          @state.following.push( TOKENS_FOLLOWING_keyWORK_IN_rollback_statement_8242 )
          keyWORK1391 = keyWORK
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, keyWORK1391.tree )
          end

        end
        # at line 1270:3: ( 'TO' ( 'SAVEPOINT' )? savepoint_name )?
        alt_362 = 2
        look_362_0 = @input.peek( 1 )

        if ( look_362_0 == T__77 )
          alt_362 = 1
        end
        case alt_362
        when 1
          # at line 1270:5: 'TO' ( 'SAVEPOINT' )? savepoint_name
          string_literal1392 = match( T__77, TOKENS_FOLLOWING_T__77_IN_rollback_statement_8251 )
          if @state.backtracking == 0

            tree_for_string_literal1392 = @adaptor.create_with_payload( string_literal1392 )
            @adaptor.add_child( root_0, tree_for_string_literal1392 )

          end
          # at line 1270:10: ( 'SAVEPOINT' )?
          alt_361 = 2
          look_361_0 = @input.peek( 1 )

          if ( look_361_0 == T__155 )
            alt_361 = 1
          end
          case alt_361
          when 1
            # at line 1270:12: 'SAVEPOINT'
            string_literal1393 = match( T__155, TOKENS_FOLLOWING_T__155_IN_rollback_statement_8255 )
            if @state.backtracking == 0

              tree_for_string_literal1393 = @adaptor.create_with_payload( string_literal1393 )
              @adaptor.add_child( root_0, tree_for_string_literal1393 )

            end

          end
          @state.following.push( TOKENS_FOLLOWING_savepoint_name_IN_rollback_statement_8260 )
          savepoint_name1394 = savepoint_name
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, savepoint_name1394.tree )
          end

        end
        # at line 1271:3: ( 'COMMENT' quoted_string )?
        alt_363 = 2
        look_363_0 = @input.peek( 1 )

        if ( look_363_0 == T__156 )
          alt_363 = 1
        end
        case alt_363
        when 1
          # at line 1271:5: 'COMMENT' quoted_string
          string_literal1395 = match( T__156, TOKENS_FOLLOWING_T__156_IN_rollback_statement_8269 )
          if @state.backtracking == 0

            tree_for_string_literal1395 = @adaptor.create_with_payload( string_literal1395 )
            @adaptor.add_child( root_0, tree_for_string_literal1395 )

          end
          @state.following.push( TOKENS_FOLLOWING_quoted_string_IN_rollback_statement_8271 )
          quoted_string1396 = quoted_string
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, quoted_string1396.tree )
          end

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 250 )
        memoize( __method__, rollback_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SavepointStatementReturnValue = define_return_scope 

    # 
    # parser rule savepoint_statement
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1274:1: savepoint_statement : 'SAVEPOINT' savepoint_name ;
    # 
    def savepoint_statement
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 251 )
      return_value = SavepointStatementReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      savepoint_statement_start_index = @input.index

      root_0 = nil
      string_literal1397 = nil
      savepoint_name1398 = nil

      tree_for_string_literal1397 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1275:4: 'SAVEPOINT' savepoint_name
        string_literal1397 = match( T__155, TOKENS_FOLLOWING_T__155_IN_savepoint_statement_8285 )
        if @state.backtracking == 0

          tree_for_string_literal1397 = @adaptor.create_with_payload( string_literal1397 )
          @adaptor.add_child( root_0, tree_for_string_literal1397 )

        end
        @state.following.push( TOKENS_FOLLOWING_savepoint_name_IN_savepoint_statement_8287 )
        savepoint_name1398 = savepoint_name
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, savepoint_name1398.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 251 )
        memoize( __method__, savepoint_statement_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SavepointNameReturnValue = define_return_scope 

    # 
    # parser rule savepoint_name
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1278:1: savepoint_name : identifier ;
    # 
    def savepoint_name
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 252 )
      return_value = SavepointNameReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      savepoint_name_start_index = @input.index

      root_0 = nil
      identifier1399 = nil


      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1279:4: identifier
        @state.following.push( TOKENS_FOLLOWING_identifier_IN_savepoint_name_8298 )
        identifier1399 = identifier
        @state.following.pop
        if @state.backtracking == 0
          @adaptor.add_child( root_0, identifier1399.tree )
        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 252 )
        memoize( __method__, savepoint_name_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    IdentifierReturnValue = define_return_scope 

    # 
    # parser rule identifier
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1282:1: identifier : ( ID | DOUBLEQUOTED_STRING );
    # 
    def identifier
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 253 )
      return_value = IdentifierReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      identifier_start_index = @input.index

      root_0 = nil
      set1400 = nil

      tree_for_set1400 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 
        set1400 = @input.look
        if @input.peek( 1 ).between?( ID, DOUBLEQUOTED_STRING )
          @input.consume
          if @state.backtracking == 0
            @adaptor.add_child( root_0, @adaptor.create_with_payload( set1400 ) )
          end
          @state.error_recovery = false
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          mse = MismatchedSet( nil )
          raise mse
        end


        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 253 )
        memoize( __method__, identifier_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    QuotedStringReturnValue = define_return_scope 

    # 
    # parser rule quoted_string
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1288:1: quoted_string : QUOTED_STRING ;
    # 
    def quoted_string
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 254 )
      return_value = QuotedStringReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      quoted_string_start_index = @input.index

      root_0 = nil
      __QUOTED_STRING1401__ = nil

      tree_for_QUOTED_STRING1401 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1289:4: QUOTED_STRING
        __QUOTED_STRING1401__ = match( QUOTED_STRING, TOKENS_FOLLOWING_QUOTED_STRING_IN_quoted_string_8330 )
        if @state.backtracking == 0

          tree_for_QUOTED_STRING1401 = @adaptor.create_with_payload( __QUOTED_STRING1401__ )
          @adaptor.add_child( root_0, tree_for_QUOTED_STRING1401 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 254 )
        memoize( __method__, quoted_string_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    MatchStringReturnValue = define_return_scope 

    # 
    # parser rule match_string
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1292:1: match_string : QUOTED_STRING ;
    # 
    def match_string
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 255 )
      return_value = MatchStringReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      match_string_start_index = @input.index

      root_0 = nil
      __QUOTED_STRING1402__ = nil

      tree_for_QUOTED_STRING1402 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1293:4: QUOTED_STRING
        __QUOTED_STRING1402__ = match( QUOTED_STRING, TOKENS_FOLLOWING_QUOTED_STRING_IN_match_string_8341 )
        if @state.backtracking == 0

          tree_for_QUOTED_STRING1402 = @adaptor.create_with_payload( __QUOTED_STRING1402__ )
          @adaptor.add_child( root_0, tree_for_QUOTED_STRING1402 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 255 )
        memoize( __method__, match_string_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyAReturnValue = define_return_scope 

    # 
    # parser rule keyA
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1295:1: keyA : {...}? ID ;
    # 
    def keyA
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 256 )
      return_value = KeyAReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyA_start_index = @input.index

      root_0 = nil
      __ID1403__ = nil

      tree_for_ID1403 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1295:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("A") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyA", "self.input.look(1).text.upcase == (\"A\")" )
        end
        __ID1403__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyA_8380 )
        if @state.backtracking == 0

          tree_for_ID1403 = @adaptor.create_with_payload( __ID1403__ )
          @adaptor.add_child( root_0, tree_for_ID1403 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 256 )
        memoize( __method__, keyA_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyAUTOMATICReturnValue = define_return_scope 

    # 
    # parser rule keyAUTOMATIC
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1296:1: keyAUTOMATIC : {...}? ID ;
    # 
    def keyAUTOMATIC
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 257 )
      return_value = KeyAUTOMATICReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyAUTOMATIC_start_index = @input.index

      root_0 = nil
      __ID1404__ = nil

      tree_for_ID1404 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1296:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("AUTOMATIC") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyAUTOMATIC", "self.input.look(1).text.upcase == (\"AUTOMATIC\")" )
        end
        __ID1404__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyAUTOMATIC_8409 )
        if @state.backtracking == 0

          tree_for_ID1404 = @adaptor.create_with_payload( __ID1404__ )
          @adaptor.add_child( root_0, tree_for_ID1404 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 257 )
        memoize( __method__, keyAUTOMATIC_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyCOUNTReturnValue = define_return_scope 

    # 
    # parser rule keyCOUNT
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1297:1: keyCOUNT : {...}? ID ;
    # 
    def keyCOUNT
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 258 )
      return_value = KeyCOUNTReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyCOUNT_start_index = @input.index

      root_0 = nil
      __ID1405__ = nil

      tree_for_ID1405 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1297:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("COUNT") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyCOUNT", "self.input.look(1).text.upcase == (\"COUNT\")" )
        end
        __ID1405__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyCOUNT_8442 )
        if @state.backtracking == 0

          tree_for_ID1405 = @adaptor.create_with_payload( __ID1405__ )
          @adaptor.add_child( root_0, tree_for_ID1405 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 258 )
        memoize( __method__, keyCOUNT_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyCROSSReturnValue = define_return_scope 

    # 
    # parser rule keyCROSS
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1298:1: keyCROSS : {...}? ID ;
    # 
    def keyCROSS
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 259 )
      return_value = KeyCROSSReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyCROSS_start_index = @input.index

      root_0 = nil
      __ID1406__ = nil

      tree_for_ID1406 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1298:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("CROSS") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyCROSS", "self.input.look(1).text.upcase == (\"CROSS\")" )
        end
        __ID1406__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyCROSS_8475 )
        if @state.backtracking == 0

          tree_for_ID1406 = @adaptor.create_with_payload( __ID1406__ )
          @adaptor.add_child( root_0, tree_for_ID1406 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 259 )
        memoize( __method__, keyCROSS_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyCUBEReturnValue = define_return_scope 

    # 
    # parser rule keyCUBE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1299:1: keyCUBE : {...}? ID ;
    # 
    def keyCUBE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 260 )
      return_value = KeyCUBEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyCUBE_start_index = @input.index

      root_0 = nil
      __ID1407__ = nil

      tree_for_ID1407 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1299:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("CUBE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyCUBE", "self.input.look(1).text.upcase == (\"CUBE\")" )
        end
        __ID1407__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyCUBE_8509 )
        if @state.backtracking == 0

          tree_for_ID1407 = @adaptor.create_with_payload( __ID1407__ )
          @adaptor.add_child( root_0, tree_for_ID1407 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 260 )
        memoize( __method__, keyCUBE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyCURRENTOFReturnValue = define_return_scope 

    # 
    # parser rule keyCURRENT_OF
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1300:1: keyCURRENT_OF : {...}? ID ;
    # 
    def keyCURRENT_OF
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 261 )
      return_value = KeyCURRENTOFReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyCURRENT_OF_start_index = @input.index

      root_0 = nil
      __ID1408__ = nil

      tree_for_ID1408 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1300:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("CURRENT_OF") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyCURRENT_OF", "self.input.look(1).text.upcase == (\"CURRENT_OF\")" )
        end
        __ID1408__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyCURRENT_OF_8537 )
        if @state.backtracking == 0

          tree_for_ID1408 = @adaptor.create_with_payload( __ID1408__ )
          @adaptor.add_child( root_0, tree_for_ID1408 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 261 )
        memoize( __method__, keyCURRENT_OF_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyDAYReturnValue = define_return_scope 

    # 
    # parser rule keyDAY
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1301:1: keyDAY : {...}? ID ;
    # 
    def keyDAY
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 262 )
      return_value = KeyDAYReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyDAY_start_index = @input.index

      root_0 = nil
      __ID1409__ = nil

      tree_for_ID1409 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1301:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("DAY") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyDAY", "self.input.look(1).text.upcase == (\"DAY\")" )
        end
        __ID1409__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyDAY_8572 )
        if @state.backtracking == 0

          tree_for_ID1409 = @adaptor.create_with_payload( __ID1409__ )
          @adaptor.add_child( root_0, tree_for_ID1409 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 262 )
        memoize( __method__, keyDAY_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyDBTIMEZONEReturnValue = define_return_scope 

    # 
    # parser rule keyDBTIMEZONE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1302:1: keyDBTIMEZONE : {...}? ID ;
    # 
    def keyDBTIMEZONE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 263 )
      return_value = KeyDBTIMEZONEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyDBTIMEZONE_start_index = @input.index

      root_0 = nil
      __ID1410__ = nil

      tree_for_ID1410 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1302:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("DBTIMEZONE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyDBTIMEZONE", "self.input.look(1).text.upcase == (\"DBTIMEZONE\")" )
        end
        __ID1410__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyDBTIMEZONE_8600 )
        if @state.backtracking == 0

          tree_for_ID1410 = @adaptor.create_with_payload( __ID1410__ )
          @adaptor.add_child( root_0, tree_for_ID1410 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 263 )
        memoize( __method__, keyDBTIMEZONE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyDECREMENTReturnValue = define_return_scope 

    # 
    # parser rule keyDECREMENT
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1303:1: keyDECREMENT : {...}? ID ;
    # 
    def keyDECREMENT
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 264 )
      return_value = KeyDECREMENTReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyDECREMENT_start_index = @input.index

      root_0 = nil
      __ID1411__ = nil

      tree_for_ID1411 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1303:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("DECREMENT") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyDECREMENT", "self.input.look(1).text.upcase == (\"DECREMENT\")" )
        end
        __ID1411__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyDECREMENT_8629 )
        if @state.backtracking == 0

          tree_for_ID1411 = @adaptor.create_with_payload( __ID1411__ )
          @adaptor.add_child( root_0, tree_for_ID1411 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 264 )
        memoize( __method__, keyDECREMENT_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyDIMENSIONReturnValue = define_return_scope 

    # 
    # parser rule keyDIMENSION
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1304:1: keyDIMENSION : {...}? ID ;
    # 
    def keyDIMENSION
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 265 )
      return_value = KeyDIMENSIONReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyDIMENSION_start_index = @input.index

      root_0 = nil
      __ID1412__ = nil

      tree_for_ID1412 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1304:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("DIMENSION") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyDIMENSION", "self.input.look(1).text.upcase == (\"DIMENSION\")" )
        end
        __ID1412__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyDIMENSION_8658 )
        if @state.backtracking == 0

          tree_for_ID1412 = @adaptor.create_with_payload( __ID1412__ )
          @adaptor.add_child( root_0, tree_for_ID1412 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 265 )
        memoize( __method__, keyDIMENSION_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyEMPTYReturnValue = define_return_scope 

    # 
    # parser rule keyEMPTY
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1305:1: keyEMPTY : {...}? ID ;
    # 
    def keyEMPTY
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 266 )
      return_value = KeyEMPTYReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyEMPTY_start_index = @input.index

      root_0 = nil
      __ID1413__ = nil

      tree_for_ID1413 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1305:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("EMPTY") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyEMPTY", "self.input.look(1).text.upcase == (\"EMPTY\")" )
        end
        __ID1413__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyEMPTY_8691 )
        if @state.backtracking == 0

          tree_for_ID1413 = @adaptor.create_with_payload( __ID1413__ )
          @adaptor.add_child( root_0, tree_for_ID1413 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 266 )
        memoize( __method__, keyEMPTY_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyEQUALSPATHReturnValue = define_return_scope 

    # 
    # parser rule keyEQUALS_PATH
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1306:1: keyEQUALS_PATH : {...}? ID ;
    # 
    def keyEQUALS_PATH
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 267 )
      return_value = KeyEQUALSPATHReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyEQUALS_PATH_start_index = @input.index

      root_0 = nil
      __ID1414__ = nil

      tree_for_ID1414 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1306:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("EQUALS_PATH") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyEQUALS_PATH", "self.input.look(1).text.upcase == (\"EQUALS_PATH\")" )
        end
        __ID1414__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyEQUALS_PATH_8718 )
        if @state.backtracking == 0

          tree_for_ID1414 = @adaptor.create_with_payload( __ID1414__ )
          @adaptor.add_child( root_0, tree_for_ID1414 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 267 )
        memoize( __method__, keyEQUALS_PATH_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyESCAPEReturnValue = define_return_scope 

    # 
    # parser rule keyESCAPE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1307:1: keyESCAPE : {...}? ID ;
    # 
    def keyESCAPE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 268 )
      return_value = KeyESCAPEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyESCAPE_start_index = @input.index

      root_0 = nil
      __ID1415__ = nil

      tree_for_ID1415 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1307:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("ESCAPE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyESCAPE", "self.input.look(1).text.upcase == (\"ESCAPE\")" )
        end
        __ID1415__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyESCAPE_8750 )
        if @state.backtracking == 0

          tree_for_ID1415 = @adaptor.create_with_payload( __ID1415__ )
          @adaptor.add_child( root_0, tree_for_ID1415 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 268 )
        memoize( __method__, keyESCAPE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyFIRSTReturnValue = define_return_scope 

    # 
    # parser rule keyFIRST
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1308:1: keyFIRST : {...}? ID ;
    # 
    def keyFIRST
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 269 )
      return_value = KeyFIRSTReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyFIRST_start_index = @input.index

      root_0 = nil
      __ID1416__ = nil

      tree_for_ID1416 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1308:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("FIRST") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyFIRST", "self.input.look(1).text.upcase == (\"FIRST\")" )
        end
        __ID1416__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyFIRST_8783 )
        if @state.backtracking == 0

          tree_for_ID1416 = @adaptor.create_with_payload( __ID1416__ )
          @adaptor.add_child( root_0, tree_for_ID1416 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 269 )
        memoize( __method__, keyFIRST_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyFULLReturnValue = define_return_scope 

    # 
    # parser rule keyFULL
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1309:1: keyFULL : {...}? ID ;
    # 
    def keyFULL
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 270 )
      return_value = KeyFULLReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyFULL_start_index = @input.index

      root_0 = nil
      __ID1417__ = nil

      tree_for_ID1417 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1309:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("FULL") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyFULL", "self.input.look(1).text.upcase == (\"FULL\")" )
        end
        __ID1417__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyFULL_8817 )
        if @state.backtracking == 0

          tree_for_ID1417 = @adaptor.create_with_payload( __ID1417__ )
          @adaptor.add_child( root_0, tree_for_ID1417 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 270 )
        memoize( __method__, keyFULL_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyGROUPINGReturnValue = define_return_scope 

    # 
    # parser rule keyGROUPING
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1310:1: keyGROUPING : {...}? ID ;
    # 
    def keyGROUPING
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 271 )
      return_value = KeyGROUPINGReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyGROUPING_start_index = @input.index

      root_0 = nil
      __ID1418__ = nil

      tree_for_ID1418 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1310:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("GROUPING") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyGROUPING", "self.input.look(1).text.upcase == (\"GROUPING\")" )
        end
        __ID1418__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyGROUPING_8847 )
        if @state.backtracking == 0

          tree_for_ID1418 = @adaptor.create_with_payload( __ID1418__ )
          @adaptor.add_child( root_0, tree_for_ID1418 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 271 )
        memoize( __method__, keyGROUPING_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyIGNOREReturnValue = define_return_scope 

    # 
    # parser rule keyIGNORE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1311:1: keyIGNORE : {...}? ID ;
    # 
    def keyIGNORE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 272 )
      return_value = KeyIGNOREReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyIGNORE_start_index = @input.index

      root_0 = nil
      __ID1419__ = nil

      tree_for_ID1419 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1311:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("IGNORE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyIGNORE", "self.input.look(1).text.upcase == (\"IGNORE\")" )
        end
        __ID1419__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyIGNORE_8879 )
        if @state.backtracking == 0

          tree_for_ID1419 = @adaptor.create_with_payload( __ID1419__ )
          @adaptor.add_child( root_0, tree_for_ID1419 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 272 )
        memoize( __method__, keyIGNORE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyINCREMENTReturnValue = define_return_scope 

    # 
    # parser rule keyINCREMENT
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1312:1: keyINCREMENT : {...}? ID ;
    # 
    def keyINCREMENT
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 273 )
      return_value = KeyINCREMENTReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyINCREMENT_start_index = @input.index

      root_0 = nil
      __ID1420__ = nil

      tree_for_ID1420 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1312:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("INCREMENT") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyINCREMENT", "self.input.look(1).text.upcase == (\"INCREMENT\")" )
        end
        __ID1420__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyINCREMENT_8908 )
        if @state.backtracking == 0

          tree_for_ID1420 = @adaptor.create_with_payload( __ID1420__ )
          @adaptor.add_child( root_0, tree_for_ID1420 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 273 )
        memoize( __method__, keyINCREMENT_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyINFINITEReturnValue = define_return_scope 

    # 
    # parser rule keyINFINITE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1313:1: keyINFINITE : {...}? ID ;
    # 
    def keyINFINITE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 274 )
      return_value = KeyINFINITEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyINFINITE_start_index = @input.index

      root_0 = nil
      __ID1421__ = nil

      tree_for_ID1421 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1313:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("INFINITE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyINFINITE", "self.input.look(1).text.upcase == (\"INFINITE\")" )
        end
        __ID1421__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyINFINITE_8938 )
        if @state.backtracking == 0

          tree_for_ID1421 = @adaptor.create_with_payload( __ID1421__ )
          @adaptor.add_child( root_0, tree_for_ID1421 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 274 )
        memoize( __method__, keyINFINITE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyINNERReturnValue = define_return_scope 

    # 
    # parser rule keyINNER
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1314:1: keyINNER : {...}? ID ;
    # 
    def keyINNER
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 275 )
      return_value = KeyINNERReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyINNER_start_index = @input.index

      root_0 = nil
      __ID1422__ = nil

      tree_for_ID1422 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1314:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("INNER") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyINNER", "self.input.look(1).text.upcase == (\"INNER\")" )
        end
        __ID1422__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyINNER_8971 )
        if @state.backtracking == 0

          tree_for_ID1422 = @adaptor.create_with_payload( __ID1422__ )
          @adaptor.add_child( root_0, tree_for_ID1422 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 275 )
        memoize( __method__, keyINNER_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyINTERVALReturnValue = define_return_scope 

    # 
    # parser rule keyINTERVAL
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1315:1: keyINTERVAL : {...}? ID ;
    # 
    def keyINTERVAL
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 276 )
      return_value = KeyINTERVALReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyINTERVAL_start_index = @input.index

      root_0 = nil
      __ID1423__ = nil

      tree_for_ID1423 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1315:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("INTERVAL") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyINTERVAL", "self.input.look(1).text.upcase == (\"INTERVAL\")" )
        end
        __ID1423__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyINTERVAL_9001 )
        if @state.backtracking == 0

          tree_for_ID1423 = @adaptor.create_with_payload( __ID1423__ )
          @adaptor.add_child( root_0, tree_for_ID1423 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 276 )
        memoize( __method__, keyINTERVAL_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyITERATEReturnValue = define_return_scope 

    # 
    # parser rule keyITERATE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1316:1: keyITERATE : {...}? ID ;
    # 
    def keyITERATE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 277 )
      return_value = KeyITERATEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyITERATE_start_index = @input.index

      root_0 = nil
      __ID1424__ = nil

      tree_for_ID1424 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1316:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("ITERATE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyITERATE", "self.input.look(1).text.upcase == (\"ITERATE\")" )
        end
        __ID1424__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyITERATE_9032 )
        if @state.backtracking == 0

          tree_for_ID1424 = @adaptor.create_with_payload( __ID1424__ )
          @adaptor.add_child( root_0, tree_for_ID1424 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 277 )
        memoize( __method__, keyITERATE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyJOINReturnValue = define_return_scope 

    # 
    # parser rule keyJOIN
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1317:1: keyJOIN : {...}? ID ;
    # 
    def keyJOIN
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 278 )
      return_value = KeyJOINReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyJOIN_start_index = @input.index

      root_0 = nil
      __ID1425__ = nil

      tree_for_ID1425 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1317:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("JOIN") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyJOIN", "self.input.look(1).text.upcase == (\"JOIN\")" )
        end
        __ID1425__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyJOIN_9066 )
        if @state.backtracking == 0

          tree_for_ID1425 = @adaptor.create_with_payload( __ID1425__ )
          @adaptor.add_child( root_0, tree_for_ID1425 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 278 )
        memoize( __method__, keyJOIN_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyKEEPReturnValue = define_return_scope 

    # 
    # parser rule keyKEEP
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1318:1: keyKEEP : {...}? ID ;
    # 
    def keyKEEP
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 279 )
      return_value = KeyKEEPReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyKEEP_start_index = @input.index

      root_0 = nil
      __ID1426__ = nil

      tree_for_ID1426 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1318:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("KEEP") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyKEEP", "self.input.look(1).text.upcase == (\"KEEP\")" )
        end
        __ID1426__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyKEEP_9100 )
        if @state.backtracking == 0

          tree_for_ID1426 = @adaptor.create_with_payload( __ID1426__ )
          @adaptor.add_child( root_0, tree_for_ID1426 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 279 )
        memoize( __method__, keyKEEP_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyLASTReturnValue = define_return_scope 

    # 
    # parser rule keyLAST
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1319:1: keyLAST : {...}? ID ;
    # 
    def keyLAST
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 280 )
      return_value = KeyLASTReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyLAST_start_index = @input.index

      root_0 = nil
      __ID1427__ = nil

      tree_for_ID1427 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1319:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("LAST") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyLAST", "self.input.look(1).text.upcase == (\"LAST\")" )
        end
        __ID1427__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyLAST_9134 )
        if @state.backtracking == 0

          tree_for_ID1427 = @adaptor.create_with_payload( __ID1427__ )
          @adaptor.add_child( root_0, tree_for_ID1427 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 280 )
        memoize( __method__, keyLAST_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyLEFTReturnValue = define_return_scope 

    # 
    # parser rule keyLEFT
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1320:1: keyLEFT : {...}? ID ;
    # 
    def keyLEFT
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 281 )
      return_value = KeyLEFTReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyLEFT_start_index = @input.index

      root_0 = nil
      __ID1428__ = nil

      tree_for_ID1428 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1320:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("LEFT") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyLEFT", "self.input.look(1).text.upcase == (\"LEFT\")" )
        end
        __ID1428__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyLEFT_9168 )
        if @state.backtracking == 0

          tree_for_ID1428 = @adaptor.create_with_payload( __ID1428__ )
          @adaptor.add_child( root_0, tree_for_ID1428 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 281 )
        memoize( __method__, keyLEFT_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyLIKE2ReturnValue = define_return_scope 

    # 
    # parser rule keyLIKE2
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1321:1: keyLIKE2 : {...}? ID ;
    # 
    def keyLIKE2
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 282 )
      return_value = KeyLIKE2ReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyLIKE2_start_index = @input.index

      root_0 = nil
      __ID1429__ = nil

      tree_for_ID1429 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1321:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("LIKE2") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyLIKE2", "self.input.look(1).text.upcase == (\"LIKE2\")" )
        end
        __ID1429__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyLIKE2_9201 )
        if @state.backtracking == 0

          tree_for_ID1429 = @adaptor.create_with_payload( __ID1429__ )
          @adaptor.add_child( root_0, tree_for_ID1429 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 282 )
        memoize( __method__, keyLIKE2_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyLIKE4ReturnValue = define_return_scope 

    # 
    # parser rule keyLIKE4
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1322:1: keyLIKE4 : {...}? ID ;
    # 
    def keyLIKE4
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 283 )
      return_value = KeyLIKE4ReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyLIKE4_start_index = @input.index

      root_0 = nil
      __ID1430__ = nil

      tree_for_ID1430 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1322:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("LIKE4") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyLIKE4", "self.input.look(1).text.upcase == (\"LIKE4\")" )
        end
        __ID1430__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyLIKE4_9234 )
        if @state.backtracking == 0

          tree_for_ID1430 = @adaptor.create_with_payload( __ID1430__ )
          @adaptor.add_child( root_0, tree_for_ID1430 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 283 )
        memoize( __method__, keyLIKE4_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyLIKECReturnValue = define_return_scope 

    # 
    # parser rule keyLIKEC
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1323:1: keyLIKEC : {...}? ID ;
    # 
    def keyLIKEC
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 284 )
      return_value = KeyLIKECReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyLIKEC_start_index = @input.index

      root_0 = nil
      __ID1431__ = nil

      tree_for_ID1431 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1323:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("LIKEC") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyLIKEC", "self.input.look(1).text.upcase == (\"LIKEC\")" )
        end
        __ID1431__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyLIKEC_9267 )
        if @state.backtracking == 0

          tree_for_ID1431 = @adaptor.create_with_payload( __ID1431__ )
          @adaptor.add_child( root_0, tree_for_ID1431 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 284 )
        memoize( __method__, keyLIKEC_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyLOCALReturnValue = define_return_scope 

    # 
    # parser rule keyLOCAL
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1324:1: keyLOCAL : {...}? ID ;
    # 
    def keyLOCAL
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 285 )
      return_value = KeyLOCALReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyLOCAL_start_index = @input.index

      root_0 = nil
      __ID1432__ = nil

      tree_for_ID1432 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1324:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("LOCAL") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyLOCAL", "self.input.look(1).text.upcase == (\"LOCAL\")" )
        end
        __ID1432__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyLOCAL_9300 )
        if @state.backtracking == 0

          tree_for_ID1432 = @adaptor.create_with_payload( __ID1432__ )
          @adaptor.add_child( root_0, tree_for_ID1432 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 285 )
        memoize( __method__, keyLOCAL_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyMAINReturnValue = define_return_scope 

    # 
    # parser rule keyMAIN
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1325:1: keyMAIN : {...}? ID ;
    # 
    def keyMAIN
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 286 )
      return_value = KeyMAINReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyMAIN_start_index = @input.index

      root_0 = nil
      __ID1433__ = nil

      tree_for_ID1433 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1325:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("MAIN") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyMAIN", "self.input.look(1).text.upcase == (\"MAIN\")" )
        end
        __ID1433__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyMAIN_9334 )
        if @state.backtracking == 0

          tree_for_ID1433 = @adaptor.create_with_payload( __ID1433__ )
          @adaptor.add_child( root_0, tree_for_ID1433 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 286 )
        memoize( __method__, keyMAIN_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyMEASURESReturnValue = define_return_scope 

    # 
    # parser rule keyMEASURES
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1326:1: keyMEASURES : {...}? ID ;
    # 
    def keyMEASURES
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 287 )
      return_value = KeyMEASURESReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyMEASURES_start_index = @input.index

      root_0 = nil
      __ID1434__ = nil

      tree_for_ID1434 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1326:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("MEASURES") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyMEASURES", "self.input.look(1).text.upcase == (\"MEASURES\")" )
        end
        __ID1434__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyMEASURES_9364 )
        if @state.backtracking == 0

          tree_for_ID1434 = @adaptor.create_with_payload( __ID1434__ )
          @adaptor.add_child( root_0, tree_for_ID1434 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 287 )
        memoize( __method__, keyMEASURES_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyMEMBERReturnValue = define_return_scope 

    # 
    # parser rule keyMEMBER
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1327:1: keyMEMBER : {...}? ID ;
    # 
    def keyMEMBER
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 288 )
      return_value = KeyMEMBERReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyMEMBER_start_index = @input.index

      root_0 = nil
      __ID1435__ = nil

      tree_for_ID1435 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1327:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("MEMBER") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyMEMBER", "self.input.look(1).text.upcase == (\"MEMBER\")" )
        end
        __ID1435__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyMEMBER_9396 )
        if @state.backtracking == 0

          tree_for_ID1435 = @adaptor.create_with_payload( __ID1435__ )
          @adaptor.add_child( root_0, tree_for_ID1435 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 288 )
        memoize( __method__, keyMEMBER_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyMODELReturnValue = define_return_scope 

    # 
    # parser rule keyMODEL
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1328:1: keyMODEL : {...}? ID ;
    # 
    def keyMODEL
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 289 )
      return_value = KeyMODELReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyMODEL_start_index = @input.index

      root_0 = nil
      __ID1436__ = nil

      tree_for_ID1436 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1328:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("MODEL") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyMODEL", "self.input.look(1).text.upcase == (\"MODEL\")" )
        end
        __ID1436__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyMODEL_9429 )
        if @state.backtracking == 0

          tree_for_ID1436 = @adaptor.create_with_payload( __ID1436__ )
          @adaptor.add_child( root_0, tree_for_ID1436 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 289 )
        memoize( __method__, keyMODEL_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyMONTHReturnValue = define_return_scope 

    # 
    # parser rule keyMONTH
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1329:1: keyMONTH : {...}? ID ;
    # 
    def keyMONTH
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 290 )
      return_value = KeyMONTHReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyMONTH_start_index = @input.index

      root_0 = nil
      __ID1437__ = nil

      tree_for_ID1437 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1329:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("MONTH") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyMONTH", "self.input.look(1).text.upcase == (\"MONTH\")" )
        end
        __ID1437__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyMONTH_9462 )
        if @state.backtracking == 0

          tree_for_ID1437 = @adaptor.create_with_payload( __ID1437__ )
          @adaptor.add_child( root_0, tree_for_ID1437 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 290 )
        memoize( __method__, keyMONTH_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyNANReturnValue = define_return_scope 

    # 
    # parser rule keyNAN
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1330:1: keyNAN : {...}? ID ;
    # 
    def keyNAN
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 291 )
      return_value = KeyNANReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyNAN_start_index = @input.index

      root_0 = nil
      __ID1438__ = nil

      tree_for_ID1438 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1330:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("NAN") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyNAN", "self.input.look(1).text.upcase == (\"NAN\")" )
        end
        __ID1438__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyNAN_9497 )
        if @state.backtracking == 0

          tree_for_ID1438 = @adaptor.create_with_payload( __ID1438__ )
          @adaptor.add_child( root_0, tree_for_ID1438 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 291 )
        memoize( __method__, keyNAN_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyNATURALReturnValue = define_return_scope 

    # 
    # parser rule keyNATURAL
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1331:1: keyNATURAL : {...}? ID ;
    # 
    def keyNATURAL
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 292 )
      return_value = KeyNATURALReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyNATURAL_start_index = @input.index

      root_0 = nil
      __ID1439__ = nil

      tree_for_ID1439 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1331:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("NATURAL") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyNATURAL", "self.input.look(1).text.upcase == (\"NATURAL\")" )
        end
        __ID1439__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyNATURAL_9528 )
        if @state.backtracking == 0

          tree_for_ID1439 = @adaptor.create_with_payload( __ID1439__ )
          @adaptor.add_child( root_0, tree_for_ID1439 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 292 )
        memoize( __method__, keyNATURAL_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyNAVReturnValue = define_return_scope 

    # 
    # parser rule keyNAV
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1332:1: keyNAV : {...}? ID ;
    # 
    def keyNAV
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 293 )
      return_value = KeyNAVReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyNAV_start_index = @input.index

      root_0 = nil
      __ID1440__ = nil

      tree_for_ID1440 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1332:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("NAV") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyNAV", "self.input.look(1).text.upcase == (\"NAV\")" )
        end
        __ID1440__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyNAV_9563 )
        if @state.backtracking == 0

          tree_for_ID1440 = @adaptor.create_with_payload( __ID1440__ )
          @adaptor.add_child( root_0, tree_for_ID1440 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 293 )
        memoize( __method__, keyNAV_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyNOCYCLEReturnValue = define_return_scope 

    # 
    # parser rule keyNOCYCLE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1333:1: keyNOCYCLE : {...}? ID ;
    # 
    def keyNOCYCLE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 294 )
      return_value = KeyNOCYCLEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyNOCYCLE_start_index = @input.index

      root_0 = nil
      __ID1441__ = nil

      tree_for_ID1441 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1333:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("NOCYCLE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyNOCYCLE", "self.input.look(1).text.upcase == (\"NOCYCLE\")" )
        end
        __ID1441__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyNOCYCLE_9594 )
        if @state.backtracking == 0

          tree_for_ID1441 = @adaptor.create_with_payload( __ID1441__ )
          @adaptor.add_child( root_0, tree_for_ID1441 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 294 )
        memoize( __method__, keyNOCYCLE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyNULLSReturnValue = define_return_scope 

    # 
    # parser rule keyNULLS
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1334:1: keyNULLS : {...}? ID ;
    # 
    def keyNULLS
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 295 )
      return_value = KeyNULLSReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyNULLS_start_index = @input.index

      root_0 = nil
      __ID1442__ = nil

      tree_for_ID1442 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1334:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("NULLS") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyNULLS", "self.input.look(1).text.upcase == (\"NULLS\")" )
        end
        __ID1442__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyNULLS_9627 )
        if @state.backtracking == 0

          tree_for_ID1442 = @adaptor.create_with_payload( __ID1442__ )
          @adaptor.add_child( root_0, tree_for_ID1442 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 295 )
        memoize( __method__, keyNULLS_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyONLYReturnValue = define_return_scope 

    # 
    # parser rule keyONLY
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1335:1: keyONLY : {...}? ID ;
    # 
    def keyONLY
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 296 )
      return_value = KeyONLYReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyONLY_start_index = @input.index

      root_0 = nil
      __ID1443__ = nil

      tree_for_ID1443 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1335:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("ONLY") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyONLY", "self.input.look(1).text.upcase == (\"ONLY\")" )
        end
        __ID1443__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyONLY_9661 )
        if @state.backtracking == 0

          tree_for_ID1443 = @adaptor.create_with_payload( __ID1443__ )
          @adaptor.add_child( root_0, tree_for_ID1443 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 296 )
        memoize( __method__, keyONLY_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyOUTERReturnValue = define_return_scope 

    # 
    # parser rule keyOUTER
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1336:1: keyOUTER : {...}? ID ;
    # 
    def keyOUTER
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 297 )
      return_value = KeyOUTERReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyOUTER_start_index = @input.index

      root_0 = nil
      __ID1444__ = nil

      tree_for_ID1444 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1336:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("OUTER") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyOUTER", "self.input.look(1).text.upcase == (\"OUTER\")" )
        end
        __ID1444__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyOUTER_9694 )
        if @state.backtracking == 0

          tree_for_ID1444 = @adaptor.create_with_payload( __ID1444__ )
          @adaptor.add_child( root_0, tree_for_ID1444 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 297 )
        memoize( __method__, keyOUTER_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyPARTITIONReturnValue = define_return_scope 

    # 
    # parser rule keyPARTITION
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1337:1: keyPARTITION : {...}? ID ;
    # 
    def keyPARTITION
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 298 )
      return_value = KeyPARTITIONReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyPARTITION_start_index = @input.index

      root_0 = nil
      __ID1445__ = nil

      tree_for_ID1445 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1337:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("PARTITION") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyPARTITION", "self.input.look(1).text.upcase == (\"PARTITION\")" )
        end
        __ID1445__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyPARTITION_9723 )
        if @state.backtracking == 0

          tree_for_ID1445 = @adaptor.create_with_payload( __ID1445__ )
          @adaptor.add_child( root_0, tree_for_ID1445 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 298 )
        memoize( __method__, keyPARTITION_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyPRECISIONReturnValue = define_return_scope 

    # 
    # parser rule keyPRECISION
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1338:1: keyPRECISION : {...}? ID ;
    # 
    def keyPRECISION
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 299 )
      return_value = KeyPRECISIONReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyPRECISION_start_index = @input.index

      root_0 = nil
      __ID1446__ = nil

      tree_for_ID1446 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1338:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("PRECISION") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyPRECISION", "self.input.look(1).text.upcase == (\"PRECISION\")" )
        end
        __ID1446__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyPRECISION_9752 )
        if @state.backtracking == 0

          tree_for_ID1446 = @adaptor.create_with_payload( __ID1446__ )
          @adaptor.add_child( root_0, tree_for_ID1446 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 299 )
        memoize( __method__, keyPRECISION_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyPRESENTReturnValue = define_return_scope 

    # 
    # parser rule keyPRESENT
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1339:1: keyPRESENT : {...}? ID ;
    # 
    def keyPRESENT
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 300 )
      return_value = KeyPRESENTReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyPRESENT_start_index = @input.index

      root_0 = nil
      __ID1447__ = nil

      tree_for_ID1447 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1339:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("PRESENT") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyPRESENT", "self.input.look(1).text.upcase == (\"PRESENT\")" )
        end
        __ID1447__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyPRESENT_9783 )
        if @state.backtracking == 0

          tree_for_ID1447 = @adaptor.create_with_payload( __ID1447__ )
          @adaptor.add_child( root_0, tree_for_ID1447 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 300 )
        memoize( __method__, keyPRESENT_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyREFERENCEReturnValue = define_return_scope 

    # 
    # parser rule keyREFERENCE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1340:1: keyREFERENCE : {...}? ID ;
    # 
    def keyREFERENCE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 301 )
      return_value = KeyREFERENCEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyREFERENCE_start_index = @input.index

      root_0 = nil
      __ID1448__ = nil

      tree_for_ID1448 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1340:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("REFERENCE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyREFERENCE", "self.input.look(1).text.upcase == (\"REFERENCE\")" )
        end
        __ID1448__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyREFERENCE_9812 )
        if @state.backtracking == 0

          tree_for_ID1448 = @adaptor.create_with_payload( __ID1448__ )
          @adaptor.add_child( root_0, tree_for_ID1448 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 301 )
        memoize( __method__, keyREFERENCE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyREGEXPLIKEReturnValue = define_return_scope 

    # 
    # parser rule keyREGEXP_LIKE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1341:1: keyREGEXP_LIKE : {...}? ID ;
    # 
    def keyREGEXP_LIKE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 302 )
      return_value = KeyREGEXPLIKEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyREGEXP_LIKE_start_index = @input.index

      root_0 = nil
      __ID1449__ = nil

      tree_for_ID1449 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1341:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("REGEXP_LIKE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyREGEXP_LIKE", "self.input.look(1).text.upcase == (\"REGEXP_LIKE\")" )
        end
        __ID1449__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyREGEXP_LIKE_9839 )
        if @state.backtracking == 0

          tree_for_ID1449 = @adaptor.create_with_payload( __ID1449__ )
          @adaptor.add_child( root_0, tree_for_ID1449 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 302 )
        memoize( __method__, keyREGEXP_LIKE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyRIGHTReturnValue = define_return_scope 

    # 
    # parser rule keyRIGHT
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1343:1: keyRIGHT : {...}? ID ;
    # 
    def keyRIGHT
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 303 )
      return_value = KeyRIGHTReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyRIGHT_start_index = @input.index

      root_0 = nil
      __ID1450__ = nil

      tree_for_ID1450 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1343:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("RIGHT") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyRIGHT", "self.input.look(1).text.upcase == (\"RIGHT\")" )
        end
        __ID1450__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyRIGHT_9873 )
        if @state.backtracking == 0

          tree_for_ID1450 = @adaptor.create_with_payload( __ID1450__ )
          @adaptor.add_child( root_0, tree_for_ID1450 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 303 )
        memoize( __method__, keyRIGHT_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyROLLUPReturnValue = define_return_scope 

    # 
    # parser rule keyROLLUP
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1344:1: keyROLLUP : {...}? ID ;
    # 
    def keyROLLUP
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 304 )
      return_value = KeyROLLUPReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyROLLUP_start_index = @input.index

      root_0 = nil
      __ID1451__ = nil

      tree_for_ID1451 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1344:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("ROLLUP") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyROLLUP", "self.input.look(1).text.upcase == (\"ROLLUP\")" )
        end
        __ID1451__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyROLLUP_9905 )
        if @state.backtracking == 0

          tree_for_ID1451 = @adaptor.create_with_payload( __ID1451__ )
          @adaptor.add_child( root_0, tree_for_ID1451 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 304 )
        memoize( __method__, keyROLLUP_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyRULESReturnValue = define_return_scope 

    # 
    # parser rule keyRULES
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1345:1: keyRULES : {...}? ID ;
    # 
    def keyRULES
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 305 )
      return_value = KeyRULESReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyRULES_start_index = @input.index

      root_0 = nil
      __ID1452__ = nil

      tree_for_ID1452 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1345:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("RULES") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyRULES", "self.input.look(1).text.upcase == (\"RULES\")" )
        end
        __ID1452__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyRULES_9938 )
        if @state.backtracking == 0

          tree_for_ID1452 = @adaptor.create_with_payload( __ID1452__ )
          @adaptor.add_child( root_0, tree_for_ID1452 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 305 )
        memoize( __method__, keyRULES_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeySECONDReturnValue = define_return_scope 

    # 
    # parser rule keySECOND
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1346:1: keySECOND : {...}? ID ;
    # 
    def keySECOND
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 306 )
      return_value = KeySECONDReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keySECOND_start_index = @input.index

      root_0 = nil
      __ID1453__ = nil

      tree_for_ID1453 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1346:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("SECOND") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keySECOND", "self.input.look(1).text.upcase == (\"SECOND\")" )
        end
        __ID1453__ = match( ID, TOKENS_FOLLOWING_ID_IN_keySECOND_9970 )
        if @state.backtracking == 0

          tree_for_ID1453 = @adaptor.create_with_payload( __ID1453__ )
          @adaptor.add_child( root_0, tree_for_ID1453 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 306 )
        memoize( __method__, keySECOND_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeySECONDSReturnValue = define_return_scope 

    # 
    # parser rule keySECONDS
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1347:1: keySECONDS : {...}? ID ;
    # 
    def keySECONDS
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 307 )
      return_value = KeySECONDSReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keySECONDS_start_index = @input.index

      root_0 = nil
      __ID1454__ = nil

      tree_for_ID1454 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1347:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("SECONDS") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keySECONDS", "self.input.look(1).text.upcase == (\"SECONDS\")" )
        end
        __ID1454__ = match( ID, TOKENS_FOLLOWING_ID_IN_keySECONDS_10001 )
        if @state.backtracking == 0

          tree_for_ID1454 = @adaptor.create_with_payload( __ID1454__ )
          @adaptor.add_child( root_0, tree_for_ID1454 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 307 )
        memoize( __method__, keySECONDS_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeySEQUENTIALReturnValue = define_return_scope 

    # 
    # parser rule keySEQUENTIAL
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1348:1: keySEQUENTIAL : {...}? ID ;
    # 
    def keySEQUENTIAL
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 308 )
      return_value = KeySEQUENTIALReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keySEQUENTIAL_start_index = @input.index

      root_0 = nil
      __ID1455__ = nil

      tree_for_ID1455 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1348:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("SEQUENTIAL") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keySEQUENTIAL", "self.input.look(1).text.upcase == (\"SEQUENTIAL\")" )
        end
        __ID1455__ = match( ID, TOKENS_FOLLOWING_ID_IN_keySEQUENTIAL_10029 )
        if @state.backtracking == 0

          tree_for_ID1455 = @adaptor.create_with_payload( __ID1455__ )
          @adaptor.add_child( root_0, tree_for_ID1455 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 308 )
        memoize( __method__, keySEQUENTIAL_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeySESSIONTIMEZONEReturnValue = define_return_scope 

    # 
    # parser rule keySESSIONTIMEZONE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1349:1: keySESSIONTIMEZONE : {...}? ID ;
    # 
    def keySESSIONTIMEZONE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 309 )
      return_value = KeySESSIONTIMEZONEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keySESSIONTIMEZONE_start_index = @input.index

      root_0 = nil
      __ID1456__ = nil

      tree_for_ID1456 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1349:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("SESSIONTIMEZONE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keySESSIONTIMEZONE", "self.input.look(1).text.upcase == (\"SESSIONTIMEZONE\")" )
        end
        __ID1456__ = match( ID, TOKENS_FOLLOWING_ID_IN_keySESSIONTIMEZONE_10052 )
        if @state.backtracking == 0

          tree_for_ID1456 = @adaptor.create_with_payload( __ID1456__ )
          @adaptor.add_child( root_0, tree_for_ID1456 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 309 )
        memoize( __method__, keySESSIONTIMEZONE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeySETSReturnValue = define_return_scope 

    # 
    # parser rule keySETS
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1350:1: keySETS : {...}? ID ;
    # 
    def keySETS
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 310 )
      return_value = KeySETSReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keySETS_start_index = @input.index

      root_0 = nil
      __ID1457__ = nil

      tree_for_ID1457 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1350:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("SETS") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keySETS", "self.input.look(1).text.upcase == (\"SETS\")" )
        end
        __ID1457__ = match( ID, TOKENS_FOLLOWING_ID_IN_keySETS_10086 )
        if @state.backtracking == 0

          tree_for_ID1457 = @adaptor.create_with_payload( __ID1457__ )
          @adaptor.add_child( root_0, tree_for_ID1457 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 310 )
        memoize( __method__, keySETS_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeySIBLINGSReturnValue = define_return_scope 

    # 
    # parser rule keySIBLINGS
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1351:1: keySIBLINGS : {...}? ID ;
    # 
    def keySIBLINGS
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 311 )
      return_value = KeySIBLINGSReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keySIBLINGS_start_index = @input.index

      root_0 = nil
      __ID1458__ = nil

      tree_for_ID1458 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1351:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("SIBLINGS") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keySIBLINGS", "self.input.look(1).text.upcase == (\"SIBLINGS\")" )
        end
        __ID1458__ = match( ID, TOKENS_FOLLOWING_ID_IN_keySIBLINGS_10116 )
        if @state.backtracking == 0

          tree_for_ID1458 = @adaptor.create_with_payload( __ID1458__ )
          @adaptor.add_child( root_0, tree_for_ID1458 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 311 )
        memoize( __method__, keySIBLINGS_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeySINGLEReturnValue = define_return_scope 

    # 
    # parser rule keySINGLE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1352:1: keySINGLE : {...}? ID ;
    # 
    def keySINGLE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 312 )
      return_value = KeySINGLEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keySINGLE_start_index = @input.index

      root_0 = nil
      __ID1459__ = nil

      tree_for_ID1459 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1352:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("SINGLE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keySINGLE", "self.input.look(1).text.upcase == (\"SINGLE\")" )
        end
        __ID1459__ = match( ID, TOKENS_FOLLOWING_ID_IN_keySINGLE_10148 )
        if @state.backtracking == 0

          tree_for_ID1459 = @adaptor.create_with_payload( __ID1459__ )
          @adaptor.add_child( root_0, tree_for_ID1459 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 312 )
        memoize( __method__, keySINGLE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeySOMEReturnValue = define_return_scope 

    # 
    # parser rule keySOME
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1353:1: keySOME : {...}? ID ;
    # 
    def keySOME
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 313 )
      return_value = KeySOMEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keySOME_start_index = @input.index

      root_0 = nil
      __ID1460__ = nil

      tree_for_ID1460 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1353:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("SOME") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keySOME", "self.input.look(1).text.upcase == (\"SOME\")" )
        end
        __ID1460__ = match( ID, TOKENS_FOLLOWING_ID_IN_keySOME_10182 )
        if @state.backtracking == 0

          tree_for_ID1460 = @adaptor.create_with_payload( __ID1460__ )
          @adaptor.add_child( root_0, tree_for_ID1460 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 313 )
        memoize( __method__, keySOME_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeySUBMULTISETReturnValue = define_return_scope 

    # 
    # parser rule keySUBMULTISET
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1354:1: keySUBMULTISET : {...}? ID ;
    # 
    def keySUBMULTISET
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 314 )
      return_value = KeySUBMULTISETReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keySUBMULTISET_start_index = @input.index

      root_0 = nil
      __ID1461__ = nil

      tree_for_ID1461 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1354:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("SUBMUlookISET") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keySUBMULTISET", "self.input.look(1).text.upcase == (\"SUBMUlookISET\")" )
        end
        __ID1461__ = match( ID, TOKENS_FOLLOWING_ID_IN_keySUBMULTISET_10209 )
        if @state.backtracking == 0

          tree_for_ID1461 = @adaptor.create_with_payload( __ID1461__ )
          @adaptor.add_child( root_0, tree_for_ID1461 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 314 )
        memoize( __method__, keySUBMULTISET_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyTIMEReturnValue = define_return_scope 

    # 
    # parser rule keyTIME
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1355:1: keyTIME : {...}? ID ;
    # 
    def keyTIME
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 315 )
      return_value = KeyTIMEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyTIME_start_index = @input.index

      root_0 = nil
      __ID1462__ = nil

      tree_for_ID1462 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1355:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("TIME") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyTIME", "self.input.look(1).text.upcase == (\"TIME\")" )
        end
        __ID1462__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyTIME_10243 )
        if @state.backtracking == 0

          tree_for_ID1462 = @adaptor.create_with_payload( __ID1462__ )
          @adaptor.add_child( root_0, tree_for_ID1462 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 315 )
        memoize( __method__, keyTIME_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyTIMESTAMPReturnValue = define_return_scope 

    # 
    # parser rule keyTIMESTAMP
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1356:1: keyTIMESTAMP : {...}? ID ;
    # 
    def keyTIMESTAMP
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 316 )
      return_value = KeyTIMESTAMPReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyTIMESTAMP_start_index = @input.index

      root_0 = nil
      __ID1463__ = nil

      tree_for_ID1463 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1356:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("TIMESTAMP") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyTIMESTAMP", "self.input.look(1).text.upcase == (\"TIMESTAMP\")" )
        end
        __ID1463__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyTIMESTAMP_10272 )
        if @state.backtracking == 0

          tree_for_ID1463 = @adaptor.create_with_payload( __ID1463__ )
          @adaptor.add_child( root_0, tree_for_ID1463 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 316 )
        memoize( __method__, keyTIMESTAMP_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyTHEReturnValue = define_return_scope 

    # 
    # parser rule keyTHE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1357:1: keyTHE : {...}? ID ;
    # 
    def keyTHE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 317 )
      return_value = KeyTHEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyTHE_start_index = @input.index

      root_0 = nil
      __ID1464__ = nil

      tree_for_ID1464 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1357:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("THE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyTHE", "self.input.look(1).text.upcase == (\"THE\")" )
        end
        __ID1464__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyTHE_10307 )
        if @state.backtracking == 0

          tree_for_ID1464 = @adaptor.create_with_payload( __ID1464__ )
          @adaptor.add_child( root_0, tree_for_ID1464 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 317 )
        memoize( __method__, keyTHE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyUNDERPATHReturnValue = define_return_scope 

    # 
    # parser rule keyUNDER_PATH
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1358:1: keyUNDER_PATH : {...}? ID ;
    # 
    def keyUNDER_PATH
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 318 )
      return_value = KeyUNDERPATHReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyUNDER_PATH_start_index = @input.index

      root_0 = nil
      __ID1465__ = nil

      tree_for_ID1465 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1358:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("UNDER_PATH") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyUNDER_PATH", "self.input.look(1).text.upcase == (\"UNDER_PATH\")" )
        end
        __ID1465__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyUNDER_PATH_10335 )
        if @state.backtracking == 0

          tree_for_ID1465 = @adaptor.create_with_payload( __ID1465__ )
          @adaptor.add_child( root_0, tree_for_ID1465 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 318 )
        memoize( __method__, keyUNDER_PATH_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyUNTILReturnValue = define_return_scope 

    # 
    # parser rule keyUNTIL
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1359:1: keyUNTIL : {...}? ID ;
    # 
    def keyUNTIL
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 319 )
      return_value = KeyUNTILReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyUNTIL_start_index = @input.index

      root_0 = nil
      __ID1466__ = nil

      tree_for_ID1466 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1359:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("UNTIL") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyUNTIL", "self.input.look(1).text.upcase == (\"UNTIL\")" )
        end
        __ID1466__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyUNTIL_10368 )
        if @state.backtracking == 0

          tree_for_ID1466 = @adaptor.create_with_payload( __ID1466__ )
          @adaptor.add_child( root_0, tree_for_ID1466 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 319 )
        memoize( __method__, keyUNTIL_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyUPDATEDReturnValue = define_return_scope 

    # 
    # parser rule keyUPDATED
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1360:1: keyUPDATED : {...}? ID ;
    # 
    def keyUPDATED
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 320 )
      return_value = KeyUPDATEDReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyUPDATED_start_index = @input.index

      root_0 = nil
      __ID1467__ = nil

      tree_for_ID1467 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1360:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("UPDATED") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyUPDATED", "self.input.look(1).text.upcase == (\"UPDATED\")" )
        end
        __ID1467__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyUPDATED_10399 )
        if @state.backtracking == 0

          tree_for_ID1467 = @adaptor.create_with_payload( __ID1467__ )
          @adaptor.add_child( root_0, tree_for_ID1467 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 320 )
        memoize( __method__, keyUPDATED_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyUPSERTReturnValue = define_return_scope 

    # 
    # parser rule keyUPSERT
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1361:1: keyUPSERT : {...}? ID ;
    # 
    def keyUPSERT
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 321 )
      return_value = KeyUPSERTReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyUPSERT_start_index = @input.index

      root_0 = nil
      __ID1468__ = nil

      tree_for_ID1468 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1361:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("UPSERT") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyUPSERT", "self.input.look(1).text.upcase == (\"UPSERT\")" )
        end
        __ID1468__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyUPSERT_10431 )
        if @state.backtracking == 0

          tree_for_ID1468 = @adaptor.create_with_payload( __ID1468__ )
          @adaptor.add_child( root_0, tree_for_ID1468 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 321 )
        memoize( __method__, keyUPSERT_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyWAITReturnValue = define_return_scope 

    # 
    # parser rule keyWAIT
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1362:1: keyWAIT : {...}? ID ;
    # 
    def keyWAIT
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 322 )
      return_value = KeyWAITReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyWAIT_start_index = @input.index

      root_0 = nil
      __ID1469__ = nil

      tree_for_ID1469 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1362:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("WAIT") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyWAIT", "self.input.look(1).text.upcase == (\"WAIT\")" )
        end
        __ID1469__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyWAIT_10465 )
        if @state.backtracking == 0

          tree_for_ID1469 = @adaptor.create_with_payload( __ID1469__ )
          @adaptor.add_child( root_0, tree_for_ID1469 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 322 )
        memoize( __method__, keyWAIT_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyYEARReturnValue = define_return_scope 

    # 
    # parser rule keyYEAR
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1363:1: keyYEAR : {...}? ID ;
    # 
    def keyYEAR
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 323 )
      return_value = KeyYEARReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyYEAR_start_index = @input.index

      root_0 = nil
      __ID1470__ = nil

      tree_for_ID1470 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1363:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("YEAR") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyYEAR", "self.input.look(1).text.upcase == (\"YEAR\")" )
        end
        __ID1470__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyYEAR_10499 )
        if @state.backtracking == 0

          tree_for_ID1470 = @adaptor.create_with_payload( __ID1470__ )
          @adaptor.add_child( root_0, tree_for_ID1470 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 323 )
        memoize( __method__, keyYEAR_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyZONEReturnValue = define_return_scope 

    # 
    # parser rule keyZONE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1364:1: keyZONE : {...}? ID ;
    # 
    def keyZONE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 324 )
      return_value = KeyZONEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyZONE_start_index = @input.index

      root_0 = nil
      __ID1471__ = nil

      tree_for_ID1471 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1364:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("ZONE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyZONE", "self.input.look(1).text.upcase == (\"ZONE\")" )
        end
        __ID1471__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyZONE_10533 )
        if @state.backtracking == 0

          tree_for_ID1471 = @adaptor.create_with_payload( __ID1471__ )
          @adaptor.add_child( root_0, tree_for_ID1471 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 324 )
        memoize( __method__, keyZONE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyARRAYReturnValue = define_return_scope 

    # 
    # parser rule keyARRAY
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1366:1: keyARRAY : {...}? ID ;
    # 
    def keyARRAY
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 325 )
      return_value = KeyARRAYReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyARRAY_start_index = @input.index

      root_0 = nil
      __ID1472__ = nil

      tree_for_ID1472 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1366:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("ARRAY") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyARRAY", "self.input.look(1).text.upcase == (\"ARRAY\")" )
        end
        __ID1472__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyARRAY_10567 )
        if @state.backtracking == 0

          tree_for_ID1472 = @adaptor.create_with_payload( __ID1472__ )
          @adaptor.add_child( root_0, tree_for_ID1472 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 325 )
        memoize( __method__, keyARRAY_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyAUTONOMOUSTRANSACTIONReturnValue = define_return_scope 

    # 
    # parser rule keyAUTONOMOUS_TRANSACTION
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1367:1: keyAUTONOMOUS_TRANSACTION : {...}? ID ;
    # 
    def keyAUTONOMOUS_TRANSACTION
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 326 )
      return_value = KeyAUTONOMOUSTRANSACTIONReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyAUTONOMOUS_TRANSACTION_start_index = @input.index

      root_0 = nil
      __ID1473__ = nil

      tree_for_ID1473 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1367:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("AUTONOMOUS_TRANSACTION") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyAUTONOMOUS_TRANSACTION", "self.input.look(1).text.upcase == (\"AUTONOMOUS_TRANSACTION\")" )
        end
        __ID1473__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyAUTONOMOUS_TRANSACTION_10583 )
        if @state.backtracking == 0

          tree_for_ID1473 = @adaptor.create_with_payload( __ID1473__ )
          @adaptor.add_child( root_0, tree_for_ID1473 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 326 )
        memoize( __method__, keyAUTONOMOUS_TRANSACTION_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyBODYReturnValue = define_return_scope 

    # 
    # parser rule keyBODY
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1368:1: keyBODY : {...}? ID ;
    # 
    def keyBODY
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 327 )
      return_value = KeyBODYReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyBODY_start_index = @input.index

      root_0 = nil
      __ID1474__ = nil

      tree_for_ID1474 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1368:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("BODY") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyBODY", "self.input.look(1).text.upcase == (\"BODY\")" )
        end
        __ID1474__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyBODY_10617 )
        if @state.backtracking == 0

          tree_for_ID1474 = @adaptor.create_with_payload( __ID1474__ )
          @adaptor.add_child( root_0, tree_for_ID1474 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 327 )
        memoize( __method__, keyBODY_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyBUILTINReturnValue = define_return_scope 

    # 
    # parser rule keyBUILTIN
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1369:1: keyBUILTIN : {...}? ID ;
    # 
    def keyBUILTIN
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 328 )
      return_value = KeyBUILTINReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyBUILTIN_start_index = @input.index

      root_0 = nil
      __ID1475__ = nil

      tree_for_ID1475 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1369:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("BUIlookIN") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyBUILTIN", "self.input.look(1).text.upcase == (\"BUIlookIN\")" )
        end
        __ID1475__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyBUILTIN_10648 )
        if @state.backtracking == 0

          tree_for_ID1475 = @adaptor.create_with_payload( __ID1475__ )
          @adaptor.add_child( root_0, tree_for_ID1475 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 328 )
        memoize( __method__, keyBUILTIN_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyBULKReturnValue = define_return_scope 

    # 
    # parser rule keyBULK
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1370:1: keyBULK : {...}? ID ;
    # 
    def keyBULK
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 329 )
      return_value = KeyBULKReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyBULK_start_index = @input.index

      root_0 = nil
      __ID1476__ = nil

      tree_for_ID1476 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1370:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("BULK") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyBULK", "self.input.look(1).text.upcase == (\"BULK\")" )
        end
        __ID1476__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyBULK_10682 )
        if @state.backtracking == 0

          tree_for_ID1476 = @adaptor.create_with_payload( __ID1476__ )
          @adaptor.add_child( root_0, tree_for_ID1476 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 329 )
        memoize( __method__, keyBULK_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyBYTEReturnValue = define_return_scope 

    # 
    # parser rule keyBYTE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1371:1: keyBYTE : {...}? ID ;
    # 
    def keyBYTE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 330 )
      return_value = KeyBYTEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyBYTE_start_index = @input.index

      root_0 = nil
      __ID1477__ = nil

      tree_for_ID1477 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1371:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("BYTE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyBYTE", "self.input.look(1).text.upcase == (\"BYTE\")" )
        end
        __ID1477__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyBYTE_10716 )
        if @state.backtracking == 0

          tree_for_ID1477 = @adaptor.create_with_payload( __ID1477__ )
          @adaptor.add_child( root_0, tree_for_ID1477 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 330 )
        memoize( __method__, keyBYTE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyCLOSEReturnValue = define_return_scope 

    # 
    # parser rule keyCLOSE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1372:1: keyCLOSE : {...}? ID ;
    # 
    def keyCLOSE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 331 )
      return_value = KeyCLOSEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyCLOSE_start_index = @input.index

      root_0 = nil
      __ID1478__ = nil

      tree_for_ID1478 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1372:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("CLOSE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyCLOSE", "self.input.look(1).text.upcase == (\"CLOSE\")" )
        end
        __ID1478__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyCLOSE_10749 )
        if @state.backtracking == 0

          tree_for_ID1478 = @adaptor.create_with_payload( __ID1478__ )
          @adaptor.add_child( root_0, tree_for_ID1478 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 331 )
        memoize( __method__, keyCLOSE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyCOLLECTReturnValue = define_return_scope 

    # 
    # parser rule keyCOLLECT
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1373:1: keyCOLLECT : {...}? ID ;
    # 
    def keyCOLLECT
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 332 )
      return_value = KeyCOLLECTReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyCOLLECT_start_index = @input.index

      root_0 = nil
      __ID1479__ = nil

      tree_for_ID1479 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1373:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("COLLECT") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyCOLLECT", "self.input.look(1).text.upcase == (\"COLLECT\")" )
        end
        __ID1479__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyCOLLECT_10780 )
        if @state.backtracking == 0

          tree_for_ID1479 = @adaptor.create_with_payload( __ID1479__ )
          @adaptor.add_child( root_0, tree_for_ID1479 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 332 )
        memoize( __method__, keyCOLLECT_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyCURSORReturnValue = define_return_scope 

    # 
    # parser rule keyCURSOR
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1374:1: keyCURSOR : {...}? ID ;
    # 
    def keyCURSOR
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 333 )
      return_value = KeyCURSORReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyCURSOR_start_index = @input.index

      root_0 = nil
      __ID1480__ = nil

      tree_for_ID1480 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1374:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("CURSOR") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyCURSOR", "self.input.look(1).text.upcase == (\"CURSOR\")" )
        end
        __ID1480__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyCURSOR_10812 )
        if @state.backtracking == 0

          tree_for_ID1480 = @adaptor.create_with_payload( __ID1480__ )
          @adaptor.add_child( root_0, tree_for_ID1480 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 333 )
        memoize( __method__, keyCURSOR_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyELSIFReturnValue = define_return_scope 

    # 
    # parser rule keyELSIF
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1375:1: keyELSIF : 'ELSIF' ;
    # 
    def keyELSIF
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 334 )
      return_value = KeyELSIFReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyELSIF_start_index = @input.index

      root_0 = nil
      string_literal1481 = nil

      tree_for_string_literal1481 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1375:36: 'ELSIF'
        string_literal1481 = match( T__157, TOKENS_FOLLOWING_T__157_IN_keyELSIF_10843 )
        if @state.backtracking == 0

          tree_for_string_literal1481 = @adaptor.create_with_payload( string_literal1481 )
          @adaptor.add_child( root_0, tree_for_string_literal1481 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 334 )
        memoize( __method__, keyELSIF_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyEXCEPTIONINITReturnValue = define_return_scope 

    # 
    # parser rule keyEXCEPTION_INIT
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1376:1: keyEXCEPTION_INIT : {...}? ID ;
    # 
    def keyEXCEPTION_INIT
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 335 )
      return_value = KeyEXCEPTIONINITReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyEXCEPTION_INIT_start_index = @input.index

      root_0 = nil
      __ID1482__ = nil

      tree_for_ID1482 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1376:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("EXCEPTION_INIT") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyEXCEPTION_INIT", "self.input.look(1).text.upcase == (\"EXCEPTION_INIT\")" )
        end
        __ID1482__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyEXCEPTION_INIT_10868 )
        if @state.backtracking == 0

          tree_for_ID1482 = @adaptor.create_with_payload( __ID1482__ )
          @adaptor.add_child( root_0, tree_for_ID1482 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 335 )
        memoize( __method__, keyEXCEPTION_INIT_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyEXITReturnValue = define_return_scope 

    # 
    # parser rule keyEXIT
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1377:1: keyEXIT : {...}? ID ;
    # 
    def keyEXIT
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 336 )
      return_value = KeyEXITReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyEXIT_start_index = @input.index

      root_0 = nil
      __ID1483__ = nil

      tree_for_ID1483 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1377:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("EXIT") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyEXIT", "self.input.look(1).text.upcase == (\"EXIT\")" )
        end
        __ID1483__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyEXIT_10902 )
        if @state.backtracking == 0

          tree_for_ID1483 = @adaptor.create_with_payload( __ID1483__ )
          @adaptor.add_child( root_0, tree_for_ID1483 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 336 )
        memoize( __method__, keyEXIT_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyFIPSFLAGReturnValue = define_return_scope 

    # 
    # parser rule keyFIPSFLAG
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1378:1: keyFIPSFLAG : {...}? ID ;
    # 
    def keyFIPSFLAG
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 337 )
      return_value = KeyFIPSFLAGReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyFIPSFLAG_start_index = @input.index

      root_0 = nil
      __ID1484__ = nil

      tree_for_ID1484 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1378:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("FIPSFLAG") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyFIPSFLAG", "self.input.look(1).text.upcase == (\"FIPSFLAG\")" )
        end
        __ID1484__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyFIPSFLAG_10932 )
        if @state.backtracking == 0

          tree_for_ID1484 = @adaptor.create_with_payload( __ID1484__ )
          @adaptor.add_child( root_0, tree_for_ID1484 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 337 )
        memoize( __method__, keyFIPSFLAG_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyFUNCTIONReturnValue = define_return_scope 

    # 
    # parser rule keyFUNCTION
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1379:1: keyFUNCTION : 'FUNCTION' ;
    # 
    def keyFUNCTION
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 338 )
      return_value = KeyFUNCTIONReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyFUNCTION_start_index = @input.index

      root_0 = nil
      string_literal1485 = nil

      tree_for_string_literal1485 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1379:36: 'FUNCTION'
        string_literal1485 = match( T__104, TOKENS_FOLLOWING_T__104_IN_keyFUNCTION_10960 )
        if @state.backtracking == 0

          tree_for_string_literal1485 = @adaptor.create_with_payload( string_literal1485 )
          @adaptor.add_child( root_0, tree_for_string_literal1485 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 338 )
        memoize( __method__, keyFUNCTION_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyINTERFACEReturnValue = define_return_scope 

    # 
    # parser rule keyINTERFACE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1380:1: keyINTERFACE : {...}? ID ;
    # 
    def keyINTERFACE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 339 )
      return_value = KeyINTERFACEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyINTERFACE_start_index = @input.index

      root_0 = nil
      __ID1486__ = nil

      tree_for_ID1486 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1380:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("INTERFACE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyINTERFACE", "self.input.look(1).text.upcase == (\"INTERFACE\")" )
        end
        __ID1486__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyINTERFACE_10990 )
        if @state.backtracking == 0

          tree_for_ID1486 = @adaptor.create_with_payload( __ID1486__ )
          @adaptor.add_child( root_0, tree_for_ID1486 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 339 )
        memoize( __method__, keyINTERFACE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyLOOPReturnValue = define_return_scope 

    # 
    # parser rule keyLOOP
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1381:1: keyLOOP : 'LOOP' ;
    # 
    def keyLOOP
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 340 )
      return_value = KeyLOOPReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyLOOP_start_index = @input.index

      root_0 = nil
      string_literal1487 = nil

      tree_for_string_literal1487 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1381:36: 'LOOP'
        string_literal1487 = match( T__158, TOKENS_FOLLOWING_T__158_IN_keyLOOP_11022 )
        if @state.backtracking == 0

          tree_for_string_literal1487 = @adaptor.create_with_payload( string_literal1487 )
          @adaptor.add_child( root_0, tree_for_string_literal1487 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 340 )
        memoize( __method__, keyLOOP_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyNEWReturnValue = define_return_scope 

    # 
    # parser rule keyNEW
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1382:1: keyNEW : {...}? ID ;
    # 
    def keyNEW
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 341 )
      return_value = KeyNEWReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyNEW_start_index = @input.index

      root_0 = nil
      __ID1488__ = nil

      tree_for_ID1488 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1382:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("NEW") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyNEW", "self.input.look(1).text.upcase == (\"NEW\")" )
        end
        __ID1488__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyNEW_11058 )
        if @state.backtracking == 0

          tree_for_ID1488 = @adaptor.create_with_payload( __ID1488__ )
          @adaptor.add_child( root_0, tree_for_ID1488 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 341 )
        memoize( __method__, keyNEW_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyNEWNAMESReturnValue = define_return_scope 

    # 
    # parser rule keyNEW_NAMES
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1383:1: keyNEW_NAMES : {...}? ID ;
    # 
    def keyNEW_NAMES
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 342 )
      return_value = KeyNEWNAMESReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyNEW_NAMES_start_index = @input.index

      root_0 = nil
      __ID1489__ = nil

      tree_for_ID1489 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1383:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("NEW_NAMES") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyNEW_NAMES", "self.input.look(1).text.upcase == (\"NEW_NAMES\")" )
        end
        __ID1489__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyNEW_NAMES_11087 )
        if @state.backtracking == 0

          tree_for_ID1489 = @adaptor.create_with_payload( __ID1489__ )
          @adaptor.add_child( root_0, tree_for_ID1489 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 342 )
        memoize( __method__, keyNEW_NAMES_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyOPENReturnValue = define_return_scope 

    # 
    # parser rule keyOPEN
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1384:1: keyOPEN : {...}? ID ;
    # 
    def keyOPEN
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 343 )
      return_value = KeyOPENReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyOPEN_start_index = @input.index

      root_0 = nil
      __ID1490__ = nil

      tree_for_ID1490 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1384:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("OPEN") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyOPEN", "self.input.look(1).text.upcase == (\"OPEN\")" )
        end
        __ID1490__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyOPEN_11121 )
        if @state.backtracking == 0

          tree_for_ID1490 = @adaptor.create_with_payload( __ID1490__ )
          @adaptor.add_child( root_0, tree_for_ID1490 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 343 )
        memoize( __method__, keyOPEN_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyOUTReturnValue = define_return_scope 

    # 
    # parser rule keyOUT
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1385:1: keyOUT : 'OUT' ;
    # 
    def keyOUT
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 344 )
      return_value = KeyOUTReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyOUT_start_index = @input.index

      root_0 = nil
      string_literal1491 = nil

      tree_for_string_literal1491 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1385:36: 'OUT'
        string_literal1491 = match( T__159, TOKENS_FOLLOWING_T__159_IN_keyOUT_11154 )
        if @state.backtracking == 0

          tree_for_string_literal1491 = @adaptor.create_with_payload( string_literal1491 )
          @adaptor.add_child( root_0, tree_for_string_literal1491 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 344 )
        memoize( __method__, keyOUT_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyPACKAGEReturnValue = define_return_scope 

    # 
    # parser rule keyPACKAGE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1386:1: keyPACKAGE : 'PACKAGE' ;
    # 
    def keyPACKAGE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 345 )
      return_value = KeyPACKAGEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyPACKAGE_start_index = @input.index

      root_0 = nil
      string_literal1492 = nil

      tree_for_string_literal1492 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1386:36: 'PACKAGE'
        string_literal1492 = match( T__160, TOKENS_FOLLOWING_T__160_IN_keyPACKAGE_11184 )
        if @state.backtracking == 0

          tree_for_string_literal1492 = @adaptor.create_with_payload( string_literal1492 )
          @adaptor.add_child( root_0, tree_for_string_literal1492 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 345 )
        memoize( __method__, keyPACKAGE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyPRAGMAReturnValue = define_return_scope 

    # 
    # parser rule keyPRAGMA
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1387:1: keyPRAGMA : 'PRAGMA' ;
    # 
    def keyPRAGMA
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 346 )
      return_value = KeyPRAGMAReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyPRAGMA_start_index = @input.index

      root_0 = nil
      string_literal1493 = nil

      tree_for_string_literal1493 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1387:36: 'PRAGMA'
        string_literal1493 = match( T__161, TOKENS_FOLLOWING_T__161_IN_keyPRAGMA_11215 )
        if @state.backtracking == 0

          tree_for_string_literal1493 = @adaptor.create_with_payload( string_literal1493 )
          @adaptor.add_child( root_0, tree_for_string_literal1493 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 346 )
        memoize( __method__, keyPRAGMA_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyRAISEReturnValue = define_return_scope 

    # 
    # parser rule keyRAISE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1388:1: keyRAISE : 'RAISE' ;
    # 
    def keyRAISE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 347 )
      return_value = KeyRAISEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyRAISE_start_index = @input.index

      root_0 = nil
      string_literal1494 = nil

      tree_for_string_literal1494 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1388:36: 'RAISE'
        string_literal1494 = match( T__162, TOKENS_FOLLOWING_T__162_IN_keyRAISE_11247 )
        if @state.backtracking == 0

          tree_for_string_literal1494 = @adaptor.create_with_payload( string_literal1494 )
          @adaptor.add_child( root_0, tree_for_string_literal1494 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 347 )
        memoize( __method__, keyRAISE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyRANGEReturnValue = define_return_scope 

    # 
    # parser rule keyRANGE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1389:1: keyRANGE : {...}? ID ;
    # 
    def keyRANGE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 348 )
      return_value = KeyRANGEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyRANGE_start_index = @input.index

      root_0 = nil
      __ID1495__ = nil

      tree_for_ID1495 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1389:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("RANGE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyRANGE", "self.input.look(1).text.upcase == (\"RANGE\")" )
        end
        __ID1495__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyRANGE_11281 )
        if @state.backtracking == 0

          tree_for_ID1495 = @adaptor.create_with_payload( __ID1495__ )
          @adaptor.add_child( root_0, tree_for_ID1495 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 348 )
        memoize( __method__, keyRANGE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyREADReturnValue = define_return_scope 

    # 
    # parser rule keyREAD
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1390:1: keyREAD : {...}? ID ;
    # 
    def keyREAD
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 349 )
      return_value = KeyREADReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyREAD_start_index = @input.index

      root_0 = nil
      __ID1496__ = nil

      tree_for_ID1496 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1390:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("READ") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyREAD", "self.input.look(1).text.upcase == (\"READ\")" )
        end
        __ID1496__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyREAD_11315 )
        if @state.backtracking == 0

          tree_for_ID1496 = @adaptor.create_with_payload( __ID1496__ )
          @adaptor.add_child( root_0, tree_for_ID1496 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 349 )
        memoize( __method__, keyREAD_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyRECORDReturnValue = define_return_scope 

    # 
    # parser rule keyRECORD
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1391:1: keyRECORD : 'RECORD' ;
    # 
    def keyRECORD
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 350 )
      return_value = KeyRECORDReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyRECORD_start_index = @input.index

      root_0 = nil
      string_literal1497 = nil

      tree_for_string_literal1497 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1391:36: 'RECORD'
        string_literal1497 = match( T__163, TOKENS_FOLLOWING_T__163_IN_keyRECORD_11345 )
        if @state.backtracking == 0

          tree_for_string_literal1497 = @adaptor.create_with_payload( string_literal1497 )
          @adaptor.add_child( root_0, tree_for_string_literal1497 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 350 )
        memoize( __method__, keyRECORD_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyREFReturnValue = define_return_scope 

    # 
    # parser rule keyREF
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1392:1: keyREF : {...}? ID ;
    # 
    def keyREF
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 351 )
      return_value = KeyREFReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyREF_start_index = @input.index

      root_0 = nil
      __ID1498__ = nil

      tree_for_ID1498 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1392:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("REF") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyREF", "self.input.look(1).text.upcase == (\"REF\")" )
        end
        __ID1498__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyREF_11381 )
        if @state.backtracking == 0

          tree_for_ID1498 = @adaptor.create_with_payload( __ID1498__ )
          @adaptor.add_child( root_0, tree_for_ID1498 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 351 )
        memoize( __method__, keyREF_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyREPLACEReturnValue = define_return_scope 

    # 
    # parser rule keyREPLACE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1393:1: keyREPLACE : {...}? ID ;
    # 
    def keyREPLACE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 352 )
      return_value = KeyREPLACEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyREPLACE_start_index = @input.index

      root_0 = nil
      __ID1499__ = nil

      tree_for_ID1499 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1393:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("REPLACE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyREPLACE", "self.input.look(1).text.upcase == (\"REPLACE\")" )
        end
        __ID1499__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyREPLACE_11412 )
        if @state.backtracking == 0

          tree_for_ID1499 = @adaptor.create_with_payload( __ID1499__ )
          @adaptor.add_child( root_0, tree_for_ID1499 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 352 )
        memoize( __method__, keyREPLACE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyRESTRICTREFERENCESReturnValue = define_return_scope 

    # 
    # parser rule keyRESTRICT_REFERENCES
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1394:1: keyRESTRICT_REFERENCES : {...}? ID ;
    # 
    def keyRESTRICT_REFERENCES
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 353 )
      return_value = KeyRESTRICTREFERENCESReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyRESTRICT_REFERENCES_start_index = @input.index

      root_0 = nil
      __ID1500__ = nil

      tree_for_ID1500 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1394:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("RESTRICT_REFERENCES") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyRESTRICT_REFERENCES", "self.input.look(1).text.upcase == (\"RESTRICT_REFERENCES\")" )
        end
        __ID1500__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyRESTRICT_REFERENCES_11431 )
        if @state.backtracking == 0

          tree_for_ID1500 = @adaptor.create_with_payload( __ID1500__ )
          @adaptor.add_child( root_0, tree_for_ID1500 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 353 )
        memoize( __method__, keyRESTRICT_REFERENCES_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyRETURNReturnValue = define_return_scope 

    # 
    # parser rule keyRETURN
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1395:1: keyRETURN : 'RETURN' ;
    # 
    def keyRETURN
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 354 )
      return_value = KeyRETURNReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyRETURN_start_index = @input.index

      root_0 = nil
      string_literal1501 = nil

      tree_for_string_literal1501 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1395:36: 'RETURN'
        string_literal1501 = match( T__164, TOKENS_FOLLOWING_T__164_IN_keyRETURN_11461 )
        if @state.backtracking == 0

          tree_for_string_literal1501 = @adaptor.create_with_payload( string_literal1501 )
          @adaptor.add_child( root_0, tree_for_string_literal1501 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 354 )
        memoize( __method__, keyRETURN_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyRETURNINGReturnValue = define_return_scope 

    # 
    # parser rule keyRETURNING
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1396:1: keyRETURNING : 'RETURNING' ;
    # 
    def keyRETURNING
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 355 )
      return_value = KeyRETURNINGReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyRETURNING_start_index = @input.index

      root_0 = nil
      string_literal1502 = nil

      tree_for_string_literal1502 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1396:36: 'RETURNING'
        string_literal1502 = match( T__165, TOKENS_FOLLOWING_T__165_IN_keyRETURNING_11489 )
        if @state.backtracking == 0

          tree_for_string_literal1502 = @adaptor.create_with_payload( string_literal1502 )
          @adaptor.add_child( root_0, tree_for_string_literal1502 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 355 )
        memoize( __method__, keyRETURNING_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyREVERSEReturnValue = define_return_scope 

    # 
    # parser rule keyREVERSE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1397:1: keyREVERSE : {...}? ID ;
    # 
    def keyREVERSE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 356 )
      return_value = KeyREVERSEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyREVERSE_start_index = @input.index

      root_0 = nil
      __ID1503__ = nil

      tree_for_ID1503 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1397:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("REVERSE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyREVERSE", "self.input.look(1).text.upcase == (\"REVERSE\")" )
        end
        __ID1503__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyREVERSE_11521 )
        if @state.backtracking == 0

          tree_for_ID1503 = @adaptor.create_with_payload( __ID1503__ )
          @adaptor.add_child( root_0, tree_for_ID1503 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 356 )
        memoize( __method__, keyREVERSE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyROLLBACKReturnValue = define_return_scope 

    # 
    # parser rule keyROLLBACK
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1398:1: keyROLLBACK : 'ROLLBACK' ;
    # 
    def keyROLLBACK
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 357 )
      return_value = KeyROLLBACKReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyROLLBACK_start_index = @input.index

      root_0 = nil
      string_literal1504 = nil

      tree_for_string_literal1504 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1398:36: 'ROLLBACK'
        string_literal1504 = match( T__166, TOKENS_FOLLOWING_T__166_IN_keyROLLBACK_11549 )
        if @state.backtracking == 0

          tree_for_string_literal1504 = @adaptor.create_with_payload( string_literal1504 )
          @adaptor.add_child( root_0, tree_for_string_literal1504 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 357 )
        memoize( __method__, keyROLLBACK_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeySERIALLYREUSABLEReturnValue = define_return_scope 

    # 
    # parser rule keySERIALLY_REUSABLE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1399:1: keySERIALLY_REUSABLE : {...}? ID ;
    # 
    def keySERIALLY_REUSABLE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 358 )
      return_value = KeySERIALLYREUSABLEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keySERIALLY_REUSABLE_start_index = @input.index

      root_0 = nil
      __ID1505__ = nil

      tree_for_ID1505 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1399:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("SERIALLY_REUSABLE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keySERIALLY_REUSABLE", "self.input.look(1).text.upcase == (\"SERIALLY_REUSABLE\")" )
        end
        __ID1505__ = match( ID, TOKENS_FOLLOWING_ID_IN_keySERIALLY_REUSABLE_11571 )
        if @state.backtracking == 0

          tree_for_ID1505 = @adaptor.create_with_payload( __ID1505__ )
          @adaptor.add_child( root_0, tree_for_ID1505 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 358 )
        memoize( __method__, keySERIALLY_REUSABLE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeySUBTYPEReturnValue = define_return_scope 

    # 
    # parser rule keySUBTYPE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1400:1: keySUBTYPE : {...}? ID ;
    # 
    def keySUBTYPE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 359 )
      return_value = KeySUBTYPEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keySUBTYPE_start_index = @input.index

      root_0 = nil
      __ID1506__ = nil

      tree_for_ID1506 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1400:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("SUBTYPE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keySUBTYPE", "self.input.look(1).text.upcase == (\"SUBTYPE\")" )
        end
        __ID1506__ = match( ID, TOKENS_FOLLOWING_ID_IN_keySUBTYPE_11602 )
        if @state.backtracking == 0

          tree_for_ID1506 = @adaptor.create_with_payload( __ID1506__ )
          @adaptor.add_child( root_0, tree_for_ID1506 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 359 )
        memoize( __method__, keySUBTYPE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyTRANSACTIONReturnValue = define_return_scope 

    # 
    # parser rule keyTRANSACTION
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1401:1: keyTRANSACTION : {...}? ID ;
    # 
    def keyTRANSACTION
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 360 )
      return_value = KeyTRANSACTIONReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyTRANSACTION_start_index = @input.index

      root_0 = nil
      __ID1507__ = nil

      tree_for_ID1507 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1401:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("TRANSACTION") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyTRANSACTION", "self.input.look(1).text.upcase == (\"TRANSACTION\")" )
        end
        __ID1507__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyTRANSACTION_11629 )
        if @state.backtracking == 0

          tree_for_ID1507 = @adaptor.create_with_payload( __ID1507__ )
          @adaptor.add_child( root_0, tree_for_ID1507 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 360 )
        memoize( __method__, keyTRANSACTION_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyTYPEReturnValue = define_return_scope 

    # 
    # parser rule keyTYPE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1402:1: keyTYPE : {...}? ID ;
    # 
    def keyTYPE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 361 )
      return_value = KeyTYPEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyTYPE_start_index = @input.index

      root_0 = nil
      __ID1508__ = nil

      tree_for_ID1508 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1402:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("TYPE") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyTYPE", "self.input.look(1).text.upcase == (\"TYPE\")" )
        end
        __ID1508__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyTYPE_11663 )
        if @state.backtracking == 0

          tree_for_ID1508 = @adaptor.create_with_payload( __ID1508__ )
          @adaptor.add_child( root_0, tree_for_ID1508 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 361 )
        memoize( __method__, keyTYPE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyUSINGReturnValue = define_return_scope 

    # 
    # parser rule keyUSING
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1403:1: keyUSING : {...}? ID ;
    # 
    def keyUSING
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 362 )
      return_value = KeyUSINGReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyUSING_start_index = @input.index

      root_0 = nil
      __ID1509__ = nil

      tree_for_ID1509 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1403:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("USING") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyUSING", "self.input.look(1).text.upcase == (\"USING\")" )
        end
        __ID1509__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyUSING_11696 )
        if @state.backtracking == 0

          tree_for_ID1509 = @adaptor.create_with_payload( __ID1509__ )
          @adaptor.add_child( root_0, tree_for_ID1509 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 362 )
        memoize( __method__, keyUSING_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyVARRAYReturnValue = define_return_scope 

    # 
    # parser rule keyVARRAY
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1404:1: keyVARRAY : {...}? ID ;
    # 
    def keyVARRAY
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 363 )
      return_value = KeyVARRAYReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyVARRAY_start_index = @input.index

      root_0 = nil
      __ID1510__ = nil

      tree_for_ID1510 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1404:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("VARRAY") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyVARRAY", "self.input.look(1).text.upcase == (\"VARRAY\")" )
        end
        __ID1510__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyVARRAY_11728 )
        if @state.backtracking == 0

          tree_for_ID1510 = @adaptor.create_with_payload( __ID1510__ )
          @adaptor.add_child( root_0, tree_for_ID1510 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 363 )
        memoize( __method__, keyVARRAY_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyVARYINGReturnValue = define_return_scope 

    # 
    # parser rule keyVARYING
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1405:1: keyVARYING : {...}? ID ;
    # 
    def keyVARYING
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 364 )
      return_value = KeyVARYINGReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyVARYING_start_index = @input.index

      root_0 = nil
      __ID1511__ = nil

      tree_for_ID1511 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1405:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("VARYING") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyVARYING", "self.input.look(1).text.upcase == (\"VARYING\")" )
        end
        __ID1511__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyVARYING_11759 )
        if @state.backtracking == 0

          tree_for_ID1511 = @adaptor.create_with_payload( __ID1511__ )
          @adaptor.add_child( root_0, tree_for_ID1511 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 364 )
        memoize( __method__, keyVARYING_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyWHILEReturnValue = define_return_scope 

    # 
    # parser rule keyWHILE
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1406:1: keyWHILE : 'WHILE' ;
    # 
    def keyWHILE
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 365 )
      return_value = KeyWHILEReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyWHILE_start_index = @input.index

      root_0 = nil
      string_literal1512 = nil

      tree_for_string_literal1512 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1406:36: 'WHILE'
        string_literal1512 = match( T__167, TOKENS_FOLLOWING_T__167_IN_keyWHILE_11790 )
        if @state.backtracking == 0

          tree_for_string_literal1512 = @adaptor.create_with_payload( string_literal1512 )
          @adaptor.add_child( root_0, tree_for_string_literal1512 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 365 )
        memoize( __method__, keyWHILE_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    KeyWORKReturnValue = define_return_scope 

    # 
    # parser rule keyWORK
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1407:1: keyWORK : {...}? ID ;
    # 
    def keyWORK
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 366 )
      return_value = KeyWORKReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      keyWORK_start_index = @input.index

      root_0 = nil
      __ID1513__ = nil

      tree_for_ID1513 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        root_0 = @adaptor.create_flat_list


        # at line 1407:36: {...}? ID
        unless ( ( self.input.look(1).text.upcase == ("WORK") ) )
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise FailedPredicate( "keyWORK", "self.input.look(1).text.upcase == (\"WORK\")" )
        end
        __ID1513__ = match( ID, TOKENS_FOLLOWING_ID_IN_keyWORK_11825 )
        if @state.backtracking == 0

          tree_for_ID1513 = @adaptor.create_with_payload( __ID1513__ )
          @adaptor.add_child( root_0, tree_for_ID1513 )

        end
        # - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 366 )
        memoize( __method__, keyWORK_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    SqlIdentifierReturnValue = define_return_scope 

    # 
    # parser rule sql_identifier
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1409:1: sql_identifier : ( identifier | 'ROWID' );
    # 
    def sql_identifier
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 367 )
      return_value = SqlIdentifierReturnValue.new

      # $rule.start = the first token seen before matching
      return_value.start = @input.look
      sql_identifier_start_index = @input.index

      root_0 = nil
      string_literal1515 = nil
      identifier1514 = nil

      tree_for_string_literal1515 = nil

      success = false # flag used for memoization

      begin
        # rule memoization
        if @state.backtracking > 0 and already_parsed_rule?( __method__ )
          success = true
          return return_value
        end
        # at line 1410:2: ( identifier | 'ROWID' )
        alt_364 = 2
        look_364_0 = @input.peek( 1 )

        if ( look_364_0.between?( ID, DOUBLEQUOTED_STRING ) )
          alt_364 = 1
        elsif ( look_364_0 == T__100 )
          alt_364 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 364, 0 )
        end
        case alt_364
        when 1
          root_0 = @adaptor.create_flat_list


          # at line 1410:4: identifier
          @state.following.push( TOKENS_FOLLOWING_identifier_IN_sql_identifier_11834 )
          identifier1514 = identifier
          @state.following.pop
          if @state.backtracking == 0
            @adaptor.add_child( root_0, identifier1514.tree )
          end

        when 2
          root_0 = @adaptor.create_flat_list


          # at line 1411:4: 'ROWID'
          string_literal1515 = match( T__100, TOKENS_FOLLOWING_T__100_IN_sql_identifier_11839 )
          if @state.backtracking == 0

            tree_for_string_literal1515 = @adaptor.create_with_payload( string_literal1515 )
            @adaptor.add_child( root_0, tree_for_string_literal1515 )

          end

        end# - - - - - - - rule clean up - - - - - - - -
        return_value.stop = @input.look( -1 )

        if @state.backtracking == 0

          return_value.tree = @adaptor.rule_post_processing( root_0 )
          @adaptor.set_token_boundaries( return_value.tree, return_value.start, return_value.stop )

        end
        success = true

      rescue ANTLR3::Error::RecognitionError => re
        report_error(re)
        recover(re)
        return_value.tree = @adaptor.create_error_node( @input, return_value.start, @input.look(-1), re )

      ensure
        # -> uncomment the next line to manually enable rule tracing
        # trace_out( __method__, 367 )
        memoize( __method__, sql_identifier_start_index, success ) if @state.backtracking > 0

      end
      
      return return_value
    end

    # 
    # syntactic predicate synpred13_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 51:4: synpred13_Plsql : type_declaration ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred13_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 380 )

      # at line 51:4: type_declaration
      @state.following.push( TOKENS_FOLLOWING_type_declaration_IN_synpred13_Plsql_242 )
      type_declaration
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 380 )

    end
    # 
    # syntactic predicate synpred14_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 52:4: synpred14_Plsql : subtype_declaration ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred14_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 381 )

      # at line 52:4: subtype_declaration
      @state.following.push( TOKENS_FOLLOWING_subtype_declaration_IN_synpred14_Plsql_247 )
      subtype_declaration
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 381 )

    end
    # 
    # syntactic predicate synpred27_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 71:29: synpred27_Plsql : keyNEW ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred27_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 394 )

      # at line 71:29: keyNEW
      @state.following.push( TOKENS_FOLLOWING_keyNEW_IN_synpred27_Plsql_369 )
      keyNEW
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 394 )

    end
    # 
    # syntactic predicate synpred43_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 101:4: synpred43_Plsql : assignment_statement ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred43_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 410 )

      # at line 101:4: assignment_statement
      @state.following.push( TOKENS_FOLLOWING_assignment_statement_IN_synpred43_Plsql_570 )
      assignment_statement
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 410 )

    end
    # 
    # syntactic predicate synpred44_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 102:4: synpred44_Plsql : exit_statement ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred44_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 411 )

      # at line 102:4: exit_statement
      @state.following.push( TOKENS_FOLLOWING_exit_statement_IN_synpred44_Plsql_575 )
      exit_statement
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 411 )

    end
    # 
    # syntactic predicate synpred46_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 104:4: synpred46_Plsql : case_statement ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred46_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 413 )

      # at line 104:4: case_statement
      @state.following.push( TOKENS_FOLLOWING_case_statement_IN_synpred46_Plsql_585 )
      case_statement
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 413 )

    end
    # 
    # syntactic predicate synpred48_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 106:4: synpred48_Plsql : loop_statement ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred48_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 415 )

      # at line 106:4: loop_statement
      @state.following.push( TOKENS_FOLLOWING_loop_statement_IN_synpred48_Plsql_596 )
      loop_statement
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 415 )

    end
    # 
    # syntactic predicate synpred52_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 110:4: synpred52_Plsql : sql_statement ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred52_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 419 )

      # at line 110:4: sql_statement
      @state.following.push( TOKENS_FOLLOWING_sql_statement_IN_synpred52_Plsql_617 )
      sql_statement
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 419 )

    end
    # 
    # syntactic predicate synpred53_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 111:4: synpred53_Plsql : plsql_block ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred53_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 420 )

      # at line 111:4: plsql_block
      @state.following.push( TOKENS_FOLLOWING_plsql_block_IN_synpred53_Plsql_622 )
      plsql_block
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 420 )

    end
    # 
    # syntactic predicate synpred62_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 127:4: synpred62_Plsql : subtype_declaration ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred62_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 429 )

      # at line 127:4: subtype_declaration
      @state.following.push( TOKENS_FOLLOWING_subtype_declaration_IN_synpred62_Plsql_731 )
      subtype_declaration
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 429 )

    end
    # 
    # syntactic predicate synpred70_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 135:4: synpred70_Plsql : type_declaration ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred70_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 437 )

      # at line 135:4: type_declaration
      @state.following.push( TOKENS_FOLLOWING_type_declaration_IN_synpred70_Plsql_777 )
      type_declaration
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 437 )

    end
    # 
    # syntactic predicate synpred73_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 141:5: synpred73_Plsql : keyRESTRICT_REFERENCES LPAREN ( 'DEFAULT' | function_name ) ( COMMA pragma_param )+ RPAREN ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred73_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 440 )

      # at line 141:5: keyRESTRICT_REFERENCES LPAREN ( 'DEFAULT' | function_name ) ( COMMA pragma_param )+ RPAREN
      @state.following.push( TOKENS_FOLLOWING_keyRESTRICT_REFERENCES_IN_synpred73_Plsql_801 )
      keyRESTRICT_REFERENCES
      @state.following.pop
      match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred73_Plsql_803 )
      # at line 141:35: ( 'DEFAULT' | function_name )
      alt_369 = 2
      look_369_0 = @input.peek( 1 )

      if ( look_369_0 == T__59 )
        alt_369 = 1
      elsif ( look_369_0 == QUOTED_STRING || look_369_0.between?( ID, DOUBLEQUOTED_STRING ) )
        alt_369 = 2
      else
        @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

        raise NoViableAlternative( "", 369, 0 )
      end
      case alt_369
      when 1
        # at line 141:37: 'DEFAULT'
        match( T__59, TOKENS_FOLLOWING_T__59_IN_synpred73_Plsql_807 )

      when 2
        # at line 141:49: function_name
        @state.following.push( TOKENS_FOLLOWING_function_name_IN_synpred73_Plsql_811 )
        function_name
        @state.following.pop

      end
      # at file 141:65: ( COMMA pragma_param )+
      match_count_370 = 0
      while true
        alt_370 = 2
        look_370_0 = @input.peek( 1 )

        if ( look_370_0 == COMMA )
          alt_370 = 1

        end
        case alt_370
        when 1
          # at line 141:67: COMMA pragma_param
          match( COMMA, TOKENS_FOLLOWING_COMMA_IN_synpred73_Plsql_817 )
          @state.following.push( TOKENS_FOLLOWING_pragma_param_IN_synpred73_Plsql_819 )
          pragma_param
          @state.following.pop

        else
          match_count_370 > 0 and break
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          eee = EarlyExit(370)


          raise eee
        end
        match_count_370 += 1
      end

      match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred73_Plsql_824 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 440 )

    end
    # 
    # syntactic predicate synpred74_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 142:5: synpred74_Plsql : keyEXCEPTION_INIT LPAREN exception_name COMMA literal RPAREN ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred74_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 441 )

      # at line 142:5: keyEXCEPTION_INIT LPAREN exception_name COMMA literal RPAREN
      @state.following.push( TOKENS_FOLLOWING_keyEXCEPTION_INIT_IN_synpred74_Plsql_831 )
      keyEXCEPTION_INIT
      @state.following.pop
      match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred74_Plsql_833 )
      @state.following.push( TOKENS_FOLLOWING_exception_name_IN_synpred74_Plsql_835 )
      exception_name
      @state.following.pop
      match( COMMA, TOKENS_FOLLOWING_COMMA_IN_synpred74_Plsql_837 )
      @state.following.push( TOKENS_FOLLOWING_literal_IN_synpred74_Plsql_839 )
      literal
      @state.following.pop
      match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred74_Plsql_841 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 441 )

    end
    # 
    # syntactic predicate synpred75_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 143:5: synpred75_Plsql : keyAUTONOMOUS_TRANSACTION ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred75_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 442 )

      # at line 143:5: keyAUTONOMOUS_TRANSACTION
      @state.following.push( TOKENS_FOLLOWING_keyAUTONOMOUS_TRANSACTION_IN_synpred75_Plsql_847 )
      keyAUTONOMOUS_TRANSACTION
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 442 )

    end
    # 
    # syntactic predicate synpred76_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 144:5: synpred76_Plsql : keySERIALLY_REUSABLE ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred76_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 443 )

      # at line 144:5: keySERIALLY_REUSABLE
      @state.following.push( TOKENS_FOLLOWING_keySERIALLY_REUSABLE_IN_synpred76_Plsql_853 )
      keySERIALLY_REUSABLE
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 443 )

    end
    # 
    # syntactic predicate synpred77_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 145:5: synpred77_Plsql : keyBUILTIN LPAREN pragma_params RPAREN ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred77_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 444 )

      # at line 145:5: keyBUILTIN LPAREN pragma_params RPAREN
      @state.following.push( TOKENS_FOLLOWING_keyBUILTIN_IN_synpred77_Plsql_859 )
      keyBUILTIN
      @state.following.pop
      match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred77_Plsql_861 )
      @state.following.push( TOKENS_FOLLOWING_pragma_params_IN_synpred77_Plsql_863 )
      pragma_params
      @state.following.pop
      match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred77_Plsql_865 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 444 )

    end
    # 
    # syntactic predicate synpred78_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 146:5: synpred78_Plsql : keyFIPSFLAG LPAREN pragma_params RPAREN ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred78_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 445 )

      # at line 146:5: keyFIPSFLAG LPAREN pragma_params RPAREN
      @state.following.push( TOKENS_FOLLOWING_keyFIPSFLAG_IN_synpred78_Plsql_871 )
      keyFIPSFLAG
      @state.following.pop
      match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred78_Plsql_873 )
      @state.following.push( TOKENS_FOLLOWING_pragma_params_IN_synpred78_Plsql_875 )
      pragma_params
      @state.following.pop
      match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred78_Plsql_877 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 445 )

    end
    # 
    # syntactic predicate synpred79_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 147:5: synpred79_Plsql : keyINTERFACE LPAREN pragma_params RPAREN ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred79_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 446 )

      # at line 147:5: keyINTERFACE LPAREN pragma_params RPAREN
      @state.following.push( TOKENS_FOLLOWING_keyINTERFACE_IN_synpred79_Plsql_883 )
      keyINTERFACE
      @state.following.pop
      match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred79_Plsql_885 )
      @state.following.push( TOKENS_FOLLOWING_pragma_params_IN_synpred79_Plsql_887 )
      pragma_params
      @state.following.pop
      match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred79_Plsql_889 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 446 )

    end
    # 
    # syntactic predicate synpred80_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 148:5: synpred80_Plsql : keyNEW_NAMES LPAREN pragma_params RPAREN ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred80_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 447 )

      # at line 148:5: keyNEW_NAMES LPAREN pragma_params RPAREN
      @state.following.push( TOKENS_FOLLOWING_keyNEW_NAMES_IN_synpred80_Plsql_895 )
      keyNEW_NAMES
      @state.following.pop
      match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred80_Plsql_897 )
      @state.following.push( TOKENS_FOLLOWING_pragma_params_IN_synpred80_Plsql_899 )
      pragma_params
      @state.following.pop
      match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred80_Plsql_901 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 447 )

    end
    # 
    # syntactic predicate synpred114_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 215:4: synpred114_Plsql : keyINTERVAL keyDAY ( LPAREN NUMBER RPAREN )? 'TO' keySECOND ( LPAREN NUMBER RPAREN )? ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred114_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 481 )

      # at line 215:4: keyINTERVAL keyDAY ( LPAREN NUMBER RPAREN )? 'TO' keySECOND ( LPAREN NUMBER RPAREN )?
      @state.following.push( TOKENS_FOLLOWING_keyINTERVAL_IN_synpred114_Plsql_1288 )
      keyINTERVAL
      @state.following.pop
      @state.following.push( TOKENS_FOLLOWING_keyDAY_IN_synpred114_Plsql_1290 )
      keyDAY
      @state.following.pop
      # at line 215:23: ( LPAREN NUMBER RPAREN )?
      alt_379 = 2
      look_379_0 = @input.peek( 1 )

      if ( look_379_0 == LPAREN )
        alt_379 = 1
      end
      case alt_379
      when 1
        # at line 215:25: LPAREN NUMBER RPAREN
        match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred114_Plsql_1294 )
        match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_synpred114_Plsql_1296 )
        match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred114_Plsql_1298 )

      end
      match( T__77, TOKENS_FOLLOWING_T__77_IN_synpred114_Plsql_1303 )
      @state.following.push( TOKENS_FOLLOWING_keySECOND_IN_synpred114_Plsql_1305 )
      keySECOND
      @state.following.pop
      # at line 215:64: ( LPAREN NUMBER RPAREN )?
      alt_380 = 2
      look_380_0 = @input.peek( 1 )

      if ( look_380_0 == LPAREN )
        alt_380 = 1
      end
      case alt_380
      when 1
        # at line 215:66: LPAREN NUMBER RPAREN
        match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred114_Plsql_1309 )
        match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_synpred114_Plsql_1311 )
        match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred114_Plsql_1313 )

      end

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 481 )

    end
    # 
    # syntactic predicate synpred116_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 216:4: synpred116_Plsql : keyINTERVAL keyYEAR ( LPAREN NUMBER RPAREN )? 'TO' keyMONTH ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred116_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 483 )

      # at line 216:4: keyINTERVAL keyYEAR ( LPAREN NUMBER RPAREN )? 'TO' keyMONTH
      @state.following.push( TOKENS_FOLLOWING_keyINTERVAL_IN_synpred116_Plsql_1321 )
      keyINTERVAL
      @state.following.pop
      @state.following.push( TOKENS_FOLLOWING_keyYEAR_IN_synpred116_Plsql_1323 )
      keyYEAR
      @state.following.pop
      # at line 216:24: ( LPAREN NUMBER RPAREN )?
      alt_381 = 2
      look_381_0 = @input.peek( 1 )

      if ( look_381_0 == LPAREN )
        alt_381 = 1
      end
      case alt_381
      when 1
        # at line 216:26: LPAREN NUMBER RPAREN
        match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred116_Plsql_1327 )
        match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_synpred116_Plsql_1329 )
        match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred116_Plsql_1331 )

      end
      match( T__77, TOKENS_FOLLOWING_T__77_IN_synpred116_Plsql_1336 )
      @state.following.push( TOKENS_FOLLOWING_keyMONTH_IN_synpred116_Plsql_1338 )
      keyMONTH
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 483 )

    end
    # 
    # syntactic predicate synpred117_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 217:6: synpred117_Plsql : keyTIME ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred117_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 484 )

      # at line 217:6: keyTIME
      @state.following.push( TOKENS_FOLLOWING_keyTIME_IN_synpred117_Plsql_1345 )
      keyTIME
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 484 )

    end
    # 
    # syntactic predicate synpred172_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 243:4: synpred172_Plsql : datatype ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred172_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 539 )

      # at line 243:4: datatype
      @state.following.push( TOKENS_FOLLOWING_datatype_IN_synpred172_Plsql_1814 )
      datatype
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 539 )

    end
    # 
    # syntactic predicate synpred232_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 447:28: synpred232_Plsql : {...}? LPAREN ( call_parameters )? RPAREN ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred232_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 599 )

      # at line 447:28: {...}? LPAREN ( call_parameters )? RPAREN
      unless ( (  @input.peek(1) != LPAREN || @input.peek(2) != PLUS || @input.peek(3) != RPAREN  ) )
        @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

        raise FailedPredicate( "synpred232_Plsql", " @input.peek(1) != LPAREN || @input.peek(2) != PLUS || @input.peek(3) != RPAREN " )
      end
      match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred232_Plsql_2929 )
      # at line 447:119: ( call_parameters )?
      alt_424 = 2
      look_424_0 = @input.peek( 1 )

      if ( look_424_0 == LPAREN || look_424_0.between?( PLUS, QUOTED_STRING ) || look_424_0.between?( ID, DOUBLEQUOTED_STRING ) || look_424_0.between?( T__57, T__58 ) || look_424_0 == T__100 || look_424_0.between?( T__110, T__111 ) || look_424_0.between?( T__116, T__117 ) || look_424_0 == T__140 || look_424_0 == T__142 )
        alt_424 = 1
      end
      case alt_424
      when 1
        # at line 447:121: call_parameters
        @state.following.push( TOKENS_FOLLOWING_call_parameters_IN_synpred232_Plsql_2933 )
        call_parameters
        @state.following.pop

      end
      match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred232_Plsql_2938 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 599 )

    end
    # 
    # syntactic predicate synpred238_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 477:7: synpred238_Plsql : numeric_loop_param ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred238_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 605 )

      # at line 477:9: numeric_loop_param
      @state.following.push( TOKENS_FOLLOWING_numeric_loop_param_IN_synpred238_Plsql_3080 )
      numeric_loop_param
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 605 )

    end
    # 
    # syntactic predicate synpred239_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 478:7: synpred239_Plsql : cursor_loop_param ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred239_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 606 )

      # at line 478:9: cursor_loop_param
      @state.following.push( TOKENS_FOLLOWING_cursor_loop_param_IN_synpred239_Plsql_3096 )
      cursor_loop_param
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 606 )

    end
    # 
    # syntactic predicate synpred242_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 489:22: synpred242_Plsql : keyREVERSE ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred242_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 609 )

      # at line 489:22: keyREVERSE
      @state.following.push( TOKENS_FOLLOWING_keyREVERSE_IN_synpred242_Plsql_3160 )
      keyREVERSE
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 609 )

    end
    # 
    # syntactic predicate synpred252_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 547:4: synpred252_Plsql : close_statement ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred252_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 619 )

      # at line 547:4: close_statement
      @state.following.push( TOKENS_FOLLOWING_close_statement_IN_synpred252_Plsql_3394 )
      close_statement
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 619 )

    end
    # 
    # syntactic predicate synpred256_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 551:4: synpred256_Plsql : open_statement ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred256_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 623 )

      # at line 551:4: open_statement
      @state.following.push( TOKENS_FOLLOWING_open_statement_IN_synpred256_Plsql_3414 )
      open_statement
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 623 )

    end
    # 
    # syntactic predicate synpred263_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 570:46: synpred263_Plsql : join_clause ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred263_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 630 )

      # at line 570:46: join_clause
      @state.following.push( TOKENS_FOLLOWING_join_clause_IN_synpred263_Plsql_3515 )
      join_clause
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 630 )

    end
    # 
    # syntactic predicate synpred264_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 570:60: synpred264_Plsql : LPAREN join_clause RPAREN ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred264_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 631 )

      # at line 570:60: LPAREN join_clause RPAREN
      match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred264_Plsql_3519 )
      @state.following.push( TOKENS_FOLLOWING_join_clause_IN_synpred264_Plsql_3521 )
      join_clause
      @state.following.pop
      match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred264_Plsql_3523 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 631 )

    end
    # 
    # syntactic predicate synpred265_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 571:5: synpred265_Plsql : where_clause ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred265_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 632 )

      # at line 571:5: where_clause
      @state.following.push( TOKENS_FOLLOWING_where_clause_IN_synpred265_Plsql_3535 )
      where_clause
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 632 )

    end
    # 
    # syntactic predicate synpred266_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 571:23: synpred266_Plsql : hierarchical_query_clause ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred266_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 633 )

      # at line 571:23: hierarchical_query_clause
      @state.following.push( TOKENS_FOLLOWING_hierarchical_query_clause_IN_synpred266_Plsql_3542 )
      hierarchical_query_clause
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 633 )

    end
    # 
    # syntactic predicate synpred267_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 571:54: synpred267_Plsql : group_by_clause ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred267_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 634 )

      # at line 571:54: group_by_clause
      @state.following.push( TOKENS_FOLLOWING_group_by_clause_IN_synpred267_Plsql_3549 )
      group_by_clause
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 634 )

    end
    # 
    # syntactic predicate synpred268_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 572:5: synpred268_Plsql : 'HAVING' sql_condition ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred268_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 635 )

      # at line 572:5: 'HAVING' sql_condition
      match( T__122, TOKENS_FOLLOWING_T__122_IN_synpred268_Plsql_3558 )
      @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_synpred268_Plsql_3560 )
      sql_condition
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 635 )

    end
    # 
    # syntactic predicate synpred269_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 572:33: synpred269_Plsql : model_clause ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred269_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 636 )

      # at line 572:33: model_clause
      @state.following.push( TOKENS_FOLLOWING_model_clause_IN_synpred269_Plsql_3567 )
      model_clause
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 636 )

    end
    # 
    # syntactic predicate synpred274_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 573:5: synpred274_Plsql : ( 'UNION' ( 'ALL' )? | 'INTERSECT' | 'MINUS' ) ( select_expression | subquery ) ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred274_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 641 )

      # at line 573:5: ( 'UNION' ( 'ALL' )? | 'INTERSECT' | 'MINUS' ) ( select_expression | subquery )
      # at line 573:5: ( 'UNION' ( 'ALL' )? | 'INTERSECT' | 'MINUS' )
      alt_429 = 3
      case look_429 = @input.peek( 1 )
      when T__123 then alt_429 = 1
      when T__124 then alt_429 = 2
      when T__125 then alt_429 = 3
      else
        @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

        raise NoViableAlternative( "", 429, 0 )
      end
      case alt_429
      when 1
        # at line 573:7: 'UNION' ( 'ALL' )?
        match( T__123, TOKENS_FOLLOWING_T__123_IN_synpred274_Plsql_3578 )
        # at line 573:15: ( 'ALL' )?
        alt_428 = 2
        look_428_0 = @input.peek( 1 )

        if ( look_428_0 == T__119 )
          alt_428 = 1
        end
        case alt_428
        when 1
          # at line 573:17: 'ALL'
          match( T__119, TOKENS_FOLLOWING_T__119_IN_synpred274_Plsql_3582 )

        end

      when 2
        # at line 574:6: 'INTERSECT'
        match( T__124, TOKENS_FOLLOWING_T__124_IN_synpred274_Plsql_3592 )

      when 3
        # at line 575:6: 'MINUS'
        match( T__125, TOKENS_FOLLOWING_T__125_IN_synpred274_Plsql_3599 )

      end
      # at line 577:4: ( select_expression | subquery )
      alt_430 = 2
      look_430_0 = @input.peek( 1 )

      if ( look_430_0 == T__116 )
        alt_430 = 1
      elsif ( look_430_0 == LPAREN )
        alt_430 = 2
      else
        @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

        raise NoViableAlternative( "", 430, 0 )
      end
      case alt_430
      when 1
        # at line 577:6: select_expression
        @state.following.push( TOKENS_FOLLOWING_select_expression_IN_synpred274_Plsql_3611 )
        select_expression
        @state.following.pop

      when 2
        # at line 578:6: subquery
        @state.following.push( TOKENS_FOLLOWING_subquery_IN_synpred274_Plsql_3619 )
        subquery
        @state.following.pop

      end

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 641 )

    end
    # 
    # syntactic predicate synpred275_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 581:5: synpred275_Plsql : order_by_clause ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred275_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 642 )

      # at line 581:5: order_by_clause
      @state.following.push( TOKENS_FOLLOWING_order_by_clause_IN_synpred275_Plsql_3635 )
      order_by_clause
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 642 )

    end
    # 
    # syntactic predicate synpred278_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 594:21: synpred278_Plsql : COMMA selected_table ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred278_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 645 )

      # at line 594:21: COMMA selected_table
      match( COMMA, TOKENS_FOLLOWING_COMMA_IN_synpred278_Plsql_3694 )
      @state.following.push( TOKENS_FOLLOWING_selected_table_IN_synpred278_Plsql_3696 )
      selected_table
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 645 )

    end
    # 
    # syntactic predicate synpred279_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 598:21: synpred279_Plsql : inner_cross_join_clause ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred279_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 646 )

      # at line 598:21: inner_cross_join_clause
      @state.following.push( TOKENS_FOLLOWING_inner_cross_join_clause_IN_synpred279_Plsql_3714 )
      inner_cross_join_clause
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 646 )

    end
    # 
    # syntactic predicate synpred280_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 598:47: synpred280_Plsql : outer_join_clause ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred280_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 647 )

      # at line 598:47: outer_join_clause
      @state.following.push( TOKENS_FOLLOWING_outer_join_clause_IN_synpred280_Plsql_3718 )
      outer_join_clause
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 647 )

    end
    # 
    # syntactic predicate synpred283_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 601:4: synpred283_Plsql : ( keyINNER )? keyJOIN table_name ( 'ON' sql_condition | keyUSING LPAREN column_specs RPAREN ) ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred283_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 650 )

      # at line 601:4: ( keyINNER )? keyJOIN table_name ( 'ON' sql_condition | keyUSING LPAREN column_specs RPAREN )
      # at line 601:4: ( keyINNER )?
      alt_431 = 2
      look_431_0 = @input.peek( 1 )

      if ( look_431_0 == ID )
        look_431_1 = @input.peek( 2 )

        if ( look_431_1 == ID )
          look_431_2 = @input.peek( 3 )

          if ( look_431_2 == ID )
            look_431_4 = @input.peek( 4 )

            if ( look_431_4 == ID || look_431_4 == T__126 )
              alt_431 = 1
            end
          elsif ( look_431_2 == DOUBLEQUOTED_STRING || look_431_2 == T__100 )
            alt_431 = 1
          end
        end
      end
      case alt_431
      when 1
        # at line 601:6: keyINNER
        @state.following.push( TOKENS_FOLLOWING_keyINNER_IN_synpred283_Plsql_3733 )
        keyINNER
        @state.following.pop

      end
      @state.following.push( TOKENS_FOLLOWING_keyJOIN_IN_synpred283_Plsql_3738 )
      keyJOIN
      @state.following.pop
      @state.following.push( TOKENS_FOLLOWING_table_name_IN_synpred283_Plsql_3740 )
      table_name
      @state.following.pop
      # at line 601:37: ( 'ON' sql_condition | keyUSING LPAREN column_specs RPAREN )
      alt_432 = 2
      look_432_0 = @input.peek( 1 )

      if ( look_432_0 == T__126 )
        alt_432 = 1
      elsif ( look_432_0 == ID )
        alt_432 = 2
      else
        @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

        raise NoViableAlternative( "", 432, 0 )
      end
      case alt_432
      when 1
        # at line 601:39: 'ON' sql_condition
        match( T__126, TOKENS_FOLLOWING_T__126_IN_synpred283_Plsql_3744 )
        @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_synpred283_Plsql_3746 )
        sql_condition
        @state.following.pop

      when 2
        # at line 601:60: keyUSING LPAREN column_specs RPAREN
        @state.following.push( TOKENS_FOLLOWING_keyUSING_IN_synpred283_Plsql_3750 )
        keyUSING
        @state.following.pop
        match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred283_Plsql_3752 )
        @state.following.push( TOKENS_FOLLOWING_column_specs_IN_synpred283_Plsql_3754 )
        column_specs
        @state.following.pop
        match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred283_Plsql_3756 )

      end

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 650 )

    end
    # 
    # syntactic predicate synpred284_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 602:6: synpred284_Plsql : keyCROSS ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred284_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 651 )

      # at line 602:6: keyCROSS
      @state.following.push( TOKENS_FOLLOWING_keyCROSS_IN_synpred284_Plsql_3765 )
      keyCROSS
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 651 )

    end
    # 
    # syntactic predicate synpred286_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 606:5: synpred286_Plsql : outer_join_type keyJOIN ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred286_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 653 )

      # at line 606:5: outer_join_type keyJOIN
      @state.following.push( TOKENS_FOLLOWING_outer_join_type_IN_synpred286_Plsql_3802 )
      outer_join_type
      @state.following.pop
      @state.following.push( TOKENS_FOLLOWING_keyJOIN_IN_synpred286_Plsql_3804 )
      keyJOIN
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 653 )

    end
    # 
    # syntactic predicate synpred287_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 607:18: synpred287_Plsql : outer_join_type ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred287_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 654 )

      # at line 607:18: outer_join_type
      @state.following.push( TOKENS_FOLLOWING_outer_join_type_IN_synpred287_Plsql_3814 )
      outer_join_type
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 654 )

    end
    # 
    # syntactic predicate synpred288_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 609:20: synpred288_Plsql : query_partition_clause ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred288_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 655 )

      # at line 609:20: query_partition_clause
      @state.following.push( TOKENS_FOLLOWING_query_partition_clause_IN_synpred288_Plsql_3831 )
      query_partition_clause
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 655 )

    end
    # 
    # syntactic predicate synpred289_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 610:5: synpred289_Plsql : 'ON' sql_condition ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred289_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 656 )

      # at line 610:5: 'ON' sql_condition
      match( T__126, TOKENS_FOLLOWING_T__126_IN_synpred289_Plsql_3840 )
      @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_synpred289_Plsql_3842 )
      sql_condition
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 656 )

    end
    # 
    # syntactic predicate synpred290_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 610:26: synpred290_Plsql : keyUSING LPAREN column_specs RPAREN ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred290_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 657 )

      # at line 610:26: keyUSING LPAREN column_specs RPAREN
      @state.following.push( TOKENS_FOLLOWING_keyUSING_IN_synpred290_Plsql_3846 )
      keyUSING
      @state.following.pop
      match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred290_Plsql_3848 )
      @state.following.push( TOKENS_FOLLOWING_column_specs_IN_synpred290_Plsql_3850 )
      column_specs
      @state.following.pop
      match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred290_Plsql_3852 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 657 )

    end
    # 
    # syntactic predicate synpred291_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 616:6: synpred291_Plsql : keyFULL ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred291_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 658 )

      # at line 616:6: keyFULL
      @state.following.push( TOKENS_FOLLOWING_keyFULL_IN_synpred291_Plsql_3881 )
      keyFULL
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 658 )

    end
    # 
    # syntactic predicate synpred292_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 616:16: synpred292_Plsql : keyLEFT ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred292_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 659 )

      # at line 616:16: keyLEFT
      @state.following.push( TOKENS_FOLLOWING_keyLEFT_IN_synpred292_Plsql_3885 )
      keyLEFT
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 659 )

    end
    # 
    # syntactic predicate synpred293_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 616:39: synpred293_Plsql : keyOUTER ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred293_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 660 )

      # at line 616:39: keyOUTER
      @state.following.push( TOKENS_FOLLOWING_keyOUTER_IN_synpred293_Plsql_3895 )
      keyOUTER
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 660 )

    end
    # 
    # syntactic predicate synpred295_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 625:55: synpred295_Plsql : keyNOCYCLE ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred295_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 662 )

      # at line 625:55: keyNOCYCLE
      @state.following.push( TOKENS_FOLLOWING_keyNOCYCLE_IN_synpred295_Plsql_3951 )
      keyNOCYCLE
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 662 )

    end
    # 
    # syntactic predicate synpred296_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 631:20: synpred296_Plsql : COMMA group_by_expr ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred296_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 663 )

      # at line 631:20: COMMA group_by_expr
      match( COMMA, TOKENS_FOLLOWING_COMMA_IN_synpred296_Plsql_3984 )
      @state.following.push( TOKENS_FOLLOWING_group_by_expr_IN_synpred296_Plsql_3986 )
      group_by_expr
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 663 )

    end
    # 
    # syntactic predicate synpred297_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 634:4: synpred297_Plsql : rollup_cube_clause ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred297_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 664 )

      # at line 634:4: rollup_cube_clause
      @state.following.push( TOKENS_FOLLOWING_rollup_cube_clause_IN_synpred297_Plsql_3999 )
      rollup_cube_clause
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 664 )

    end
    # 
    # syntactic predicate synpred298_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 635:4: synpred298_Plsql : grouping_sets_clause ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred298_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 665 )

      # at line 635:4: grouping_sets_clause
      @state.following.push( TOKENS_FOLLOWING_grouping_sets_clause_IN_synpred298_Plsql_4004 )
      grouping_sets_clause
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 665 )

    end
    # 
    # syntactic predicate synpred299_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 639:6: synpred299_Plsql : keyROLLUP ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred299_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 666 )

      # at line 639:6: keyROLLUP
      @state.following.push( TOKENS_FOLLOWING_keyROLLUP_IN_synpred299_Plsql_4021 )
      keyROLLUP
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 666 )

    end
    # 
    # syntactic predicate synpred301_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 648:4: synpred301_Plsql : rollup_cube_clause ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred301_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 668 )

      # at line 648:4: rollup_cube_clause
      @state.following.push( TOKENS_FOLLOWING_rollup_cube_clause_IN_synpred301_Plsql_4080 )
      rollup_cube_clause
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 668 )

    end
    # 
    # syntactic predicate synpred304_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 656:8: synpred304_Plsql : keyIGNORE ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred304_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 671 )

      # at line 656:8: keyIGNORE
      @state.following.push( TOKENS_FOLLOWING_keyIGNORE_IN_synpred304_Plsql_4134 )
      keyIGNORE
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 671 )

    end
    # 
    # syntactic predicate synpred305_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 656:6: synpred305_Plsql : ( keyIGNORE | keyKEEP ) keyNAV ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred305_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 672 )

      # at line 656:6: ( keyIGNORE | keyKEEP ) keyNAV
      # at line 656:6: ( keyIGNORE | keyKEEP )
      alt_433 = 2
      look_433_0 = @input.peek( 1 )

      if ( look_433_0 == ID )
        look_433_1 = @input.peek( 2 )

        if ( ( syntactic_predicate?( :synpred304_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("IGNORE") ) ) )
          alt_433 = 1
        elsif ( ( self.input.look(1).text.upcase == ("KEEP") ) )
          alt_433 = 2
        else
          @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

          raise NoViableAlternative( "", 433, 1 )
        end
      else
        @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

        raise NoViableAlternative( "", 433, 0 )
      end
      case alt_433
      when 1
        # at line 656:8: keyIGNORE
        @state.following.push( TOKENS_FOLLOWING_keyIGNORE_IN_synpred305_Plsql_4134 )
        keyIGNORE
        @state.following.pop

      when 2
        # at line 656:20: keyKEEP
        @state.following.push( TOKENS_FOLLOWING_keyKEEP_IN_synpred305_Plsql_4138 )
        keyKEEP
        @state.following.pop

      end
      @state.following.push( TOKENS_FOLLOWING_keyNAV_IN_synpred305_Plsql_4142 )
      keyNAV
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 672 )

    end
    # 
    # syntactic predicate synpred306_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 657:16: synpred306_Plsql : keyDIMENSION ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred306_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 673 )

      # at line 657:16: keyDIMENSION
      @state.following.push( TOKENS_FOLLOWING_keyDIMENSION_IN_synpred306_Plsql_4155 )
      keyDIMENSION
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 673 )

    end
    # 
    # syntactic predicate synpred311_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 677:6: synpred311_Plsql : query_partition_clause ( column_spec )? ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred311_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 678 )

      # at line 677:6: query_partition_clause ( column_spec )?
      @state.following.push( TOKENS_FOLLOWING_query_partition_clause_IN_synpred311_Plsql_4279 )
      query_partition_clause
      @state.following.pop
      # at line 677:29: ( column_spec )?
      alt_435 = 2
      look_435_0 = @input.peek( 1 )

      if ( look_435_0.between?( ID, DOUBLEQUOTED_STRING ) || look_435_0 == T__100 )
        alt_435 = 1
      end
      case alt_435
      when 1
        # at line 677:31: column_spec
        @state.following.push( TOKENS_FOLLOWING_column_spec_IN_synpred311_Plsql_4283 )
        column_spec
        @state.following.pop

      end

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 678 )

    end
    # 
    # syntactic predicate synpred318_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 688:56: synpred318_Plsql : keyAUTOMATIC ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred318_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 685 )

      # at line 688:56: keyAUTOMATIC
      @state.following.push( TOKENS_FOLLOWING_keyAUTOMATIC_IN_synpred318_Plsql_4390 )
      keyAUTOMATIC
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 685 )

    end
    # 
    # syntactic predicate synpred330_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 705:4: synpred330_Plsql : sql_condition ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred330_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 697 )

      # at line 705:4: sql_condition
      @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_synpred330_Plsql_4551 )
      sql_condition
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 697 )

    end
    # 
    # syntactic predicate synpred331_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 705:20: synpred331_Plsql : sql_expression ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred331_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 698 )

      # at line 705:20: sql_expression
      @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_synpred331_Plsql_4555 )
      sql_expression
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 698 )

    end
    # 
    # syntactic predicate synpred335_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 713:55: synpred335_Plsql : keyINCREMENT ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred335_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 702 )

      # at line 713:55: keyINCREMENT
      @state.following.push( TOKENS_FOLLOWING_keyINCREMENT_IN_synpred335_Plsql_4626 )
      keyINCREMENT
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 702 )

    end
    # 
    # syntactic predicate synpred343_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 739:20: synpred343_Plsql : COMMA order_by_expr ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred343_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 710 )

      # at line 739:20: COMMA order_by_expr
      match( COMMA, TOKENS_FOLLOWING_COMMA_IN_synpred343_Plsql_4793 )
      @state.following.push( TOKENS_FOLLOWING_order_by_expr_IN_synpred343_Plsql_4795 )
      order_by_expr
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 710 )

    end
    # 
    # syntactic predicate synpred346_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 746:25: synpred346_Plsql : keyNULLS keyFIRST ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred346_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 713 )

      # at line 746:25: keyNULLS keyFIRST
      @state.following.push( TOKENS_FOLLOWING_keyNULLS_IN_synpred346_Plsql_4833 )
      keyNULLS
      @state.following.pop
      @state.following.push( TOKENS_FOLLOWING_keyFIRST_IN_synpred346_Plsql_4835 )
      keyFIRST
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 713 )

    end
    # 
    # syntactic predicate synpred347_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 746:45: synpred347_Plsql : keyNULLS keyLAST ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred347_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 714 )

      # at line 746:45: keyNULLS keyLAST
      @state.following.push( TOKENS_FOLLOWING_keyNULLS_IN_synpred347_Plsql_4839 )
      keyNULLS
      @state.following.pop
      @state.following.push( TOKENS_FOLLOWING_keyLAST_IN_synpred347_Plsql_4841 )
      keyLAST
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 714 )

    end
    # 
    # syntactic predicate synpred354_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 791:4: synpred354_Plsql : {...}? sql_expression ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred354_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 721 )

      # at line 791:4: {...}? sql_expression
      unless ( (   @is_sql  ) )
        @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

        raise FailedPredicate( "synpred354_Plsql", "  @is_sql " )
      end
      @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_synpred354_Plsql_5006 )
      sql_expression
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 721 )

    end
    # 
    # syntactic predicate synpred356_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 810:14: synpred356_Plsql : 'OR' expr_or ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred356_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 723 )

      # at line 810:14: 'OR' expr_or
      match( T__51, TOKENS_FOLLOWING_T__51_IN_synpred356_Plsql_5084 )
      @state.following.push( TOKENS_FOLLOWING_expr_or_IN_synpred356_Plsql_5086 )
      expr_or
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 723 )

    end
    # 
    # syntactic predicate synpred357_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 813:15: synpred357_Plsql : 'AND' expr_and ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred357_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 724 )

      # at line 813:15: 'AND' expr_and
      match( T__138, TOKENS_FOLLOWING_T__138_IN_synpred357_Plsql_5103 )
      @state.following.push( TOKENS_FOLLOWING_expr_and_IN_synpred357_Plsql_5105 )
      expr_and
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 724 )

    end
    # 
    # syntactic predicate synpred359_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 820:5: synpred359_Plsql : relational_op expr_add ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred359_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 726 )

      # at line 820:5: relational_op expr_add
      @state.following.push( TOKENS_FOLLOWING_relational_op_IN_synpred359_Plsql_5142 )
      relational_op
      @state.following.pop
      @state.following.push( TOKENS_FOLLOWING_expr_add_IN_synpred359_Plsql_5144 )
      expr_add
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 726 )

    end
    # 
    # syntactic predicate synpred360_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 821:5: synpred360_Plsql : FOUND_ATTR ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred360_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 727 )

      # at line 821:5: FOUND_ATTR
      match( FOUND_ATTR, TOKENS_FOLLOWING_FOUND_ATTR_IN_synpred360_Plsql_5150 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 727 )

    end
    # 
    # syntactic predicate synpred361_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 821:18: synpred361_Plsql : NOTFOUND_ATTR ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred361_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 728 )

      # at line 821:18: NOTFOUND_ATTR
      match( NOTFOUND_ATTR, TOKENS_FOLLOWING_NOTFOUND_ATTR_IN_synpred361_Plsql_5154 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 728 )

    end
    # 
    # syntactic predicate synpred362_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 821:34: synpred362_Plsql : ISOPEN_ATTR ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred362_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 729 )

      # at line 821:34: ISOPEN_ATTR
      match( ISOPEN_ATTR, TOKENS_FOLLOWING_ISOPEN_ATTR_IN_synpred362_Plsql_5158 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 729 )

    end
    # 
    # syntactic predicate synpred363_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 821:48: synpred363_Plsql : ROWCOUNT_ATTR ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred363_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 730 )

      # at line 821:48: ROWCOUNT_ATTR
      match( ROWCOUNT_ATTR, TOKENS_FOLLOWING_ROWCOUNT_ATTR_IN_synpred363_Plsql_5162 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 730 )

    end
    # 
    # syntactic predicate synpred364_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 821:64: synpred364_Plsql : BULK_ROWCOUNT_ATTR ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred364_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 731 )

      # at line 821:64: BULK_ROWCOUNT_ATTR
      match( BULK_ROWCOUNT_ATTR, TOKENS_FOLLOWING_BULK_ROWCOUNT_ATTR_IN_synpred364_Plsql_5166 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 731 )

    end
    # 
    # syntactic predicate synpred366_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 822:5: synpred366_Plsql : 'IS' ( 'NOT' )? 'NULL' ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred366_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 733 )

      # at line 822:5: 'IS' ( 'NOT' )? 'NULL'
      match( T__52, TOKENS_FOLLOWING_T__52_IN_synpred366_Plsql_5172 )
      # at line 822:10: ( 'NOT' )?
      alt_447 = 2
      look_447_0 = @input.peek( 1 )

      if ( look_447_0 == T__57 )
        alt_447 = 1
      end
      case alt_447
      when 1
        # at line 822:12: 'NOT'
        match( T__57, TOKENS_FOLLOWING_T__57_IN_synpred366_Plsql_5176 )

      end
      match( T__58, TOKENS_FOLLOWING_T__58_IN_synpred366_Plsql_5181 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 733 )

    end
    # 
    # syntactic predicate synpred368_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 823:5: synpred368_Plsql : ( 'NOT' )? 'LIKE' expr_add ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred368_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 735 )

      # at line 823:5: ( 'NOT' )? 'LIKE' expr_add
      # at line 823:5: ( 'NOT' )?
      alt_448 = 2
      look_448_0 = @input.peek( 1 )

      if ( look_448_0 == T__57 )
        alt_448 = 1
      end
      case alt_448
      when 1
        # at line 823:7: 'NOT'
        match( T__57, TOKENS_FOLLOWING_T__57_IN_synpred368_Plsql_5189 )

      end
      match( T__134, TOKENS_FOLLOWING_T__134_IN_synpred368_Plsql_5194 )
      @state.following.push( TOKENS_FOLLOWING_expr_add_IN_synpred368_Plsql_5196 )
      expr_add
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 735 )

    end
    # 
    # syntactic predicate synpred370_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 824:5: synpred370_Plsql : ( 'NOT' )? 'BETWEEN' expr_add 'AND' expr_add ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred370_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 737 )

      # at line 824:5: ( 'NOT' )? 'BETWEEN' expr_add 'AND' expr_add
      # at line 824:5: ( 'NOT' )?
      alt_449 = 2
      look_449_0 = @input.peek( 1 )

      if ( look_449_0 == T__57 )
        alt_449 = 1
      end
      case alt_449
      when 1
        # at line 824:7: 'NOT'
        match( T__57, TOKENS_FOLLOWING_T__57_IN_synpred370_Plsql_5204 )

      end
      match( T__139, TOKENS_FOLLOWING_T__139_IN_synpred370_Plsql_5209 )
      @state.following.push( TOKENS_FOLLOWING_expr_add_IN_synpred370_Plsql_5211 )
      expr_add
      @state.following.pop
      match( T__138, TOKENS_FOLLOWING_T__138_IN_synpred370_Plsql_5213 )
      @state.following.push( TOKENS_FOLLOWING_expr_add_IN_synpred370_Plsql_5215 )
      expr_add
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 737 )

    end
    # 
    # syntactic predicate synpred372_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 825:5: synpred372_Plsql : ( 'NOT' )? 'IN' LPAREN nested_expressions RPAREN ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred372_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 739 )

      # at line 825:5: ( 'NOT' )? 'IN' LPAREN nested_expressions RPAREN
      # at line 825:5: ( 'NOT' )?
      alt_450 = 2
      look_450_0 = @input.peek( 1 )

      if ( look_450_0 == T__57 )
        alt_450 = 1
      end
      case alt_450
      when 1
        # at line 825:7: 'NOT'
        match( T__57, TOKENS_FOLLOWING_T__57_IN_synpred372_Plsql_5223 )

      end
      match( T__102, TOKENS_FOLLOWING_T__102_IN_synpred372_Plsql_5228 )
      match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred372_Plsql_5230 )
      @state.following.push( TOKENS_FOLLOWING_nested_expressions_IN_synpred372_Plsql_5232 )
      nested_expressions
      @state.following.pop
      match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred372_Plsql_5234 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 739 )

    end
    # 
    # syntactic predicate synpred374_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 834:21: synpred374_Plsql : COMMA sql_expression ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred374_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 741 )

      # at line 834:21: COMMA sql_expression
      match( COMMA, TOKENS_FOLLOWING_COMMA_IN_synpred374_Plsql_5269 )
      @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_synpred374_Plsql_5271 )
      sql_expression
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 741 )

    end
    # 
    # syntactic predicate synpred377_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 841:15: synpred377_Plsql : ( PLUS | MINUS | DOUBLEVERTBAR ) expr_mul ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred377_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 744 )

      # at line 841:15: ( PLUS | MINUS | DOUBLEVERTBAR ) expr_mul
      if @input.peek( 1 ).between?( PLUS, MINUS ) || @input.peek(1) == DOUBLEVERTBAR
        @input.consume
        @state.error_recovery = false
      else
        @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

        mse = MismatchedSet( nil )
        raise mse
      end


      @state.following.push( TOKENS_FOLLOWING_expr_mul_IN_synpred377_Plsql_5319 )
      expr_mul
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 744 )

    end
    # 
    # syntactic predicate synpred379_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 844:16: synpred379_Plsql : ( ASTERISK | DIVIDE ) expr_sign ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred379_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 746 )

      # at line 844:16: ( ASTERISK | DIVIDE ) expr_sign
      if @input.peek(1) == ASTERISK || @input.peek(1) == DIVIDE
        @input.consume
        @state.error_recovery = false
      else
        @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

        mse = MismatchedSet( nil )
        raise mse
      end


      @state.following.push( TOKENS_FOLLOWING_expr_sign_IN_synpred379_Plsql_5346 )
      expr_sign
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 746 )

    end
    # 
    # syntactic predicate synpred382_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 850:16: synpred382_Plsql : EXPONENT expr_expr ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred382_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 749 )

      # at line 850:16: EXPONENT expr_expr
      match( EXPONENT, TOKENS_FOLLOWING_EXPONENT_IN_synpred382_Plsql_5384 )
      @state.following.push( TOKENS_FOLLOWING_expr_expr_IN_synpred382_Plsql_5386 )
      expr_expr
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 749 )

    end
    # 
    # syntactic predicate synpred383_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 853:4: synpred383_Plsql : expr_paren ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred383_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 750 )

      # at line 853:6: expr_paren
      @state.following.push( TOKENS_FOLLOWING_expr_paren_IN_synpred383_Plsql_5401 )
      expr_paren
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 750 )

    end
    # 
    # syntactic predicate synpred384_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 854:4: synpred384_Plsql : function_expression ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred384_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 751 )

      # at line 854:6: function_expression
      @state.following.push( TOKENS_FOLLOWING_function_expression_IN_synpred384_Plsql_5414 )
      function_expression
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 751 )

    end
    # 
    # syntactic predicate synpred385_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 861:4: synpred385_Plsql : case_expression ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred385_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 752 )

      # at line 861:6: case_expression
      @state.following.push( TOKENS_FOLLOWING_case_expression_IN_synpred385_Plsql_5434 )
      case_expression
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 752 )

    end
    # 
    # syntactic predicate synpred386_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 862:4: synpred386_Plsql : cursor_expression ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred386_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 753 )

      # at line 862:6: cursor_expression
      @state.following.push( TOKENS_FOLLOWING_cursor_expression_IN_synpred386_Plsql_5447 )
      cursor_expression
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 753 )

    end
    # 
    # syntactic predicate synpred387_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 863:4: synpred387_Plsql : simple_expression ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred387_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 754 )

      # at line 863:6: simple_expression
      @state.following.push( TOKENS_FOLLOWING_simple_expression_IN_synpred387_Plsql_5460 )
      simple_expression
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 754 )

    end
    # 
    # syntactic predicate synpred388_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 864:4: synpred388_Plsql : select_expression ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred388_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 755 )

      # at line 864:6: select_expression
      @state.following.push( TOKENS_FOLLOWING_select_expression_IN_synpred388_Plsql_5473 )
      select_expression
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 755 )

    end
    # 
    # syntactic predicate synpred395_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 869:4: synpred395_Plsql : column_spec ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred395_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 762 )

      # at line 869:6: column_spec
      @state.following.push( TOKENS_FOLLOWING_column_spec_IN_synpred395_Plsql_5524 )
      column_spec
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 762 )

    end
    # 
    # syntactic predicate synpred409_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 917:23: synpred409_Plsql : keyDBTIMEZONE ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred409_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 776 )

      # at line 917:23: keyDBTIMEZONE
      @state.following.push( TOKENS_FOLLOWING_keyDBTIMEZONE_IN_synpred409_Plsql_5823 )
      keyDBTIMEZONE
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 776 )

    end
    # 
    # syntactic predicate synpred410_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 917:39: synpred410_Plsql : keySESSIONTIMEZONE ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred410_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 777 )

      # at line 917:39: keySESSIONTIMEZONE
      @state.following.push( TOKENS_FOLLOWING_keySESSIONTIMEZONE_IN_synpred410_Plsql_5827 )
      keySESSIONTIMEZONE
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 777 )

    end
    # 
    # syntactic predicate synpred412_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 921:4: synpred412_Plsql : function_call ( DOT nested_expression )? ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred412_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 779 )

      # at line 921:4: function_call ( DOT nested_expression )?
      @state.following.push( TOKENS_FOLLOWING_function_call_IN_synpred412_Plsql_5847 )
      function_call
      @state.following.pop
      # at line 921:18: ( DOT nested_expression )?
      alt_451 = 2
      look_451_0 = @input.peek( 1 )

      if ( look_451_0 == DOT )
        alt_451 = 1
      end
      case alt_451
      when 1
        # at line 921:20: DOT nested_expression
        match( DOT, TOKENS_FOLLOWING_DOT_IN_synpred412_Plsql_5851 )
        @state.following.push( TOKENS_FOLLOWING_nested_expression_IN_synpred412_Plsql_5853 )
        nested_expression
        @state.following.pop

      end

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 779 )

    end
    # 
    # syntactic predicate synpred415_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 924:18: synpred415_Plsql : LPAREN nested_expression RPAREN ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred415_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 782 )

      # at line 924:18: LPAREN nested_expression RPAREN
      match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred415_Plsql_5891 )
      @state.following.push( TOKENS_FOLLOWING_nested_expression_IN_synpred415_Plsql_5893 )
      nested_expression
      @state.following.pop
      match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred415_Plsql_5895 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 782 )

    end
    # 
    # syntactic predicate synpred420_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 935:5: synpred420_Plsql : keyDAY ( LPAREN leading_field_precision RPAREN )? 'TO' keySECOND ( LPAREN fractional_second_precision RPAREN )? ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred420_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 787 )

      # at line 935:5: keyDAY ( LPAREN leading_field_precision RPAREN )? 'TO' keySECOND ( LPAREN fractional_second_precision RPAREN )?
      @state.following.push( TOKENS_FOLLOWING_keyDAY_IN_synpred420_Plsql_5967 )
      keyDAY
      @state.following.pop
      # at line 935:12: ( LPAREN leading_field_precision RPAREN )?
      alt_454 = 2
      look_454_0 = @input.peek( 1 )

      if ( look_454_0 == LPAREN )
        alt_454 = 1
      end
      case alt_454
      when 1
        # at line 935:14: LPAREN leading_field_precision RPAREN
        match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred420_Plsql_5971 )
        @state.following.push( TOKENS_FOLLOWING_leading_field_precision_IN_synpred420_Plsql_5973 )
        leading_field_precision
        @state.following.pop
        match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred420_Plsql_5975 )

      end
      match( T__77, TOKENS_FOLLOWING_T__77_IN_synpred420_Plsql_5980 )
      @state.following.push( TOKENS_FOLLOWING_keySECOND_IN_synpred420_Plsql_5982 )
      keySECOND
      @state.following.pop
      # at line 935:70: ( LPAREN fractional_second_precision RPAREN )?
      alt_455 = 2
      look_455_0 = @input.peek( 1 )

      if ( look_455_0 == LPAREN )
        alt_455 = 1
      end
      case alt_455
      when 1
        # at line 935:72: LPAREN fractional_second_precision RPAREN
        match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred420_Plsql_5986 )
        @state.following.push( TOKENS_FOLLOWING_fractional_second_precision_IN_synpred420_Plsql_5988 )
        fractional_second_precision
        @state.following.pop
        match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred420_Plsql_5990 )

      end

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 787 )

    end
    # 
    # syntactic predicate synpred427_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 991:21: synpred427_Plsql : DOT sql_identifier ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred427_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 794 )

      # at line 991:21: DOT sql_identifier
      match( DOT, TOKENS_FOLLOWING_DOT_IN_synpred427_Plsql_6237 )
      @state.following.push( TOKENS_FOLLOWING_sql_identifier_IN_synpred427_Plsql_6239 )
      sql_identifier
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 794 )

    end
    # 
    # syntactic predicate synpred431_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 995:6: synpred431_Plsql : table_spec ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred431_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 798 )

      # at line 995:6: table_spec
      @state.following.push( TOKENS_FOLLOWING_table_spec_IN_synpred431_Plsql_6277 )
      table_spec
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 798 )

    end
    # 
    # syntactic predicate synpred434_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 995:54: synpred434_Plsql : objalias ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred434_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 801 )

      # at line 995:54: objalias
      @state.following.push( TOKENS_FOLLOWING_objalias_IN_synpred434_Plsql_6298 )
      objalias
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 801 )

    end
    # 
    # syntactic predicate synpred440_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1010:4: synpred440_Plsql : {...}? condition_or ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred440_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 807 )

      # at line 1010:4: {...}? condition_or
      unless ( (   @is_sql  ) )
        @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

        raise FailedPredicate( "synpred440_Plsql", "  @is_sql " )
      end
      @state.following.push( TOKENS_FOLLOWING_condition_or_IN_synpred440_Plsql_6389 )
      condition_or
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 807 )

    end
    # 
    # syntactic predicate synpred441_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1022:20: synpred441_Plsql : 'OR' condition_and ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred441_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 808 )

      # at line 1022:20: 'OR' condition_and
      match( T__51, TOKENS_FOLLOWING_T__51_IN_synpred441_Plsql_6442 )
      @state.following.push( TOKENS_FOLLOWING_condition_and_IN_synpred441_Plsql_6444 )
      condition_and
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 808 )

    end
    # 
    # syntactic predicate synpred442_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1025:20: synpred442_Plsql : 'AND' condition_not ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred442_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 809 )

      # at line 1025:20: 'AND' condition_not
      match( T__138, TOKENS_FOLLOWING_T__138_IN_synpred442_Plsql_6461 )
      @state.following.push( TOKENS_FOLLOWING_condition_not_IN_synpred442_Plsql_6463 )
      condition_not
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 809 )

    end
    # 
    # syntactic predicate synpred445_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1033:4: synpred445_Plsql : condition_is ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred445_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 812 )

      # at line 1033:4: condition_is
      @state.following.push( TOKENS_FOLLOWING_condition_is_IN_synpred445_Plsql_6498 )
      condition_is
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 812 )

    end
    # 
    # syntactic predicate synpred446_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1034:4: synpred446_Plsql : condition_comparison ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred446_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 813 )

      # at line 1034:4: condition_comparison
      @state.following.push( TOKENS_FOLLOWING_condition_comparison_IN_synpred446_Plsql_6503 )
      condition_comparison
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 813 )

    end
    # 
    # syntactic predicate synpred447_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1035:4: synpred447_Plsql : condition_group_comparison ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred447_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 814 )

      # at line 1035:4: condition_group_comparison
      @state.following.push( TOKENS_FOLLOWING_condition_group_comparison_IN_synpred447_Plsql_6508 )
      condition_group_comparison
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 814 )

    end
    # 
    # syntactic predicate synpred448_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1036:4: synpred448_Plsql : condition_in ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred448_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 815 )

      # at line 1036:4: condition_in
      @state.following.push( TOKENS_FOLLOWING_condition_in_IN_synpred448_Plsql_6513 )
      condition_in
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 815 )

    end
    # 
    # syntactic predicate synpred449_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1037:4: synpred449_Plsql : condition_is_a_set ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred449_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 816 )

      # at line 1037:4: condition_is_a_set
      @state.following.push( TOKENS_FOLLOWING_condition_is_a_set_IN_synpred449_Plsql_6518 )
      condition_is_a_set
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 816 )

    end
    # 
    # syntactic predicate synpred450_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1038:4: synpred450_Plsql : condition_is_any ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred450_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 817 )

      # at line 1038:4: condition_is_any
      @state.following.push( TOKENS_FOLLOWING_condition_is_any_IN_synpred450_Plsql_6523 )
      condition_is_any
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 817 )

    end
    # 
    # syntactic predicate synpred451_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1039:4: synpred451_Plsql : condition_is_empty ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred451_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 818 )

      # at line 1039:4: condition_is_empty
      @state.following.push( TOKENS_FOLLOWING_condition_is_empty_IN_synpred451_Plsql_6528 )
      condition_is_empty
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 818 )

    end
    # 
    # syntactic predicate synpred452_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1040:4: synpred452_Plsql : condition_is_of_type ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred452_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 819 )

      # at line 1040:4: condition_is_of_type
      @state.following.push( TOKENS_FOLLOWING_condition_is_of_type_IN_synpred452_Plsql_6533 )
      condition_is_of_type
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 819 )

    end
    # 
    # syntactic predicate synpred453_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1041:4: synpred453_Plsql : condition_is_present ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred453_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 820 )

      # at line 1041:4: condition_is_present
      @state.following.push( TOKENS_FOLLOWING_condition_is_present_IN_synpred453_Plsql_6538 )
      condition_is_present
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 820 )

    end
    # 
    # syntactic predicate synpred454_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1042:4: synpred454_Plsql : condition_like ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred454_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 821 )

      # at line 1042:4: condition_like
      @state.following.push( TOKENS_FOLLOWING_condition_like_IN_synpred454_Plsql_6543 )
      condition_like
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 821 )

    end
    # 
    # syntactic predicate synpred455_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1043:4: synpred455_Plsql : condition_memeber ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred455_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 822 )

      # at line 1043:4: condition_memeber
      @state.following.push( TOKENS_FOLLOWING_condition_memeber_IN_synpred455_Plsql_6548 )
      condition_memeber
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 822 )

    end
    # 
    # syntactic predicate synpred456_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1044:4: synpred456_Plsql : condition_between ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred456_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 823 )

      # at line 1044:4: condition_between
      @state.following.push( TOKENS_FOLLOWING_condition_between_IN_synpred456_Plsql_6553 )
      condition_between
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 823 )

    end
    # 
    # syntactic predicate synpred457_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1045:4: synpred457_Plsql : condition_regexp_like ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred457_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 824 )

      # at line 1045:4: condition_regexp_like
      @state.following.push( TOKENS_FOLLOWING_condition_regexp_like_IN_synpred457_Plsql_6558 )
      condition_regexp_like
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 824 )

    end
    # 
    # syntactic predicate synpred458_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1046:4: synpred458_Plsql : condition_submultiset ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred458_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 825 )

      # at line 1046:4: condition_submultiset
      @state.following.push( TOKENS_FOLLOWING_condition_submultiset_IN_synpred458_Plsql_6563 )
      condition_submultiset
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 825 )

    end
    # 
    # syntactic predicate synpred459_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1047:4: synpred459_Plsql : condition_equals_path ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred459_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 826 )

      # at line 1047:4: condition_equals_path
      @state.following.push( TOKENS_FOLLOWING_condition_equals_path_IN_synpred459_Plsql_6568 )
      condition_equals_path
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 826 )

    end
    # 
    # syntactic predicate synpred460_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1048:4: synpred460_Plsql : condition_under_path ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred460_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 827 )

      # at line 1048:4: condition_under_path
      @state.following.push( TOKENS_FOLLOWING_condition_under_path_IN_synpred460_Plsql_6573 )
      condition_under_path
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 827 )

    end
    # 
    # syntactic predicate synpred462_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1055:37: synpred462_Plsql : keyNAN ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred462_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 829 )

      # at line 1055:37: keyNAN
      @state.following.push( TOKENS_FOLLOWING_keyNAN_IN_synpred462_Plsql_6617 )
      keyNAN
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 829 )

    end
    # 
    # syntactic predicate synpred463_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1055:46: synpred463_Plsql : keyINFINITE ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred463_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 830 )

      # at line 1055:46: keyINFINITE
      @state.following.push( TOKENS_FOLLOWING_keyINFINITE_IN_synpred463_Plsql_6621 )
      keyINFINITE
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 830 )

    end
    # 
    # syntactic predicate synpred466_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1058:102: synpred466_Plsql : outer_join_sign ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred466_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 833 )

      # at line 1058:102: outer_join_sign
      @state.following.push( TOKENS_FOLLOWING_outer_join_sign_IN_synpred466_Plsql_6668 )
      outer_join_sign
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 833 )

    end
    # 
    # syntactic predicate synpred467_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1058:4: synpred467_Plsql : LPAREN sql_expressions RPAREN ( outer_join_sign )? ( EQ | NOT_EQ ) LPAREN select_command RPAREN ( outer_join_sign )? ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred467_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 834 )

      # at line 1058:4: LPAREN sql_expressions RPAREN ( outer_join_sign )? ( EQ | NOT_EQ ) LPAREN select_command RPAREN ( outer_join_sign )?
      match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred467_Plsql_6637 )
      @state.following.push( TOKENS_FOLLOWING_sql_expressions_IN_synpred467_Plsql_6639 )
      sql_expressions
      @state.following.pop
      match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred467_Plsql_6641 )
      # at line 1058:34: ( outer_join_sign )?
      alt_457 = 2
      look_457_0 = @input.peek( 1 )

      if ( look_457_0 == LPAREN )
        alt_457 = 1
      end
      case alt_457
      when 1
        # at line 1058:36: outer_join_sign
        @state.following.push( TOKENS_FOLLOWING_outer_join_sign_IN_synpred467_Plsql_6645 )
        outer_join_sign
        @state.following.pop

      end
      if @input.peek(1) == EQ || @input.peek(1) == NOT_EQ
        @input.consume
        @state.error_recovery = false
      else
        @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

        mse = MismatchedSet( nil )
        raise mse
      end


      match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred467_Plsql_6660 )
      @state.following.push( TOKENS_FOLLOWING_select_command_IN_synpred467_Plsql_6662 )
      select_command
      @state.following.pop
      match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred467_Plsql_6664 )
      # at line 1058:100: ( outer_join_sign )?
      alt_458 = 2
      look_458_0 = @input.peek( 1 )

      if ( look_458_0 == LPAREN )
        alt_458 = 1
      end
      case alt_458
      when 1
        # at line 1058:102: outer_join_sign
        @state.following.push( TOKENS_FOLLOWING_outer_join_sign_IN_synpred467_Plsql_6668 )
        outer_join_sign
        @state.following.pop

      end

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 834 )

    end
    # 
    # syntactic predicate synpred476_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1059:108: synpred476_Plsql : sql_expression ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred476_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 843 )

      # at line 1059:108: sql_expression
      @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_synpred476_Plsql_6727 )
      sql_expression
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 843 )

    end
    # 
    # syntactic predicate synpred477_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1059:158: synpred477_Plsql : outer_join_sign ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred477_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 844 )

      # at line 1059:158: outer_join_sign
      @state.following.push( TOKENS_FOLLOWING_outer_join_sign_IN_synpred477_Plsql_6741 )
      outer_join_sign
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 844 )

    end
    # 
    # syntactic predicate synpred481_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1062:87: synpred481_Plsql : grouping_expression_list ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred481_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 848 )

      # at line 1062:87: grouping_expression_list
      @state.following.push( TOKENS_FOLLOWING_grouping_expression_list_IN_synpred481_Plsql_6788 )
      grouping_expression_list
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 848 )

    end
    # 
    # syntactic predicate synpred482_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1062:4: synpred482_Plsql : LPAREN sql_expressions RPAREN ( EQ | NOT_EQ ) ( 'ANY' | keySOME | 'ALL' ) LPAREN ( grouping_expression_list | select_command ) RPAREN ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred482_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 849 )

      # at line 1062:4: LPAREN sql_expressions RPAREN ( EQ | NOT_EQ ) ( 'ANY' | keySOME | 'ALL' ) LPAREN ( grouping_expression_list | select_command ) RPAREN
      match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred482_Plsql_6754 )
      @state.following.push( TOKENS_FOLLOWING_sql_expressions_IN_synpred482_Plsql_6756 )
      sql_expressions
      @state.following.pop
      match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred482_Plsql_6758 )
      if @input.peek(1) == EQ || @input.peek(1) == NOT_EQ
        @input.consume
        @state.error_recovery = false
      else
        @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

        mse = MismatchedSet( nil )
        raise mse
      end


      # at line 1062:50: ( 'ANY' | keySOME | 'ALL' )
      alt_459 = 3
      case look_459 = @input.peek( 1 )
      when T__146 then alt_459 = 1
      when ID then alt_459 = 2
      when T__119 then alt_459 = 3
      else
        @state.backtracking > 0 and raise( ANTLR3::Error::BacktrackingFailed )

        raise NoViableAlternative( "", 459, 0 )
      end
      case alt_459
      when 1
        # at line 1062:52: 'ANY'
        match( T__146, TOKENS_FOLLOWING_T__146_IN_synpred482_Plsql_6772 )

      when 2
        # at line 1062:60: keySOME
        @state.following.push( TOKENS_FOLLOWING_keySOME_IN_synpred482_Plsql_6776 )
        keySOME
        @state.following.pop

      when 3
        # at line 1062:70: 'ALL'
        match( T__119, TOKENS_FOLLOWING_T__119_IN_synpred482_Plsql_6780 )

      end
      match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred482_Plsql_6784 )
      # at line 1062:85: ( grouping_expression_list | select_command )
      alt_460 = 2
      alt_460 = @dfa460.predict( @input )
      case alt_460
      when 1
        # at line 1062:87: grouping_expression_list
        @state.following.push( TOKENS_FOLLOWING_grouping_expression_list_IN_synpred482_Plsql_6788 )
        grouping_expression_list
        @state.following.pop

      when 2
        # at line 1062:114: select_command
        @state.following.push( TOKENS_FOLLOWING_select_command_IN_synpred482_Plsql_6792 )
        select_command
        @state.following.pop

      end
      match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred482_Plsql_6796 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 849 )

    end
    # 
    # syntactic predicate synpred490_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1063:96: synpred490_Plsql : sql_expressions ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred490_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 857 )

      # at line 1063:96: sql_expressions
      @state.following.push( TOKENS_FOLLOWING_sql_expressions_IN_synpred490_Plsql_6847 )
      sql_expressions
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 857 )

    end
    # 
    # syntactic predicate synpred492_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1066:59: synpred492_Plsql : grouping_expression_list ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred492_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 859 )

      # at line 1066:59: grouping_expression_list
      @state.following.push( TOKENS_FOLLOWING_grouping_expression_list_IN_synpred492_Plsql_6884 )
      grouping_expression_list
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 859 )

    end
    # 
    # syntactic predicate synpred493_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1066:4: synpred493_Plsql : LPAREN sql_expressions RPAREN ( 'NOT' )? 'IN' LPAREN ( grouping_expression_list | select_command ) RPAREN ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred493_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 860 )

      # at line 1066:4: LPAREN sql_expressions RPAREN ( 'NOT' )? 'IN' LPAREN ( grouping_expression_list | select_command ) RPAREN
      match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred493_Plsql_6865 )
      @state.following.push( TOKENS_FOLLOWING_sql_expressions_IN_synpred493_Plsql_6867 )
      sql_expressions
      @state.following.pop
      match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred493_Plsql_6869 )
      # at line 1066:34: ( 'NOT' )?
      alt_461 = 2
      look_461_0 = @input.peek( 1 )

      if ( look_461_0 == T__57 )
        alt_461 = 1
      end
      case alt_461
      when 1
        # at line 1066:36: 'NOT'
        match( T__57, TOKENS_FOLLOWING_T__57_IN_synpred493_Plsql_6873 )

      end
      match( T__102, TOKENS_FOLLOWING_T__102_IN_synpred493_Plsql_6878 )
      match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred493_Plsql_6880 )
      # at line 1066:57: ( grouping_expression_list | select_command )
      alt_462 = 2
      alt_462 = @dfa462.predict( @input )
      case alt_462
      when 1
        # at line 1066:59: grouping_expression_list
        @state.following.push( TOKENS_FOLLOWING_grouping_expression_list_IN_synpred493_Plsql_6884 )
        grouping_expression_list
        @state.following.pop

      when 2
        # at line 1066:86: select_command
        @state.following.push( TOKENS_FOLLOWING_select_command_IN_synpred493_Plsql_6888 )
        select_command
        @state.following.pop

      end
      match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred493_Plsql_6892 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 860 )

    end
    # 
    # syntactic predicate synpred495_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1067:44: synpred495_Plsql : expression_list ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred495_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 862 )

      # at line 1067:44: expression_list
      @state.following.push( TOKENS_FOLLOWING_expression_list_IN_synpred495_Plsql_6912 )
      expression_list
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 862 )

    end
    # 
    # syntactic predicate synpred505_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1091:41: synpred505_Plsql : keyLIKEC ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred505_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 872 )

      # at line 1091:41: keyLIKEC
      @state.following.push( TOKENS_FOLLOWING_keyLIKEC_IN_synpred505_Plsql_7092 )
      keyLIKEC
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 872 )

    end
    # 
    # syntactic predicate synpred506_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1091:52: synpred506_Plsql : keyLIKE2 ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred506_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 873 )

      # at line 1091:52: keyLIKE2
      @state.following.push( TOKENS_FOLLOWING_keyLIKE2_IN_synpred506_Plsql_7096 )
      keyLIKE2
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 873 )

    end
    # 
    # syntactic predicate synpred507_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1091:91: synpred507_Plsql : keyESCAPE sql_expression ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred507_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 874 )

      # at line 1091:91: keyESCAPE sql_expression
      @state.following.push( TOKENS_FOLLOWING_keyESCAPE_IN_synpred507_Plsql_7108 )
      keyESCAPE
      @state.following.pop
      @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_synpred507_Plsql_7110 )
      sql_expression
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 874 )

    end
    # 
    # syntactic predicate synpred516_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1121:22: synpred516_Plsql : COMMA expression_list ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred516_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 883 )

      # at line 1121:22: COMMA expression_list
      match( COMMA, TOKENS_FOLLOWING_COMMA_IN_synpred516_Plsql_7321 )
      @state.following.push( TOKENS_FOLLOWING_expression_list_IN_synpred516_Plsql_7323 )
      expression_list
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 883 )

    end
    # 
    # syntactic predicate synpred517_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1124:4: synpred517_Plsql : LPAREN sql_expressions RPAREN ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred517_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 884 )

      # at line 1124:4: LPAREN sql_expressions RPAREN
      match( LPAREN, TOKENS_FOLLOWING_LPAREN_IN_synpred517_Plsql_7336 )
      @state.following.push( TOKENS_FOLLOWING_sql_expressions_IN_synpred517_Plsql_7338 )
      sql_expressions
      @state.following.pop
      match( RPAREN, TOKENS_FOLLOWING_RPAREN_IN_synpred517_Plsql_7340 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 884 )

    end
    # 
    # syntactic predicate synpred525_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1142:4: synpred525_Plsql : sql_expression ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred525_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 892 )

      # at line 1142:6: sql_expression
      @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_synpred525_Plsql_7437 )
      sql_expression
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 892 )

    end
    # 
    # syntactic predicate synpred528_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1156:9: synpred528_Plsql : 'PRIOR' ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred528_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 895 )

      # at line 1156:9: 'PRIOR'
      match( T__141, TOKENS_FOLLOWING_T__141_IN_synpred528_Plsql_7530 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 895 )

    end
    # 
    # syntactic predicate synpred529_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1156:5: synpred529_Plsql : ( 'PRIOR' )? sql_condition ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred529_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 896 )

      # at line 1156:7: ( 'PRIOR' )? sql_condition
      # at line 1156:7: ( 'PRIOR' )?
      alt_463 = 2
      look_463_0 = @input.peek( 1 )

      if ( look_463_0 == T__141 )
        look_463_1 = @input.peek( 2 )

        if ( syntactic_predicate?( :synpred528_Plsql ) )
          alt_463 = 1
        end
      end
      case alt_463
      when 1
        # at line 1156:9: 'PRIOR'
        match( T__141, TOKENS_FOLLOWING_T__141_IN_synpred529_Plsql_7530 )

      end
      @state.following.push( TOKENS_FOLLOWING_sql_condition_IN_synpred529_Plsql_7535 )
      sql_condition
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 896 )

    end
    # 
    # syntactic predicate synpred530_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1156:40: synpred530_Plsql : 'PRIOR' ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred530_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 897 )

      # at line 1156:40: 'PRIOR'
      match( T__141, TOKENS_FOLLOWING_T__141_IN_synpred530_Plsql_7542 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 897 )

    end
    # 
    # syntactic predicate synpred539_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1175:6: synpred539_Plsql : sql_expression ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred539_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 906 )

      # at line 1175:8: sql_expression
      @state.following.push( TOKENS_FOLLOWING_sql_expression_IN_synpred539_Plsql_7693 )
      sql_expression
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 906 )

    end
    # 
    # syntactic predicate synpred540_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1175:45: synpred540_Plsql : NUMBER ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred540_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 907 )

      # at line 1175:47: NUMBER
      match( NUMBER, TOKENS_FOLLOWING_NUMBER_IN_synpred540_Plsql_7705 )

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 907 )

    end
    # 
    # syntactic predicate synpred561_Plsql
    # 
    # (in vorax\\lib\\ruby\\Plsql.g)
    # 1245:5: synpred561_Plsql : variable_names ;
    # 
    # This is an imaginary rule inserted by ANTLR to
    # implement a syntactic predicate decision
    # 
    def synpred561_Plsql
      # -> uncomment the next line to manually enable rule tracing
      # trace_in( __method__, 928 )

      # at line 1245:5: variable_names
      @state.following.push( TOKENS_FOLLOWING_variable_names_IN_synpred561_Plsql_8117 )
      variable_names
      @state.following.pop

    ensure
      # -> uncomment the next line to manually enable rule tracing
      # trace_out( __method__, 928 )

    end


    # - - - - - - - - - - DFA definitions - - - - - - - - - - -
    class DFA10 < ANTLR3::DFA
      EOT = unpack( 708, -1 )
      EOF = unpack( 708, -1 )
      MIN = unpack( 1, 40, 2, 5, 3, -1, 16, 4, 1, 40, 7, 4, 1, 85, 9, 4, 
                     2, -1, 1, 7, 1, 15, 1, 4, 3, 15, 1, 40, 2, 7, 1, 40, 
                     1, 4, 1, 40, 1, 4, 1, -1, 1, 15, 2, 4, 1, 15, 1, 87, 
                     1, 15, 1, 87, 1, 15, 1, 87, 1, 4, 1, 15, 1, 4, 3, 15, 
                     1, 4, 1, 87, 1, 40, 2, 15, 16, 4, 1, 40, 7, 4, 1, 85, 
                     9, 4, 1, -1, 5, 8, 1, 40, 2, -1, 1, 4, 1, -1, 1, 15, 
                     1, 40, 1, 4, 1, 5, 2, 20, 2, 8, 1, 40, 1, 8, 1, 40, 
                     1, 8, 1, 40, 4, 8, 1, 4, 1, 15, 1, 40, 1, 5, 2, 8, 
                     1, 58, 1, -1, 1, 0, 1, 15, 1, 4, 2, 15, 1, 7, 2, 40, 
                     2, 4, 1, 40, 1, 4, 1, 15, 2, 4, 1, 15, 1, 87, 1, 15, 
                     1, 87, 1, 15, 1, 87, 1, 4, 1, 15, 1, 4, 3, 15, 1, 4, 
                     1, 87, 1, 40, 3, 15, 4, 4, 6, 8, 3, 7, 2, 8, 1, 5, 
                     3, 8, 1, 7, 1, 8, 1, 40, 7, 7, 1, 85, 6, 8, 1, 5, 1, 
                     7, 1, 5, 1, 40, 1, 52, 1, 4, 1, 7, 1, 4, 1, 8, 1, 4, 
                     1, 7, 1, 40, 1, 15, 1, 40, 1, 4, 2, 8, 2, 4, 1, 5, 
                     2, 8, 2, 4, 1, 5, 2, 8, 2, 4, 1, 5, 4, 4, 1, 8, 1, 
                     4, 1, 5, 3, 4, 4, 8, 1, 40, 1, 4, 1, 5, 1, 15, 1, 40, 
                     2, 20, 2, 8, 1, 40, 1, 8, 1, 40, 1, 8, 1, 40, 4, 8, 
                     1, 4, 1, 15, 1, 40, 1, 5, 3, 8, 1, 15, 1, 7, 2, 15, 
                     1, 40, 1, 8, 1, 40, 1, 8, 1, 15, 1, 40, 1, 7, 1, 15, 
                     1, 8, 1, 7, 1, 15, 1, 87, 1, 15, 1, 87, 1, 15, 1, 87, 
                     1, 7, 1, 15, 1, 7, 3, 15, 1, 7, 1, 87, 1, 40, 2, 15, 
                     1, 8, 1, 4, 1, 8, 1, 15, 1, 77, 1, 15, 1, 4, 2, 19, 
                     1, 40, 1, 4, 1, 40, 1, 4, 1, 40, 2, 4, 1, 40, 1, 4, 
                     1, 15, 5, 4, 2, 40, 1, 8, 2, 4, 2, 8, 2, 4, 1, 5, 2, 
                     8, 2, 4, 1, 5, 2, 8, 2, 4, 1, 5, 4, 4, 1, 8, 1, 4, 
                     1, 5, 2, 4, 3, 8, 2, 20, 2, 5, 1, 8, 1, 40, 1, 15, 
                     1, 40, 2, 8, 1, 40, 1, 8, 1, 40, 1, 8, 1, 40, 4, 8, 
                     1, 7, 1, 15, 1, 40, 1, 5, 8, 8, 3, 7, 2, 8, 1, 5, 3, 
                     8, 1, 7, 1, 8, 1, 40, 7, 7, 1, 85, 6, 8, 1, 5, 1, 7, 
                     1, 5, 1, 4, 2, 8, 1, 40, 8, 5, 1, 8, 2, 4, 2, 19, 1, 
                     4, 1, 15, 1, 40, 1, 4, 1, 40, 1, 4, 1, 40, 2, 4, 1, 
                     40, 1, 4, 1, 15, 3, 8, 2, 40, 3, 8, 1, 7, 4, 8, 2, 
                     5, 3, 8, 2, 5, 3, 8, 2, 5, 5, 8, 2, 5, 2, 8, 1, 15, 
                     1, 7, 2, 15, 1, 7, 1, 40, 1, 8, 1, 15, 2, 40, 1, 8, 
                     1, 15, 1, 8, 1, 7, 1, 15, 1, 87, 1, 15, 1, 87, 1, 15, 
                     1, 87, 1, 7, 1, 15, 1, 7, 3, 15, 1, 7, 1, 87, 1, 40, 
                     2, 15, 1, -1, 3, 4, 5, 40, 1, 8, 8, 5, 1, 8, 1, 5, 
                     2, 19, 1, 8, 1, 77, 1, 15, 1, 40, 1, 8, 1, 40, 1, 8, 
                     1, 40, 2, 8, 1, 40, 4, 8, 1, 15, 1, 40, 2, 20, 1, 8, 
                     1, 40, 2, 5, 2, 8, 1, 40, 1, 8, 1, 40, 1, 8, 1, 40, 
                     4, 8, 1, 7, 1, 15, 1, 40, 1, 5, 2, 8, 8, 18, 2, 4, 
                     5, 40, 1, 8, 8, 5, 1, 15, 4, 8, 1, 7, 2, 8, 2, 40, 
                     4, 8, 2, 5, 3, 8, 2, 5, 3, 8, 2, 5, 5, 8, 2, 5, 2, 
                     8, 8, 18, 1, 5, 1, 8, 4, 40, 1, 8, 1, 77, 1, 15, 1, 
                     8, 1, 5, 2, 19, 1, 40, 1, 8, 1, 40, 1, 8, 1, 40, 2, 
                     8, 1, 40, 1, 8, 8, 18, 1, 8, 1, 40, 8, 5, 1, 8, 1, 
                     5, 4, 40, 8, 18 )
      MAX = unpack( 1, 161, 2, 101, 3, -1, 6, 59, 1, 74, 3, 59, 1, 164, 
                     5, 59, 1, 40, 3, 86, 4, 59, 1, 86, 3, 59, 1, 86, 4, 
                     59, 1, 164, 2, -1, 1, 101, 1, 15, 1, 59, 2, 15, 1, 
                     41, 1, 40, 1, 163, 1, 77, 1, 100, 1, 59, 1, 100, 1, 
                     59, 1, -1, 1, 15, 1, 59, 1, 86, 1, 15, 1, 87, 1, 15, 
                     1, 87, 1, 15, 1, 87, 1, 59, 1, 15, 1, 59, 3, 15, 1, 
                     59, 1, 87, 1, 100, 1, 15, 1, 41, 6, 57, 1, 74, 3, 57, 
                     1, 101, 5, 57, 1, 40, 3, 86, 4, 57, 1, 86, 3, 57, 1, 
                     86, 5, 57, 1, -1, 1, 12, 3, 8, 1, 102, 1, 40, 2, -1, 
                     1, 101, 1, -1, 1, 15, 1, 40, 1, 59, 1, 33, 2, 20, 1, 
                     8, 1, 85, 1, 100, 1, 85, 1, 100, 1, 85, 1, 100, 4, 
                     8, 1, 59, 1, 15, 1, 100, 1, 33, 2, 8, 1, 58, 1, -1, 
                     1, 0, 1, 15, 1, 57, 2, 15, 1, 142, 1, 40, 1, 100, 1, 
                     78, 1, 57, 1, 100, 1, 57, 1, 15, 1, 57, 1, 86, 1, 15, 
                     1, 87, 1, 15, 1, 87, 1, 15, 1, 87, 1, 57, 1, 15, 1, 
                     57, 3, 15, 1, 57, 1, 87, 1, 100, 3, 15, 3, 59, 1, 78, 
                     1, 101, 6, 12, 1, 74, 3, 12, 1, 78, 5, 12, 1, 40, 3, 
                     86, 2, 40, 2, 12, 1, 86, 3, 12, 1, 86, 2, 12, 1, 33, 
                     1, 12, 1, 33, 1, 41, 1, 164, 1, 59, 1, 142, 1, 78, 
                     1, 8, 1, 59, 1, 163, 1, 100, 1, 15, 1, 100, 1, 59, 
                     2, 8, 1, 86, 1, 59, 1, 18, 2, 8, 1, 86, 1, 59, 1, 18, 
                     2, 8, 1, 86, 1, 59, 1, 18, 4, 59, 1, 8, 1, 59, 1, 18, 
                     2, 59, 1, 4, 1, 12, 2, 8, 1, 139, 1, 40, 1, 57, 1, 
                     33, 1, 15, 1, 40, 2, 20, 1, 8, 1, 85, 1, 100, 1, 85, 
                     1, 100, 1, 85, 1, 100, 4, 8, 1, 57, 1, 15, 1, 100, 
                     1, 33, 3, 8, 1, 15, 1, 12, 2, 15, 1, 100, 1, 12, 1, 
                     100, 1, 12, 1, 15, 1, 40, 1, 77, 1, 15, 1, 12, 1, 86, 
                     1, 15, 1, 87, 1, 15, 1, 87, 1, 15, 1, 87, 1, 12, 1, 
                     15, 1, 12, 3, 15, 1, 40, 1, 87, 1, 100, 2, 15, 1, 102, 
                     1, 59, 1, 139, 1, 15, 1, 77, 1, 15, 1, 59, 2, 19, 1, 
                     100, 1, 59, 1, 100, 1, 59, 1, 100, 2, 59, 1, 100, 1, 
                     59, 1, 15, 3, 57, 1, 78, 1, 57, 2, 100, 1, 8, 2, 57, 
                     2, 8, 1, 86, 1, 57, 1, 18, 2, 8, 1, 86, 1, 57, 1, 18, 
                     2, 8, 1, 86, 1, 57, 1, 18, 4, 57, 1, 8, 1, 57, 1, 18, 
                     2, 57, 1, 12, 2, 8, 2, 20, 2, 33, 1, 8, 1, 40, 1, 15, 
                     1, 40, 1, 8, 1, 85, 1, 100, 1, 85, 1, 100, 1, 85, 1, 
                     100, 4, 8, 1, 12, 1, 15, 1, 100, 1, 33, 2, 8, 1, 101, 
                     6, 12, 1, 74, 3, 12, 1, 78, 5, 12, 1, 40, 3, 86, 2, 
                     40, 2, 12, 1, 86, 3, 12, 1, 86, 2, 12, 1, 33, 1, 12, 
                     1, 33, 1, 106, 2, 8, 1, 41, 8, 18, 1, 8, 2, 57, 2, 
                     19, 1, 78, 1, 15, 1, 100, 1, 57, 1, 100, 1, 57, 1, 
                     100, 2, 57, 1, 100, 1, 57, 1, 15, 3, 12, 2, 100, 1, 
                     78, 1, 40, 1, 8, 2, 12, 2, 8, 1, 86, 2, 18, 2, 8, 1, 
                     86, 2, 18, 2, 8, 1, 86, 2, 18, 4, 12, 1, 8, 2, 18, 
                     2, 12, 1, 15, 1, 12, 2, 15, 1, 77, 1, 100, 1, 12, 1, 
                     15, 1, 40, 1, 100, 1, 12, 1, 15, 1, 12, 1, 86, 1, 15, 
                     1, 87, 1, 15, 1, 87, 1, 15, 1, 87, 1, 12, 1, 15, 1, 
                     12, 3, 15, 1, 40, 1, 87, 1, 100, 2, 15, 1, -1, 1, 106, 
                     2, 59, 4, 100, 1, 41, 1, 8, 8, 18, 1, 8, 3, 19, 1, 
                     12, 1, 77, 1, 15, 1, 100, 1, 12, 1, 100, 1, 12, 1, 
                     100, 2, 12, 1, 100, 2, 12, 2, 8, 1, 15, 1, 40, 2, 20, 
                     1, 8, 1, 40, 2, 33, 1, 8, 1, 85, 1, 100, 1, 85, 1, 
                     100, 1, 85, 1, 100, 4, 8, 1, 12, 1, 15, 1, 100, 1, 
                     33, 2, 8, 8, 18, 2, 57, 4, 100, 1, 41, 1, 8, 8, 18, 
                     1, 15, 3, 12, 1, 8, 1, 12, 1, 78, 1, 40, 2, 100, 1, 
                     12, 2, 8, 1, 86, 2, 18, 2, 8, 1, 86, 2, 18, 2, 8, 1, 
                     86, 2, 18, 4, 12, 1, 8, 2, 18, 2, 12, 8, 18, 2, 12, 
                     4, 100, 1, 8, 1, 77, 1, 15, 1, 12, 3, 19, 1, 100, 1, 
                     12, 1, 100, 1, 12, 1, 100, 2, 12, 1, 100, 1, 12, 8, 
                     18, 1, 8, 1, 41, 8, 18, 2, 12, 4, 100, 8, 18 )
      ACCEPT = unpack( 3, -1, 1, 9, 1, 10, 1, 12, 34, -1, 1, 1, 1, 11, 
                        13, -1, 1, 8, 54, -1, 1, 2, 6, -1, 1, 5, 1, 4, 1, 
                        -1, 1, 7, 24, -1, 1, 3, 379, -1, 1, 6, 182, -1 )
      SPECIAL = unpack( 146, -1, 1, 0, 561, -1 )
      TRANSITION = [
        unpack( 1, 1, 1, 2, 61, -1, 1, 3, 1, 4, 56, -1, 1, 5 ),
        unpack( 1, 41, 34, -1, 1, 16, 1, 39, 14, -1, 1, 40, 4, -1, 1, 
                  41, 2, -1, 1, 6, 1, 7, 1, 8, 1, 9, 1, 10, 4, 11, 1, 12, 
                  1, 13, 1, 14, 1, 15, 2, -1, 1, 17, 1, 18, 1, 19, 1, 20, 
                  1, 21, 1, 22, 1, 23, 1, 26, 1, -1, 1, 24, 1, 25, 1, 27, 
                  1, 28, 1, 29, 1, 30, 1, 31, 1, 32, 1, 33, 1, 34, 1, 35, 
                  1, 36, 1, 37, 1, 38 ),
        unpack( 1, 41, 34, -1, 2, 40, 14, -1, 1, 40, 4, -1, 1, 41, 2, 
                  -1, 13, 40, 2, -1, 8, 40, 1, -1, 14, 40 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 43, 44, -1, 1, 42, 4, -1, 1, 40, 
                  1, -1, 1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 45, 44, -1, 1, 42, 4, -1, 1, 40, 
                  1, -1, 1, 40, 14, -1, 1, 44 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 46, 44, -1, 1, 42, 4, -1, 1, 40, 
                  1, -1, 1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, 51, 1, 40, 1, 47, 11, -1, 1, 52, 1, 54, 12, 
                  -1, 1, 53, 6, -1, 1, 50, 11, -1, 1, 49, 4, -1, 1, 40, 
                  1, -1, 1, 40, 18, -1, 1, 48, 85, -1, 1, 55 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 56, 44, -1, 1, 42, 4, -1, 1, 40, 
                  1, -1, 1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 57 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 59, 32, -1, 1, 58, 11, -1, 1, 
                  42, 4, -1, 1, 40, 1, -1, 1, 40, 26, -1, 1, 60 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 61, 44, -1, 1, 42, 4, -1, 1, 40, 
                  1, -1, 1, 40, 26, -1, 1, 62 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 63, 44, -1, 1, 42, 4, -1, 1, 40, 
                  1, -1, 1, 40, 26, -1, 1, 64 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 66, 32, -1, 1, 65, 11, -1, 1, 
                  42, 4, -1, 1, 40, 1, -1, 1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 68, 32, -1, 1, 67, 11, -1, 1, 
                  42, 4, -1, 1, 40, 1, -1, 1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 69, 44, -1, 1, 42, 4, -1, 1, 40, 
                  1, -1, 1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 70, 44, -1, 1, 42, 4, -1, 1, 40, 
                  1, -1, 1, 40 ),
        unpack( 2, 71 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40, 26, -1, 1, 72 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, 73, 1, 40, 12, -1, 1, 52, 1, 54, 12, -1, 1, 
                  53, 18, -1, 1, 42, 4, -1, 1, 40, 1, -1, 1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 74, 44, -1, 1, 42, 4, -1, 1, 40, 
                  1, -1, 1, 40 ),
        unpack( 1, 40, 1, 51, 1, 40, 1, 75, 11, -1, 1, 52, 1, 54, 12, 
                  -1, 1, 53, 18, -1, 1, 49, 4, -1, 1, 40, 1, -1, 1, 40, 
                  104, -1, 1, 55 ),
        unpack(  ),
        unpack(  ),
        unpack( 1, 110, 32, -1, 1, 86, 1, 109, 22, -1, 1, 76, 1, 77, 1, 
                  78, 1, 79, 1, 80, 4, 81, 1, 82, 1, 83, 1, 84, 1, 85, 2, 
                  -1, 1, 87, 1, 88, 1, 89, 1, 90, 1, 91, 1, 92, 1, 93, 1, 
                  96, 1, -1, 1, 94, 1, 95, 1, 97, 1, 98, 1, 99, 1, 100, 
                  1, 101, 1, 102, 1, 103, 1, 104, 1, 105, 1, 106, 1, 107, 
                  1, 108 ),
        unpack( 1, 111 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 45, 44, -1, 1, 42, 4, -1, 1, 40, 
                  1, -1, 1, 40 ),
        unpack( 1, 112 ),
        unpack( 1, 113 ),
        unpack( 1, 114, 24, -1, 2, 115 ),
        unpack( 1, 116 ),
        unpack( 1, 110, 32, -1, 1, 119, 1, 109, 22, -1, 1, 76, 1, 77, 
                  1, 78, 1, 79, 1, 80, 4, 81, 1, 82, 1, 83, 1, 84, 1, 85, 
                  2, -1, 1, 87, 1, 88, 1, 89, 1, 90, 1, 91, 1, 92, 1, 93, 
                  1, 96, 1, -1, 1, 94, 1, 95, 1, 97, 1, 98, 1, 99, 1, 100, 
                  1, 101, 1, 102, 1, 103, 1, 104, 1, 105, 1, 106, 1, 107, 
                  1, 108, 3, -1, 1, 117, 10, -1, 1, 120, 46, -1, 1, 118 ),
        unpack( 1, 121, 69, -1, 1, 122 ),
        unpack( 2, 123, 58, -1, 1, 124 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 2, 125, 58, -1, 1, 126 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack(  ),
        unpack( 1, 127 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 59, 44, -1, 1, 42, 4, -1, 1, 40, 
                  1, -1, 1, 40, 26, -1, 1, 60 ),
        unpack( 1, 128 ),
        unpack( 1, 129 ),
        unpack( 1, 130 ),
        unpack( 1, 131 ),
        unpack( 1, 132 ),
        unpack( 1, 133 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 66, 44, -1, 1, 42, 4, -1, 1, 40, 
                  1, -1, 1, 40 ),
        unpack( 1, 134 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 68, 44, -1, 1, 42, 4, -1, 1, 40, 
                  1, -1, 1, 40 ),
        unpack( 1, 135 ),
        unpack( 1, 136 ),
        unpack( 1, 137 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 139, 32, -1, 1, 138, 11, -1, 1, 
                  42, 4, -1, 1, 40, 1, -1, 1, 40 ),
        unpack( 1, 140 ),
        unpack( 2, 141, 58, -1, 1, 124 ),
        unpack( 1, 142 ),
        unpack( 1, 143, 24, -1, 2, 115 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 2, -1, 1, 147, 32, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 2, -1, 1, 149, 32, -1, 1, 145, 16, -1, 1, 144, 
                  16, -1, 1, 148 ),
        unpack( 1, 146, 2, -1, 1, 150, 32, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 1, 153, 1, -1, 1, 151, 11, -1, 1, 155, 1, 157, 
                  12, -1, 1, 156, 6, -1, 1, 154, 1, 110, 15, -1, 1, 144, 
                  6, -1, 13, 110, 1, -1, 1, 152, 8, 110, 1, -1, 14, 110 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 2, -1, 1, 158, 32, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 159 ),
        unpack( 1, 146, 2, -1, 1, 161, 32, -1, 1, 160, 16, -1, 1, 144, 
                  28, -1, 1, 162 ),
        unpack( 1, 146, 2, -1, 1, 163, 32, -1, 1, 145, 16, -1, 1, 144, 
                  28, -1, 1, 164 ),
        unpack( 1, 146, 2, -1, 1, 165, 32, -1, 1, 145, 16, -1, 1, 144, 
                  28, -1, 1, 166 ),
        unpack( 1, 146, 2, -1, 1, 168, 32, -1, 1, 167, 16, -1, 1, 144 ),
        unpack( 1, 146, 2, -1, 1, 170, 32, -1, 1, 169, 16, -1, 1, 144 ),
        unpack( 1, 146, 2, -1, 1, 171, 32, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 2, -1, 1, 172, 32, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 2, 173 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144, 28, -1, 1, 174 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 1, 175, 13, -1, 1, 155, 1, 157, 12, -1, 1, 156, 
                  6, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 2, -1, 1, 176, 32, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 1, 153, 1, -1, 1, 177, 11, -1, 1, 155, 1, 157, 
                  12, -1, 1, 156, 6, -1, 1, 145, 16, -1, 1, 144 ),
        unpack(  ),
        unpack( 1, 179, 3, -1, 1, 178 ),
        unpack( 1, 180 ),
        unpack( 1, 181 ),
        unpack( 1, 182 ),
        unpack( 1, 219, 3, -1, 1, 218, 27, -1, 1, 194, 1, 217, 22, -1, 
                  1, 184, 1, 185, 1, 186, 1, 187, 1, 188, 4, 189, 1, 190, 
                  1, 191, 1, 192, 1, 193, 2, -1, 1, 195, 1, 196, 1, 197, 
                  1, 198, 1, 199, 1, 200, 1, 201, 1, 204, 1, -1, 1, 202, 
                  1, 203, 1, 205, 1, 206, 1, 207, 1, 208, 1, 209, 1, 210, 
                  1, 211, 1, 212, 1, 213, 1, 214, 1, 215, 1, 216, 1, 183 ),
        unpack( 1, 220 ),
        unpack(  ),
        unpack(  ),
        unpack( 1, 146, 1, 153, 1, -1, 1, 221, 11, -1, 1, 155, 1, 157, 
                  12, -1, 1, 156, 6, -1, 1, 222, 1, 110, 15, -1, 1, 144, 
                  6, -1, 13, 110, 1, -1, 1, 152, 8, 110, 1, -1, 14, 110 ),
        unpack(  ),
        unpack( 1, 223 ),
        unpack( 1, 224 ),
        unpack( 1, 40, 1, 226, 1, 40, 1, 227, 11, -1, 1, 52, 1, 54, 12, 
                  -1, 1, 53, 18, -1, 1, 225, 4, -1, 1, 40, 1, -1, 1, 40 ),
        unpack( 1, 228, 13, -1, 1, 52, 1, 54, 12, -1, 1, 53 ),
        unpack( 1, 54 ),
        unpack( 1, 54 ),
        unpack( 1, 229 ),
        unpack( 1, 232, 31, -1, 1, 230, 44, -1, 1, 231 ),
        unpack( 2, 233, 58, -1, 1, 234 ),
        unpack( 1, 237, 31, -1, 1, 235, 44, -1, 1, 236 ),
        unpack( 2, 238, 58, -1, 1, 239 ),
        unpack( 1, 242, 31, -1, 1, 240, 44, -1, 1, 241 ),
        unpack( 2, 243, 58, -1, 1, 244 ),
        unpack( 1, 245 ),
        unpack( 1, 246 ),
        unpack( 1, 247 ),
        unpack( 1, 248 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 139, 44, -1, 1, 42, 4, -1, 1, 
                  40, 1, -1, 1, 40 ),
        unpack( 1, 249 ),
        unpack( 2, 250, 58, -1, 1, 251 ),
        unpack( 1, 228, 13, -1, 1, 52, 1, 54, 12, -1, 1, 53 ),
        unpack( 1, 252 ),
        unpack( 1, 253 ),
        unpack( 1, 254 ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack( 1, 255 ),
        unpack( 1, 146, 2, -1, 1, 149, 32, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 256 ),
        unpack( 1, 257 ),
        unpack( 1, 110, 5, -1, 2, 110, 1, 258, 1, 110, 23, -1, 2, 110, 
                  15, -1, 2, 110, 41, -1, 1, 110, 9, -1, 2, 110, 4, -1, 
                  2, 110, 22, -1, 1, 110, 1, -1, 1, 110 ),
        unpack( 1, 259 ),
        unpack( 2, 260, 58, -1, 1, 261 ),
        unpack( 2, 110, 1, -1, 1, 262, 5, -1, 4, 145, 2, -1, 2, 110, 12, 
                  -1, 1, 110, 6, -1, 1, 110, 16, -1, 1, 110, 19, -1, 1, 
                  263, 1, 110 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 2, 264, 58, -1, 1, 265 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 266 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 2, -1, 1, 161, 5, -1, 4, 145, 23, -1, 1, 145, 
                  16, -1, 1, 144, 28, -1, 1, 162 ),
        unpack( 1, 267 ),
        unpack( 1, 268 ),
        unpack( 1, 269 ),
        unpack( 1, 270 ),
        unpack( 1, 271 ),
        unpack( 1, 272 ),
        unpack( 1, 146, 2, -1, 1, 168, 5, -1, 4, 145, 23, -1, 1, 145, 
                  16, -1, 1, 144 ),
        unpack( 1, 273 ),
        unpack( 1, 146, 2, -1, 1, 170, 5, -1, 4, 145, 23, -1, 1, 145, 
                  16, -1, 1, 144 ),
        unpack( 1, 274 ),
        unpack( 1, 275 ),
        unpack( 1, 276 ),
        unpack( 1, 146, 2, -1, 1, 278, 32, -1, 1, 277, 16, -1, 1, 144 ),
        unpack( 1, 279 ),
        unpack( 2, 280, 58, -1, 1, 261 ),
        unpack( 1, 281 ),
        unpack( 1, 282 ),
        unpack( 1, 283 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40, 18, -1, 1, 48 ),
        unpack( 1, 219, 3, -1, 1, 218, 27, -1, 1, 194, 1, 217, 22, -1, 
                  1, 184, 1, 185, 1, 186, 1, 187, 1, 188, 4, 189, 1, 190, 
                  1, 191, 1, 192, 1, 193, 2, -1, 1, 195, 1, 196, 1, 197, 
                  1, 198, 1, 199, 1, 200, 1, 201, 1, 204, 1, -1, 1, 202, 
                  1, 203, 1, 205, 1, 206, 1, 207, 1, 208, 1, 209, 1, 210, 
                  1, 211, 1, 212, 1, 213, 1, 214, 1, 215, 1, 216 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 284, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 286, 1, 219, 3, -1, 1, 218, 61, -1, 1, 285 ),
        unpack( 1, 287, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 290, 1, -1, 1, 292, 1, 219, 3, -1, 1, 218, 6, -1, 1, 
                  291, 1, 289, 12, -1, 1, 288, 6, -1, 1, 294, 37, -1, 1, 
                  293 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 295, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 296 ),
        unpack( 1, 298, 1, 219, 3, -1, 1, 218, 27, -1, 1, 297, 45, -1, 
                  1, 299 ),
        unpack( 1, 300, 1, 219, 3, -1, 1, 218, 73, -1, 1, 301 ),
        unpack( 1, 302, 1, 219, 3, -1, 1, 218, 73, -1, 1, 303 ),
        unpack( 1, 305, 1, 219, 3, -1, 1, 218, 27, -1, 1, 304 ),
        unpack( 1, 307, 1, 219, 3, -1, 1, 218, 27, -1, 1, 306 ),
        unpack( 1, 308, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 309, 1, 219, 3, -1, 1, 218 ),
        unpack( 2, 310 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218, 73, -1, 1, 311 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 312, 2, -1, 1, 219, 3, -1, 1, 218, 6, -1, 1, 291, 1, 
                  289, 12, -1, 1, 288 ),
        unpack( 1, 313, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 290, 1, -1, 1, 314, 1, 219, 3, -1, 1, 218, 6, -1, 1, 
                  291, 1, 289, 12, -1, 1, 288 ),
        unpack( 2, 315 ),
        unpack( 1, 120, 111, -1, 1, 55 ),
        unpack( 1, 40, 1, -1, 1, 40, 33, -1, 1, 316, 11, -1, 1, 42, 4, 
                  -1, 1, 40, 1, -1, 1, 40 ),
        unpack( 1, 110, 5, -1, 2, 110, 1, 317, 1, 110, 23, -1, 2, 110, 
                  15, -1, 2, 110, 41, -1, 1, 110, 9, -1, 2, 110, 4, -1, 
                  2, 110, 22, -1, 1, 110, 1, -1, 1, 110 ),
        unpack( 2, 110, 1, -1, 1, 318, 5, -1, 4, 145, 2, -1, 2, 110, 12, 
                  -1, 1, 110, 6, -1, 1, 110, 16, -1, 1, 110, 19, -1, 1, 
                  263, 1, 110 ),
        unpack( 1, 319 ),
        unpack( 1, 40, 1, -1, 1, 40, 1, 320, 44, -1, 1, 42, 4, -1, 1, 
                  40, 1, -1, 1, 40 ),
        unpack( 1, 110, 32, -1, 1, 119, 1, 109, 22, -1, 1, 76, 1, 77, 
                  1, 78, 1, 79, 1, 80, 4, 81, 1, 82, 1, 83, 1, 84, 1, 85, 
                  2, -1, 1, 87, 1, 88, 1, 89, 1, 90, 1, 91, 1, 92, 1, 93, 
                  1, 96, 1, -1, 1, 94, 1, 95, 1, 97, 1, 98, 1, 99, 1, 100, 
                  1, 101, 1, 102, 1, 103, 1, 104, 1, 105, 1, 106, 1, 107, 
                  1, 108, 3, -1, 1, 117, 57, -1, 1, 118 ),
        unpack( 2, 321, 58, -1, 1, 322 ),
        unpack( 1, 143 ),
        unpack( 2, 323, 58, -1, 1, 322 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 232 ),
        unpack( 1, 232 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40, 26, -1, 1, 60 ),
        unpack( 1, 40, 1, 324, 1, 40, 11, -1, 1, 325, 33, -1, 1, 42, 4, 
                  -1, 1, 40, 1, -1, 1, 40 ),
        unpack( 1, 324, 12, -1, 1, 325 ),
        unpack( 1, 237 ),
        unpack( 1, 237 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40, 26, -1, 1, 62 ),
        unpack( 1, 40, 1, 326, 1, 40, 11, -1, 1, 327, 33, -1, 1, 42, 4, 
                  -1, 1, 40, 1, -1, 1, 40 ),
        unpack( 1, 326, 12, -1, 1, 327 ),
        unpack( 1, 242 ),
        unpack( 1, 242 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40, 26, -1, 1, 64 ),
        unpack( 1, 40, 1, 328, 1, 40, 11, -1, 1, 329, 33, -1, 1, 42, 4, 
                  -1, 1, 40, 1, -1, 1, 40 ),
        unpack( 1, 328, 12, -1, 1, 329 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 330 ),
        unpack( 1, 40, 1, 331, 1, 40, 11, -1, 1, 332, 33, -1, 1, 42, 4, 
                  -1, 1, 40, 1, -1, 1, 40 ),
        unpack( 1, 331, 12, -1, 1, 332 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 146 ),
        unpack( 1, 334, 3, -1, 1, 333 ),
        unpack( 1, 335 ),
        unpack( 1, 336 ),
        unpack( 1, 337, 3, -1, 3, 110, 6, -1, 2, 110, 2, -1, 8, 110, 1, 
                  -1, 5, 110, 12, -1, 2, 110, 4, -1, 1, 110, 44, -1, 1, 
                  110, 31, -1, 1, 110, 3, -1, 2, 110 ),
        unpack( 1, 338 ),
        unpack( 1, 146, 1, 339, 1, -1, 1, 177, 11, -1, 1, 155, 1, 157, 
                  12, -1, 1, 156, 6, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 340, 13, -1, 1, 155, 1, 157, 12, -1, 1, 156 ),
        unpack( 1, 341 ),
        unpack( 1, 342 ),
        unpack( 1, 157 ),
        unpack( 1, 157 ),
        unpack( 1, 343 ),
        unpack( 1, 346, 31, -1, 1, 344, 44, -1, 1, 345 ),
        unpack( 2, 347, 58, -1, 1, 348 ),
        unpack( 1, 351, 31, -1, 1, 349, 44, -1, 1, 350 ),
        unpack( 2, 352, 58, -1, 1, 353 ),
        unpack( 1, 356, 31, -1, 1, 354, 44, -1, 1, 355 ),
        unpack( 2, 357, 58, -1, 1, 358 ),
        unpack( 1, 359 ),
        unpack( 1, 360 ),
        unpack( 1, 361 ),
        unpack( 1, 362 ),
        unpack( 1, 146, 2, -1, 1, 278, 5, -1, 4, 145, 23, -1, 1, 145, 
                  16, -1, 1, 144 ),
        unpack( 1, 363 ),
        unpack( 2, 364, 58, -1, 1, 365 ),
        unpack( 1, 340, 13, -1, 1, 155, 1, 157, 12, -1, 1, 156 ),
        unpack( 1, 366 ),
        unpack( 1, 367 ),
        unpack( 1, 179 ),
        unpack( 1, 368 ),
        unpack( 1, 286, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 369 ),
        unpack( 1, 370 ),
        unpack( 2, 371, 58, -1, 1, 372 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 2, 373, 58, -1, 1, 374 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 375 ),
        unpack( 1, 376 ),
        unpack( 1, 377, 69, -1, 1, 378 ),
        unpack( 1, 379 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 298, 1, 219, 3, -1, 1, 218, 73, -1, 1, 299 ),
        unpack( 1, 380 ),
        unpack( 1, 381 ),
        unpack( 1, 382 ),
        unpack( 1, 383 ),
        unpack( 1, 384 ),
        unpack( 1, 385 ),
        unpack( 1, 305, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 386 ),
        unpack( 1, 307, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 387 ),
        unpack( 1, 388 ),
        unpack( 1, 389 ),
        unpack( 1, 391, 1, 219, 3, -1, 1, 218, 27, -1, 1, 390 ),
        unpack( 1, 392 ),
        unpack( 2, 393, 58, -1, 1, 374 ),
        unpack( 1, 394 ),
        unpack( 1, 395 ),
        unpack( 1, 219, 3, -1, 1, 218, 27, -1, 1, 407, 1, 430, 22, -1, 
                  1, 397, 1, 398, 1, 399, 1, 400, 1, 401, 4, 402, 1, 403, 
                  1, 404, 1, 405, 1, 406, 2, -1, 1, 408, 1, 409, 1, 410, 
                  1, 411, 1, 412, 1, 413, 1, 414, 1, 417, 1, -1, 1, 415, 
                  1, 416, 1, 418, 1, 419, 1, 420, 1, 421, 1, 422, 1, 423, 
                  1, 424, 1, 425, 1, 426, 1, 427, 1, 428, 1, 429, 1, 396 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 431, 3, -1, 3, 110, 6, -1, 2, 110, 2, -1, 8, 110, 1, 
                  -1, 5, 110, 12, -1, 2, 110, 4, -1, 1, 110, 44, -1, 1, 
                  110, 31, -1, 1, 110, 3, -1, 2, 110 ),
        unpack( 1, 432 ),
        unpack( 1, 122 ),
        unpack( 1, 433 ),
        unpack( 1, 40, 1, 434, 1, 40, 1, 227, 11, -1, 1, 52, 32, -1, 1, 
                  225, 4, -1, 1, 40, 1, -1, 1, 40 ),
        unpack( 1, 52 ),
        unpack( 1, 52 ),
        unpack( 2, 435, 58, -1, 1, 436 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 2, 437, 58, -1, 1, 438 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 2, 439, 58, -1, 1, 440 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 2, 441, 58, -1, 1, 442 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 443 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144, 20, -1, 1, 152 ),
        unpack( 1, 146, 35, -1, 1, 444, 16, -1, 1, 144 ),
        unpack( 2, 445, 58, -1, 1, 446 ),
        unpack( 2, 447, 58, -1, 1, 446 ),
        unpack( 1, 448 ),
        unpack( 1, 146, 2, -1, 1, 449, 32, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 346 ),
        unpack( 1, 346 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144, 28, -1, 1, 162 ),
        unpack( 1, 146, 1, 450, 12, -1, 1, 451, 21, -1, 1, 145, 16, -1, 
                  1, 144 ),
        unpack( 1, 450, 12, -1, 1, 451 ),
        unpack( 1, 351 ),
        unpack( 1, 351 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144, 28, -1, 1, 164 ),
        unpack( 1, 146, 1, 452, 12, -1, 1, 453, 21, -1, 1, 145, 16, -1, 
                  1, 144 ),
        unpack( 1, 452, 12, -1, 1, 453 ),
        unpack( 1, 356 ),
        unpack( 1, 356 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144, 28, -1, 1, 166 ),
        unpack( 1, 146, 1, 454, 12, -1, 1, 455, 21, -1, 1, 145, 16, -1, 
                  1, 144 ),
        unpack( 1, 454, 12, -1, 1, 455 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 456 ),
        unpack( 1, 146, 1, 457, 12, -1, 1, 458, 21, -1, 1, 145, 16, -1, 
                  1, 144 ),
        unpack( 1, 457, 12, -1, 1, 458 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 460, 3, -1, 1, 459 ),
        unpack( 1, 461 ),
        unpack( 1, 462 ),
        unpack( 1, 289 ),
        unpack( 1, 289 ),
        unpack( 1, 463, 1, -1, 1, 314, 1, 219, 3, -1, 1, 218, 6, -1, 1, 
                  291, 1, 289, 12, -1, 1, 288 ),
        unpack( 1, 464, 13, -1, 1, 291, 1, 289, 12, -1, 1, 288 ),
        unpack( 1, 465 ),
        unpack( 1, 466 ),
        unpack( 1, 467 ),
        unpack( 1, 468 ),
        unpack( 1, 469 ),
        unpack( 1, 472, 31, -1, 1, 470, 44, -1, 1, 471 ),
        unpack( 2, 473, 58, -1, 1, 474 ),
        unpack( 1, 477, 31, -1, 1, 475, 44, -1, 1, 476 ),
        unpack( 2, 478, 58, -1, 1, 479 ),
        unpack( 1, 482, 31, -1, 1, 480, 44, -1, 1, 481 ),
        unpack( 2, 483, 58, -1, 1, 484 ),
        unpack( 1, 485 ),
        unpack( 1, 486 ),
        unpack( 1, 487 ),
        unpack( 1, 488 ),
        unpack( 1, 391, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 489 ),
        unpack( 2, 490, 58, -1, 1, 491 ),
        unpack( 1, 464, 13, -1, 1, 291, 1, 289, 12, -1, 1, 288 ),
        unpack( 1, 492 ),
        unpack( 1, 493 ),
        unpack( 1, 219, 3, -1, 1, 218, 27, -1, 1, 407, 1, 430, 22, -1, 
                  1, 397, 1, 398, 1, 399, 1, 400, 1, 401, 4, 402, 1, 403, 
                  1, 404, 1, 405, 1, 406, 2, -1, 1, 408, 1, 409, 1, 410, 
                  1, 411, 1, 412, 1, 413, 1, 414, 1, 417, 1, -1, 1, 415, 
                  1, 416, 1, 418, 1, 419, 1, 420, 1, 421, 1, 422, 1, 423, 
                  1, 424, 1, 425, 1, 426, 1, 427, 1, 428, 1, 429 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 494, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 496, 1, 219, 3, -1, 1, 218, 61, -1, 1, 495 ),
        unpack( 1, 497, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 503, 1, -1, 1, 501, 1, 219, 3, -1, 1, 218, 6, -1, 1, 
                  504, 1, 500, 12, -1, 1, 499, 6, -1, 1, 498, 37, -1, 1, 
                  502 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 505, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 506 ),
        unpack( 1, 508, 1, 219, 3, -1, 1, 218, 27, -1, 1, 507, 45, -1, 
                  1, 509 ),
        unpack( 1, 510, 1, 219, 3, -1, 1, 218, 73, -1, 1, 511 ),
        unpack( 1, 512, 1, 219, 3, -1, 1, 218, 73, -1, 1, 513 ),
        unpack( 1, 515, 1, 219, 3, -1, 1, 218, 27, -1, 1, 514 ),
        unpack( 1, 517, 1, 219, 3, -1, 1, 218, 27, -1, 1, 516 ),
        unpack( 1, 518, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 519, 1, 219, 3, -1, 1, 218 ),
        unpack( 2, 520 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218, 73, -1, 1, 521 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 522, 2, -1, 1, 219, 3, -1, 1, 218, 6, -1, 1, 504, 1, 
                  500, 12, -1, 1, 499 ),
        unpack( 1, 523, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 503, 1, -1, 1, 524, 1, 219, 3, -1, 1, 218, 6, -1, 1, 
                  504, 1, 500, 12, -1, 1, 499 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144, 20, -1, 1, 152, 
                  27, -1, 1, 525 ),
        unpack( 1, 526 ),
        unpack( 1, 527 ),
        unpack( 2, 528 ),
        unpack( 1, 529, 12, -1, 1, 325 ),
        unpack( 1, 529, 12, -1, 1, 325 ),
        unpack( 1, 530, 12, -1, 1, 327 ),
        unpack( 1, 530, 12, -1, 1, 327 ),
        unpack( 1, 531, 12, -1, 1, 329 ),
        unpack( 1, 531, 12, -1, 1, 329 ),
        unpack( 1, 532, 12, -1, 1, 332 ),
        unpack( 1, 532, 12, -1, 1, 332 ),
        unpack( 1, 334 ),
        unpack( 1, 146, 8, -1, 4, 145, 23, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 1, 533, 1, -1, 1, 177, 11, -1, 1, 155, 20, -1, 
                  1, 145, 16, -1, 1, 144 ),
        unpack( 1, 155 ),
        unpack( 1, 155 ),
        unpack( 1, 110, 52, -1, 1, 110, 19, -1, 1, 263, 1, 110 ),
        unpack( 1, 534 ),
        unpack( 2, 535, 58, -1, 1, 536 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 2, 537, 58, -1, 1, 538 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 2, 539, 58, -1, 1, 540 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 2, 541, 58, -1, 1, 542 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 1, 543 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 2, 544, 58, -1, 1, 545 ),
        unpack( 2, 546, 58, -1, 1, 545 ),
        unpack( 1, 219, 3, -1, 1, 218, 65, -1, 1, 293 ),
        unpack( 1, 219, 3, -1, 1, 218, 27, -1, 1, 547 ),
        unpack( 1, 548 ),
        unpack( 1, 549, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 472 ),
        unpack( 1, 472 ),
        unpack( 1, 219, 3, -1, 1, 218, 73, -1, 1, 299 ),
        unpack( 1, 550, 2, -1, 1, 219, 3, -1, 1, 218, 5, -1, 1, 551 ),
        unpack( 1, 550, 12, -1, 1, 551 ),
        unpack( 1, 477 ),
        unpack( 1, 477 ),
        unpack( 1, 219, 3, -1, 1, 218, 73, -1, 1, 301 ),
        unpack( 1, 552, 2, -1, 1, 219, 3, -1, 1, 218, 5, -1, 1, 553 ),
        unpack( 1, 552, 12, -1, 1, 553 ),
        unpack( 1, 482 ),
        unpack( 1, 482 ),
        unpack( 1, 219, 3, -1, 1, 218, 73, -1, 1, 303 ),
        unpack( 1, 554, 2, -1, 1, 219, 3, -1, 1, 218, 5, -1, 1, 555 ),
        unpack( 1, 554, 12, -1, 1, 555 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 556 ),
        unpack( 1, 557, 2, -1, 1, 219, 3, -1, 1, 218, 5, -1, 1, 558 ),
        unpack( 1, 557, 12, -1, 1, 558 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 559 ),
        unpack( 1, 496, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 560 ),
        unpack( 1, 561 ),
        unpack( 1, 562, 69, -1, 1, 563 ),
        unpack( 2, 564, 58, -1, 1, 565 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 566 ),
        unpack( 1, 567 ),
        unpack( 2, 568, 58, -1, 1, 569 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 570 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 508, 1, 219, 3, -1, 1, 218, 73, -1, 1, 509 ),
        unpack( 1, 571 ),
        unpack( 1, 572 ),
        unpack( 1, 573 ),
        unpack( 1, 574 ),
        unpack( 1, 575 ),
        unpack( 1, 576 ),
        unpack( 1, 515, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 577 ),
        unpack( 1, 517, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 578 ),
        unpack( 1, 579 ),
        unpack( 1, 580 ),
        unpack( 1, 582, 1, 219, 3, -1, 1, 218, 27, -1, 1, 581 ),
        unpack( 1, 583 ),
        unpack( 2, 584, 58, -1, 1, 569 ),
        unpack( 1, 585 ),
        unpack( 1, 586 ),
        unpack(  ),
        unpack( 1, 110, 52, -1, 1, 110, 19, -1, 1, 263, 1, 110, 27, -1, 
                  1, 525 ),
        unpack( 1, 40, 1, -1, 1, 40, 45, -1, 1, 42, 4, -1, 1, 40, 1, -1, 
                  1, 40 ),
        unpack( 1, 40, 1, 434, 1, 40, 1, 227, 44, -1, 1, 225, 4, -1, 1, 
                  40, 1, -1, 1, 40 ),
        unpack( 2, 587, 58, -1, 1, 588 ),
        unpack( 2, 589, 58, -1, 1, 590 ),
        unpack( 2, 591, 58, -1, 1, 592 ),
        unpack( 2, 593, 58, -1, 1, 594 ),
        unpack( 2, 595 ),
        unpack( 1, 596 ),
        unpack( 1, 597, 12, -1, 1, 451 ),
        unpack( 1, 597, 12, -1, 1, 451 ),
        unpack( 1, 598, 12, -1, 1, 453 ),
        unpack( 1, 598, 12, -1, 1, 453 ),
        unpack( 1, 599, 12, -1, 1, 455 ),
        unpack( 1, 599, 12, -1, 1, 455 ),
        unpack( 1, 600, 12, -1, 1, 458 ),
        unpack( 1, 600, 12, -1, 1, 458 ),
        unpack( 1, 460 ),
        unpack( 1, 601, 1, -1, 1, 314, 1, 219, 3, -1, 1, 218, 6, -1, 1, 
                  291 ),
        unpack( 1, 291 ),
        unpack( 1, 291 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 378 ),
        unpack( 1, 602 ),
        unpack( 2, 603, 58, -1, 1, 604 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 2, 605, 58, -1, 1, 606 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 2, 607, 58, -1, 1, 608 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 2, 609, 58, -1, 1, 610 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 612, 3, -1, 1, 611 ),
        unpack( 1, 613 ),
        unpack( 1, 614 ),
        unpack( 1, 615 ),
        unpack( 1, 616 ),
        unpack( 1, 500 ),
        unpack( 1, 500 ),
        unpack( 1, 617 ),
        unpack( 1, 618 ),
        unpack( 1, 619, 1, -1, 1, 524, 1, 219, 3, -1, 1, 218, 6, -1, 1, 
                  504, 1, 500, 12, -1, 1, 499 ),
        unpack( 1, 620, 13, -1, 1, 504, 1, 500, 12, -1, 1, 499 ),
        unpack( 1, 621 ),
        unpack( 1, 624, 31, -1, 1, 622, 44, -1, 1, 623 ),
        unpack( 2, 625, 58, -1, 1, 626 ),
        unpack( 1, 629, 31, -1, 1, 627, 44, -1, 1, 628 ),
        unpack( 2, 630, 58, -1, 1, 631 ),
        unpack( 1, 634, 31, -1, 1, 632, 44, -1, 1, 633 ),
        unpack( 2, 635, 58, -1, 1, 636 ),
        unpack( 1, 637 ),
        unpack( 1, 638 ),
        unpack( 1, 639 ),
        unpack( 1, 640 ),
        unpack( 1, 582, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 641 ),
        unpack( 2, 642, 58, -1, 1, 643 ),
        unpack( 1, 620, 13, -1, 1, 504, 1, 500, 12, -1, 1, 499 ),
        unpack( 1, 644 ),
        unpack( 1, 645 ),
        unpack( 1, 325 ),
        unpack( 1, 325 ),
        unpack( 1, 327 ),
        unpack( 1, 327 ),
        unpack( 1, 329 ),
        unpack( 1, 329 ),
        unpack( 1, 332 ),
        unpack( 1, 332 ),
        unpack( 1, 146, 1, 533, 1, -1, 1, 177, 32, -1, 1, 145, 16, -1, 
                  1, 144 ),
        unpack( 1, 146, 35, -1, 1, 145, 16, -1, 1, 144 ),
        unpack( 2, 646, 58, -1, 1, 647 ),
        unpack( 2, 648, 58, -1, 1, 649 ),
        unpack( 2, 650, 58, -1, 1, 651 ),
        unpack( 2, 652, 58, -1, 1, 653 ),
        unpack( 2, 654 ),
        unpack( 1, 655 ),
        unpack( 1, 656, 12, -1, 1, 551 ),
        unpack( 1, 656, 12, -1, 1, 551 ),
        unpack( 1, 657, 12, -1, 1, 553 ),
        unpack( 1, 657, 12, -1, 1, 553 ),
        unpack( 1, 658, 12, -1, 1, 555 ),
        unpack( 1, 658, 12, -1, 1, 555 ),
        unpack( 1, 659, 12, -1, 1, 558 ),
        unpack( 1, 659, 12, -1, 1, 558 ),
        unpack( 1, 660 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 661 ),
        unpack( 1, 662, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218, 65, -1, 1, 502 ),
        unpack( 1, 219, 3, -1, 1, 218, 27, -1, 1, 663 ),
        unpack( 2, 664, 58, -1, 1, 665 ),
        unpack( 2, 666, 58, -1, 1, 665 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 624 ),
        unpack( 1, 624 ),
        unpack( 1, 219, 3, -1, 1, 218, 73, -1, 1, 509 ),
        unpack( 1, 667, 2, -1, 1, 219, 3, -1, 1, 218, 5, -1, 1, 668 ),
        unpack( 1, 667, 12, -1, 1, 668 ),
        unpack( 1, 629 ),
        unpack( 1, 629 ),
        unpack( 1, 219, 3, -1, 1, 218, 73, -1, 1, 511 ),
        unpack( 1, 669, 2, -1, 1, 219, 3, -1, 1, 218, 5, -1, 1, 670 ),
        unpack( 1, 669, 12, -1, 1, 670 ),
        unpack( 1, 634 ),
        unpack( 1, 634 ),
        unpack( 1, 219, 3, -1, 1, 218, 73, -1, 1, 513 ),
        unpack( 1, 671, 2, -1, 1, 219, 3, -1, 1, 218, 5, -1, 1, 672 ),
        unpack( 1, 671, 12, -1, 1, 672 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 673 ),
        unpack( 1, 674, 2, -1, 1, 219, 3, -1, 1, 218, 5, -1, 1, 675 ),
        unpack( 1, 674, 12, -1, 1, 675 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 451 ),
        unpack( 1, 451 ),
        unpack( 1, 453 ),
        unpack( 1, 453 ),
        unpack( 1, 455 ),
        unpack( 1, 455 ),
        unpack( 1, 458 ),
        unpack( 1, 458 ),
        unpack( 1, 601, 1, -1, 1, 314, 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 2, 676, 58, -1, 1, 677 ),
        unpack( 2, 678, 58, -1, 1, 679 ),
        unpack( 2, 680, 58, -1, 1, 681 ),
        unpack( 2, 682, 58, -1, 1, 683 ),
        unpack( 1, 612 ),
        unpack( 1, 563 ),
        unpack( 1, 684 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 685, 1, -1, 1, 524, 1, 219, 3, -1, 1, 218, 6, -1, 1, 
                  504 ),
        unpack( 1, 504 ),
        unpack( 1, 504 ),
        unpack( 2, 686, 58, -1, 1, 687 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 2, 688, 58, -1, 1, 689 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 2, 690, 58, -1, 1, 691 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 2, 692, 58, -1, 1, 693 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 551 ),
        unpack( 1, 551 ),
        unpack( 1, 553 ),
        unpack( 1, 553 ),
        unpack( 1, 555 ),
        unpack( 1, 555 ),
        unpack( 1, 558 ),
        unpack( 1, 558 ),
        unpack( 1, 694 ),
        unpack( 2, 695 ),
        unpack( 1, 696, 12, -1, 1, 668 ),
        unpack( 1, 696, 12, -1, 1, 668 ),
        unpack( 1, 697, 12, -1, 1, 670 ),
        unpack( 1, 697, 12, -1, 1, 670 ),
        unpack( 1, 698, 12, -1, 1, 672 ),
        unpack( 1, 698, 12, -1, 1, 672 ),
        unpack( 1, 699, 12, -1, 1, 675 ),
        unpack( 1, 699, 12, -1, 1, 675 ),
        unpack( 1, 219, 3, -1, 1, 218 ),
        unpack( 1, 685, 1, -1, 1, 524, 1, 219, 3, -1, 1, 218 ),
        unpack( 2, 700, 58, -1, 1, 701 ),
        unpack( 2, 702, 58, -1, 1, 703 ),
        unpack( 2, 704, 58, -1, 1, 705 ),
        unpack( 2, 706, 58, -1, 1, 707 ),
        unpack( 1, 668 ),
        unpack( 1, 668 ),
        unpack( 1, 670 ),
        unpack( 1, 670 ),
        unpack( 1, 672 ),
        unpack( 1, 672 ),
        unpack( 1, 675 ),
        unpack( 1, 675 )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 10
      

      def description
        <<-'__dfa_description__'.strip!
          49:1: package_obj_spec : ( variable_declaration | type_declaration | subtype_declaration | record_declaration | plsql_table_declaration | varray_declaration | cursor_declaration | cursor_spec | procedure_spec | function_spec | exception_declaration | pragma_declaration );
        __dfa_description__
      end
    end
    class DFA14 < ANTLR3::DFA
      EOT = unpack( 11, -1 )
      EOF = unpack( 11, -1 )
      MIN = unpack( 1, 7, 1, 4, 1, -1, 1, 4, 1, 7, 1, -1, 1, 15, 2, 8, 
                     1, 0, 1, 4 )
      MAX = unpack( 2, 101, 1, -1, 1, 78, 1, 142, 1, -1, 1, 15, 1, 139, 
                     1, 8, 1, 0, 1, 78 )
      ACCEPT = unpack( 2, -1, 1, 2, 2, -1, 1, 1, 5, -1 )
      SPECIAL = unpack( 9, -1, 1, 0, 1, -1 )
      TRANSITION = [
        unpack( 1, 2, 32, -1, 1, 1, 1, 2, 22, -1, 13, 2, 2, -1, 8, 2, 1, 
                 -1, 14, 2 ),
        unpack( 2, 2, 1, -1, 1, 4, 11, -1, 2, 2, 12, -1, 1, 2, 6, -1, 
                  1, 3, 1, 5, 15, -1, 1, 2, 6, -1, 13, 5, 1, -1, 1, 2, 8, 
                  5, 1, -1, 14, 5 ),
        unpack(  ),
        unpack( 2, 5, 1, -1, 1, 6, 11, -1, 2, 5, 12, -1, 1, 5, 6, -1, 
                  1, 5, 16, -1, 1, 5, 19, -1, 1, 2, 1, 5 ),
        unpack( 1, 5, 5, -1, 2, 5, 1, 7, 1, 5, 23, -1, 2, 5, 15, -1, 2, 
                  5, 41, -1, 1, 5, 9, -1, 2, 5, 4, -1, 2, 5, 22, -1, 1, 
                  5, 1, -1, 1, 5 ),
        unpack(  ),
        unpack( 1, 8 ),
        unpack( 1, 9, 3, -1, 3, 5, 6, -1, 2, 5, 2, -1, 8, 5, 1, -1, 5, 
                  5, 12, -1, 2, 5, 4, -1, 1, 5, 44, -1, 1, 5, 31, -1, 1, 
                  5, 3, -1, 2, 5 ),
        unpack( 1, 10 ),
        unpack( 1, -1 ),
        unpack( 1, 5, 52, -1, 1, 5, 19, -1, 1, 2, 1, 5 )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 14
      

      def description
        <<-'__dfa_description__'.strip!
          71:27: ( keyNEW )?
        __dfa_description__
      end
    end
    class DFA19 < ANTLR3::DFA
      EOT = unpack( 195, -1 )
      EOF = unpack( 195, -1 )
      MIN = unpack( 1, 40, 2, 5, 1, 51, 3, -1, 17, 4, 1, 40, 7, 4, 1, 85, 
                     8, 4, 2, -1, 1, 40, 1, 7, 2, 40, 1, 15, 2, 40, 2, 4, 
                     1, -1, 1, 15, 1, 4, 4, 15, 2, 4, 1, 15, 1, 87, 1, 15, 
                     1, 87, 1, 15, 1, 87, 1, 4, 1, 15, 1, 4, 3, 15, 1, 4, 
                     1, 87, 1, 40, 1, 15, 1, 103, 1, 15, 1, 40, 1, 4, 1, 
                     5, 3, -1, 1, 4, 1, 8, 1, 40, 2, 20, 6, 8, 1, 40, 1, 
                     8, 1, 40, 1, 8, 1, 40, 4, 8, 1, 4, 1, 15, 1, 40, 1, 
                     5, 2, 8, 1, 4, 2, 40, 1, 15, 1, 40, 1, 15, 1, 7, 2, 
                     4, 1, 15, 5, 4, 2, 8, 2, 4, 1, 5, 2, 8, 2, 4, 1, 5, 
                     2, 8, 2, 4, 1, 5, 4, 4, 1, 8, 1, 4, 1, 5, 1, 4, 1, 
                     77, 1, 15, 1, 4, 2, 19, 1, 8, 1, 15, 1, 4, 1, 8, 1, 
                     40, 1, 4, 1, 40, 1, 4, 1, 40, 2, 4, 1, 40, 1, 4, 1, 
                     8, 1, 40, 1, 4, 1, 8, 8, 5, 2, 4, 1, -1, 1, 77, 4, 
                     40, 8, 18 )
      MAX = unpack( 1, 161, 2, 101, 1, 104, 3, -1, 1, 78, 6, 59, 1, 74, 
                     9, 59, 1, 40, 3, 86, 4, 59, 1, 86, 3, 59, 1, 86, 4, 
                     59, 2, -1, 1, 40, 1, 77, 1, 100, 1, 163, 1, 41, 1, 
                     40, 1, 100, 2, 59, 1, -1, 1, 15, 1, 59, 2, 15, 1, 41, 
                     1, 15, 1, 59, 1, 86, 1, 15, 1, 87, 1, 15, 1, 87, 1, 
                     15, 1, 87, 1, 59, 1, 15, 1, 59, 3, 15, 1, 59, 1, 87, 
                     1, 100, 1, 15, 1, 104, 1, 15, 1, 40, 1, 59, 1, 33, 
                     3, -1, 1, 78, 1, 8, 1, 40, 2, 20, 1, 12, 4, 8, 1, 85, 
                     1, 100, 1, 85, 1, 100, 1, 85, 1, 100, 4, 8, 1, 59, 
                     1, 15, 1, 100, 1, 33, 2, 8, 1, 59, 1, 163, 1, 100, 
                     1, 15, 1, 100, 1, 15, 1, 77, 1, 78, 1, 59, 1, 15, 5, 
                     59, 2, 8, 1, 86, 1, 59, 1, 18, 2, 8, 1, 86, 1, 59, 
                     1, 18, 2, 8, 1, 86, 1, 59, 1, 18, 4, 59, 1, 8, 1, 59, 
                     1, 18, 1, 59, 1, 77, 1, 15, 1, 59, 2, 19, 1, 8, 1, 
                     15, 1, 59, 1, 8, 1, 100, 1, 59, 1, 100, 1, 59, 1, 100, 
                     2, 59, 1, 100, 1, 59, 1, 8, 1, 41, 1, 106, 1, 8, 8, 
                     18, 2, 59, 1, -1, 1, 106, 4, 100, 8, 18 )
      ACCEPT = unpack( 4, -1, 1, 8, 1, 9, 1, 10, 34, -1, 1, 1, 1, 4, 9, 
                        -1, 1, 2, 29, -1, 1, 6, 1, 3, 1, 5, 96, -1, 1, 7, 
                        13, -1 )
      SPECIAL = unpack( 195, -1 )
      TRANSITION = [
        unpack( 1, 1, 1, 2, 8, -1, 1, 3, 52, -1, 1, 4, 1, 5, 56, -1, 1, 
                 6 ),
        unpack( 1, 42, 34, -1, 1, 7, 1, 18, 14, -1, 1, 41, 4, -1, 1, 42, 
                  2, -1, 1, 8, 1, 9, 1, 10, 1, 11, 1, 12, 4, 13, 1, 14, 
                  1, 15, 1, 16, 1, 17, 2, -1, 1, 19, 1, 20, 1, 21, 1, 22, 
                  1, 23, 1, 24, 1, 25, 1, 28, 1, -1, 1, 26, 1, 27, 1, 29, 
                  1, 30, 1, 31, 1, 32, 1, 33, 1, 34, 1, 35, 1, 36, 1, 37, 
                  1, 38, 1, 39, 1, 40 ),
        unpack( 1, 42, 34, -1, 2, 41, 14, -1, 1, 41, 4, -1, 1, 42, 2, 
                  -1, 13, 41, 2, -1, 8, 41, 1, -1, 14, 41 ),
        unpack( 1, 43, 51, -1, 1, 4, 1, 5 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 1, 41, 1, 45, 1, 41, 1, 47, 11, -1, 1, 51, 1, 50, 12, 
                  -1, 1, 49, 6, -1, 1, 44, 11, -1, 1, 46, 4, -1, 1, 41, 
                  1, -1, 1, 41, 18, -1, 1, 48 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 53, 44, -1, 1, 52, 4, -1, 1, 41, 
                  1, -1, 1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 55, 44, -1, 1, 52, 4, -1, 1, 41, 
                  1, -1, 1, 41, 14, -1, 1, 54 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 56, 44, -1, 1, 52, 4, -1, 1, 41, 
                  1, -1, 1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, 45, 1, 41, 1, 57, 11, -1, 1, 51, 1, 50, 12, 
                  -1, 1, 49, 18, -1, 1, 46, 4, -1, 1, 41, 1, -1, 1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 58, 44, -1, 1, 52, 4, -1, 1, 41, 
                  1, -1, 1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 59 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 61, 32, -1, 1, 60, 11, -1, 1, 
                  52, 4, -1, 1, 41, 1, -1, 1, 41, 26, -1, 1, 62 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 63, 44, -1, 1, 52, 4, -1, 1, 41, 
                  1, -1, 1, 41, 26, -1, 1, 64 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 65, 44, -1, 1, 52, 4, -1, 1, 41, 
                  1, -1, 1, 41, 26, -1, 1, 66 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 68, 32, -1, 1, 67, 11, -1, 1, 
                  52, 4, -1, 1, 41, 1, -1, 1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 70, 32, -1, 1, 69, 11, -1, 1, 
                  52, 4, -1, 1, 41, 1, -1, 1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 71, 44, -1, 1, 52, 4, -1, 1, 41, 
                  1, -1, 1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 72, 44, -1, 1, 52, 4, -1, 1, 41, 
                  1, -1, 1, 41 ),
        unpack( 2, 73 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41, 26, -1, 1, 74 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, 75, 1, 41, 12, -1, 1, 51, 1, 50, 12, -1, 1, 
                  49, 18, -1, 1, 52, 4, -1, 1, 41, 1, -1, 1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 76, 44, -1, 1, 52, 4, -1, 1, 41, 
                  1, -1, 1, 41 ),
        unpack(  ),
        unpack(  ),
        unpack( 1, 77 ),
        unpack( 1, 78, 69, -1, 1, 79 ),
        unpack( 2, 80, 58, -1, 1, 81 ),
        unpack( 1, 85, 1, 52, 22, -1, 13, 52, 2, -1, 8, 52, 1, -1, 14, 
                  52, 3, -1, 1, 82, 10, -1, 1, 83, 46, -1, 1, 84 ),
        unpack( 1, 86, 24, -1, 2, 83 ),
        unpack( 1, 87 ),
        unpack( 2, 88, 58, -1, 1, 89 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack(  ),
        unpack( 1, 90 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 55, 44, -1, 1, 52, 4, -1, 1, 41, 
                  1, -1, 1, 41 ),
        unpack( 1, 91 ),
        unpack( 1, 92 ),
        unpack( 1, 93, 24, -1, 2, 83 ),
        unpack( 1, 94 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 61, 44, -1, 1, 52, 4, -1, 1, 41, 
                  1, -1, 1, 41, 26, -1, 1, 62 ),
        unpack( 1, 95 ),
        unpack( 1, 96 ),
        unpack( 1, 97 ),
        unpack( 1, 98 ),
        unpack( 1, 99 ),
        unpack( 1, 100 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 68, 44, -1, 1, 52, 4, -1, 1, 41, 
                  1, -1, 1, 41 ),
        unpack( 1, 101 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 70, 44, -1, 1, 52, 4, -1, 1, 41, 
                  1, -1, 1, 41 ),
        unpack( 1, 102 ),
        unpack( 1, 103 ),
        unpack( 1, 104 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 106, 32, -1, 1, 105, 11, -1, 1, 
                  52, 4, -1, 1, 41, 1, -1, 1, 41 ),
        unpack( 1, 107 ),
        unpack( 2, 108, 58, -1, 1, 81 ),
        unpack( 1, 109 ),
        unpack( 1, 4, 1, 5 ),
        unpack( 1, 110 ),
        unpack( 1, 111 ),
        unpack( 1, 41, 1, 113, 1, 41, 1, 114, 11, -1, 1, 51, 1, 50, 12, 
                  -1, 1, 49, 18, -1, 1, 112, 4, -1, 1, 41, 1, -1, 1, 41 ),
        unpack( 1, 115, 13, -1, 1, 51, 1, 50, 12, -1, 1, 49 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 2, 52, 1, -1, 1, 116, 11, -1, 2, 52, 12, -1, 1, 52, 6, 
                  -1, 1, 117, 16, -1, 1, 52, 20, -1, 1, 52 ),
        unpack( 1, 118 ),
        unpack( 1, 119 ),
        unpack( 1, 50 ),
        unpack( 1, 50 ),
        unpack( 1, 121, 3, -1, 1, 120 ),
        unpack( 1, 122 ),
        unpack( 1, 123 ),
        unpack( 1, 124 ),
        unpack( 1, 125 ),
        unpack( 1, 128, 31, -1, 1, 126, 44, -1, 1, 127 ),
        unpack( 2, 129, 58, -1, 1, 130 ),
        unpack( 1, 133, 31, -1, 1, 131, 44, -1, 1, 132 ),
        unpack( 2, 134, 58, -1, 1, 135 ),
        unpack( 1, 138, 31, -1, 1, 136, 44, -1, 1, 137 ),
        unpack( 2, 139, 58, -1, 1, 140 ),
        unpack( 1, 141 ),
        unpack( 1, 142 ),
        unpack( 1, 143 ),
        unpack( 1, 144 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 106, 44, -1, 1, 52, 4, -1, 1, 
                  41, 1, -1, 1, 41 ),
        unpack( 1, 145 ),
        unpack( 2, 146, 58, -1, 1, 147 ),
        unpack( 1, 115, 13, -1, 1, 51, 1, 50, 12, -1, 1, 49 ),
        unpack( 1, 148 ),
        unpack( 1, 149 ),
        unpack( 1, 41, 1, -1, 1, 41, 1, 150, 44, -1, 1, 52, 4, -1, 1, 
                  41, 1, -1, 1, 41 ),
        unpack( 1, 85, 1, 52, 22, -1, 13, 52, 2, -1, 8, 52, 1, -1, 14, 
                  52, 3, -1, 1, 82, 57, -1, 1, 84 ),
        unpack( 2, 151, 58, -1, 1, 152 ),
        unpack( 1, 93 ),
        unpack( 2, 153, 58, -1, 1, 152 ),
        unpack( 1, 154 ),
        unpack( 1, 155, 5, -1, 4, 52, 60, -1, 1, 52 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41, 18, -1, 1, 48 ),
        unpack( 1, 41, 1, -1, 1, 41, 33, -1, 1, 156, 11, -1, 1, 52, 4, 
                  -1, 1, 41, 1, -1, 1, 41 ),
        unpack( 1, 157 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 128 ),
        unpack( 1, 128 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41, 26, -1, 1, 62 ),
        unpack( 1, 41, 1, 158, 1, 41, 11, -1, 1, 159, 33, -1, 1, 52, 4, 
                  -1, 1, 41, 1, -1, 1, 41 ),
        unpack( 1, 158, 12, -1, 1, 159 ),
        unpack( 1, 133 ),
        unpack( 1, 133 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41, 26, -1, 1, 64 ),
        unpack( 1, 41, 1, 160, 1, 41, 11, -1, 1, 161, 33, -1, 1, 52, 4, 
                  -1, 1, 41, 1, -1, 1, 41 ),
        unpack( 1, 160, 12, -1, 1, 161 ),
        unpack( 1, 138 ),
        unpack( 1, 138 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41, 26, -1, 1, 66 ),
        unpack( 1, 41, 1, 162, 1, 41, 11, -1, 1, 163, 33, -1, 1, 52, 4, 
                  -1, 1, 41, 1, -1, 1, 41 ),
        unpack( 1, 162, 12, -1, 1, 163 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 164 ),
        unpack( 1, 41, 1, 165, 1, 41, 11, -1, 1, 166, 33, -1, 1, 52, 4, 
                  -1, 1, 41, 1, -1, 1, 41 ),
        unpack( 1, 165, 12, -1, 1, 166 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 79 ),
        unpack( 1, 167 ),
        unpack( 1, 41, 1, 168, 1, 41, 1, 114, 11, -1, 1, 51, 32, -1, 1, 
                  112, 4, -1, 1, 41, 1, -1, 1, 41 ),
        unpack( 1, 51 ),
        unpack( 1, 51 ),
        unpack( 1, 169 ),
        unpack( 1, 170 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 121 ),
        unpack( 2, 171, 58, -1, 1, 172 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 2, 173, 58, -1, 1, 174 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 2, 175, 58, -1, 1, 176 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 2, 177, 58, -1, 1, 178 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 179 ),
        unpack( 2, 180 ),
        unpack( 1, 52, 35, -1, 1, 52, 16, -1, 1, 52, 20, -1, 1, 52, 27, 
                  -1, 1, 181 ),
        unpack( 1, 182 ),
        unpack( 1, 183, 12, -1, 1, 159 ),
        unpack( 1, 183, 12, -1, 1, 159 ),
        unpack( 1, 184, 12, -1, 1, 161 ),
        unpack( 1, 184, 12, -1, 1, 161 ),
        unpack( 1, 185, 12, -1, 1, 163 ),
        unpack( 1, 185, 12, -1, 1, 163 ),
        unpack( 1, 186, 12, -1, 1, 166 ),
        unpack( 1, 186, 12, -1, 1, 166 ),
        unpack( 1, 41, 1, -1, 1, 41, 45, -1, 1, 52, 4, -1, 1, 41, 1, -1, 
                  1, 41 ),
        unpack( 1, 41, 1, 168, 1, 41, 1, 114, 44, -1, 1, 112, 4, -1, 1, 
                  41, 1, -1, 1, 41 ),
        unpack(  ),
        unpack( 1, 52, 28, -1, 1, 181 ),
        unpack( 2, 187, 58, -1, 1, 188 ),
        unpack( 2, 189, 58, -1, 1, 190 ),
        unpack( 2, 191, 58, -1, 1, 192 ),
        unpack( 2, 193, 58, -1, 1, 194 ),
        unpack( 1, 159 ),
        unpack( 1, 159 ),
        unpack( 1, 161 ),
        unpack( 1, 161 ),
        unpack( 1, 163 ),
        unpack( 1, 163 ),
        unpack( 1, 166 ),
        unpack( 1, 166 )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 19
      

      def description
        <<-'__dfa_description__'.strip!
          83:1: package_obj_body : ( variable_declaration | subtype_declaration | cursor_declaration | exception_declaration | record_declaration | plsql_table_declaration | varray_declaration | procedure_body | function_body | pragma_declaration );
        __dfa_description__
      end
    end
    class DFA21 < ANTLR3::DFA
      EOT = unpack( 32, -1 )
      EOF = unpack( 32, -1 )
      MIN = unpack( 1, 10, 1, 0, 1, -1, 1, 0, 3, -1, 1, 0, 24, -1 )
      MAX = unpack( 1, 167, 1, 0, 1, -1, 1, 0, 3, -1, 1, 0, 24, -1 )
      ACCEPT = unpack( 2, -1, 1, 1, 1, -1, 1, 3, 1, 4, 1, 5, 1, -1, 1, 
                        6, 2, -1, 1, 7, 1, 8, 1, 9, 1, 10, 9, -1, 1, 11, 
                        5, -1, 1, 12, 1, 2 )
      SPECIAL = unpack( 1, -1, 1, 0, 1, -1, 1, 1, 3, -1, 1, 2, 24, -1 )
      TRANSITION = [
        unpack( 1, 7, 6, -1, 1, 2, 22, -1, 1, 1, 1, 3, 8, -1, 1, 24, 4, 
                 -1, 1, 24, 2, -1, 1, 11, 1, -1, 1, 24, 1, -1, 1, 4, 24, 
                 -1, 1, 14, 12, -1, 1, 30, 2, -1, 2, 24, 7, -1, 1, 8, 1, 
                 14, 1, 6, 1, -1, 1, 14, 15, -1, 1, 14, 9, -1, 1, 5, 2, 
                 -1, 1, 14, 1, -1, 1, 14, 1, -1, 2, 14, 4, -1, 1, 14, 2, 
                 -1, 1, 8, 2, -1, 1, 24, 1, 12, 1, -1, 1, 13, 1, -1, 1, 
                 14, 1, 8 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 21
      

      def description
        <<-'__dfa_description__'.strip!
          100:1: statement : ( assignment_statement | exit_statement | goto_statement | case_statement | if_statement | loop_statement | null_statement | raise_statement | return_statement | sql_statement | plsql_block | function_call );
        __dfa_description__
      end
    end
    class DFA29 < ANTLR3::DFA
      EOT = unpack( 368, -1 )
      EOF = unpack( 368, -1 )
      MIN = unpack( 1, 40, 2, 5, 1, 51, 3, -1, 17, 4, 1, 40, 7, 4, 1, 85, 
                     8, 4, 2, -1, 1, 40, 1, 15, 1, 40, 2, 7, 1, 40, 1, 4, 
                     1, 40, 1, 4, 1, 7, 1, 15, 1, 4, 4, 15, 2, 4, 1, 15, 
                     1, 87, 1, 15, 1, 87, 1, 15, 1, 87, 1, 4, 1, 15, 1, 
                     4, 3, 15, 1, 4, 1, 87, 1, 40, 1, 15, 1, 103, 1, 8, 
                     1, -1, 1, 40, 1, -1, 16, 4, 1, 40, 7, 4, 1, 85, 9, 
                     4, 2, -1, 1, 15, 1, 40, 2, 20, 1, 4, 1, 5, 1, 4, 6, 
                     8, 1, 40, 1, 8, 1, 40, 1, 8, 1, 40, 4, 8, 1, 4, 1, 
                     15, 1, 40, 1, 5, 1, 8, 2, 4, 1, 7, 1, 40, 1, 58, 1, 
                     4, 1, 0, 1, 40, 1, 4, 1, 40, 1, 4, 1, -1, 1, 15, 1, 
                     4, 3, 15, 2, 4, 1, 15, 1, 87, 1, 15, 1, 87, 1, 15, 
                     1, 87, 1, 4, 1, 15, 1, 4, 3, 15, 1, 4, 1, 87, 1, 40, 
                     2, 15, 1, 8, 1, 4, 1, 15, 1, 7, 2, 40, 1, 7, 1, 4, 
                     1, 15, 5, 4, 2, 8, 2, 4, 1, 5, 2, 8, 2, 4, 1, 5, 2, 
                     8, 2, 4, 1, 5, 4, 4, 1, 8, 1, 4, 1, 5, 2, 4, 1, 8, 
                     1, 40, 1, 4, 1, 15, 1, 40, 1, 4, 1, 5, 2, 20, 5, 8, 
                     1, 40, 1, 8, 1, 40, 1, 8, 1, 40, 4, 8, 1, 4, 1, 15, 
                     1, 40, 1, 5, 2, 8, 1, 77, 1, 15, 1, 4, 2, 19, 1, 8, 
                     1, 15, 1, 8, 1, 40, 1, 4, 1, 40, 1, 4, 1, 40, 2, 4, 
                     1, 40, 3, 4, 1, 8, 1, 4, 2, 40, 1, 15, 4, 4, 2, 8, 
                     2, 4, 1, 5, 2, 8, 2, 4, 1, 5, 2, 8, 2, 4, 1, 5, 4, 
                     4, 1, 8, 1, 4, 1, 5, 2, 4, 1, 8, 1, 40, 1, 4, 1, 8, 
                     8, 5, 1, -1, 2, 4, 1, 15, 1, 4, 2, 19, 1, 8, 1, 40, 
                     1, 4, 1, 40, 1, 4, 1, 40, 2, 4, 1, 40, 4, 4, 4, 40, 
                     1, 8, 1, 40, 8, 5, 8, 18, 2, 4, 4, 40, 8, 18 )
      MAX = unpack( 1, 161, 2, 101, 1, 104, 3, -1, 1, 78, 6, 59, 1, 74, 
                     9, 59, 1, 40, 3, 86, 4, 59, 1, 86, 3, 59, 1, 86, 4, 
                     59, 2, -1, 1, 40, 1, 41, 1, 40, 1, 163, 1, 77, 1, 100, 
                     1, 59, 1, 100, 1, 59, 1, 101, 1, 15, 1, 59, 2, 15, 
                     1, 41, 1, 15, 1, 59, 1, 86, 1, 15, 1, 87, 1, 15, 1, 
                     87, 1, 15, 1, 87, 1, 59, 1, 15, 1, 59, 3, 15, 1, 59, 
                     1, 87, 1, 100, 1, 15, 1, 104, 1, 8, 1, -1, 1, 40, 1, 
                     -1, 1, 101, 6, 57, 1, 74, 8, 57, 1, 40, 3, 86, 4, 57, 
                     1, 86, 3, 57, 1, 86, 5, 57, 2, -1, 1, 15, 1, 40, 2, 
                     20, 1, 59, 1, 33, 1, 101, 1, 12, 4, 8, 1, 85, 1, 100, 
                     1, 85, 1, 100, 1, 85, 1, 100, 4, 8, 1, 59, 1, 15, 1, 
                     100, 1, 33, 1, 8, 1, 78, 1, 59, 1, 142, 1, 40, 1, 58, 
                     1, 78, 1, 0, 1, 100, 1, 57, 1, 100, 1, 57, 1, -1, 1, 
                     15, 1, 57, 3, 15, 1, 57, 1, 86, 1, 15, 1, 87, 1, 15, 
                     1, 87, 1, 15, 1, 87, 1, 57, 1, 15, 1, 57, 3, 15, 1, 
                     57, 1, 87, 1, 100, 2, 15, 1, 8, 1, 59, 1, 15, 1, 163, 
                     2, 100, 1, 142, 1, 78, 1, 15, 5, 59, 2, 8, 1, 86, 1, 
                     59, 1, 18, 2, 8, 1, 86, 1, 59, 1, 18, 2, 8, 1, 86, 
                     1, 59, 1, 18, 4, 59, 1, 8, 1, 59, 1, 18, 2, 59, 1, 
                     139, 1, 40, 1, 4, 1, 15, 1, 40, 1, 57, 1, 33, 2, 20, 
                     1, 12, 3, 8, 1, 85, 1, 100, 1, 85, 1, 100, 1, 85, 1, 
                     100, 4, 8, 1, 57, 1, 15, 1, 100, 1, 33, 2, 8, 1, 77, 
                     1, 15, 1, 59, 2, 19, 1, 139, 1, 15, 1, 8, 1, 100, 1, 
                     59, 1, 100, 1, 59, 1, 100, 2, 59, 1, 100, 1, 59, 1, 
                     106, 1, 57, 1, 8, 1, 57, 2, 100, 1, 15, 4, 57, 2, 8, 
                     1, 86, 1, 57, 1, 18, 2, 8, 1, 86, 1, 57, 1, 18, 2, 
                     8, 1, 86, 1, 57, 1, 18, 4, 57, 1, 8, 1, 57, 1, 18, 
                     2, 57, 1, 8, 1, 41, 1, 78, 1, 8, 8, 18, 1, -1, 1, 57, 
                     1, 106, 1, 15, 1, 57, 2, 19, 1, 8, 1, 100, 1, 57, 1, 
                     100, 1, 57, 1, 100, 2, 57, 1, 100, 1, 57, 2, 59, 1, 
                     78, 4, 100, 1, 8, 1, 41, 16, 18, 2, 57, 4, 100, 8, 
                     18 )
      ACCEPT = unpack( 4, -1, 1, 8, 1, 9, 1, 11, 34, -1, 1, 4, 1, 1, 36, 
                        -1, 1, 3, 1, -1, 1, 6, 34, -1, 1, 10, 1, 5, 38, 
                        -1, 1, 2, 155, -1, 1, 7, 55, -1 )
      SPECIAL = unpack( 151, -1, 1, 0, 216, -1 )
      TRANSITION = [
        unpack( 1, 1, 1, 2, 8, -1, 1, 3, 52, -1, 1, 4, 1, 5, 56, -1, 1, 
                 6 ),
        unpack( 1, 41, 34, -1, 1, 7, 1, 18, 14, -1, 1, 42, 4, -1, 1, 41, 
                  2, -1, 1, 8, 1, 9, 1, 10, 1, 11, 1, 12, 4, 13, 1, 14, 
                  1, 15, 1, 16, 1, 17, 2, -1, 1, 19, 1, 20, 1, 21, 1, 22, 
                  1, 23, 1, 24, 1, 25, 1, 28, 1, -1, 1, 26, 1, 27, 1, 29, 
                  1, 30, 1, 31, 1, 32, 1, 33, 1, 34, 1, 35, 1, 36, 1, 37, 
                  1, 38, 1, 39, 1, 40 ),
        unpack( 1, 41, 34, -1, 2, 42, 14, -1, 1, 42, 4, -1, 1, 41, 2, 
                  -1, 13, 42, 2, -1, 8, 42, 1, -1, 14, 42 ),
        unpack( 1, 43, 51, -1, 1, 4, 1, 5 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 1, 42, 1, 50, 1, 42, 1, 44, 11, -1, 1, 51, 1, 49, 12, 
                  -1, 1, 48, 6, -1, 1, 47, 11, -1, 1, 46, 4, -1, 1, 42, 
                  1, -1, 1, 42, 18, -1, 1, 45 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 53, 44, -1, 1, 52, 4, -1, 1, 42, 
                  1, -1, 1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 55, 44, -1, 1, 52, 4, -1, 1, 42, 
                  1, -1, 1, 42, 14, -1, 1, 54 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 56, 44, -1, 1, 52, 4, -1, 1, 42, 
                  1, -1, 1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, 50, 1, 42, 1, 57, 11, -1, 1, 51, 1, 49, 12, 
                  -1, 1, 48, 18, -1, 1, 46, 4, -1, 1, 42, 1, -1, 1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 58, 44, -1, 1, 52, 4, -1, 1, 42, 
                  1, -1, 1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 59 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 61, 32, -1, 1, 60, 11, -1, 1, 
                  52, 4, -1, 1, 42, 1, -1, 1, 42, 26, -1, 1, 62 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 63, 44, -1, 1, 52, 4, -1, 1, 42, 
                  1, -1, 1, 42, 26, -1, 1, 64 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 65, 44, -1, 1, 52, 4, -1, 1, 42, 
                  1, -1, 1, 42, 26, -1, 1, 66 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 68, 32, -1, 1, 67, 11, -1, 1, 
                  52, 4, -1, 1, 42, 1, -1, 1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 70, 32, -1, 1, 69, 11, -1, 1, 
                  52, 4, -1, 1, 42, 1, -1, 1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 71, 44, -1, 1, 52, 4, -1, 1, 42, 
                  1, -1, 1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 72, 44, -1, 1, 52, 4, -1, 1, 42, 
                  1, -1, 1, 42 ),
        unpack( 2, 73 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42, 26, -1, 1, 74 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, 75, 1, 42, 12, -1, 1, 51, 1, 49, 12, -1, 1, 
                  48, 18, -1, 1, 52, 4, -1, 1, 42, 1, -1, 1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 76, 44, -1, 1, 52, 4, -1, 1, 42, 
                  1, -1, 1, 42 ),
        unpack(  ),
        unpack(  ),
        unpack( 1, 77 ),
        unpack( 1, 78, 24, -1, 2, 79 ),
        unpack( 1, 80 ),
        unpack( 1, 116, 32, -1, 1, 82, 1, 115, 22, -1, 1, 83, 1, 84, 1, 
                  85, 1, 86, 1, 87, 4, 88, 1, 89, 1, 90, 1, 91, 1, 92, 2, 
                  -1, 1, 93, 1, 94, 1, 95, 1, 96, 1, 97, 1, 98, 1, 99, 1, 
                  102, 1, -1, 1, 100, 1, 101, 1, 103, 1, 104, 1, 105, 1, 
                  106, 1, 107, 1, 108, 1, 109, 1, 110, 1, 111, 1, 112, 1, 
                  113, 1, 114, 3, -1, 1, 81, 10, -1, 1, 79, 46, -1, 1, 117 ),
        unpack( 1, 118, 69, -1, 1, 119 ),
        unpack( 2, 120, 58, -1, 1, 121 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 2, 122, 58, -1, 1, 123 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 116, 32, -1, 1, 124, 1, 115, 22, -1, 1, 83, 1, 84, 
                  1, 85, 1, 86, 1, 87, 4, 88, 1, 89, 1, 90, 1, 91, 1, 92, 
                  2, -1, 1, 93, 1, 94, 1, 95, 1, 96, 1, 97, 1, 98, 1, 99, 
                  1, 102, 1, -1, 1, 100, 1, 101, 1, 103, 1, 104, 1, 105, 
                  1, 106, 1, 107, 1, 108, 1, 109, 1, 110, 1, 111, 1, 112, 
                  1, 113, 1, 114 ),
        unpack( 1, 125 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 55, 44, -1, 1, 52, 4, -1, 1, 42, 
                  1, -1, 1, 42 ),
        unpack( 1, 126 ),
        unpack( 1, 127 ),
        unpack( 1, 128, 24, -1, 2, 79 ),
        unpack( 1, 129 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 61, 44, -1, 1, 52, 4, -1, 1, 42, 
                  1, -1, 1, 42, 26, -1, 1, 62 ),
        unpack( 1, 130 ),
        unpack( 1, 131 ),
        unpack( 1, 132 ),
        unpack( 1, 133 ),
        unpack( 1, 134 ),
        unpack( 1, 135 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 68, 44, -1, 1, 52, 4, -1, 1, 42, 
                  1, -1, 1, 42 ),
        unpack( 1, 136 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 70, 44, -1, 1, 52, 4, -1, 1, 42, 
                  1, -1, 1, 42 ),
        unpack( 1, 137 ),
        unpack( 1, 138 ),
        unpack( 1, 139 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 141, 32, -1, 1, 140, 11, -1, 1, 
                  52, 4, -1, 1, 42, 1, -1, 1, 42 ),
        unpack( 1, 142 ),
        unpack( 2, 143, 58, -1, 1, 123 ),
        unpack( 1, 144 ),
        unpack( 1, 4, 1, 5 ),
        unpack( 1, 145 ),
        unpack(  ),
        unpack( 1, 146 ),
        unpack(  ),
        unpack( 1, 151, 1, 152, 1, -1, 1, 147, 11, -1, 1, 153, 1, 155, 
                  12, -1, 1, 154, 6, -1, 1, 150, 1, 116, 15, -1, 1, 149, 
                  6, -1, 13, 116, 1, -1, 1, 148, 8, 116, 1, -1, 14, 116 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 2, -1, 1, 157, 32, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 2, -1, 1, 159, 32, -1, 1, 156, 16, -1, 1, 149, 
                  16, -1, 1, 158 ),
        unpack( 1, 151, 2, -1, 1, 160, 32, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 2, -1, 1, 161, 32, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 162 ),
        unpack( 1, 151, 2, -1, 1, 164, 32, -1, 1, 163, 16, -1, 1, 149, 
                  28, -1, 1, 165 ),
        unpack( 1, 151, 2, -1, 1, 166, 32, -1, 1, 156, 16, -1, 1, 149, 
                  28, -1, 1, 167 ),
        unpack( 1, 151, 2, -1, 1, 168, 32, -1, 1, 156, 16, -1, 1, 149, 
                  28, -1, 1, 169 ),
        unpack( 1, 151, 2, -1, 1, 171, 32, -1, 1, 170, 16, -1, 1, 149 ),
        unpack( 1, 151, 2, -1, 1, 173, 32, -1, 1, 172, 16, -1, 1, 149 ),
        unpack( 1, 151, 2, -1, 1, 174, 32, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 2, -1, 1, 175, 32, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 2, 176 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149, 28, -1, 1, 177 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 1, 178, 13, -1, 1, 153, 1, 155, 12, -1, 1, 154, 
                  6, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 2, -1, 1, 179, 32, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 1, 152, 1, -1, 1, 180, 11, -1, 1, 153, 1, 155, 
                  12, -1, 1, 154, 6, -1, 1, 156, 16, -1, 1, 149 ),
        unpack(  ),
        unpack(  ),
        unpack( 1, 181 ),
        unpack( 1, 182 ),
        unpack( 1, 49 ),
        unpack( 1, 49 ),
        unpack( 1, 42, 1, 185, 1, 42, 1, 183, 11, -1, 1, 51, 1, 49, 12, 
                  -1, 1, 48, 18, -1, 1, 184, 4, -1, 1, 42, 1, -1, 1, 42 ),
        unpack( 1, 186, 13, -1, 1, 51, 1, 49, 12, -1, 1, 48 ),
        unpack( 1, 151, 1, 152, 1, -1, 1, 187, 11, -1, 1, 153, 1, 155, 
                  12, -1, 1, 154, 6, -1, 1, 188, 1, 116, 15, -1, 1, 149, 
                  6, -1, 13, 116, 1, -1, 1, 148, 8, 116, 1, -1, 14, 116 ),
        unpack( 1, 190, 3, -1, 1, 189 ),
        unpack( 1, 191 ),
        unpack( 1, 192 ),
        unpack( 1, 193 ),
        unpack( 1, 194 ),
        unpack( 1, 197, 31, -1, 1, 195, 44, -1, 1, 196 ),
        unpack( 2, 198, 58, -1, 1, 199 ),
        unpack( 1, 202, 31, -1, 1, 200, 44, -1, 1, 201 ),
        unpack( 2, 203, 58, -1, 1, 204 ),
        unpack( 1, 207, 31, -1, 1, 205, 44, -1, 1, 206 ),
        unpack( 2, 208, 58, -1, 1, 209 ),
        unpack( 1, 210 ),
        unpack( 1, 211 ),
        unpack( 1, 212 ),
        unpack( 1, 213 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 141, 44, -1, 1, 52, 4, -1, 1, 
                  42, 1, -1, 1, 42 ),
        unpack( 1, 214 ),
        unpack( 2, 215, 58, -1, 1, 216 ),
        unpack( 1, 186, 13, -1, 1, 51, 1, 49, 12, -1, 1, 48 ),
        unpack( 1, 217 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42, 18, -1, 1, 45 ),
        unpack( 1, 42, 1, -1, 1, 42, 33, -1, 1, 218, 11, -1, 1, 52, 4, 
                  -1, 1, 42, 1, -1, 1, 42 ),
        unpack( 1, 116, 5, -1, 2, 116, 1, 219, 1, 116, 23, -1, 2, 116, 
                  15, -1, 2, 116, 41, -1, 1, 116, 9, -1, 2, 116, 4, -1, 
                  2, 116, 22, -1, 1, 116, 1, -1, 1, 116 ),
        unpack( 1, 220 ),
        unpack( 1, 221 ),
        unpack( 2, 116, 1, -1, 1, 222, 5, -1, 4, 156, 2, -1, 2, 116, 12, 
                  -1, 1, 116, 6, -1, 1, 116, 16, -1, 1, 116, 19, -1, 1, 
                  223, 1, 116 ),
        unpack( 1, -1 ),
        unpack( 2, 224, 58, -1, 1, 225 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 2, 226, 58, -1, 1, 227 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack(  ),
        unpack( 1, 228 ),
        unpack( 1, 151, 2, -1, 1, 159, 32, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 229 ),
        unpack( 1, 230 ),
        unpack( 1, 231 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 2, -1, 1, 164, 5, -1, 4, 156, 23, -1, 1, 156, 
                  16, -1, 1, 149, 28, -1, 1, 165 ),
        unpack( 1, 232 ),
        unpack( 1, 233 ),
        unpack( 1, 234 ),
        unpack( 1, 235 ),
        unpack( 1, 236 ),
        unpack( 1, 237 ),
        unpack( 1, 151, 2, -1, 1, 171, 5, -1, 4, 156, 23, -1, 1, 156, 
                  16, -1, 1, 149 ),
        unpack( 1, 238 ),
        unpack( 1, 151, 2, -1, 1, 173, 5, -1, 4, 156, 23, -1, 1, 156, 
                  16, -1, 1, 149 ),
        unpack( 1, 239 ),
        unpack( 1, 240 ),
        unpack( 1, 241 ),
        unpack( 1, 151, 2, -1, 1, 243, 32, -1, 1, 242, 16, -1, 1, 149 ),
        unpack( 1, 244 ),
        unpack( 2, 245, 58, -1, 1, 225 ),
        unpack( 1, 246 ),
        unpack( 1, 247 ),
        unpack( 1, 248 ),
        unpack( 1, 42, 1, -1, 1, 42, 1, 249, 44, -1, 1, 52, 4, -1, 1, 
                  42, 1, -1, 1, 42 ),
        unpack( 1, 128 ),
        unpack( 1, 116, 32, -1, 1, 82, 1, 115, 22, -1, 1, 83, 1, 84, 1, 
                  85, 1, 86, 1, 87, 4, 88, 1, 89, 1, 90, 1, 91, 1, 92, 2, 
                  -1, 1, 93, 1, 94, 1, 95, 1, 96, 1, 97, 1, 98, 1, 99, 1, 
                  102, 1, -1, 1, 100, 1, 101, 1, 103, 1, 104, 1, 105, 1, 
                  106, 1, 107, 1, 108, 1, 109, 1, 110, 1, 111, 1, 112, 1, 
                  113, 1, 114, 3, -1, 1, 81, 57, -1, 1, 117 ),
        unpack( 2, 250, 58, -1, 1, 251 ),
        unpack( 2, 252, 58, -1, 1, 251 ),
        unpack( 1, 116, 5, -1, 2, 116, 1, 253, 1, 116, 23, -1, 2, 116, 
                  15, -1, 2, 116, 41, -1, 1, 116, 9, -1, 2, 116, 4, -1, 
                  2, 116, 22, -1, 1, 116, 1, -1, 1, 116 ),
        unpack( 2, 116, 1, -1, 1, 254, 5, -1, 4, 156, 2, -1, 2, 116, 12, 
                  -1, 1, 116, 6, -1, 1, 116, 16, -1, 1, 116, 19, -1, 1, 
                  223, 1, 116 ),
        unpack( 1, 255 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 197 ),
        unpack( 1, 197 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42, 26, -1, 1, 62 ),
        unpack( 1, 42, 1, 256, 1, 42, 11, -1, 1, 257, 33, -1, 1, 52, 4, 
                  -1, 1, 42, 1, -1, 1, 42 ),
        unpack( 1, 256, 12, -1, 1, 257 ),
        unpack( 1, 202 ),
        unpack( 1, 202 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42, 26, -1, 1, 64 ),
        unpack( 1, 42, 1, 258, 1, 42, 11, -1, 1, 259, 33, -1, 1, 52, 4, 
                  -1, 1, 42, 1, -1, 1, 42 ),
        unpack( 1, 258, 12, -1, 1, 259 ),
        unpack( 1, 207 ),
        unpack( 1, 207 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42, 26, -1, 1, 66 ),
        unpack( 1, 42, 1, 260, 1, 42, 11, -1, 1, 261, 33, -1, 1, 52, 4, 
                  -1, 1, 42, 1, -1, 1, 42 ),
        unpack( 1, 260, 12, -1, 1, 261 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 262 ),
        unpack( 1, 42, 1, 263, 1, 42, 11, -1, 1, 264, 33, -1, 1, 52, 4, 
                  -1, 1, 42, 1, -1, 1, 42 ),
        unpack( 1, 263, 12, -1, 1, 264 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 265, 3, -1, 3, 116, 6, -1, 2, 116, 2, -1, 8, 116, 1, 
                  -1, 5, 116, 12, -1, 2, 116, 4, -1, 1, 116, 44, -1, 1, 
                  116, 31, -1, 1, 116, 3, -1, 2, 116 ),
        unpack( 1, 266 ),
        unpack( 1, 151 ),
        unpack( 1, 267 ),
        unpack( 1, 268 ),
        unpack( 1, 151, 1, 269, 1, -1, 1, 180, 11, -1, 1, 153, 1, 155, 
                  12, -1, 1, 154, 6, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 270, 13, -1, 1, 153, 1, 155, 12, -1, 1, 154 ),
        unpack( 1, 155 ),
        unpack( 1, 155 ),
        unpack( 1, 272, 3, -1, 1, 271 ),
        unpack( 1, 273 ),
        unpack( 1, 274 ),
        unpack( 1, 275 ),
        unpack( 1, 278, 31, -1, 1, 276, 44, -1, 1, 277 ),
        unpack( 2, 279, 58, -1, 1, 280 ),
        unpack( 1, 283, 31, -1, 1, 281, 44, -1, 1, 282 ),
        unpack( 2, 284, 58, -1, 1, 285 ),
        unpack( 1, 288, 31, -1, 1, 286, 44, -1, 1, 287 ),
        unpack( 2, 289, 58, -1, 1, 290 ),
        unpack( 1, 291 ),
        unpack( 1, 292 ),
        unpack( 1, 293 ),
        unpack( 1, 294 ),
        unpack( 1, 151, 2, -1, 1, 243, 5, -1, 4, 156, 23, -1, 1, 156, 
                  16, -1, 1, 149 ),
        unpack( 1, 295 ),
        unpack( 2, 296, 58, -1, 1, 297 ),
        unpack( 1, 270, 13, -1, 1, 153, 1, 155, 12, -1, 1, 154 ),
        unpack( 1, 298 ),
        unpack( 1, 299 ),
        unpack( 1, 119 ),
        unpack( 1, 300 ),
        unpack( 1, 42, 1, 301, 1, 42, 1, 183, 11, -1, 1, 51, 32, -1, 1, 
                  184, 4, -1, 1, 42, 1, -1, 1, 42 ),
        unpack( 1, 51 ),
        unpack( 1, 51 ),
        unpack( 1, 302, 3, -1, 3, 116, 6, -1, 2, 116, 2, -1, 8, 116, 1, 
                  -1, 5, 116, 12, -1, 2, 116, 4, -1, 1, 116, 44, -1, 1, 
                  116, 31, -1, 1, 116, 3, -1, 2, 116 ),
        unpack( 1, 303 ),
        unpack( 1, 190 ),
        unpack( 2, 304, 58, -1, 1, 305 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 2, 306, 58, -1, 1, 307 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 2, 308, 58, -1, 1, 309 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 2, 310, 58, -1, 1, 311 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149, 20, -1, 1, 148, 
                  27, -1, 1, 312 ),
        unpack( 1, 151, 35, -1, 1, 313, 16, -1, 1, 149 ),
        unpack( 1, 314 ),
        unpack( 1, 151, 2, -1, 1, 315, 32, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 2, 316, 58, -1, 1, 317 ),
        unpack( 2, 318, 58, -1, 1, 317 ),
        unpack( 1, 319 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 278 ),
        unpack( 1, 278 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149, 28, -1, 1, 165 ),
        unpack( 1, 151, 1, 320, 12, -1, 1, 321, 21, -1, 1, 156, 16, -1, 
                  1, 149 ),
        unpack( 1, 320, 12, -1, 1, 321 ),
        unpack( 1, 283 ),
        unpack( 1, 283 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149, 28, -1, 1, 167 ),
        unpack( 1, 151, 1, 322, 12, -1, 1, 323, 21, -1, 1, 156, 16, -1, 
                  1, 149 ),
        unpack( 1, 322, 12, -1, 1, 323 ),
        unpack( 1, 288 ),
        unpack( 1, 288 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149, 28, -1, 1, 169 ),
        unpack( 1, 151, 1, 324, 12, -1, 1, 325, 21, -1, 1, 156, 16, -1, 
                  1, 149 ),
        unpack( 1, 324, 12, -1, 1, 325 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 326 ),
        unpack( 1, 151, 1, 327, 12, -1, 1, 328, 21, -1, 1, 156, 16, -1, 
                  1, 149 ),
        unpack( 1, 327, 12, -1, 1, 328 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 329 ),
        unpack( 2, 330 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149, 20, -1, 1, 148 ),
        unpack( 1, 331 ),
        unpack( 1, 332, 12, -1, 1, 257 ),
        unpack( 1, 332, 12, -1, 1, 257 ),
        unpack( 1, 333, 12, -1, 1, 259 ),
        unpack( 1, 333, 12, -1, 1, 259 ),
        unpack( 1, 334, 12, -1, 1, 261 ),
        unpack( 1, 334, 12, -1, 1, 261 ),
        unpack( 1, 335, 12, -1, 1, 264 ),
        unpack( 1, 335, 12, -1, 1, 264 ),
        unpack(  ),
        unpack( 1, 151, 8, -1, 4, 156, 23, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 116, 52, -1, 1, 116, 19, -1, 1, 223, 1, 116, 27, -1, 
                  1, 312 ),
        unpack( 1, 336 ),
        unpack( 1, 151, 1, 337, 1, -1, 1, 180, 11, -1, 1, 153, 20, -1, 
                  1, 156, 16, -1, 1, 149 ),
        unpack( 1, 153 ),
        unpack( 1, 153 ),
        unpack( 1, 272 ),
        unpack( 2, 338, 58, -1, 1, 339 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 2, 340, 58, -1, 1, 341 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 2, 342, 58, -1, 1, 343 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 2, 344, 58, -1, 1, 345 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 42, 1, -1, 1, 42, 45, -1, 1, 52, 4, -1, 1, 42, 1, -1, 
                  1, 42 ),
        unpack( 1, 42, 1, 301, 1, 42, 1, 183, 44, -1, 1, 184, 4, -1, 1, 
                  42, 1, -1, 1, 42 ),
        unpack( 1, 116, 52, -1, 1, 116, 19, -1, 1, 223, 1, 116 ),
        unpack( 2, 346, 58, -1, 1, 347 ),
        unpack( 2, 348, 58, -1, 1, 349 ),
        unpack( 2, 350, 58, -1, 1, 351 ),
        unpack( 2, 352, 58, -1, 1, 353 ),
        unpack( 1, 354 ),
        unpack( 2, 355 ),
        unpack( 1, 356, 12, -1, 1, 321 ),
        unpack( 1, 356, 12, -1, 1, 321 ),
        unpack( 1, 357, 12, -1, 1, 323 ),
        unpack( 1, 357, 12, -1, 1, 323 ),
        unpack( 1, 358, 12, -1, 1, 325 ),
        unpack( 1, 358, 12, -1, 1, 325 ),
        unpack( 1, 359, 12, -1, 1, 328 ),
        unpack( 1, 359, 12, -1, 1, 328 ),
        unpack( 1, 257 ),
        unpack( 1, 257 ),
        unpack( 1, 259 ),
        unpack( 1, 259 ),
        unpack( 1, 261 ),
        unpack( 1, 261 ),
        unpack( 1, 264 ),
        unpack( 1, 264 ),
        unpack( 1, 151, 35, -1, 1, 156, 16, -1, 1, 149 ),
        unpack( 1, 151, 1, 337, 1, -1, 1, 180, 32, -1, 1, 156, 16, -1, 
                  1, 149 ),
        unpack( 2, 360, 58, -1, 1, 361 ),
        unpack( 2, 362, 58, -1, 1, 363 ),
        unpack( 2, 364, 58, -1, 1, 365 ),
        unpack( 2, 366, 58, -1, 1, 367 ),
        unpack( 1, 321 ),
        unpack( 1, 321 ),
        unpack( 1, 323 ),
        unpack( 1, 323 ),
        unpack( 1, 325 ),
        unpack( 1, 325 ),
        unpack( 1, 328 ),
        unpack( 1, 328 )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 29
      

      def description
        <<-'__dfa_description__'.strip!
          125:1: declare_spec : ( variable_declaration | subtype_declaration | cursor_declaration | exception_declaration | record_declaration | plsql_table_declaration | varray_declaration | procedure_declaration | function_declaration | type_declaration | pragma_declaration );
        __dfa_description__
      end
    end
    class DFA32 < ANTLR3::DFA
      EOT = unpack( 33, -1 )
      EOF = unpack( 33, -1 )
      MIN = unpack( 1, 40, 1, 7, 1, 13, 2, -1, 1, 5, 1, 15, 2, 8, 1, -1, 
                     1, 13, 1, 0, 1, -1, 2, 13, 1, 15, 3, 8, 5, -1, 1, 15, 
                     3, 8, 1, 15, 2, 8, 2, 0 )
      MAX = unpack( 1, 40, 1, 7, 1, 59, 2, -1, 1, 12, 1, 15, 2, 12, 1, 
                     -1, 1, 41, 1, 0, 1, -1, 2, 41, 1, 15, 3, 12, 5, -1, 
                     1, 15, 3, 12, 1, 15, 2, 12, 2, 0 )
      ACCEPT = unpack( 3, -1, 1, 3, 1, 4, 4, -1, 1, 1, 2, -1, 1, 2, 6, 
                        -1, 1, 5, 1, 6, 1, 7, 1, 8, 1, 9, 9, -1 )
      SPECIAL = unpack( 1, -1, 1, 2, 9, -1, 1, 0, 19, -1, 1, 3, 1, 1 )
      TRANSITION = [
        unpack( 1, 1 ),
        unpack( 1, 2 ),
        unpack( 2, 6, 1, 7, 1, 8, 23, -1, 2, 5, 17, -1, 1, 9 ),
        unpack(  ),
        unpack(  ),
        unpack( 1, 12, 2, -1, 1, 11, 3, -1, 1, 10 ),
        unpack( 1, 7 ),
        unpack( 1, 11, 3, -1, 1, 13 ),
        unpack( 1, 11, 3, -1, 1, 14 ),
        unpack(  ),
        unpack( 2, 15, 1, 16, 1, 17, 23, -1, 2, 18 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack( 2, 24, 1, 25, 1, 26, 23, -1, 2, 27 ),
        unpack( 2, 28, 1, 29, 1, 30, 23, -1, 2, 18 ),
        unpack( 1, 16 ),
        unpack( 1, 31, 3, -1, 1, 14 ),
        unpack( 1, 31, 3, -1, 1, 14 ),
        unpack( 1, 32, 3, -1, 1, 14 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 1, 25 ),
        unpack( 1, 11, 3, -1, 1, 13 ),
        unpack( 1, 11, 3, -1, 1, 13 ),
        unpack( 1, 11, 3, -1, 1, 13 ),
        unpack( 1, 29 ),
        unpack( 1, 32, 3, -1, 1, 14 ),
        unpack( 1, 32, 3, -1, 1, 14 ),
        unpack( 1, -1 ),
        unpack( 1, -1 )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 32
      

      def description
        <<-'__dfa_description__'.strip!
          141:3: ( keyRESTRICT_REFERENCES LPAREN ( 'DEFAULT' | function_name ) ( COMMA pragma_param )+ RPAREN | keyEXCEPTION_INIT LPAREN exception_name COMMA literal RPAREN | keyAUTONOMOUS_TRANSACTION | keySERIALLY_REUSABLE | keyBUILTIN LPAREN pragma_params RPAREN | keyFIPSFLAG LPAREN pragma_params RPAREN | keyINTERFACE LPAREN pragma_params RPAREN | keyNEW_NAMES LPAREN pragma_params RPAREN | keyTIMESTAMP LPAREN pragma_params RPAREN )
        __dfa_description__
      end
    end
    class DFA79 < ANTLR3::DFA
      EOT = unpack( 43, -1 )
      EOF = unpack( 11, -1, 1, 34, 31, -1 )
      MIN = unpack( 1, 40, 10, -1, 1, 4, 23, -1, 1, 5, 1, 15, 1, 40, 1, 
                     8, 1, 0, 1, 77, 2, -1 )
      MAX = unpack( 1, 101, 10, -1, 1, 161, 23, -1, 1, 101, 1, 15, 1, 40, 
                     1, 8, 1, 0, 1, 77, 2, -1 )
      ACCEPT = unpack( 1, -1, 1, 1, 1, 2, 1, 3, 1, 4, 1, 5, 1, 6, 1, 7, 
                        1, 8, 1, 9, 1, 10, 1, -1, 1, 14, 1, 15, 1, 16, 1, 
                        17, 1, 18, 1, 19, 1, 20, 1, 21, 1, 22, 1, 23, 1, 
                        24, 1, 25, 1, 26, 1, 27, 1, 28, 1, 29, 1, 30, 1, 
                        31, 1, 32, 1, 33, 1, 34, 1, 35, 1, 13, 6, -1, 1, 
                        11, 1, 12 )
      SPECIAL = unpack( 39, -1, 1, 0, 3, -1 )
      TRANSITION = [
        unpack( 1, 11, 23, -1, 1, 1, 1, 2, 1, 3, 1, 4, 1, 5, 4, 6, 1, 7, 
                 1, 8, 1, 9, 1, 10, 2, -1, 1, 12, 1, 13, 1, 14, 1, 15, 1, 
                 16, 1, 17, 1, 18, 1, 21, 1, -1, 1, 19, 1, 20, 1, 22, 1, 
                 23, 1, 24, 1, 25, 1, 26, 1, 27, 1, 28, 1, 29, 1, 30, 1, 
                 31, 1, 32, 1, 33 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 1, 34, 1, -1, 3, 34, 3, -1, 1, 34, 27, -1, 1, 35, 1, 34, 
                  8, -1, 1, 34, 1, -1, 4, 34, 1, -1, 1, 34, 1, -1, 1, 34, 
                  18, -1, 1, 34, 24, -1, 2, 34, 2, -1, 1, 34, 53, -1, 1, 
                  34 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 1, 34, 1, -1, 1, 36, 5, -1, 4, 34, 23, -1, 2, 34, 14, 
                  -1, 1, 34, 4, -1, 1, 34, 2, -1, 13, 34, 1, 37, 1, -1, 
                  8, 34, 1, -1, 14, 34 ),
        unpack( 1, 38 ),
        unpack( 1, 39 ),
        unpack( 1, 40 ),
        unpack( 1, -1 ),
        unpack( 1, 37 ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 79
      

      def description
        <<-'__dfa_description__'.strip!
          204:1: datatype : ( 'BINARY_INTEGER' | 'BINARY_FLOAT' | 'BINARY_DOUBLE' | 'NATURAL' | 'POSITIVE' | ( 'NUMBER' | 'NUMERIC' | 'DECIMAL' | 'DEC' ) ( LPAREN NUMBER ( COMMA NUMBER )? RPAREN )? | 'LONG' ( 'RAW' )? ( LPAREN NUMBER RPAREN )? | 'RAW' ( LPAREN NUMBER RPAREN )? | 'BOOLEAN' | 'DATE' | keyINTERVAL keyDAY ( LPAREN NUMBER RPAREN )? 'TO' keySECOND ( LPAREN NUMBER RPAREN )? | keyINTERVAL keyYEAR ( LPAREN NUMBER RPAREN )? 'TO' keyMONTH | ( keyTIME | keyTIMESTAMP ) ( LPAREN NUMBER RPAREN )? ( 'WITH' ( keyLOCAL )? keyTIME keyZONE )? | 'INTEGER' | 'INT' | 'SMALLINT' | 'FLOAT' ( LPAREN NUMBER RPAREN )? | 'REAL' | 'DOUBLE' keyPRECISION | 'CHAR' ( keyVARYING )? ( LPAREN NUMBER ( keyBYTE | 'CHAR' )? RPAREN )? ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )? | 'VARCHAR' ( LPAREN NUMBER ( keyBYTE | 'CHAR' )? RPAREN )? ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )? | 'VARCHAR2' ( LPAREN NUMBER ( keyBYTE | 'CHAR' )? RPAREN )? ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )? | 'CHARACTER' ( keyVARYING )? ( LPAREN NUMBER RPAREN )? | 'NCHAR' ( keyVARYING )? ( LPAREN NUMBER RPAREN )? | 'NVARCHAR' ( LPAREN NUMBER RPAREN )? | 'NVARCHAR2' ( LPAREN NUMBER RPAREN )? | 'NATIONAL' ( 'CHARACTER' | 'CHAR' ) ( keyVARYING )? ( LPAREN NUMBER RPAREN )? | 'MLSLABEL' | 'PLS_INTEGER' | 'BLOB' | 'CLOB' ( 'CHARACTER' 'SET' ( identifier | column_spec CHARSET_ATTR ) )? | 'NCLOB' | 'BFILE' | 'ROWID' | 'UROWID' ( LPAREN NUMBER RPAREN )? );
        __dfa_description__
      end
    end
    class DFA52 < ANTLR3::DFA
      EOT = unpack( 14, -1 )
      EOF = unpack( 2, -1, 1, 3, 1, -1, 1, 7, 9, -1 )
      MIN = unpack( 2, 40, 1, 4, 1, -1, 3, 4, 1, -1, 1, 40, 2, 4, 1, 15, 
                     1, 8, 1, 4 )
      MAX = unpack( 2, 40, 1, 161, 1, -1, 1, 161, 2, 164, 1, -1, 1, 100, 
                     1, 164, 1, 61, 1, 41, 1, 8, 1, 78 )
      ACCEPT = unpack( 3, -1, 1, 2, 3, -1, 1, 1, 6, -1 )
      SPECIAL = unpack( 14, -1 )
      TRANSITION = [
        unpack( 1, 1 ),
        unpack( 1, 2 ),
        unpack( 1, 3, 1, -1, 1, 3, 1, -1, 1, 3, 3, -1, 1, 3, 27, -1, 1, 
                  4, 1, 3, 8, -1, 1, 3, 1, -1, 4, 3, 1, -1, 1, 3, 1, -1, 
                  1, 3, 43, -1, 2, 3, 2, -1, 1, 3, 53, -1, 1, 3 ),
        unpack(  ),
        unpack( 1, 7, 1, 3, 1, 7, 1, -1, 1, 7, 3, -1, 1, 7, 4, 3, 23, 
                  -1, 1, 5, 1, 6, 8, -1, 1, 7, 1, -1, 4, 7, 1, 3, 1, 7, 
                  1, -1, 1, 7, 1, -1, 1, 3, 2, -1, 13, 3, 2, -1, 8, 3, 1, 
                  -1, 14, 3, 1, -1, 2, 7, 2, -1, 1, 7, 53, -1, 1, 7 ),
        unpack( 1, 3, 1, 8, 2, 3, 5, -1, 4, 7, 2, -1, 2, 3, 12, -1, 1, 
                  3, 6, -1, 1, 9, 1, 7, 10, -1, 1, 3, 3, -1, 1, 7, 1, 3, 
                  1, -1, 1, 3, 1, -1, 1, 7, 2, -1, 13, 7, 1, -1, 1, 3, 8, 
                  7, 1, -1, 14, 7, 62, -1, 1, 3 ),
        unpack( 1, 3, 1, 8, 2, 3, 11, -1, 2, 3, 12, -1, 1, 3, 6, -1, 2, 
                  7, 10, -1, 1, 3, 3, -1, 1, 7, 1, 3, 1, -1, 1, 3, 1, -1, 
                  1, 7, 2, -1, 13, 7, 2, -1, 8, 7, 1, -1, 14, 7, 62, -1, 
                  1, 3 ),
        unpack(  ),
        unpack( 2, 10, 58, -1, 1, 3 ),
        unpack( 3, 7, 1, 11, 11, -1, 2, 7, 12, -1, 1, 7, 6, -1, 1, 7, 
                  11, -1, 1, 7, 4, -1, 1, 7, 1, -1, 1, 7, 17, -1, 1, 3, 
                  1, 7, 85, -1, 1, 7 ),
        unpack( 4, 3, 11, -1, 2, 3, 12, -1, 1, 3, 18, -1, 1, 3, 4, -1, 
                  1, 3, 1, -1, 1, 3, 1, -1, 1, 7 ),
        unpack( 1, 12, 24, -1, 2, 7 ),
        unpack( 1, 13 ),
        unpack( 1, 7, 1, -1, 1, 7, 45, -1, 1, 7, 4, -1, 1, 7, 1, -1, 1, 
                  7, 17, -1, 1, 3, 1, 7 )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 52
      

      def description
        <<-'__dfa_description__'.strip!
          217:66: ( keyLOCAL )?
        __dfa_description__
      end
    end
    class DFA55 < ANTLR3::DFA
      EOT = unpack( 13, -1 )
      EOF = unpack( 1, 2, 1, 6, 11, -1 )
      MIN = unpack( 2, 4, 1, -1, 3, 4, 1, -1, 1, 40, 2, 4, 1, 15, 1, 8, 
                     1, 4 )
      MAX = unpack( 2, 161, 1, -1, 2, 164, 1, 87, 1, -1, 1, 100, 1, 164, 
                     1, 61, 1, 41, 1, 8, 1, 78 )
      ACCEPT = unpack( 2, -1, 1, 2, 3, -1, 1, 1, 6, -1 )
      SPECIAL = unpack( 13, -1 )
      TRANSITION = [
        unpack( 1, 2, 1, -1, 3, 2, 3, -1, 1, 2, 27, -1, 1, 1, 1, 2, 8, 
                 -1, 1, 2, 1, -1, 4, 2, 1, -1, 1, 2, 1, -1, 1, 2, 26, -1, 
                 1, 2, 16, -1, 2, 2, 2, -1, 1, 2, 53, -1, 1, 2 ),
        unpack( 1, 6, 1, 2, 3, 6, 3, -1, 1, 6, 4, 2, 23, -1, 1, 3, 1, 
                  4, 8, -1, 1, 6, 1, -1, 4, 6, 1, 2, 1, 6, 1, -1, 1, 6, 
                  1, -1, 1, 2, 2, -1, 13, 2, 2, -1, 7, 2, 1, 5, 1, -1, 14, 
                  2, 1, -1, 2, 6, 2, -1, 1, 6, 53, -1, 1, 6 ),
        unpack(  ),
        unpack( 1, 2, 1, 7, 2, 2, 5, -1, 4, 6, 2, -1, 2, 2, 12, -1, 1, 
                  2, 6, -1, 1, 8, 1, 6, 10, -1, 1, 2, 3, -1, 1, 6, 1, 2, 
                  1, -1, 1, 2, 1, -1, 1, 6, 2, -1, 13, 6, 1, -1, 1, 2, 8, 
                  6, 1, -1, 14, 6, 62, -1, 1, 2 ),
        unpack( 1, 2, 1, 7, 2, 2, 11, -1, 2, 2, 12, -1, 1, 2, 6, -1, 2, 
                  6, 10, -1, 1, 2, 3, -1, 1, 6, 1, 2, 1, -1, 1, 2, 1, -1, 
                  1, 6, 2, -1, 13, 6, 2, -1, 8, 6, 1, -1, 14, 6, 62, -1, 
                  1, 2 ),
        unpack( 1, 2, 1, -1, 2, 2, 32, -1, 1, 2, 11, -1, 1, 2, 4, -1, 
                  1, 2, 1, -1, 1, 2, 27, -1, 1, 6 ),
        unpack(  ),
        unpack( 2, 9, 58, -1, 1, 2 ),
        unpack( 3, 6, 1, 10, 11, -1, 2, 6, 12, -1, 1, 6, 6, -1, 1, 6, 
                  11, -1, 1, 6, 4, -1, 1, 6, 1, -1, 1, 6, 17, -1, 1, 2, 
                  1, 6, 85, -1, 1, 6 ),
        unpack( 4, 2, 11, -1, 2, 2, 12, -1, 1, 2, 18, -1, 1, 2, 4, -1, 
                  1, 2, 1, -1, 1, 2, 1, -1, 1, 6 ),
        unpack( 1, 11, 24, -1, 2, 6 ),
        unpack( 1, 12 ),
        unpack( 1, 6, 1, -1, 1, 6, 45, -1, 1, 6, 4, -1, 1, 6, 1, -1, 1, 
                  6, 17, -1, 1, 2, 1, 6 )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 55
      

      def description
        <<-'__dfa_description__'.strip!
          224:16: ( keyVARYING )?
        __dfa_description__
      end
    end
    class DFA68 < ANTLR3::DFA
      EOT = unpack( 12, -1 )
      EOF = unpack( 1, 2, 1, 5, 10, -1 )
      MIN = unpack( 2, 4, 1, -1, 2, 4, 1, -1, 1, 40, 2, 4, 1, 15, 1, 8, 
                     1, 4 )
      MAX = unpack( 2, 161, 1, -1, 2, 164, 1, -1, 1, 100, 1, 164, 1, 61, 
                     1, 41, 1, 8, 1, 78 )
      ACCEPT = unpack( 2, -1, 1, 2, 2, -1, 1, 1, 6, -1 )
      SPECIAL = unpack( 12, -1 )
      TRANSITION = [
        unpack( 1, 2, 1, -1, 3, 2, 3, -1, 1, 2, 27, -1, 1, 1, 1, 2, 8, 
                 -1, 1, 2, 1, -1, 4, 2, 1, -1, 1, 2, 1, -1, 1, 2, 43, -1, 
                 2, 2, 2, -1, 1, 2, 53, -1, 1, 2 ),
        unpack( 1, 5, 1, 2, 3, 5, 3, -1, 1, 5, 4, 2, 23, -1, 1, 3, 1, 
                  4, 8, -1, 1, 5, 1, -1, 4, 5, 1, 2, 1, 5, 1, -1, 1, 5, 
                  1, -1, 1, 2, 2, -1, 13, 2, 2, -1, 8, 2, 1, -1, 14, 2, 
                  1, -1, 2, 5, 2, -1, 1, 5, 53, -1, 1, 5 ),
        unpack(  ),
        unpack( 1, 2, 1, 6, 2, 2, 5, -1, 4, 5, 2, -1, 2, 2, 12, -1, 1, 
                  2, 6, -1, 1, 7, 1, 5, 10, -1, 1, 2, 3, -1, 1, 5, 1, 2, 
                  1, -1, 1, 2, 1, -1, 1, 5, 2, -1, 13, 5, 1, -1, 1, 2, 8, 
                  5, 1, -1, 14, 5, 62, -1, 1, 2 ),
        unpack( 1, 2, 1, 6, 2, 2, 11, -1, 2, 2, 12, -1, 1, 2, 6, -1, 2, 
                  5, 10, -1, 1, 2, 3, -1, 1, 5, 1, 2, 1, -1, 1, 2, 1, -1, 
                  1, 5, 2, -1, 13, 5, 2, -1, 8, 5, 1, -1, 14, 5, 62, -1, 
                  1, 2 ),
        unpack(  ),
        unpack( 2, 8, 58, -1, 1, 2 ),
        unpack( 3, 5, 1, 9, 11, -1, 2, 5, 12, -1, 1, 5, 6, -1, 1, 5, 11, 
                  -1, 1, 5, 4, -1, 1, 5, 1, -1, 1, 5, 17, -1, 1, 2, 1, 5, 
                  85, -1, 1, 5 ),
        unpack( 4, 2, 11, -1, 2, 2, 12, -1, 1, 2, 18, -1, 1, 2, 4, -1, 
                  1, 2, 1, -1, 1, 2, 1, -1, 1, 5 ),
        unpack( 1, 10, 24, -1, 2, 5 ),
        unpack( 1, 11 ),
        unpack( 1, 5, 1, -1, 1, 5, 45, -1, 1, 5, 4, -1, 1, 5, 1, -1, 1, 
                  5, 17, -1, 1, 2, 1, 5 )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 68
      

      def description
        <<-'__dfa_description__'.strip!
          227:16: ( keyVARYING )?
        __dfa_description__
      end
    end
    class DFA70 < ANTLR3::DFA
      EOT = unpack( 12, -1 )
      EOF = unpack( 1, 2, 1, 5, 10, -1 )
      MIN = unpack( 2, 4, 1, -1, 2, 4, 1, -1, 1, 40, 2, 4, 1, 15, 1, 8, 
                     1, 4 )
      MAX = unpack( 2, 161, 1, -1, 2, 164, 1, -1, 1, 100, 1, 164, 1, 61, 
                     1, 41, 1, 8, 1, 78 )
      ACCEPT = unpack( 2, -1, 1, 2, 2, -1, 1, 1, 6, -1 )
      SPECIAL = unpack( 12, -1 )
      TRANSITION = [
        unpack( 1, 2, 1, -1, 3, 2, 3, -1, 1, 2, 27, -1, 1, 1, 1, 2, 8, 
                 -1, 1, 2, 1, -1, 4, 2, 1, -1, 1, 2, 1, -1, 1, 2, 43, -1, 
                 2, 2, 2, -1, 1, 2, 53, -1, 1, 2 ),
        unpack( 1, 5, 1, 2, 3, 5, 3, -1, 1, 5, 4, 2, 23, -1, 1, 3, 1, 
                  4, 8, -1, 1, 5, 1, -1, 4, 5, 1, 2, 1, 5, 1, -1, 1, 5, 
                  1, -1, 1, 2, 2, -1, 13, 2, 2, -1, 8, 2, 1, -1, 14, 2, 
                  1, -1, 2, 5, 2, -1, 1, 5, 53, -1, 1, 5 ),
        unpack(  ),
        unpack( 1, 2, 1, 6, 2, 2, 5, -1, 4, 5, 2, -1, 2, 2, 12, -1, 1, 
                  2, 6, -1, 1, 7, 1, 5, 10, -1, 1, 2, 3, -1, 1, 5, 1, 2, 
                  1, -1, 1, 2, 1, -1, 1, 5, 2, -1, 13, 5, 1, -1, 1, 2, 8, 
                  5, 1, -1, 14, 5, 62, -1, 1, 2 ),
        unpack( 1, 2, 1, 6, 2, 2, 11, -1, 2, 2, 12, -1, 1, 2, 6, -1, 2, 
                  5, 10, -1, 1, 2, 3, -1, 1, 5, 1, 2, 1, -1, 1, 2, 1, -1, 
                  1, 5, 2, -1, 13, 5, 2, -1, 8, 5, 1, -1, 14, 5, 62, -1, 
                  1, 2 ),
        unpack(  ),
        unpack( 2, 8, 58, -1, 1, 2 ),
        unpack( 3, 5, 1, 9, 11, -1, 2, 5, 12, -1, 1, 5, 6, -1, 1, 5, 11, 
                  -1, 1, 5, 4, -1, 1, 5, 1, -1, 1, 5, 17, -1, 1, 2, 1, 5, 
                  85, -1, 1, 5 ),
        unpack( 4, 2, 11, -1, 2, 2, 12, -1, 1, 2, 18, -1, 1, 2, 4, -1, 
                  1, 2, 1, -1, 1, 2, 1, -1, 1, 5 ),
        unpack( 1, 10, 24, -1, 2, 5 ),
        unpack( 1, 11 ),
        unpack( 1, 5, 1, -1, 1, 5, 45, -1, 1, 5, 4, -1, 1, 5, 1, -1, 1, 
                  5, 17, -1, 1, 2, 1, 5 )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 70
      

      def description
        <<-'__dfa_description__'.strip!
          228:16: ( keyVARYING )?
        __dfa_description__
      end
    end
    class DFA74 < ANTLR3::DFA
      EOT = unpack( 12, -1 )
      EOF = unpack( 1, 2, 1, 5, 10, -1 )
      MIN = unpack( 2, 4, 1, -1, 2, 4, 1, -1, 1, 40, 2, 4, 1, 15, 1, 8, 
                     1, 4 )
      MAX = unpack( 2, 161, 1, -1, 2, 164, 1, -1, 1, 100, 1, 164, 1, 61, 
                     1, 41, 1, 8, 1, 78 )
      ACCEPT = unpack( 2, -1, 1, 2, 2, -1, 1, 1, 6, -1 )
      SPECIAL = unpack( 12, -1 )
      TRANSITION = [
        unpack( 1, 2, 1, -1, 3, 2, 3, -1, 1, 2, 27, -1, 1, 1, 1, 2, 8, 
                 -1, 1, 2, 1, -1, 4, 2, 1, -1, 1, 2, 1, -1, 1, 2, 43, -1, 
                 2, 2, 2, -1, 1, 2, 53, -1, 1, 2 ),
        unpack( 1, 5, 1, 2, 3, 5, 3, -1, 1, 5, 4, 2, 23, -1, 1, 3, 1, 
                  4, 8, -1, 1, 5, 1, -1, 4, 5, 1, 2, 1, 5, 1, -1, 1, 5, 
                  1, -1, 1, 2, 2, -1, 13, 2, 2, -1, 8, 2, 1, -1, 14, 2, 
                  1, -1, 2, 5, 2, -1, 1, 5, 53, -1, 1, 5 ),
        unpack(  ),
        unpack( 1, 2, 1, 6, 2, 2, 5, -1, 4, 5, 2, -1, 2, 2, 12, -1, 1, 
                  2, 6, -1, 1, 7, 1, 5, 10, -1, 1, 2, 3, -1, 1, 5, 1, 2, 
                  1, -1, 1, 2, 1, -1, 1, 5, 2, -1, 13, 5, 1, -1, 1, 2, 8, 
                  5, 1, -1, 14, 5, 62, -1, 1, 2 ),
        unpack( 1, 2, 1, 6, 2, 2, 11, -1, 2, 2, 12, -1, 1, 2, 6, -1, 2, 
                  5, 10, -1, 1, 2, 3, -1, 1, 5, 1, 2, 1, -1, 1, 2, 1, -1, 
                  1, 5, 2, -1, 13, 5, 2, -1, 8, 5, 1, -1, 14, 5, 62, -1, 
                  1, 2 ),
        unpack(  ),
        unpack( 2, 8, 58, -1, 1, 2 ),
        unpack( 3, 5, 1, 9, 11, -1, 2, 5, 12, -1, 1, 5, 6, -1, 1, 5, 11, 
                  -1, 1, 5, 4, -1, 1, 5, 1, -1, 1, 5, 17, -1, 1, 2, 1, 5, 
                  85, -1, 1, 5 ),
        unpack( 4, 2, 11, -1, 2, 2, 12, -1, 1, 2, 18, -1, 1, 2, 4, -1, 
                  1, 2, 1, -1, 1, 2, 1, -1, 1, 5 ),
        unpack( 1, 10, 24, -1, 2, 5 ),
        unpack( 1, 11 ),
        unpack( 1, 5, 1, -1, 1, 5, 45, -1, 1, 5, 4, -1, 1, 5, 1, -1, 1, 
                  5, 17, -1, 1, 2, 1, 5 )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 74
      

      def description
        <<-'__dfa_description__'.strip!
          231:41: ( keyVARYING )?
        __dfa_description__
      end
    end
    class DFA81 < ANTLR3::DFA
      EOT = unpack( 15, -1 )
      EOF = unpack( 3, -1, 1, 1, 1, 8, 7, -1, 1, 8, 1, -1, 1, 8 )
      MIN = unpack( 1, 40, 1, -1, 1, 5, 2, 4, 1, 40, 3, -1, 1, 40, 2, 5, 
                     1, 4, 1, 40, 1, 4 )
      MAX = unpack( 1, 101, 1, -1, 1, 33, 2, 161, 1, 100, 3, -1, 1, 100, 
                     2, 33, 1, 161, 1, 100, 1, 161 )
      ACCEPT = unpack( 1, -1, 1, 1, 4, -1, 1, 3, 1, 2, 1, 4, 6, -1 )
      SPECIAL = unpack( 2, -1, 1, 0, 12, -1 )
      TRANSITION = [
        unpack( 1, 2, 1, 4, 22, -1, 13, 1, 2, -1, 8, 1, 1, -1, 12, 1, 1, 
                 3, 1, 1 ),
        unpack(  ),
        unpack( 1, 5, 13, -1, 1, 7, 1, 6, 12, -1, 1, 6 ),
        unpack( 1, 1, 1, 5, 1, 1, 1, -1, 1, 1, 3, -1, 1, 1, 6, -1, 1, 
                  7, 1, 6, 12, -1, 1, 6, 6, -1, 2, 1, 8, -1, 1, 1, 1, -1, 
                  4, 1, 1, -1, 1, 1, 1, -1, 1, 1, 43, -1, 2, 1, 2, -1, 1, 
                  1, 53, -1, 1, 1 ),
        unpack( 1, 8, 1, 9, 3, 8, 3, -1, 1, 8, 6, -1, 1, 7, 1, 6, 12, 
                  -1, 1, 6, 6, -1, 2, 8, 8, -1, 1, 8, 1, -1, 4, 8, 1, -1, 
                  1, 8, 1, -1, 1, 8, 43, -1, 2, 8, 2, -1, 1, 8, 53, -1, 
                  1, 8 ),
        unpack( 2, 10, 58, -1, 1, 11 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 2, 12, 58, -1, 1, 11 ),
        unpack( 1, 7, 13, -1, 1, 7, 1, 6, 12, -1, 1, 6 ),
        unpack( 1, 7, 13, -1, 1, 7, 1, 6, 12, -1, 1, 6 ),
        unpack( 1, 8, 1, 13, 3, 8, 3, -1, 1, 8, 6, -1, 1, 7, 1, 6, 12, 
                  -1, 1, 6, 6, -1, 2, 8, 8, -1, 1, 8, 1, -1, 4, 8, 1, -1, 
                  1, 8, 1, -1, 1, 8, 43, -1, 2, 8, 2, -1, 1, 8, 53, -1, 
                  1, 8 ),
        unpack( 2, 14, 58, -1, 1, 7 ),
        unpack( 5, 8, 3, -1, 1, 8, 6, -1, 1, 7, 20, -1, 2, 8, 8, -1, 1, 
                  8, 1, -1, 4, 8, 1, -1, 1, 8, 1, -1, 1, 8, 43, -1, 2, 8, 
                  2, -1, 1, 8, 53, -1, 1, 8 )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 81
      

      def description
        <<-'__dfa_description__'.strip!
          242:1: type_spec : ( datatype | column_spec TYPE_ATTR | table_spec ROWTYPE_ATTR | type_name ( LPAREN NUMBER RPAREN )? );
        __dfa_description__
      end
    end
    class DFA125 < ANTLR3::DFA
      EOT = unpack( 64, -1 )
      EOF = unpack( 1, 2, 63, -1 )
      MIN = unpack( 1, 4, 1, 0, 62, -1 )
      MAX = unpack( 1, 165, 1, 0, 62, -1 )
      ACCEPT = unpack( 2, -1, 1, 2, 60, -1, 1, 1 )
      SPECIAL = unpack( 1, -1, 1, 0, 62, -1 )
      TRANSITION = [
        unpack( 2, 2, 1, -1, 1, 1, 2, 2, 2, -1, 5, 2, 4, -1, 2, 2, 1, -1, 
                 9, 2, 1, -1, 5, 2, 1, -1, 2, 2, 9, -1, 4, 2, 2, -1, 2, 
                 2, 4, -1, 1, 2, 36, -1, 1, 2, 1, -1, 1, 2, 6, -1, 3, 2, 
                 3, -1, 3, 2, 2, -1, 11, 2, 2, -1, 4, 2, 1, -1, 7, 2, 1, 
                 -1, 1, 2, 11, -1, 1, 2, 5, -1, 2, 2 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 125
      

      def description
        <<-'__dfa_description__'.strip!
          447:26: ({...}? LPAREN ( call_parameters )? RPAREN )?
        __dfa_description__
      end
    end
    class DFA133 < ANTLR3::DFA
      EOT = unpack( 15, -1 )
      EOF = unpack( 15, -1 )
      MIN = unpack( 1, 7, 1, 0, 13, -1 )
      MAX = unpack( 1, 142, 1, 0, 13, -1 )
      ACCEPT = unpack( 2, -1, 1, 2, 11, -1, 1, 1 )
      SPECIAL = unpack( 1, -1, 1, 0, 13, -1 )
      TRANSITION = [
        unpack( 1, 2, 5, -1, 4, 2, 23, -1, 1, 1, 1, 2, 16, -1, 1, 2, 41, 
                 -1, 1, 2, 9, -1, 2, 2, 4, -1, 2, 2, 22, -1, 1, 2, 1, -1, 
                 1, 2 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 133
      

      def description
        <<-'__dfa_description__'.strip!
          489:20: ( keyREVERSE )?
        __dfa_description__
      end
    end
    class DFA140 < ANTLR3::DFA
      EOT = unpack( 10, -1 )
      EOF = unpack( 10, -1 )
      MIN = unpack( 2, 40, 5, -1, 1, 0, 2, -1 )
      MAX = unpack( 1, 166, 1, 41, 5, -1, 1, 0, 2, -1 )
      ACCEPT = unpack( 2, -1, 1, 2, 1, 3, 1, 4, 1, 6, 1, 7, 1, -1, 1, 1, 
                        1, 5 )
      SPECIAL = unpack( 7, -1, 1, 0, 2, -1 )
      TRANSITION = [
        unpack( 1, 1, 72, -1, 1, 2, 35, -1, 1, 3, 1, 4, 4, -1, 1, 6, 10, 
                 -1, 1, 5 ),
        unpack( 2, 7 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 140
      

      def description
        <<-'__dfa_description__'.strip!
          546:1: to_control_data : ( close_statement | commit_statement | fetch_statement | lock_table_statement | open_statement | rollback_statement | savepoint_statement );
        __dfa_description__
      end
    end
    class DFA141 < ANTLR3::DFA
      EOT = unpack( 16, -1 )
      EOF = unpack( 16, -1 )
      MIN = unpack( 1, 7, 1, 0, 14, -1 )
      MAX = unpack( 1, 142, 1, 0, 14, -1 )
      ACCEPT = unpack( 2, -1, 1, 2, 5, -1, 1, 1, 7, -1 )
      SPECIAL = unpack( 1, -1, 1, 0, 14, -1 )
      TRANSITION = [
        unpack( 1, 2, 5, -1, 4, 2, 4, -1, 1, 2, 18, -1, 2, 2, 16, -1, 1, 
                 2, 41, -1, 1, 2, 9, -1, 2, 2, 4, -1, 1, 2, 1, 1, 2, 8, 
                 20, -1, 1, 2, 1, -1, 1, 2 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 141
      

      def description
        <<-'__dfa_description__'.strip!
          567:26: ( 'DISTINCT' | 'UNIQUE' | 'ALL' )?
        __dfa_description__
      end
    end
    class DFA157 < ANTLR3::DFA
      EOT = unpack( 64, -1 )
      EOF = unpack( 1, 1, 63, -1 )
      MIN = unpack( 1, 4, 33, -1, 1, 0, 29, -1 )
      MAX = unpack( 1, 165, 33, -1, 1, 0, 29, -1 )
      ACCEPT = unpack( 1, -1, 1, 2, 61, -1, 1, 1 )
      SPECIAL = unpack( 34, -1, 1, 0, 29, -1 )
      TRANSITION = [
        unpack( 1, 1, 2, -1, 3, 1, 2, -1, 1, 34, 4, 1, 4, -1, 2, 1, 1, 
                 -1, 9, 1, 1, -1, 5, 1, 1, -1, 2, 1, 9, -1, 4, 1, 2, -1, 
                 2, 1, 4, -1, 1, 1, 36, -1, 1, 1, 1, -1, 1, 1, 6, -1, 3, 
                 1, 3, -1, 3, 1, 2, -1, 11, 1, 2, -1, 4, 1, 1, -1, 7, 1, 
                 1, -1, 1, 1, 1, -1, 1, 1, 9, -1, 1, 1, 5, -1, 2, 1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 157
      

      def description
        <<-'__dfa_description__'.strip!
          ()* loopback of 594:19: ( COMMA selected_table )*
        __dfa_description__
      end
    end
    class DFA166 < ANTLR3::DFA
      EOT = unpack( 63, -1 )
      EOF = unpack( 1, 2, 62, -1 )
      MIN = unpack( 1, 4, 1, 0, 61, -1 )
      MAX = unpack( 1, 165, 1, 0, 61, -1 )
      ACCEPT = unpack( 2, -1, 1, 2, 59, -1, 1, 1 )
      SPECIAL = unpack( 1, -1, 1, 0, 61, -1 )
      TRANSITION = [
        unpack( 1, 2, 2, -1, 3, 2, 2, -1, 5, 2, 4, -1, 2, 2, 1, -1, 9, 
                 2, 1, -1, 5, 2, 1, -1, 1, 1, 1, 2, 9, -1, 4, 2, 2, -1, 
                 2, 2, 4, -1, 1, 2, 36, -1, 1, 2, 1, -1, 1, 2, 6, -1, 3, 
                 2, 3, -1, 3, 2, 2, -1, 11, 2, 2, -1, 4, 2, 1, -1, 7, 2, 
                 1, -1, 1, 2, 11, -1, 1, 2, 5, -1, 2, 2 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 166
      

      def description
        <<-'__dfa_description__'.strip!
          609:18: ( query_partition_clause )?
        __dfa_description__
      end
    end
    class DFA171 < ANTLR3::DFA
      EOT = unpack( 19, -1 )
      EOF = unpack( 19, -1 )
      MIN = unpack( 1, 7, 1, 0, 17, -1 )
      MAX = unpack( 1, 146, 1, 0, 17, -1 )
      ACCEPT = unpack( 2, -1, 1, 2, 15, -1, 1, 1 )
      SPECIAL = unpack( 1, -1, 1, 0, 17, -1 )
      TRANSITION = [
        unpack( 1, 2, 5, -1, 4, 2, 23, -1, 1, 1, 1, 2, 15, -1, 2, 2, 41, 
                 -1, 1, 2, 9, -1, 2, 2, 4, -1, 2, 2, 22, -1, 3, 2, 1, -1, 
                 1, 2, 1, -1, 1, 2 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 171
      

      def description
        <<-'__dfa_description__'.strip!
          625:53: ( keyNOCYCLE )?
        __dfa_description__
      end
    end
    class DFA173 < ANTLR3::DFA
      EOT = unpack( 16, -1 )
      EOF = unpack( 16, -1 )
      MIN = unpack( 1, 7, 1, 0, 14, -1 )
      MAX = unpack( 1, 142, 1, 0, 14, -1 )
      ACCEPT = unpack( 2, -1, 1, 3, 11, -1, 1, 1, 1, 2 )
      SPECIAL = unpack( 1, -1, 1, 0, 14, -1 )
      TRANSITION = [
        unpack( 1, 2, 5, -1, 4, 2, 23, -1, 1, 1, 1, 2, 16, -1, 1, 2, 41, 
                 -1, 1, 2, 9, -1, 2, 2, 4, -1, 2, 2, 22, -1, 1, 2, 1, -1, 
                 1, 2 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 173
      

      def description
        <<-'__dfa_description__'.strip!
          633:1: group_by_expr : ( rollup_cube_clause | grouping_sets_clause | grouping_expression_list );
        __dfa_description__
      end
    end
    class DFA176 < ANTLR3::DFA
      EOT = unpack( 15, -1 )
      EOF = unpack( 15, -1 )
      MIN = unpack( 1, 7, 1, 0, 13, -1 )
      MAX = unpack( 1, 142, 1, 0, 13, -1 )
      ACCEPT = unpack( 2, -1, 1, 2, 11, -1, 1, 1 )
      SPECIAL = unpack( 1, -1, 1, 0, 13, -1 )
      TRANSITION = [
        unpack( 1, 2, 5, -1, 4, 2, 23, -1, 1, 1, 1, 2, 16, -1, 1, 2, 41, 
                 -1, 1, 2, 9, -1, 2, 2, 4, -1, 2, 2, 22, -1, 1, 2, 1, -1, 
                 1, 2 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 176
      

      def description
        <<-'__dfa_description__'.strip!
          647:1: grouping_sets_expr : ( rollup_cube_clause | grouping_expression_list );
        __dfa_description__
      end
    end
    class DFA203 < ANTLR3::DFA
      EOT = unpack( 20, -1 )
      EOF = unpack( 20, -1 )
      MIN = unpack( 1, 7, 2, -1, 13, 0, 4, -1 )
      MAX = unpack( 1, 146, 2, -1, 13, 0, 4, -1 )
      ACCEPT = unpack( 1, -1, 1, 1, 16, -1, 1, 3, 1, 2 )
      SPECIAL = unpack( 3, -1, 1, 0, 1, 1, 1, 2, 1, 3, 1, 4, 1, 5, 1, 6, 
                         1, 7, 1, 8, 1, 9, 1, 10, 1, 11, 1, 12, 4, -1 )
      TRANSITION = [
        unpack( 1, 4, 5, -1, 2, 3, 1, 13, 1, 12, 23, -1, 1, 5, 1, 7, 15, 
                 -1, 1, 1, 1, 14, 41, -1, 1, 6, 9, -1, 2, 10, 1, 18, 3, 
                 -1, 1, 15, 1, 8, 22, -1, 1, 11, 1, 1, 1, 9, 1, -1, 1, 1, 
                 1, -1, 1, 1 ),
        unpack(  ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 203
      

      def description
        <<-'__dfa_description__'.strip!
          704:1: cell_assignment_expr : ( sql_condition | sql_expression | single_column_for_loop );
        __dfa_description__
      end
    end
    class DFA219 < ANTLR3::DFA
      EOT = unpack( 15, -1 )
      EOF = unpack( 1, -1, 2, 3, 1, -1, 1, 3, 2, -1, 3, 3, 1, -1, 3, 3, 
                     1, -1 )
      MIN = unpack( 1, 7, 2, 5, 1, -1, 1, 5, 1, 7, 1, -1, 3, 5, 1, 7, 3, 
                     5, 1, 7 )
      MAX = unpack( 1, 142, 2, 121, 1, -1, 1, 121, 1, 145, 1, -1, 3, 139, 
                     1, 145, 3, 139, 1, 145 )
      ACCEPT = unpack( 3, -1, 1, 2, 2, -1, 1, 1, 8, -1 )
      SPECIAL = unpack( 15, -1 )
      TRANSITION = [
        unpack( 1, 3, 5, -1, 4, 3, 23, -1, 1, 1, 1, 4, 16, -1, 1, 3, 41, 
                 -1, 1, 2, 9, -1, 2, 3, 4, -1, 2, 3, 22, -1, 1, 3, 1, -1, 
                 1, 3 ),
        unpack( 1, 5, 1, -1, 1, 3, 4, -1, 3, 3, 6, -1, 1, 3, 8, -1, 3, 
                  3, 7, -1, 2, 3, 11, -1, 1, 3, 46, -1, 1, 3, 19, -1, 2, 
                  3 ),
        unpack( 1, 5, 1, -1, 1, 3, 4, -1, 3, 3, 6, -1, 1, 3, 8, -1, 3, 
                  3, 7, -1, 2, 3, 11, -1, 1, 3, 46, -1, 1, 3, 19, -1, 2, 
                  3 ),
        unpack(  ),
        unpack( 1, 5, 1, -1, 1, 3, 4, -1, 3, 3, 6, -1, 1, 3, 8, -1, 3, 
                  3, 7, -1, 2, 3, 11, -1, 1, 3, 46, -1, 1, 3, 19, -1, 2, 
                  3 ),
        unpack( 1, 3, 5, -1, 4, 3, 4, -1, 1, 6, 18, -1, 1, 7, 1, 9, 15, 
                  -1, 2, 3, 41, -1, 1, 8, 9, -1, 2, 3, 4, -1, 2, 3, 22, 
                  -1, 3, 3, 1, -1, 2, 3 ),
        unpack(  ),
        unpack( 1, 10, 1, -1, 1, 3, 4, -1, 3, 3, 6, -1, 2, 3, 2, -1, 8, 
                  3, 1, -1, 5, 3, 1, -1, 2, 3, 9, -1, 3, 3, 3, -1, 1, 3, 
                  42, -1, 1, 3, 1, -1, 1, 3, 17, -1, 2, 3, 12, -1, 1, 3, 
                  3, -1, 2, 3 ),
        unpack( 1, 10, 1, -1, 1, 3, 4, -1, 3, 3, 6, -1, 2, 3, 2, -1, 8, 
                  3, 1, -1, 5, 3, 1, -1, 2, 3, 9, -1, 3, 3, 3, -1, 1, 3, 
                  42, -1, 1, 3, 1, -1, 1, 3, 17, -1, 2, 3, 12, -1, 1, 3, 
                  3, -1, 2, 3 ),
        unpack( 1, 10, 1, -1, 1, 3, 4, -1, 3, 3, 6, -1, 2, 3, 2, -1, 8, 
                  3, 1, -1, 5, 3, 1, -1, 2, 3, 9, -1, 3, 3, 3, -1, 1, 3, 
                  42, -1, 1, 3, 1, -1, 1, 3, 17, -1, 2, 3, 12, -1, 1, 3, 
                  3, -1, 2, 3 ),
        unpack( 1, 3, 5, -1, 4, 3, 4, -1, 1, 6, 18, -1, 1, 11, 1, 13, 
                  15, -1, 2, 3, 41, -1, 1, 12, 9, -1, 2, 3, 4, -1, 2, 3, 
                  22, -1, 3, 3, 1, -1, 2, 3 ),
        unpack( 1, 14, 1, -1, 1, 3, 4, -1, 3, 3, 6, -1, 2, 3, 2, -1, 8, 
                  3, 1, -1, 5, 3, 1, -1, 2, 3, 9, -1, 3, 3, 3, -1, 1, 3, 
                  42, -1, 1, 3, 1, -1, 1, 3, 17, -1, 2, 3, 12, -1, 1, 3, 
                  3, -1, 2, 3 ),
        unpack( 1, 14, 1, -1, 1, 3, 4, -1, 3, 3, 6, -1, 2, 3, 2, -1, 8, 
                  3, 1, -1, 5, 3, 1, -1, 2, 3, 9, -1, 3, 3, 3, -1, 1, 3, 
                  42, -1, 1, 3, 1, -1, 1, 3, 17, -1, 2, 3, 12, -1, 1, 3, 
                  3, -1, 2, 3 ),
        unpack( 1, 14, 1, -1, 1, 3, 4, -1, 3, 3, 6, -1, 2, 3, 2, -1, 8, 
                  3, 1, -1, 5, 3, 1, -1, 2, 3, 9, -1, 3, 3, 3, -1, 1, 3, 
                  42, -1, 1, 3, 1, -1, 1, 3, 17, -1, 2, 3, 12, -1, 1, 3, 
                  3, -1, 2, 3 ),
        unpack( 1, 3, 5, -1, 4, 3, 4, -1, 1, 6, 18, -1, 2, 3, 15, -1, 
                  2, 3, 41, -1, 1, 3, 9, -1, 2, 3, 4, -1, 2, 3, 22, -1, 
                  3, 3, 1, -1, 2, 3 )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 219
      

      def description
        <<-'__dfa_description__'.strip!
          761:4: ( ( column_spec DOT ASTERISK ) | sql_expression )
        __dfa_description__
      end
    end
    class DFA222 < ANTLR3::DFA
      EOT = unpack( 16, -1 )
      EOF = unpack( 16, -1 )
      MIN = unpack( 1, 7, 13, 0, 2, -1 )
      MAX = unpack( 1, 142, 13, 0, 2, -1 )
      ACCEPT = unpack( 14, -1, 1, 2, 1, 1 )
      SPECIAL = unpack( 1, -1, 1, 0, 1, 1, 1, 2, 1, 3, 1, 4, 1, 5, 1, 6, 
                         1, 7, 1, 8, 1, 9, 1, 10, 1, 11, 1, 12, 2, -1 )
      TRANSITION = [
        unpack( 1, 2, 5, -1, 2, 1, 1, 11, 1, 10, 23, -1, 1, 3, 1, 5, 15, 
                 -1, 1, 14, 1, 12, 41, -1, 1, 4, 9, -1, 2, 8, 4, -1, 1, 
                 13, 1, 6, 22, -1, 1, 9, 1, -1, 1, 7 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 222
      

      def description
        <<-'__dfa_description__'.strip!
          790:1: nested_expression : ({...}? sql_expression | {...}? plsql_expression );
        __dfa_description__
      end
    end
    class DFA231 < ANTLR3::DFA
      EOT = unpack( 24, -1 )
      EOF = unpack( 1, 1, 23, -1 )
      MIN = unpack( 1, 4, 1, -1, 12, 0, 10, -1 )
      MAX = unpack( 1, 165, 1, -1, 12, 0, 10, -1 )
      ACCEPT = unpack( 1, -1, 1, 11, 12, -1, 1, 1, 1, 2, 1, 3, 1, 4, 1, 
                        5, 1, 6, 1, 7, 1, 8, 1, 9, 1, 10 )
      SPECIAL = unpack( 2, -1, 1, 1, 1, 5, 1, 11, 1, 7, 1, 8, 1, 9, 1, 
                         3, 1, 4, 1, 6, 1, 10, 1, 2, 1, 0, 10, -1 )
      TRANSITION = [
        unpack( 1, 1, 2, -1, 3, 1, 2, -1, 5, 1, 4, -1, 1, 1, 1, 2, 1, -1, 
                 1, 1, 1, 3, 1, 4, 1, 5, 1, 6, 1, 7, 3, 1, 1, -1, 5, 13, 
                 1, -1, 2, 1, 9, -1, 1, 1, 1, 8, 2, 1, 2, -1, 1, 9, 1, 1, 
                 4, -1, 1, 1, 36, -1, 1, 1, 1, -1, 1, 12, 6, -1, 3, 1, 3, 
                 -1, 3, 1, 2, -1, 11, 1, 2, -1, 1, 1, 1, 10, 2, 1, 1, -1, 
                 1, 1, 1, 11, 5, 1, 1, -1, 1, 1, 11, -1, 1, 1, 5, -1, 2, 
                 1 ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 231
      

      def description
        <<-'__dfa_description__'.strip!
          ()* loopback of 820:3: ( relational_op expr_add | FOUND_ATTR | NOTFOUND_ATTR | ISOPEN_ATTR | ROWCOUNT_ATTR | BULK_ROWCOUNT_ATTR | 'IS' ( 'NOT' )? 'NULL' | ( 'NOT' )? 'LIKE' expr_add | ( 'NOT' )? 'BETWEEN' expr_add 'AND' expr_add | ( 'NOT' )? 'IN' LPAREN nested_expressions RPAREN )*
        __dfa_description__
      end
    end
    class DFA237 < ANTLR3::DFA
      EOT = unpack( 14, -1 )
      EOF = unpack( 14, -1 )
      MIN = unpack( 1, 7, 1, -1, 1, 7, 2, 0, 9, -1 )
      MAX = unpack( 1, 142, 1, -1, 1, 7, 2, 0, 9, -1 )
      ACCEPT = unpack( 1, -1, 1, 1, 3, -1, 1, 2, 1, 3, 5, 5, 1, 6, 1, 4 )
      SPECIAL = unpack( 1, 3, 1, -1, 1, 1, 1, 2, 1, 0, 9, -1 )
      TRANSITION = [
        unpack( 1, 1, 7, -1, 1, 10, 1, 9, 23, -1, 1, 2, 1, 4, 16, -1, 1, 
                 11, 41, -1, 1, 3, 9, -1, 2, 7, 4, -1, 1, 12, 1, 5, 22, 
                 -1, 1, 8, 1, -1, 1, 6 ),
        unpack(  ),
        unpack( 1, 13 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 237
      

      def description
        <<-'__dfa_description__'.strip!
          852:1: expr_expr : ( ( expr_paren )=> expr_paren | ( function_expression )=> function_expression | ( case_expression )=> case_expression | ( cursor_expression )=> cursor_expression | ( simple_expression )=> simple_expression | ( select_expression )=> select_expression );
        __dfa_description__
      end
    end
    class DFA253 < ANTLR3::DFA
      EOT = unpack( 16, -1 )
      EOF = unpack( 16, -1 )
      MIN = unpack( 1, 7, 1, 0, 14, -1 )
      MAX = unpack( 1, 142, 1, 0, 14, -1 )
      ACCEPT = unpack( 2, -1, 1, 2, 12, -1, 1, 1 )
      SPECIAL = unpack( 1, -1, 1, 0, 14, -1 )
      TRANSITION = [
        unpack( 1, 1, 5, -1, 4, 2, 23, -1, 2, 2, 15, -1, 2, 2, 41, -1, 
                 1, 2, 9, -1, 2, 2, 4, -1, 2, 2, 22, -1, 1, 2, 1, -1, 1, 
                 2 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 253
      

      def description
        <<-'__dfa_description__'.strip!
          924:16: ( LPAREN nested_expression RPAREN | nested_expression )
        __dfa_description__
      end
    end
    class DFA266 < ANTLR3::DFA
      EOT = unpack( 11, -1 )
      EOF = unpack( 7, -1, 2, 9, 2, -1 )
      MIN = unpack( 1, 40, 2, 5, 1, 40, 2, 5, 1, 40, 2, 4, 2, -1 )
      MAX = unpack( 1, 100, 2, 5, 1, 100, 2, 5, 1, 100, 2, 165, 2, -1 )
      ACCEPT = unpack( 9, -1, 1, 2, 1, 1 )
      SPECIAL = unpack( 11, -1 )
      TRANSITION = [
        unpack( 2, 1, 58, -1, 1, 2 ),
        unpack( 1, 3 ),
        unpack( 1, 3 ),
        unpack( 2, 4, 58, -1, 1, 5 ),
        unpack( 1, 6 ),
        unpack( 1, 6 ),
        unpack( 2, 7, 58, -1, 1, 8 ),
        unpack( 1, 9, 1, 10, 1, -1, 3, 9, 2, -1, 5, 9, 4, -1, 2, 9, 1, 
                  -1, 9, 9, 1, -1, 5, 9, 1, -1, 2, 9, 9, -1, 4, 9, 2, -1, 
                  2, 9, 4, -1, 1, 9, 36, -1, 1, 9, 1, -1, 1, 9, 6, -1, 3, 
                  9, 3, -1, 3, 9, 2, -1, 11, 9, 2, -1, 4, 9, 1, -1, 7, 9, 
                  1, -1, 1, 9, 11, -1, 1, 9, 5, -1, 2, 9 ),
        unpack( 1, 9, 1, 10, 1, -1, 3, 9, 2, -1, 5, 9, 4, -1, 2, 9, 1, 
                  -1, 9, 9, 1, -1, 5, 9, 1, -1, 2, 9, 9, -1, 4, 9, 2, -1, 
                  2, 9, 4, -1, 1, 9, 36, -1, 1, 9, 1, -1, 1, 9, 6, -1, 3, 
                  9, 3, -1, 3, 9, 2, -1, 11, 9, 2, -1, 4, 9, 1, -1, 7, 9, 
                  1, -1, 1, 9, 11, -1, 1, 9, 5, -1, 2, 9 ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 266
      

      def description
        <<-'__dfa_description__'.strip!
          987:4: ( schema_name DOT )?
        __dfa_description__
      end
    end
    class DFA277 < ANTLR3::DFA
      EOT = unpack( 19, -1 )
      EOF = unpack( 19, -1 )
      MIN = unpack( 1, 7, 1, 0, 1, -1, 13, 0, 3, -1 )
      MAX = unpack( 1, 146, 1, 0, 1, -1, 13, 0, 3, -1 )
      ACCEPT = unpack( 2, -1, 1, 1, 15, -1, 1, 2 )
      SPECIAL = unpack( 1, -1, 1, 0, 1, -1, 1, 1, 1, 2, 1, 3, 1, 4, 1, 
                         5, 1, 6, 1, 7, 1, 8, 1, 9, 1, 10, 1, 11, 1, 12, 
                         1, 13, 3, -1 )
      TRANSITION = [
        unpack( 1, 4, 5, -1, 2, 3, 1, 13, 1, 12, 23, -1, 1, 5, 1, 7, 15, 
                 -1, 1, 1, 1, 14, 41, -1, 1, 6, 9, -1, 2, 10, 4, -1, 1, 
                 15, 1, 8, 22, -1, 1, 11, 1, 2, 1, 9, 1, -1, 1, 2, 1, -1, 
                 1, 2 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 277
      

      def description
        <<-'__dfa_description__'.strip!
          1009:1: nested_condition : ({...}? condition_or | {...}? expr_bool );
        __dfa_description__
      end
    end
    class DFA281 < ANTLR3::DFA
      EOT = unpack( 32, -1 )
      EOF = unpack( 32, -1 )
      MIN = unpack( 1, 7, 1, -1, 13, 0, 17, -1 )
      MAX = unpack( 1, 146, 1, -1, 13, 0, 17, -1 )
      ACCEPT = unpack( 1, -1, 1, 1, 13, -1, 1, 3, 1, 7, 1, 2, 1, 4, 1, 
                        5, 1, 9, 1, 11, 1, 12, 1, 13, 1, 18, 1, 6, 1, 8, 
                        1, 10, 1, 14, 1, 15, 1, 16, 1, 17 )
      SPECIAL = unpack( 2, -1, 1, 0, 1, 1, 1, 2, 1, 3, 1, 4, 1, 5, 1, 6, 
                         1, 7, 1, 8, 1, 9, 1, 10, 1, 11, 1, 12, 17, -1 )
      TRANSITION = [
        unpack( 1, 3, 5, -1, 2, 2, 1, 12, 1, 11, 23, -1, 1, 4, 1, 6, 16, 
                 -1, 1, 13, 41, -1, 1, 5, 9, -1, 2, 9, 4, -1, 1, 14, 1, 
                 7, 22, -1, 1, 10, 1, 15, 1, 8, 1, -1, 1, 1, 1, -1, 1, 16 ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 281
      

      def description
        <<-'__dfa_description__'.strip!
          1031:1: condition_expr : ( condition_exists | condition_is | condition_comparison | condition_group_comparison | condition_in | condition_is_a_set | condition_is_any | condition_is_empty | condition_is_of_type | condition_is_present | condition_like | condition_memeber | condition_between | condition_regexp_like | condition_submultiset | condition_equals_path | condition_under_path | condition_paren );
        __dfa_description__
      end
    end
    class DFA291 < ANTLR3::DFA
      EOT = unpack( 16, -1 )
      EOF = unpack( 16, -1 )
      MIN = unpack( 1, 7, 1, 0, 14, -1 )
      MAX = unpack( 1, 142, 1, 0, 14, -1 )
      ACCEPT = unpack( 2, -1, 1, 2, 12, -1, 1, 1 )
      SPECIAL = unpack( 1, -1, 1, 0, 14, -1 )
      TRANSITION = [
        unpack( 1, 1, 5, -1, 4, 2, 23, -1, 2, 2, 16, -1, 1, 2, 41, -1, 
                 1, 2, 9, -1, 2, 2, 4, -1, 2, 2, 22, -1, 3, 2 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 291
      

      def description
        <<-'__dfa_description__'.strip!
          1057:1: condition_comparison : ( LPAREN sql_expressions RPAREN ( outer_join_sign )? ( EQ | NOT_EQ ) LPAREN select_command RPAREN ( outer_join_sign )? | ( 'PRIOR' )? sql_expression ( outer_join_sign )? ( EQ | NOT_EQ | GTH | GEQ | LTH | LEQ ) ( 'PRIOR' )? ( sql_expression | LPAREN select_command RPAREN ) ( outer_join_sign )? );
        __dfa_description__
      end
    end
    class DFA289 < ANTLR3::DFA
      EOT = unpack( 15, -1 )
      EOF = unpack( 15, -1 )
      MIN = unpack( 1, 7, 1, -1, 1, 0, 12, -1 )
      MAX = unpack( 1, 142, 1, -1, 1, 0, 12, -1 )
      ACCEPT = unpack( 1, -1, 1, 1, 12, -1, 1, 2 )
      SPECIAL = unpack( 2, -1, 1, 0, 12, -1 )
      TRANSITION = [
        unpack( 1, 2, 5, -1, 4, 1, 23, -1, 2, 1, 16, -1, 1, 1, 41, -1, 
                 1, 1, 9, -1, 2, 1, 4, -1, 2, 1, 22, -1, 1, 1, 1, -1, 1, 
                 1 ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 289
      

      def description
        <<-'__dfa_description__'.strip!
          1059:106: ( sql_expression | LPAREN select_command RPAREN )
        __dfa_description__
      end
    end
    class DFA296 < ANTLR3::DFA
      EOT = unpack( 15, -1 )
      EOF = unpack( 15, -1 )
      MIN = unpack( 1, 7, 1, 0, 13, -1 )
      MAX = unpack( 1, 142, 1, 0, 13, -1 )
      ACCEPT = unpack( 2, -1, 1, 2, 11, -1, 1, 1 )
      SPECIAL = unpack( 1, -1, 1, 0, 13, -1 )
      TRANSITION = [
        unpack( 1, 1, 5, -1, 4, 2, 23, -1, 2, 2, 16, -1, 1, 2, 41, -1, 
                 1, 2, 9, -1, 2, 2, 4, -1, 2, 2, 22, -1, 1, 2, 1, -1, 1, 
                 2 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 296
      

      def description
        <<-'__dfa_description__'.strip!
          1061:1: condition_group_comparison : ( LPAREN sql_expressions RPAREN ( EQ | NOT_EQ ) ( 'ANY' | keySOME | 'ALL' ) LPAREN ( grouping_expression_list | select_command ) RPAREN | sql_expression ( EQ | NOT_EQ | GTH | GEQ | LTH | LEQ ) ( 'ANY' | keySOME | 'ALL' ) LPAREN ( sql_expressions | select_command ) RPAREN );
        __dfa_description__
      end
    end
    class DFA293 < ANTLR3::DFA
      EOT = unpack( 15, -1 )
      EOF = unpack( 15, -1 )
      MIN = unpack( 1, 7, 12, -1, 1, 0, 1, -1 )
      MAX = unpack( 1, 142, 12, -1, 1, 0, 1, -1 )
      ACCEPT = unpack( 1, -1, 1, 1, 12, -1, 1, 2 )
      SPECIAL = unpack( 13, -1, 1, 0, 1, -1 )
      TRANSITION = [
        unpack( 1, 1, 5, -1, 4, 1, 23, -1, 2, 1, 16, -1, 1, 1, 41, -1, 
                 1, 1, 9, -1, 2, 1, 4, -1, 1, 13, 1, 1, 22, -1, 1, 1, 1, 
                 -1, 1, 1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 293
      

      def description
        <<-'__dfa_description__'.strip!
          1062:85: ( grouping_expression_list | select_command )
        __dfa_description__
      end
    end
    class DFA295 < ANTLR3::DFA
      EOT = unpack( 15, -1 )
      EOF = unpack( 15, -1 )
      MIN = unpack( 1, 7, 12, -1, 1, 0, 1, -1 )
      MAX = unpack( 1, 142, 12, -1, 1, 0, 1, -1 )
      ACCEPT = unpack( 1, -1, 1, 1, 12, -1, 1, 2 )
      SPECIAL = unpack( 13, -1, 1, 0, 1, -1 )
      TRANSITION = [
        unpack( 1, 1, 5, -1, 4, 1, 23, -1, 2, 1, 16, -1, 1, 1, 41, -1, 
                 1, 1, 9, -1, 2, 1, 4, -1, 1, 13, 1, 1, 22, -1, 1, 1, 1, 
                 -1, 1, 1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 295
      

      def description
        <<-'__dfa_description__'.strip!
          1063:94: ( sql_expressions | select_command )
        __dfa_description__
      end
    end
    class DFA301 < ANTLR3::DFA
      EOT = unpack( 15, -1 )
      EOF = unpack( 15, -1 )
      MIN = unpack( 1, 7, 1, 0, 13, -1 )
      MAX = unpack( 1, 142, 1, 0, 13, -1 )
      ACCEPT = unpack( 2, -1, 1, 2, 11, -1, 1, 1 )
      SPECIAL = unpack( 1, -1, 1, 0, 13, -1 )
      TRANSITION = [
        unpack( 1, 1, 5, -1, 4, 2, 23, -1, 2, 2, 16, -1, 1, 2, 41, -1, 
                 1, 2, 9, -1, 2, 2, 4, -1, 2, 2, 22, -1, 1, 2, 1, -1, 1, 
                 2 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 301
      

      def description
        <<-'__dfa_description__'.strip!
          1065:1: condition_in : ( LPAREN sql_expressions RPAREN ( 'NOT' )? 'IN' LPAREN ( grouping_expression_list | select_command ) RPAREN | sql_expression ( 'NOT' )? 'IN' LPAREN ( expression_list | select_command ) RPAREN );
        __dfa_description__
      end
    end
    class DFA298 < ANTLR3::DFA
      EOT = unpack( 15, -1 )
      EOF = unpack( 15, -1 )
      MIN = unpack( 1, 7, 12, -1, 1, 0, 1, -1 )
      MAX = unpack( 1, 142, 12, -1, 1, 0, 1, -1 )
      ACCEPT = unpack( 1, -1, 1, 1, 12, -1, 1, 2 )
      SPECIAL = unpack( 13, -1, 1, 0, 1, -1 )
      TRANSITION = [
        unpack( 1, 1, 5, -1, 4, 1, 23, -1, 2, 1, 16, -1, 1, 1, 41, -1, 
                 1, 1, 9, -1, 2, 1, 4, -1, 1, 13, 1, 1, 22, -1, 1, 1, 1, 
                 -1, 1, 1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 298
      

      def description
        <<-'__dfa_description__'.strip!
          1066:57: ( grouping_expression_list | select_command )
        __dfa_description__
      end
    end
    class DFA300 < ANTLR3::DFA
      EOT = unpack( 15, -1 )
      EOF = unpack( 15, -1 )
      MIN = unpack( 1, 7, 12, -1, 1, 0, 1, -1 )
      MAX = unpack( 1, 142, 12, -1, 1, 0, 1, -1 )
      ACCEPT = unpack( 1, -1, 1, 1, 12, -1, 1, 2 )
      SPECIAL = unpack( 13, -1, 1, 0, 1, -1 )
      TRANSITION = [
        unpack( 1, 1, 5, -1, 4, 1, 23, -1, 2, 1, 16, -1, 1, 1, 41, -1, 
                 1, 1, 9, -1, 2, 1, 4, -1, 1, 13, 1, 1, 22, -1, 1, 1, 1, 
                 -1, 1, 1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 300
      

      def description
        <<-'__dfa_description__'.strip!
          1067:42: ( expression_list | select_command )
        __dfa_description__
      end
    end
    class DFA321 < ANTLR3::DFA
      EOT = unpack( 15, -1 )
      EOF = unpack( 15, -1 )
      MIN = unpack( 1, 7, 1, 0, 13, -1 )
      MAX = unpack( 1, 142, 1, 0, 13, -1 )
      ACCEPT = unpack( 2, -1, 1, 2, 11, -1, 1, 1 )
      SPECIAL = unpack( 1, -1, 1, 0, 13, -1 )
      TRANSITION = [
        unpack( 1, 1, 5, -1, 4, 2, 23, -1, 2, 2, 16, -1, 1, 2, 41, -1, 
                 1, 2, 9, -1, 2, 2, 4, -1, 2, 2, 22, -1, 1, 2, 1, -1, 1, 
                 2 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 321
      

      def description
        <<-'__dfa_description__'.strip!
          1123:1: expression_list : ( LPAREN sql_expressions RPAREN | sql_expressions );
        __dfa_description__
      end
    end
    class DFA324 < ANTLR3::DFA
      EOT = unpack( 15, -1 )
      EOF = unpack( 15, -1 )
      MIN = unpack( 1, 7, 1, -1, 1, 0, 12, -1 )
      MAX = unpack( 1, 142, 1, -1, 1, 0, 12, -1 )
      ACCEPT = unpack( 1, -1, 1, 1, 1, -1, 11, 1, 1, 2 )
      SPECIAL = unpack( 1, 0, 1, -1, 1, 1, 12, -1 )
      TRANSITION = [
        unpack( 1, 2, 5, -1, 2, 1, 1, 11, 1, 10, 23, -1, 1, 3, 1, 5, 16, 
                 -1, 1, 12, 41, -1, 1, 4, 9, -1, 2, 8, 4, -1, 1, 13, 1, 
                 6, 22, -1, 1, 9, 1, -1, 1, 7 ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 324
      

      def description
        <<-'__dfa_description__'.strip!
          1141:1: exp_set : ( ( sql_expression )=> sql_expression | subquery );
        __dfa_description__
      end
    end
    class DFA330 < ANTLR3::DFA
      EOT = unpack( 19, -1 )
      EOF = unpack( 19, -1 )
      MIN = unpack( 1, 7, 3, -1, 13, 0, 2, -1 )
      MAX = unpack( 1, 146, 3, -1, 13, 0, 2, -1 )
      ACCEPT = unpack( 1, -1, 3, 1, 13, -1, 1, 1, 1, 2 )
      SPECIAL = unpack( 1, 0, 3, -1, 1, 1, 1, 2, 1, 3, 1, 4, 1, 5, 1, 6, 
                         1, 7, 1, 8, 1, 9, 1, 10, 1, 11, 1, 12, 1, 13, 2, 
                         -1 )
      TRANSITION = [
        unpack( 1, 5, 5, -1, 2, 4, 1, 14, 1, 13, 23, -1, 1, 6, 1, 8, 15, 
                 -1, 1, 2, 1, 15, 41, -1, 1, 7, 9, -1, 2, 11, 4, -1, 1, 
                 16, 1, 9, 22, -1, 1, 12, 1, 1, 1, 10, 1, -1, 1, 3, 1, -1, 
                 1, 17 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 330
      

      def description
        <<-'__dfa_description__'.strip!
          1156:3: ( ( ( 'PRIOR' )? sql_condition )=> ( 'PRIOR' )? sql_condition | sql_expression relational_op ( 'PRIOR' )? sql_expression ( 'AND' sql_condition )? )
        __dfa_description__
      end
    end
    class DFA336 < ANTLR3::DFA
      EOT = unpack( 15, -1 )
      EOF = unpack( 15, -1 )
      MIN = unpack( 1, 7, 10, -1, 1, 0, 3, -1 )
      MAX = unpack( 1, 142, 10, -1, 1, 0, 3, -1 )
      ACCEPT = unpack( 1, -1, 10, 1, 1, -1, 2, 1, 1, 2 )
      SPECIAL = unpack( 1, 0, 10, -1, 1, 1, 3, -1 )
      TRANSITION = [
        unpack( 1, 2, 5, -1, 2, 1, 1, 11, 1, 10, 23, -1, 1, 3, 1, 5, 16, 
                 -1, 1, 12, 41, -1, 1, 4, 9, -1, 2, 8, 4, -1, 1, 13, 1, 
                 6, 22, -1, 1, 9, 1, -1, 1, 7 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack(  ),
        unpack(  ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 336
      

      def description
        <<-'__dfa_description__'.strip!
          1175:4: ( ( sql_expression )=> sql_expression | ( NUMBER )=> NUMBER )
        __dfa_description__
      end
    end
    class DFA460 < ANTLR3::DFA
      EOT = unpack( 15, -1 )
      EOF = unpack( 15, -1 )
      MIN = unpack( 1, 7, 12, -1, 1, 0, 1, -1 )
      MAX = unpack( 1, 142, 12, -1, 1, 0, 1, -1 )
      ACCEPT = unpack( 1, -1, 1, 1, 12, -1, 1, 2 )
      SPECIAL = unpack( 13, -1, 1, 0, 1, -1 )
      TRANSITION = [
        unpack( 1, 1, 5, -1, 4, 1, 23, -1, 2, 1, 16, -1, 1, 1, 41, -1, 
                 1, 1, 9, -1, 2, 1, 4, -1, 1, 13, 1, 1, 22, -1, 1, 1, 1, 
                 -1, 1, 1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 460
      

      def description
        <<-'__dfa_description__'.strip!
          1062:85: ( grouping_expression_list | select_command )
        __dfa_description__
      end
    end
    class DFA462 < ANTLR3::DFA
      EOT = unpack( 15, -1 )
      EOF = unpack( 15, -1 )
      MIN = unpack( 1, 7, 12, -1, 1, 0, 1, -1 )
      MAX = unpack( 1, 142, 12, -1, 1, 0, 1, -1 )
      ACCEPT = unpack( 1, -1, 1, 1, 12, -1, 1, 2 )
      SPECIAL = unpack( 13, -1, 1, 0, 1, -1 )
      TRANSITION = [
        unpack( 1, 1, 5, -1, 4, 1, 23, -1, 2, 1, 16, -1, 1, 1, 41, -1, 
                 1, 1, 9, -1, 2, 1, 4, -1, 1, 13, 1, 1, 22, -1, 1, 1, 1, 
                 -1, 1, 1 ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack(  ),
        unpack( 1, -1 ),
        unpack(  )
      ].freeze
      
      ( 0 ... MIN.length ).zip( MIN, MAX ) do | i, a, z |
        if a > 0 and z < 0
          MAX[ i ] %= 0x10000
        end
      end
      
      @decision = 462
      

      def description
        <<-'__dfa_description__'.strip!
          1066:57: ( grouping_expression_list | select_command )
        __dfa_description__
      end
    end


    private

    def initialize_dfas
      super rescue nil
      @dfa10 = DFA10.new( self, 10 ) do |s|
        case s
        when 0
          look_10_146 = @input.peek
          index_10_146 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred13_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("TYPE") ) ) )
            s = 110
          elsif ( ( syntactic_predicate?( :synpred14_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("SUBTYPE") ) ) )
            s = 145
          end
           
          @input.seek( index_10_146 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa10.description, 10, s, input )
          @dfa10.error( nva )
          raise nva
        end
        
        s
      end
      @dfa14 = DFA14.new( self, 14 ) do |s|
        case s
        when 0
          look_14_9 = @input.peek
          index_14_9 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred27_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("NEW") ) ) )
            s = 5
          elsif ( true )
            s = 2
          end
           
          @input.seek( index_14_9 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa14.description, 14, s, input )
          @dfa14.error( nva )
          raise nva
        end
        
        s
      end
      @dfa19 = DFA19.new( self, 19 )
      @dfa21 = DFA21.new( self, 21 ) do |s|
        case s
        when 0
          look_21_1 = @input.peek
          index_21_1 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred43_Plsql ) )
            s = 2
          elsif ( ( syntactic_predicate?( :synpred44_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("EXIT") ) ) )
            s = 31
          elsif ( syntactic_predicate?( :synpred46_Plsql ) )
            s = 5
          elsif ( ( ( syntactic_predicate?( :synpred52_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CLOSE") ) ) ) or ( ( syntactic_predicate?( :synpred52_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("OPEN") ) ) ) )
            s = 14
          elsif ( ( ( syntactic_predicate?( :synpred53_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( syntactic_predicate?( :synpred53_Plsql ) ) or ( ( syntactic_predicate?( :synpred53_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("TYPE") ) ) ) or ( ( syntactic_predicate?( :synpred53_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("TYPE") ) ) ) or ( ( syntactic_predicate?( :synpred53_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("TYPE") ) ) ) or ( ( syntactic_predicate?( :synpred53_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("SUBTYPE") ) ) ) or ( ( syntactic_predicate?( :synpred53_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("TYPE") ) ) ) )
            s = 24
          elsif ( true )
            s = 30
          end
           
          @input.seek( index_21_1 )

        when 1
          look_21_3 = @input.peek
          index_21_3 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred43_Plsql ) )
            s = 2
          elsif ( syntactic_predicate?( :synpred46_Plsql ) )
            s = 5
          elsif ( syntactic_predicate?( :synpred53_Plsql ) )
            s = 24
          elsif ( true )
            s = 30
          end
           
          @input.seek( index_21_3 )

        when 2
          look_21_7 = @input.peek
          index_21_7 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred48_Plsql ) )
            s = 8
          elsif ( syntactic_predicate?( :synpred53_Plsql ) )
            s = 24
          end
           
          @input.seek( index_21_7 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa21.description, 21, s, input )
          @dfa21.error( nva )
          raise nva
        end
        
        s
      end
      @dfa29 = DFA29.new( self, 29 ) do |s|
        case s
        when 0
          look_29_151 = @input.peek
          index_29_151 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred62_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("SUBTYPE") ) ) )
            s = 156
          elsif ( ( syntactic_predicate?( :synpred70_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("TYPE") ) ) )
            s = 116
          end
           
          @input.seek( index_29_151 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa29.description, 29, s, input )
          @dfa29.error( nva )
          raise nva
        end
        
        s
      end
      @dfa32 = DFA32.new( self, 32 ) do |s|
        case s
        when 0
          look_32_11 = @input.peek
          index_32_11 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred77_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("BUIlookIN") ) ) )
            s = 19
          elsif ( ( syntactic_predicate?( :synpred78_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("FIPSFLAG") ) ) )
            s = 20
          elsif ( ( syntactic_predicate?( :synpred79_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("INTERFACE") ) ) )
            s = 21
          elsif ( ( syntactic_predicate?( :synpred80_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("NEW_NAMES") ) ) )
            s = 22
          elsif ( ( self.input.look(1).text.upcase == ("TIMESTAMP") ) )
            s = 23
          end
           
          @input.seek( index_32_11 )

        when 1
          look_32_32 = @input.peek
          index_32_32 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred73_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("RESTRICT_REFERENCES") ) ) )
            s = 9
          elsif ( ( syntactic_predicate?( :synpred77_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("BUIlookIN") ) ) )
            s = 19
          elsif ( ( syntactic_predicate?( :synpred78_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("FIPSFLAG") ) ) )
            s = 20
          elsif ( ( syntactic_predicate?( :synpred79_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("INTERFACE") ) ) )
            s = 21
          elsif ( ( syntactic_predicate?( :synpred80_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("NEW_NAMES") ) ) )
            s = 22
          elsif ( ( self.input.look(1).text.upcase == ("TIMESTAMP") ) )
            s = 23
          end
           
          @input.seek( index_32_32 )

        when 2
          look_32_1 = @input.peek
          index_32_1 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( look_32_1 == LPAREN )
            s = 2
          elsif ( ( syntactic_predicate?( :synpred75_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("AUTONOMOUS_TRANSACTION") ) ) )
            s = 3
          elsif ( ( syntactic_predicate?( :synpred76_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("SERIALLY_REUSABLE") ) ) )
            s = 4
          end
           
          @input.seek( index_32_1 )

        when 3
          look_32_31 = @input.peek
          index_32_31 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred73_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("RESTRICT_REFERENCES") ) ) )
            s = 9
          elsif ( ( syntactic_predicate?( :synpred74_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("EXCEPTION_INIT") ) ) )
            s = 12
          elsif ( ( syntactic_predicate?( :synpred77_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("BUIlookIN") ) ) )
            s = 19
          elsif ( ( syntactic_predicate?( :synpred78_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("FIPSFLAG") ) ) )
            s = 20
          elsif ( ( syntactic_predicate?( :synpred79_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("INTERFACE") ) ) )
            s = 21
          elsif ( ( syntactic_predicate?( :synpred80_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("NEW_NAMES") ) ) )
            s = 22
          elsif ( ( self.input.look(1).text.upcase == ("TIMESTAMP") ) )
            s = 23
          end
           
          @input.seek( index_32_31 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa32.description, 32, s, input )
          @dfa32.error( nva )
          raise nva
        end
        
        s
      end
      @dfa79 = DFA79.new( self, 79 ) do |s|
        case s
        when 0
          look_79_39 = @input.peek
          index_79_39 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred114_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("INTERVAL") ) ) )
            s = 41
          elsif ( ( syntactic_predicate?( :synpred116_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("INTERVAL") ) ) )
            s = 42
          end
           
          @input.seek( index_79_39 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa79.description, 79, s, input )
          @dfa79.error( nva )
          raise nva
        end
        
        s
      end
      @dfa52 = DFA52.new( self, 52 )
      @dfa55 = DFA55.new( self, 55 )
      @dfa68 = DFA68.new( self, 68 )
      @dfa70 = DFA70.new( self, 70 )
      @dfa74 = DFA74.new( self, 74 )
      @dfa81 = DFA81.new( self, 81 ) do |s|
        case s
        when 0
          look_81_2 = @input.peek
          index_81_2 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( look_81_2 == DOT )
            s = 5
          elsif ( look_81_2 == ROWTYPE_ATTR || look_81_2 == AT_SIGN )
            s = 6
          elsif ( look_81_2 == TYPE_ATTR )
            s = 7
          elsif ( ( ( syntactic_predicate?( :synpred172_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("TIMESTAMP") ) ) ) or ( ( syntactic_predicate?( :synpred172_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("TIME") ) ) ) or ( ( syntactic_predicate?( :synpred172_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("INTERVAL") ) ) ) or ( ( syntactic_predicate?( :synpred172_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("INTERVAL") ) ) ) )
            s = 1
          elsif ( true )
            s = 8
          end
           
          @input.seek( index_81_2 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa81.description, 81, s, input )
          @dfa81.error( nva )
          raise nva
        end
        
        s
      end
      @dfa125 = DFA125.new( self, 125 ) do |s|
        case s
        when 0
          look_125_1 = @input.peek
          index_125_1 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred232_Plsql ) ) and ( (  @input.peek(1) != LPAREN || @input.peek(2) != PLUS || @input.peek(3) != RPAREN  ) ) )
            s = 63
          elsif ( true )
            s = 2
          end
           
          @input.seek( index_125_1 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa125.description, 125, s, input )
          @dfa125.error( nva )
          raise nva
        end
        
        s
      end
      @dfa133 = DFA133.new( self, 133 ) do |s|
        case s
        when 0
          look_133_1 = @input.peek
          index_133_1 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred242_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("REVERSE") ) ) )
            s = 14
          elsif ( true )
            s = 2
          end
           
          @input.seek( index_133_1 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa133.description, 133, s, input )
          @dfa133.error( nva )
          raise nva
        end
        
        s
      end
      @dfa140 = DFA140.new( self, 140 ) do |s|
        case s
        when 0
          look_140_7 = @input.peek
          index_140_7 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred252_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CLOSE") ) ) )
            s = 8
          elsif ( ( syntactic_predicate?( :synpred256_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("OPEN") ) ) )
            s = 9
          end
           
          @input.seek( index_140_7 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa140.description, 140, s, input )
          @dfa140.error( nva )
          raise nva
        end
        
        s
      end
      @dfa141 = DFA141.new( self, 141 ) do |s|
        case s
        when 0
          look_141_1 = @input.peek
          index_141_1 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( not ( (  @is_sql  ) ) )
            s = 8
          elsif ( (  @is_sql  ) )
            s = 2
          end
           
          @input.seek( index_141_1 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa141.description, 141, s, input )
          @dfa141.error( nva )
          raise nva
        end
        
        s
      end
      @dfa157 = DFA157.new( self, 157 ) do |s|
        case s
        when 0
          look_157_34 = @input.peek
          index_157_34 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred278_Plsql ) )
            s = 63
          elsif ( true )
            s = 1
          end
           
          @input.seek( index_157_34 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa157.description, 157, s, input )
          @dfa157.error( nva )
          raise nva
        end
        
        s
      end
      @dfa166 = DFA166.new( self, 166 ) do |s|
        case s
        when 0
          look_166_1 = @input.peek
          index_166_1 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred288_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("PARTITION") ) ) )
            s = 62
          elsif ( true )
            s = 2
          end
           
          @input.seek( index_166_1 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa166.description, 166, s, input )
          @dfa166.error( nva )
          raise nva
        end
        
        s
      end
      @dfa171 = DFA171.new( self, 171 ) do |s|
        case s
        when 0
          look_171_1 = @input.peek
          index_171_1 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred295_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("NOCYCLE") ) ) )
            s = 18
          elsif ( true )
            s = 2
          end
           
          @input.seek( index_171_1 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa171.description, 171, s, input )
          @dfa171.error( nva )
          raise nva
        end
        
        s
      end
      @dfa173 = DFA173.new( self, 173 ) do |s|
        case s
        when 0
          look_173_1 = @input.peek
          index_173_1 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( ( syntactic_predicate?( :synpred297_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("ROLLUP") ) ) ) or ( ( syntactic_predicate?( :synpred297_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CUBE") ) ) ) )
            s = 14
          elsif ( ( syntactic_predicate?( :synpred298_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("GROUPING") ) ) )
            s = 15
          elsif ( true )
            s = 2
          end
           
          @input.seek( index_173_1 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa173.description, 173, s, input )
          @dfa173.error( nva )
          raise nva
        end
        
        s
      end
      @dfa176 = DFA176.new( self, 176 ) do |s|
        case s
        when 0
          look_176_1 = @input.peek
          index_176_1 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( ( syntactic_predicate?( :synpred301_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CUBE") ) ) ) or ( ( syntactic_predicate?( :synpred301_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("ROLLUP") ) ) ) )
            s = 14
          elsif ( true )
            s = 2
          end
           
          @input.seek( index_176_1 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa176.description, 176, s, input )
          @dfa176.error( nva )
          raise nva
        end
        
        s
      end
      @dfa203 = DFA203.new( self, 203 ) do |s|
        case s
        when 0
          look_203_3 = @input.peek
          index_203_3 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred330_Plsql ) )
            s = 1
          elsif ( syntactic_predicate?( :synpred331_Plsql ) )
            s = 19
          end
           
          @input.seek( index_203_3 )

        when 1
          look_203_4 = @input.peek
          index_203_4 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred330_Plsql ) )
            s = 1
          elsif ( syntactic_predicate?( :synpred331_Plsql ) )
            s = 19
          end
           
          @input.seek( index_203_4 )

        when 2
          look_203_5 = @input.peek
          index_203_5 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("UNDER_PATH") ) ) ) or ( ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( syntactic_predicate?( :synpred330_Plsql ) ) or ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("REGEXP_LIKE") ) ) ) or ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("EQUALS_PATH") ) ) ) or ( ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) )
            s = 1
          elsif ( ( ( syntactic_predicate?( :synpred331_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( ( syntactic_predicate?( :synpred331_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( syntactic_predicate?( :synpred331_Plsql ) ) )
            s = 19
          end
           
          @input.seek( index_203_5 )

        when 3
          look_203_6 = @input.peek
          index_203_6 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred330_Plsql ) )
            s = 1
          elsif ( syntactic_predicate?( :synpred331_Plsql ) )
            s = 19
          end
           
          @input.seek( index_203_6 )

        when 4
          look_203_7 = @input.peek
          index_203_7 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred330_Plsql ) )
            s = 1
          elsif ( syntactic_predicate?( :synpred331_Plsql ) )
            s = 19
          end
           
          @input.seek( index_203_7 )

        when 5
          look_203_8 = @input.peek
          index_203_8 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( (  @is_sql  ) ) ) or ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( (  @is_sql  ) ) ) or ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( (  @is_sql  ) ) ) or ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( (  @is_sql  ) ) ) or ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( (  @is_sql  ) ) ) or ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( (  @is_sql  ) ) ) or ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( (  @is_sql  ) ) ) or ( ( syntactic_predicate?( :synpred330_Plsql ) ) and ( (  @is_sql  ) ) ) )
            s = 1
          elsif ( ( syntactic_predicate?( :synpred331_Plsql ) ) and ( (  @is_sql  ) ) )
            s = 19
          end
           
          @input.seek( index_203_8 )

        when 6
          look_203_9 = @input.peek
          index_203_9 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred330_Plsql ) )
            s = 1
          elsif ( syntactic_predicate?( :synpred331_Plsql ) )
            s = 19
          end
           
          @input.seek( index_203_9 )

        when 7
          look_203_10 = @input.peek
          index_203_10 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred330_Plsql ) )
            s = 1
          elsif ( syntactic_predicate?( :synpred331_Plsql ) )
            s = 19
          end
           
          @input.seek( index_203_10 )

        when 8
          look_203_11 = @input.peek
          index_203_11 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred330_Plsql ) )
            s = 1
          elsif ( syntactic_predicate?( :synpred331_Plsql ) )
            s = 19
          end
           
          @input.seek( index_203_11 )

        when 9
          look_203_12 = @input.peek
          index_203_12 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred330_Plsql ) )
            s = 1
          elsif ( syntactic_predicate?( :synpred331_Plsql ) )
            s = 19
          end
           
          @input.seek( index_203_12 )

        when 10
          look_203_13 = @input.peek
          index_203_13 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred330_Plsql ) )
            s = 1
          elsif ( syntactic_predicate?( :synpred331_Plsql ) )
            s = 19
          end
           
          @input.seek( index_203_13 )

        when 11
          look_203_14 = @input.peek
          index_203_14 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred330_Plsql ) )
            s = 1
          elsif ( syntactic_predicate?( :synpred331_Plsql ) )
            s = 19
          end
           
          @input.seek( index_203_14 )

        when 12
          look_203_15 = @input.peek
          index_203_15 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred330_Plsql ) )
            s = 1
          elsif ( syntactic_predicate?( :synpred331_Plsql ) )
            s = 19
          end
           
          @input.seek( index_203_15 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa203.description, 203, s, input )
          @dfa203.error( nva )
          raise nva
        end
        
        s
      end
      @dfa219 = DFA219.new( self, 219 )
      @dfa222 = DFA222.new( self, 222 ) do |s|
        case s
        when 0
          look_222_1 = @input.peek
          index_222_1 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred354_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 15
          elsif ( (  !@is_sql  ) )
            s = 14
          end
           
          @input.seek( index_222_1 )

        when 1
          look_222_2 = @input.peek
          index_222_2 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred354_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 15
          elsif ( (  !@is_sql  ) )
            s = 14
          end
           
          @input.seek( index_222_2 )

        when 2
          look_222_3 = @input.peek
          index_222_3 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( ( syntactic_predicate?( :synpred354_Plsql ) ) and ( (   @is_sql  ) ) ) or ( ( ( syntactic_predicate?( :synpred354_Plsql ) ) and ( (   @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( ( ( syntactic_predicate?( :synpred354_Plsql ) ) and ( (   @is_sql  ) ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) )
            s = 15
          elsif ( ( ( ( (  !@is_sql  ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( (  !@is_sql  ) ) or ( ( (  !@is_sql  ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) )
            s = 14
          end
           
          @input.seek( index_222_3 )

        when 3
          look_222_4 = @input.peek
          index_222_4 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred354_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 15
          elsif ( (  !@is_sql  ) )
            s = 14
          end
           
          @input.seek( index_222_4 )

        when 4
          look_222_5 = @input.peek
          index_222_5 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred354_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 15
          elsif ( (  !@is_sql  ) )
            s = 14
          end
           
          @input.seek( index_222_5 )

        when 5
          look_222_6 = @input.peek
          index_222_6 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( ( syntactic_predicate?( :synpred354_Plsql ) ) and ( (   @is_sql  ) ) ) and ( (  @is_sql  ) ) )
            s = 15
          elsif ( ( (  !@is_sql  ) ) and ( (  @is_sql  ) ) )
            s = 14
          end
           
          @input.seek( index_222_6 )

        when 6
          look_222_7 = @input.peek
          index_222_7 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred354_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 15
          elsif ( (  !@is_sql  ) )
            s = 14
          end
           
          @input.seek( index_222_7 )

        when 7
          look_222_8 = @input.peek
          index_222_8 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred354_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 15
          elsif ( (  !@is_sql  ) )
            s = 14
          end
           
          @input.seek( index_222_8 )

        when 8
          look_222_9 = @input.peek
          index_222_9 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred354_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 15
          elsif ( (  !@is_sql  ) )
            s = 14
          end
           
          @input.seek( index_222_9 )

        when 9
          look_222_10 = @input.peek
          index_222_10 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred354_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 15
          elsif ( (  !@is_sql  ) )
            s = 14
          end
           
          @input.seek( index_222_10 )

        when 10
          look_222_11 = @input.peek
          index_222_11 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred354_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 15
          elsif ( (  !@is_sql  ) )
            s = 14
          end
           
          @input.seek( index_222_11 )

        when 11
          look_222_12 = @input.peek
          index_222_12 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred354_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 15
          elsif ( (  !@is_sql  ) )
            s = 14
          end
           
          @input.seek( index_222_12 )

        when 12
          look_222_13 = @input.peek
          index_222_13 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred354_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 15
          elsif ( (  !@is_sql  ) )
            s = 14
          end
           
          @input.seek( index_222_13 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa222.description, 222, s, input )
          @dfa222.error( nva )
          raise nva
        end
        
        s
      end
      @dfa231 = DFA231.new( self, 231 ) do |s|
        case s
        when 0
          look_231_13 = @input.peek
          index_231_13 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred359_Plsql ) )
            s = 14
          elsif ( true )
            s = 1
          end
           
          @input.seek( index_231_13 )

        when 1
          look_231_2 = @input.peek
          index_231_2 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred359_Plsql ) )
            s = 14
          elsif ( true )
            s = 1
          end
           
          @input.seek( index_231_2 )

        when 2
          look_231_12 = @input.peek
          index_231_12 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred372_Plsql ) )
            s = 23
          elsif ( true )
            s = 1
          end
           
          @input.seek( index_231_12 )

        when 3
          look_231_8 = @input.peek
          index_231_8 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred366_Plsql ) )
            s = 20
          elsif ( true )
            s = 1
          end
           
          @input.seek( index_231_8 )

        when 4
          look_231_9 = @input.peek
          index_231_9 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred368_Plsql ) )
            s = 21
          elsif ( syntactic_predicate?( :synpred370_Plsql ) )
            s = 22
          elsif ( syntactic_predicate?( :synpred372_Plsql ) )
            s = 23
          elsif ( true )
            s = 1
          end
           
          @input.seek( index_231_9 )

        when 5
          look_231_3 = @input.peek
          index_231_3 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred360_Plsql ) )
            s = 15
          elsif ( true )
            s = 1
          end
           
          @input.seek( index_231_3 )

        when 6
          look_231_10 = @input.peek
          index_231_10 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred368_Plsql ) )
            s = 21
          elsif ( true )
            s = 1
          end
           
          @input.seek( index_231_10 )

        when 7
          look_231_5 = @input.peek
          index_231_5 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred362_Plsql ) )
            s = 17
          elsif ( true )
            s = 1
          end
           
          @input.seek( index_231_5 )

        when 8
          look_231_6 = @input.peek
          index_231_6 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred363_Plsql ) )
            s = 18
          elsif ( true )
            s = 1
          end
           
          @input.seek( index_231_6 )

        when 9
          look_231_7 = @input.peek
          index_231_7 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred364_Plsql ) )
            s = 19
          elsif ( true )
            s = 1
          end
           
          @input.seek( index_231_7 )

        when 10
          look_231_11 = @input.peek
          index_231_11 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred370_Plsql ) )
            s = 22
          elsif ( true )
            s = 1
          end
           
          @input.seek( index_231_11 )

        when 11
          look_231_4 = @input.peek
          index_231_4 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred361_Plsql ) )
            s = 16
          elsif ( true )
            s = 1
          end
           
          @input.seek( index_231_4 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa231.description, 231, s, input )
          @dfa231.error( nva )
          raise nva
        end
        
        s
      end
      @dfa237 = DFA237.new( self, 237 ) do |s|
        case s
        when 0
          look_237_4 = @input.peek
          index_237_4 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred384_Plsql ) )
            s = 5
          elsif ( syntactic_predicate?( :synpred387_Plsql ) )
            s = 11
          end
           
          @input.seek( index_237_4 )

        when 1
          look_237_2 = @input.peek
          index_237_2 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( look_237_2 == LPAREN ) and ( syntactic_predicate?( :synpred386_Plsql ) )
            s = 13
          elsif ( ( syntactic_predicate?( :synpred384_Plsql ) ) or ( ( ( syntactic_predicate?( :synpred384_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) )
            s = 5
          elsif ( syntactic_predicate?( :synpred387_Plsql ) )
            s = 11
          end
           
          @input.seek( index_237_2 )

        when 2
          look_237_3 = @input.peek
          index_237_3 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred384_Plsql ) )
            s = 5
          elsif ( syntactic_predicate?( :synpred387_Plsql ) )
            s = 11
          end
           
          @input.seek( index_237_3 )

        when 3
          look_237_0 = @input.peek
          index_237_0 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( look_237_0 == LPAREN ) and ( syntactic_predicate?( :synpred383_Plsql ) )
            s = 1
          elsif ( look_237_0 == ID )
            s = 2
          elsif ( look_237_0 == T__100 )
            s = 3
          elsif ( look_237_0 == DOUBLEQUOTED_STRING )
            s = 4
          elsif ( look_237_0 == T__117 ) and ( syntactic_predicate?( :synpred384_Plsql ) )
            s = 5
          elsif ( look_237_0 == T__142 ) and ( syntactic_predicate?( :synpred385_Plsql ) )
            s = 6
          elsif ( look_237_0.between?( T__110, T__111 ) ) and ( syntactic_predicate?( :synpred387_Plsql ) )
            s = 7
          elsif ( look_237_0 == T__140 ) and ( syntactic_predicate?( :synpred387_Plsql ) )
            s = 8
          elsif ( look_237_0 == QUOTED_STRING ) and ( syntactic_predicate?( :synpred387_Plsql ) )
            s = 9
          elsif ( look_237_0 == NUMBER ) and ( syntactic_predicate?( :synpred387_Plsql ) )
            s = 10
          elsif ( look_237_0 == T__58 ) and ( syntactic_predicate?( :synpred387_Plsql ) )
            s = 11
          elsif ( look_237_0 == T__116 ) and ( syntactic_predicate?( :synpred388_Plsql ) )
            s = 12
          end
           
          @input.seek( index_237_0 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa237.description, 237, s, input )
          @dfa237.error( nva )
          raise nva
        end
        
        s
      end
      @dfa253 = DFA253.new( self, 253 ) do |s|
        case s
        when 0
          look_253_1 = @input.peek
          index_253_1 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred415_Plsql ) )
            s = 15
          elsif ( ( (  !@is_sql  ) ) or ( (   @is_sql  ) ) )
            s = 2
          end
           
          @input.seek( index_253_1 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa253.description, 253, s, input )
          @dfa253.error( nva )
          raise nva
        end
        
        s
      end
      @dfa266 = DFA266.new( self, 266 )
      @dfa277 = DFA277.new( self, 277 ) do |s|
        case s
        when 0
          look_277_1 = @input.peek
          index_277_1 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 2
          elsif ( (  !@is_sql  ) )
            s = 18
          end
           
          @input.seek( index_277_1 )

        when 1
          look_277_3 = @input.peek
          index_277_3 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 2
          elsif ( (  !@is_sql  ) )
            s = 18
          end
           
          @input.seek( index_277_3 )

        when 2
          look_277_4 = @input.peek
          index_277_4 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 2
          elsif ( (  !@is_sql  ) )
            s = 18
          end
           
          @input.seek( index_277_4 )

        when 3
          look_277_5 = @input.peek
          index_277_5 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("EQUALS_PATH") ) ) ) or ( ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("REGEXP_LIKE") ) ) ) or ( ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) or ( ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("UNDER_PATH") ) ) ) or ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) )
            s = 2
          elsif ( ( ( (  !@is_sql  ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( (  !@is_sql  ) ) or ( ( ( (  !@is_sql  ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) )
            s = 18
          end
           
          @input.seek( index_277_5 )

        when 4
          look_277_6 = @input.peek
          index_277_6 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 2
          elsif ( (  !@is_sql  ) )
            s = 18
          end
           
          @input.seek( index_277_6 )

        when 5
          look_277_7 = @input.peek
          index_277_7 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 2
          elsif ( (  !@is_sql  ) )
            s = 18
          end
           
          @input.seek( index_277_7 )

        when 6
          look_277_8 = @input.peek
          index_277_8 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( (  @is_sql  ) ) ) or ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( (  @is_sql  ) ) ) or ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( (  @is_sql  ) ) ) or ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( (  @is_sql  ) ) ) or ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( (  @is_sql  ) ) ) or ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( (  @is_sql  ) ) ) or ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( (  @is_sql  ) ) ) or ( ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) ) and ( (  @is_sql  ) ) ) )
            s = 2
          elsif ( ( (  !@is_sql  ) ) and ( (  @is_sql  ) ) )
            s = 18
          end
           
          @input.seek( index_277_8 )

        when 7
          look_277_9 = @input.peek
          index_277_9 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 2
          elsif ( (  !@is_sql  ) )
            s = 18
          end
           
          @input.seek( index_277_9 )

        when 8
          look_277_10 = @input.peek
          index_277_10 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 2
          elsif ( (  !@is_sql  ) )
            s = 18
          end
           
          @input.seek( index_277_10 )

        when 9
          look_277_11 = @input.peek
          index_277_11 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 2
          elsif ( (  !@is_sql  ) )
            s = 18
          end
           
          @input.seek( index_277_11 )

        when 10
          look_277_12 = @input.peek
          index_277_12 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 2
          elsif ( (  !@is_sql  ) )
            s = 18
          end
           
          @input.seek( index_277_12 )

        when 11
          look_277_13 = @input.peek
          index_277_13 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 2
          elsif ( (  !@is_sql  ) )
            s = 18
          end
           
          @input.seek( index_277_13 )

        when 12
          look_277_14 = @input.peek
          index_277_14 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 2
          elsif ( (  !@is_sql  ) )
            s = 18
          end
           
          @input.seek( index_277_14 )

        when 13
          look_277_15 = @input.peek
          index_277_15 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred440_Plsql ) ) and ( (   @is_sql  ) ) )
            s = 2
          elsif ( (  !@is_sql  ) )
            s = 18
          end
           
          @input.seek( index_277_15 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa277.description, 277, s, input )
          @dfa277.error( nva )
          raise nva
        end
        
        s
      end
      @dfa281 = DFA281.new( self, 281 ) do |s|
        case s
        when 0
          look_281_2 = @input.peek
          index_281_2 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred445_Plsql ) )
            s = 17
          elsif ( syntactic_predicate?( :synpred446_Plsql ) )
            s = 15
          elsif ( syntactic_predicate?( :synpred447_Plsql ) )
            s = 18
          elsif ( syntactic_predicate?( :synpred448_Plsql ) )
            s = 19
          elsif ( syntactic_predicate?( :synpred452_Plsql ) )
            s = 20
          elsif ( syntactic_predicate?( :synpred454_Plsql ) )
            s = 21
          elsif ( syntactic_predicate?( :synpred455_Plsql ) )
            s = 22
          elsif ( syntactic_predicate?( :synpred456_Plsql ) )
            s = 23
          end
           
          @input.seek( index_281_2 )

        when 1
          look_281_3 = @input.peek
          index_281_3 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred445_Plsql ) )
            s = 17
          elsif ( syntactic_predicate?( :synpred446_Plsql ) )
            s = 15
          elsif ( syntactic_predicate?( :synpred447_Plsql ) )
            s = 18
          elsif ( syntactic_predicate?( :synpred448_Plsql ) )
            s = 19
          elsif ( syntactic_predicate?( :synpred452_Plsql ) )
            s = 20
          elsif ( syntactic_predicate?( :synpred454_Plsql ) )
            s = 21
          elsif ( syntactic_predicate?( :synpred455_Plsql ) )
            s = 22
          elsif ( syntactic_predicate?( :synpred456_Plsql ) )
            s = 23
          elsif ( true )
            s = 24
          end
           
          @input.seek( index_281_3 )

        when 2
          look_281_4 = @input.peek
          index_281_4 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred445_Plsql ) ) or ( ( ( syntactic_predicate?( :synpred445_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( syntactic_predicate?( :synpred445_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) )
            s = 17
          elsif ( ( ( syntactic_predicate?( :synpred446_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( syntactic_predicate?( :synpred446_Plsql ) ) or ( ( ( syntactic_predicate?( :synpred446_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) )
            s = 15
          elsif ( ( syntactic_predicate?( :synpred447_Plsql ) ) or ( ( syntactic_predicate?( :synpred447_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( ( syntactic_predicate?( :synpred447_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) )
            s = 18
          elsif ( ( ( ( syntactic_predicate?( :synpred448_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( syntactic_predicate?( :synpred448_Plsql ) ) or ( ( syntactic_predicate?( :synpred448_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) )
            s = 19
          elsif ( syntactic_predicate?( :synpred449_Plsql ) )
            s = 25
          elsif ( syntactic_predicate?( :synpred450_Plsql ) )
            s = 16
          elsif ( syntactic_predicate?( :synpred451_Plsql ) )
            s = 26
          elsif ( ( ( ( syntactic_predicate?( :synpred452_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( syntactic_predicate?( :synpred452_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( syntactic_predicate?( :synpred452_Plsql ) ) )
            s = 20
          elsif ( syntactic_predicate?( :synpred453_Plsql ) )
            s = 27
          elsif ( ( ( ( syntactic_predicate?( :synpred454_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( syntactic_predicate?( :synpred454_Plsql ) ) or ( ( syntactic_predicate?( :synpred454_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) )
            s = 21
          elsif ( ( ( syntactic_predicate?( :synpred455_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( ( syntactic_predicate?( :synpred455_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( syntactic_predicate?( :synpred455_Plsql ) ) )
            s = 22
          elsif ( ( ( syntactic_predicate?( :synpred456_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( ( syntactic_predicate?( :synpred456_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( syntactic_predicate?( :synpred456_Plsql ) ) )
            s = 23
          elsif ( ( syntactic_predicate?( :synpred457_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("REGEXP_LIKE") ) ) )
            s = 28
          elsif ( syntactic_predicate?( :synpred458_Plsql ) )
            s = 29
          elsif ( ( syntactic_predicate?( :synpred459_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("EQUALS_PATH") ) ) )
            s = 30
          elsif ( ( syntactic_predicate?( :synpred460_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("UNDER_PATH") ) ) )
            s = 31
          end
           
          @input.seek( index_281_4 )

        when 3
          look_281_5 = @input.peek
          index_281_5 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred445_Plsql ) )
            s = 17
          elsif ( syntactic_predicate?( :synpred446_Plsql ) )
            s = 15
          elsif ( syntactic_predicate?( :synpred447_Plsql ) )
            s = 18
          elsif ( syntactic_predicate?( :synpred448_Plsql ) )
            s = 19
          elsif ( syntactic_predicate?( :synpred449_Plsql ) )
            s = 25
          elsif ( syntactic_predicate?( :synpred450_Plsql ) )
            s = 16
          elsif ( syntactic_predicate?( :synpred451_Plsql ) )
            s = 26
          elsif ( syntactic_predicate?( :synpred452_Plsql ) )
            s = 20
          elsif ( syntactic_predicate?( :synpred453_Plsql ) )
            s = 27
          elsif ( syntactic_predicate?( :synpred454_Plsql ) )
            s = 21
          elsif ( syntactic_predicate?( :synpred455_Plsql ) )
            s = 22
          elsif ( syntactic_predicate?( :synpred456_Plsql ) )
            s = 23
          elsif ( syntactic_predicate?( :synpred458_Plsql ) )
            s = 29
          end
           
          @input.seek( index_281_5 )

        when 4
          look_281_6 = @input.peek
          index_281_6 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred445_Plsql ) )
            s = 17
          elsif ( syntactic_predicate?( :synpred446_Plsql ) )
            s = 15
          elsif ( syntactic_predicate?( :synpred447_Plsql ) )
            s = 18
          elsif ( syntactic_predicate?( :synpred448_Plsql ) )
            s = 19
          elsif ( syntactic_predicate?( :synpred449_Plsql ) )
            s = 25
          elsif ( syntactic_predicate?( :synpred450_Plsql ) )
            s = 16
          elsif ( syntactic_predicate?( :synpred451_Plsql ) )
            s = 26
          elsif ( syntactic_predicate?( :synpred452_Plsql ) )
            s = 20
          elsif ( syntactic_predicate?( :synpred453_Plsql ) )
            s = 27
          elsif ( syntactic_predicate?( :synpred454_Plsql ) )
            s = 21
          elsif ( syntactic_predicate?( :synpred455_Plsql ) )
            s = 22
          elsif ( syntactic_predicate?( :synpred456_Plsql ) )
            s = 23
          elsif ( syntactic_predicate?( :synpred458_Plsql ) )
            s = 29
          end
           
          @input.seek( index_281_6 )

        when 5
          look_281_7 = @input.peek
          index_281_7 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( syntactic_predicate?( :synpred445_Plsql ) ) and ( (  @is_sql  ) ) )
            s = 17
          elsif ( ( syntactic_predicate?( :synpred446_Plsql ) ) and ( (  @is_sql  ) ) )
            s = 15
          elsif ( ( syntactic_predicate?( :synpred447_Plsql ) ) and ( (  @is_sql  ) ) )
            s = 18
          elsif ( ( syntactic_predicate?( :synpred448_Plsql ) ) and ( (  @is_sql  ) ) )
            s = 19
          elsif ( ( syntactic_predicate?( :synpred452_Plsql ) ) and ( (  @is_sql  ) ) )
            s = 20
          elsif ( ( syntactic_predicate?( :synpred454_Plsql ) ) and ( (  @is_sql  ) ) )
            s = 21
          elsif ( ( syntactic_predicate?( :synpred455_Plsql ) ) and ( (  @is_sql  ) ) )
            s = 22
          elsif ( ( syntactic_predicate?( :synpred456_Plsql ) ) and ( (  @is_sql  ) ) )
            s = 23
          end
           
          @input.seek( index_281_7 )

        when 6
          look_281_8 = @input.peek
          index_281_8 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred445_Plsql ) )
            s = 17
          elsif ( syntactic_predicate?( :synpred446_Plsql ) )
            s = 15
          elsif ( syntactic_predicate?( :synpred447_Plsql ) )
            s = 18
          elsif ( syntactic_predicate?( :synpred448_Plsql ) )
            s = 19
          elsif ( syntactic_predicate?( :synpred452_Plsql ) )
            s = 20
          elsif ( syntactic_predicate?( :synpred454_Plsql ) )
            s = 21
          elsif ( syntactic_predicate?( :synpred455_Plsql ) )
            s = 22
          elsif ( syntactic_predicate?( :synpred456_Plsql ) )
            s = 23
          end
           
          @input.seek( index_281_8 )

        when 7
          look_281_9 = @input.peek
          index_281_9 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred445_Plsql ) )
            s = 17
          elsif ( syntactic_predicate?( :synpred446_Plsql ) )
            s = 15
          elsif ( syntactic_predicate?( :synpred447_Plsql ) )
            s = 18
          elsif ( syntactic_predicate?( :synpred448_Plsql ) )
            s = 19
          elsif ( syntactic_predicate?( :synpred452_Plsql ) )
            s = 20
          elsif ( syntactic_predicate?( :synpred454_Plsql ) )
            s = 21
          elsif ( syntactic_predicate?( :synpred455_Plsql ) )
            s = 22
          elsif ( syntactic_predicate?( :synpred456_Plsql ) )
            s = 23
          end
           
          @input.seek( index_281_9 )

        when 8
          look_281_10 = @input.peek
          index_281_10 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred445_Plsql ) )
            s = 17
          elsif ( syntactic_predicate?( :synpred446_Plsql ) )
            s = 15
          elsif ( syntactic_predicate?( :synpred447_Plsql ) )
            s = 18
          elsif ( syntactic_predicate?( :synpred448_Plsql ) )
            s = 19
          elsif ( syntactic_predicate?( :synpred452_Plsql ) )
            s = 20
          elsif ( syntactic_predicate?( :synpred454_Plsql ) )
            s = 21
          elsif ( syntactic_predicate?( :synpred455_Plsql ) )
            s = 22
          elsif ( syntactic_predicate?( :synpred456_Plsql ) )
            s = 23
          end
           
          @input.seek( index_281_10 )

        when 9
          look_281_11 = @input.peek
          index_281_11 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred445_Plsql ) )
            s = 17
          elsif ( syntactic_predicate?( :synpred446_Plsql ) )
            s = 15
          elsif ( syntactic_predicate?( :synpred447_Plsql ) )
            s = 18
          elsif ( syntactic_predicate?( :synpred448_Plsql ) )
            s = 19
          elsif ( syntactic_predicate?( :synpred452_Plsql ) )
            s = 20
          elsif ( syntactic_predicate?( :synpred454_Plsql ) )
            s = 21
          elsif ( syntactic_predicate?( :synpred455_Plsql ) )
            s = 22
          elsif ( syntactic_predicate?( :synpred456_Plsql ) )
            s = 23
          end
           
          @input.seek( index_281_11 )

        when 10
          look_281_12 = @input.peek
          index_281_12 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred445_Plsql ) )
            s = 17
          elsif ( syntactic_predicate?( :synpred446_Plsql ) )
            s = 15
          elsif ( syntactic_predicate?( :synpred447_Plsql ) )
            s = 18
          elsif ( syntactic_predicate?( :synpred448_Plsql ) )
            s = 19
          elsif ( syntactic_predicate?( :synpred452_Plsql ) )
            s = 20
          elsif ( syntactic_predicate?( :synpred454_Plsql ) )
            s = 21
          elsif ( syntactic_predicate?( :synpred455_Plsql ) )
            s = 22
          elsif ( syntactic_predicate?( :synpred456_Plsql ) )
            s = 23
          end
           
          @input.seek( index_281_12 )

        when 11
          look_281_13 = @input.peek
          index_281_13 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred445_Plsql ) )
            s = 17
          elsif ( syntactic_predicate?( :synpred446_Plsql ) )
            s = 15
          elsif ( syntactic_predicate?( :synpred447_Plsql ) )
            s = 18
          elsif ( syntactic_predicate?( :synpred448_Plsql ) )
            s = 19
          elsif ( syntactic_predicate?( :synpred452_Plsql ) )
            s = 20
          elsif ( syntactic_predicate?( :synpred454_Plsql ) )
            s = 21
          elsif ( syntactic_predicate?( :synpred455_Plsql ) )
            s = 22
          elsif ( syntactic_predicate?( :synpred456_Plsql ) )
            s = 23
          end
           
          @input.seek( index_281_13 )

        when 12
          look_281_14 = @input.peek
          index_281_14 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred445_Plsql ) )
            s = 17
          elsif ( syntactic_predicate?( :synpred446_Plsql ) )
            s = 15
          elsif ( syntactic_predicate?( :synpred447_Plsql ) )
            s = 18
          elsif ( syntactic_predicate?( :synpred448_Plsql ) )
            s = 19
          elsif ( syntactic_predicate?( :synpred452_Plsql ) )
            s = 20
          elsif ( syntactic_predicate?( :synpred454_Plsql ) )
            s = 21
          elsif ( syntactic_predicate?( :synpred455_Plsql ) )
            s = 22
          elsif ( syntactic_predicate?( :synpred456_Plsql ) )
            s = 23
          end
           
          @input.seek( index_281_14 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa281.description, 281, s, input )
          @dfa281.error( nva )
          raise nva
        end
        
        s
      end
      @dfa291 = DFA291.new( self, 291 ) do |s|
        case s
        when 0
          look_291_1 = @input.peek
          index_291_1 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred467_Plsql ) )
            s = 15
          elsif ( true )
            s = 2
          end
           
          @input.seek( index_291_1 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa291.description, 291, s, input )
          @dfa291.error( nva )
          raise nva
        end
        
        s
      end
      @dfa289 = DFA289.new( self, 289 ) do |s|
        case s
        when 0
          look_289_2 = @input.peek
          index_289_2 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred476_Plsql ) )
            s = 1
          elsif ( true )
            s = 14
          end
           
          @input.seek( index_289_2 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa289.description, 289, s, input )
          @dfa289.error( nva )
          raise nva
        end
        
        s
      end
      @dfa296 = DFA296.new( self, 296 ) do |s|
        case s
        when 0
          look_296_1 = @input.peek
          index_296_1 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred482_Plsql ) )
            s = 14
          elsif ( true )
            s = 2
          end
           
          @input.seek( index_296_1 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa296.description, 296, s, input )
          @dfa296.error( nva )
          raise nva
        end
        
        s
      end
      @dfa293 = DFA293.new( self, 293 ) do |s|
        case s
        when 0
          look_293_13 = @input.peek
          index_293_13 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred481_Plsql ) )
            s = 1
          elsif ( true )
            s = 14
          end
           
          @input.seek( index_293_13 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa293.description, 293, s, input )
          @dfa293.error( nva )
          raise nva
        end
        
        s
      end
      @dfa295 = DFA295.new( self, 295 ) do |s|
        case s
        when 0
          look_295_13 = @input.peek
          index_295_13 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred490_Plsql ) )
            s = 1
          elsif ( true )
            s = 14
          end
           
          @input.seek( index_295_13 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa295.description, 295, s, input )
          @dfa295.error( nva )
          raise nva
        end
        
        s
      end
      @dfa301 = DFA301.new( self, 301 ) do |s|
        case s
        when 0
          look_301_1 = @input.peek
          index_301_1 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred493_Plsql ) )
            s = 14
          elsif ( true )
            s = 2
          end
           
          @input.seek( index_301_1 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa301.description, 301, s, input )
          @dfa301.error( nva )
          raise nva
        end
        
        s
      end
      @dfa298 = DFA298.new( self, 298 ) do |s|
        case s
        when 0
          look_298_13 = @input.peek
          index_298_13 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred492_Plsql ) )
            s = 1
          elsif ( true )
            s = 14
          end
           
          @input.seek( index_298_13 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa298.description, 298, s, input )
          @dfa298.error( nva )
          raise nva
        end
        
        s
      end
      @dfa300 = DFA300.new( self, 300 ) do |s|
        case s
        when 0
          look_300_13 = @input.peek
          index_300_13 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred495_Plsql ) )
            s = 1
          elsif ( true )
            s = 14
          end
           
          @input.seek( index_300_13 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa300.description, 300, s, input )
          @dfa300.error( nva )
          raise nva
        end
        
        s
      end
      @dfa321 = DFA321.new( self, 321 ) do |s|
        case s
        when 0
          look_321_1 = @input.peek
          index_321_1 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred517_Plsql ) )
            s = 14
          elsif ( true )
            s = 2
          end
           
          @input.seek( index_321_1 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa321.description, 321, s, input )
          @dfa321.error( nva )
          raise nva
        end
        
        s
      end
      @dfa324 = DFA324.new( self, 324 ) do |s|
        case s
        when 0
          look_324_0 = @input.peek
          index_324_0 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( look_324_0.between?( PLUS, MINUS ) ) and ( syntactic_predicate?( :synpred525_Plsql ) )
            s = 1
          elsif ( look_324_0 == LPAREN )
            s = 2
          elsif ( look_324_0 == ID ) and ( syntactic_predicate?( :synpred525_Plsql ) )
            s = 3
          elsif ( look_324_0 == T__100 ) and ( syntactic_predicate?( :synpred525_Plsql ) )
            s = 4
          elsif ( look_324_0 == DOUBLEQUOTED_STRING ) and ( syntactic_predicate?( :synpred525_Plsql ) )
            s = 5
          elsif ( look_324_0 == T__117 ) and ( syntactic_predicate?( :synpred525_Plsql ) )
            s = 6
          elsif ( look_324_0 == T__142 ) and ( syntactic_predicate?( :synpred525_Plsql ) )
            s = 7
          elsif ( look_324_0.between?( T__110, T__111 ) ) and ( syntactic_predicate?( :synpred525_Plsql ) )
            s = 8
          elsif ( look_324_0 == T__140 ) and ( syntactic_predicate?( :synpred525_Plsql ) )
            s = 9
          elsif ( look_324_0 == QUOTED_STRING ) and ( syntactic_predicate?( :synpred525_Plsql ) )
            s = 10
          elsif ( look_324_0 == NUMBER ) and ( syntactic_predicate?( :synpred525_Plsql ) )
            s = 11
          elsif ( look_324_0 == T__58 ) and ( syntactic_predicate?( :synpred525_Plsql ) )
            s = 12
          elsif ( look_324_0 == T__116 ) and ( syntactic_predicate?( :synpred525_Plsql ) )
            s = 13
          end
           
          @input.seek( index_324_0 )

        when 1
          look_324_2 = @input.peek
          index_324_2 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred525_Plsql ) )
            s = 13
          elsif ( true )
            s = 14
          end
           
          @input.seek( index_324_2 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa324.description, 324, s, input )
          @dfa324.error( nva )
          raise nva
        end
        
        s
      end
      @dfa330 = DFA330.new( self, 330 ) do |s|
        case s
        when 0
          look_330_0 = @input.peek
          index_330_0 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( look_330_0 == T__141 ) and ( syntactic_predicate?( :synpred529_Plsql ) )
            s = 1
          elsif ( look_330_0 == T__57 ) and ( syntactic_predicate?( :synpred529_Plsql ) )
            s = 2
          elsif ( look_330_0 == T__144 ) and ( syntactic_predicate?( :synpred529_Plsql ) )
            s = 3
          elsif ( look_330_0.between?( PLUS, MINUS ) )
            s = 4
          elsif ( look_330_0 == LPAREN )
            s = 5
          elsif ( look_330_0 == ID )
            s = 6
          elsif ( look_330_0 == T__100 )
            s = 7
          elsif ( look_330_0 == DOUBLEQUOTED_STRING )
            s = 8
          elsif ( look_330_0 == T__117 )
            s = 9
          elsif ( look_330_0 == T__142 )
            s = 10
          elsif ( look_330_0.between?( T__110, T__111 ) )
            s = 11
          elsif ( look_330_0 == T__140 )
            s = 12
          elsif ( look_330_0 == QUOTED_STRING )
            s = 13
          elsif ( look_330_0 == NUMBER )
            s = 14
          elsif ( look_330_0 == T__58 )
            s = 15
          elsif ( look_330_0 == T__116 )
            s = 16
          elsif ( look_330_0 == T__146 ) and ( syntactic_predicate?( :synpred529_Plsql ) )
            s = 17
          end
           
          @input.seek( index_330_0 )

        when 1
          look_330_4 = @input.peek
          index_330_4 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred529_Plsql ) )
            s = 17
          elsif ( true )
            s = 18
          end
           
          @input.seek( index_330_4 )

        when 2
          look_330_5 = @input.peek
          index_330_5 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred529_Plsql ) )
            s = 17
          elsif ( true )
            s = 18
          end
           
          @input.seek( index_330_5 )

        when 3
          look_330_6 = @input.peek
          index_330_6 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("UNDER_PATH") ) ) ) or ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("EQUALS_PATH") ) ) ) or ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("REGEXP_LIKE") ) ) ) or ( ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( ( self.input.look(1).text.upcase == ("CURSOR") ) ) ) or ( syntactic_predicate?( :synpred529_Plsql ) ) or ( ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) or ( ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( (  @is_sql  ) ) ) and ( ( self.input.look(1).text.upcase == ("COUNT") ) ) ) )
            s = 17
          elsif ( true )
            s = 18
          end
           
          @input.seek( index_330_6 )

        when 4
          look_330_7 = @input.peek
          index_330_7 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred529_Plsql ) )
            s = 17
          elsif ( true )
            s = 18
          end
           
          @input.seek( index_330_7 )

        when 5
          look_330_8 = @input.peek
          index_330_8 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred529_Plsql ) )
            s = 17
          elsif ( true )
            s = 18
          end
           
          @input.seek( index_330_8 )

        when 6
          look_330_9 = @input.peek
          index_330_9 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( (  @is_sql  ) ) ) or ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( (  @is_sql  ) ) ) or ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( (  @is_sql  ) ) ) or ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( (  @is_sql  ) ) ) or ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( (  @is_sql  ) ) ) or ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( (  @is_sql  ) ) ) or ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( (  @is_sql  ) ) ) or ( ( syntactic_predicate?( :synpred529_Plsql ) ) and ( (  @is_sql  ) ) ) )
            s = 17
          elsif ( (  @is_sql  ) )
            s = 18
          end
           
          @input.seek( index_330_9 )

        when 7
          look_330_10 = @input.peek
          index_330_10 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred529_Plsql ) )
            s = 17
          elsif ( true )
            s = 18
          end
           
          @input.seek( index_330_10 )

        when 8
          look_330_11 = @input.peek
          index_330_11 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred529_Plsql ) )
            s = 17
          elsif ( true )
            s = 18
          end
           
          @input.seek( index_330_11 )

        when 9
          look_330_12 = @input.peek
          index_330_12 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred529_Plsql ) )
            s = 17
          elsif ( true )
            s = 18
          end
           
          @input.seek( index_330_12 )

        when 10
          look_330_13 = @input.peek
          index_330_13 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred529_Plsql ) )
            s = 17
          elsif ( true )
            s = 18
          end
           
          @input.seek( index_330_13 )

        when 11
          look_330_14 = @input.peek
          index_330_14 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred529_Plsql ) )
            s = 17
          elsif ( true )
            s = 18
          end
           
          @input.seek( index_330_14 )

        when 12
          look_330_15 = @input.peek
          index_330_15 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred529_Plsql ) )
            s = 17
          elsif ( true )
            s = 18
          end
           
          @input.seek( index_330_15 )

        when 13
          look_330_16 = @input.peek
          index_330_16 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred529_Plsql ) )
            s = 17
          elsif ( true )
            s = 18
          end
           
          @input.seek( index_330_16 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa330.description, 330, s, input )
          @dfa330.error( nva )
          raise nva
        end
        
        s
      end
      @dfa336 = DFA336.new( self, 336 ) do |s|
        case s
        when 0
          look_336_0 = @input.peek
          index_336_0 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( look_336_0.between?( PLUS, MINUS ) ) and ( syntactic_predicate?( :synpred539_Plsql ) )
            s = 1
          elsif ( look_336_0 == LPAREN ) and ( syntactic_predicate?( :synpred539_Plsql ) )
            s = 2
          elsif ( look_336_0 == ID ) and ( syntactic_predicate?( :synpred539_Plsql ) )
            s = 3
          elsif ( look_336_0 == T__100 ) and ( syntactic_predicate?( :synpred539_Plsql ) )
            s = 4
          elsif ( look_336_0 == DOUBLEQUOTED_STRING ) and ( syntactic_predicate?( :synpred539_Plsql ) )
            s = 5
          elsif ( look_336_0 == T__117 ) and ( syntactic_predicate?( :synpred539_Plsql ) )
            s = 6
          elsif ( look_336_0 == T__142 ) and ( syntactic_predicate?( :synpred539_Plsql ) )
            s = 7
          elsif ( look_336_0.between?( T__110, T__111 ) ) and ( syntactic_predicate?( :synpred539_Plsql ) )
            s = 8
          elsif ( look_336_0 == T__140 ) and ( syntactic_predicate?( :synpred539_Plsql ) )
            s = 9
          elsif ( look_336_0 == QUOTED_STRING ) and ( syntactic_predicate?( :synpred539_Plsql ) )
            s = 10
          elsif ( look_336_0 == NUMBER )
            s = 11
          elsif ( look_336_0 == T__58 ) and ( syntactic_predicate?( :synpred539_Plsql ) )
            s = 12
          elsif ( look_336_0 == T__116 ) and ( syntactic_predicate?( :synpred539_Plsql ) )
            s = 13
          end
           
          @input.seek( index_336_0 )

        when 1
          look_336_11 = @input.peek
          index_336_11 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred539_Plsql ) )
            s = 13
          elsif ( syntactic_predicate?( :synpred540_Plsql ) )
            s = 14
          end
           
          @input.seek( index_336_11 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa336.description, 336, s, input )
          @dfa336.error( nva )
          raise nva
        end
        
        s
      end
      @dfa460 = DFA460.new( self, 460 ) do |s|
        case s
        when 0
          look_460_13 = @input.peek
          index_460_13 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred481_Plsql ) )
            s = 1
          elsif ( true )
            s = 14
          end
           
          @input.seek( index_460_13 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa460.description, 460, s, input )
          @dfa460.error( nva )
          raise nva
        end
        
        s
      end
      @dfa462 = DFA462.new( self, 462 ) do |s|
        case s
        when 0
          look_462_13 = @input.peek
          index_462_13 = @input.index
          @input.rewind( @input.last_marker, false )
          s = -1
          if ( syntactic_predicate?( :synpred492_Plsql ) )
            s = 1
          elsif ( true )
            s = 14
          end
           
          @input.seek( index_462_13 )

        end
        
        if s < 0
          @state.backtracking > 0 and raise ANTLR3::Error::BacktrackingFailed
          nva = ANTLR3::Error::NoViableAlternative.new( @dfa462.description, 462, s, input )
          @dfa462.error( nva )
          raise nva
        end
        
        s
      end

    end
    TOKENS_FOLLOWING_create_package_IN_start_rule_58 = Set[ 50 ]
    TOKENS_FOLLOWING_EOF_IN_start_rule_62 = Set[ 1 ]
    TOKENS_FOLLOWING_T__50_IN_create_package_73 = Set[ 51, 160 ]
    TOKENS_FOLLOWING_T__51_IN_create_package_77 = Set[ 40 ]
    TOKENS_FOLLOWING_keyREPLACE_IN_create_package_79 = Set[ 51, 160 ]
    TOKENS_FOLLOWING_package_spec_IN_create_package_88 = Set[ 1 ]
    TOKENS_FOLLOWING_package_body_IN_create_package_92 = Set[ 1 ]
    TOKENS_FOLLOWING_keyPACKAGE_IN_package_spec_106 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_package_name_IN_package_spec_108 = Set[ 52, 53 ]
    TOKENS_FOLLOWING_set_IN_package_spec_110 = Set[ 40, 41, 54, 103, 104, 161 ]
    TOKENS_FOLLOWING_package_obj_spec_IN_package_spec_125 = Set[ 40, 41, 54, 103, 104, 161 ]
    TOKENS_FOLLOWING_T__54_IN_package_spec_132 = Set[ 4, 40, 41, 100 ]
    TOKENS_FOLLOWING_package_name_IN_package_spec_135 = Set[ 4 ]
    TOKENS_FOLLOWING_SEMI_IN_package_spec_139 = Set[ 1 ]
    TOKENS_FOLLOWING_keyPACKAGE_IN_package_body_151 = Set[ 40 ]
    TOKENS_FOLLOWING_keyBODY_IN_package_body_155 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_package_name_IN_package_body_159 = Set[ 52, 53 ]
    TOKENS_FOLLOWING_set_IN_package_body_161 = Set[ 40, 41, 50, 54, 55, 103, 104, 161 ]
    TOKENS_FOLLOWING_package_obj_body_IN_package_body_175 = Set[ 40, 41, 50, 54, 55, 103, 104, 161 ]
    TOKENS_FOLLOWING_T__55_IN_package_body_184 = Set[ 10, 17, 40, 41, 50, 55, 58, 60, 62, 87, 100, 103, 104, 112, 113, 114, 116, 132, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_seq_of_statements_IN_package_body_186 = Set[ 54 ]
    TOKENS_FOLLOWING_T__54_IN_package_body_195 = Set[ 4, 40, 41, 100 ]
    TOKENS_FOLLOWING_package_name_IN_package_body_199 = Set[ 4 ]
    TOKENS_FOLLOWING_SEMI_IN_package_body_204 = Set[ 1 ]
    TOKENS_FOLLOWING_schema_name_IN_package_name_217 = Set[ 5 ]
    TOKENS_FOLLOWING_DOT_IN_package_name_219 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_identifier_IN_package_name_224 = Set[ 1 ]
    TOKENS_FOLLOWING_variable_declaration_IN_package_obj_spec_236 = Set[ 1 ]
    TOKENS_FOLLOWING_type_declaration_IN_package_obj_spec_242 = Set[ 1 ]
    TOKENS_FOLLOWING_subtype_declaration_IN_package_obj_spec_247 = Set[ 1 ]
    TOKENS_FOLLOWING_record_declaration_IN_package_obj_spec_253 = Set[ 1 ]
    TOKENS_FOLLOWING_plsql_table_declaration_IN_package_obj_spec_259 = Set[ 1 ]
    TOKENS_FOLLOWING_varray_declaration_IN_package_obj_spec_265 = Set[ 1 ]
    TOKENS_FOLLOWING_cursor_declaration_IN_package_obj_spec_270 = Set[ 1 ]
    TOKENS_FOLLOWING_cursor_spec_IN_package_obj_spec_276 = Set[ 1 ]
    TOKENS_FOLLOWING_procedure_spec_IN_package_obj_spec_282 = Set[ 1 ]
    TOKENS_FOLLOWING_function_spec_IN_package_obj_spec_288 = Set[ 1 ]
    TOKENS_FOLLOWING_exception_declaration_IN_package_obj_spec_294 = Set[ 1 ]
    TOKENS_FOLLOWING_pragma_declaration_IN_package_obj_spec_300 = Set[ 1 ]
    TOKENS_FOLLOWING_variable_name_IN_variable_declaration_311 = Set[ 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_T__56_IN_variable_declaration_314 = Set[ 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_type_spec_IN_variable_declaration_320 = Set[ 4, 6, 57, 59 ]
    TOKENS_FOLLOWING_T__57_IN_variable_declaration_323 = Set[ 58 ]
    TOKENS_FOLLOWING_T__58_IN_variable_declaration_325 = Set[ 4, 6, 59 ]
    TOKENS_FOLLOWING_set_IN_variable_declaration_334 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_plsql_expression_IN_variable_declaration_344 = Set[ 4 ]
    TOKENS_FOLLOWING_SEMI_IN_variable_declaration_348 = Set[ 1 ]
    TOKENS_FOLLOWING_keyTYPE_IN_type_declaration_361 = Set[ 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_type_spec_IN_type_declaration_363 = Set[ 52 ]
    TOKENS_FOLLOWING_T__52_IN_type_declaration_365 = Set[ 7, 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_keyNEW_IN_type_declaration_369 = Set[ 7, 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_type_spec_IN_type_declaration_376 = Set[ 4, 57 ]
    TOKENS_FOLLOWING_T__57_IN_type_declaration_380 = Set[ 58 ]
    TOKENS_FOLLOWING_T__58_IN_type_declaration_382 = Set[ 4 ]
    TOKENS_FOLLOWING_LPAREN_IN_type_declaration_389 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_plsql_expressions_IN_type_declaration_391 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_type_declaration_393 = Set[ 4 ]
    TOKENS_FOLLOWING_SEMI_IN_type_declaration_397 = Set[ 1 ]
    TOKENS_FOLLOWING_keySUBTYPE_IN_subtype_declaration_410 = Set[ 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_type_spec_IN_subtype_declaration_412 = Set[ 52 ]
    TOKENS_FOLLOWING_T__52_IN_subtype_declaration_414 = Set[ 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_type_spec_IN_subtype_declaration_416 = Set[ 4, 40, 57 ]
    TOKENS_FOLLOWING_T__57_IN_subtype_declaration_420 = Set[ 58 ]
    TOKENS_FOLLOWING_T__58_IN_subtype_declaration_422 = Set[ 4 ]
    TOKENS_FOLLOWING_keyRANGE_IN_subtype_declaration_426 = Set[ 13, 14, 15, 16 ]
    TOKENS_FOLLOWING_literal_IN_subtype_declaration_428 = Set[ 9 ]
    TOKENS_FOLLOWING_DOUBLEDOT_IN_subtype_declaration_430 = Set[ 13, 14, 15, 16 ]
    TOKENS_FOLLOWING_literal_IN_subtype_declaration_432 = Set[ 4 ]
    TOKENS_FOLLOWING_SEMI_IN_subtype_declaration_437 = Set[ 1 ]
    TOKENS_FOLLOWING_keyCURSOR_IN_cursor_declaration_450 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_cursor_name_IN_cursor_declaration_452 = Set[ 7, 52 ]
    TOKENS_FOLLOWING_LPAREN_IN_cursor_declaration_458 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_parameter_specs_IN_cursor_declaration_460 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_cursor_declaration_462 = Set[ 52 ]
    TOKENS_FOLLOWING_T__52_IN_cursor_declaration_469 = Set[ 116 ]
    TOKENS_FOLLOWING_select_command_IN_cursor_declaration_471 = Set[ 4 ]
    TOKENS_FOLLOWING_SEMI_IN_cursor_declaration_473 = Set[ 1 ]
    TOKENS_FOLLOWING_variable_declaration_IN_package_obj_body_483 = Set[ 1 ]
    TOKENS_FOLLOWING_subtype_declaration_IN_package_obj_body_489 = Set[ 1 ]
    TOKENS_FOLLOWING_cursor_declaration_IN_package_obj_body_495 = Set[ 1 ]
    TOKENS_FOLLOWING_exception_declaration_IN_package_obj_body_501 = Set[ 1 ]
    TOKENS_FOLLOWING_record_declaration_IN_package_obj_body_507 = Set[ 1 ]
    TOKENS_FOLLOWING_plsql_table_declaration_IN_package_obj_body_513 = Set[ 1 ]
    TOKENS_FOLLOWING_varray_declaration_IN_package_obj_body_519 = Set[ 1 ]
    TOKENS_FOLLOWING_procedure_body_IN_package_obj_body_524 = Set[ 1 ]
    TOKENS_FOLLOWING_function_body_IN_package_obj_body_530 = Set[ 1 ]
    TOKENS_FOLLOWING_pragma_declaration_IN_package_obj_body_536 = Set[ 1 ]
    TOKENS_FOLLOWING_statement_IN_seq_of_statements_547 = Set[ 4 ]
    TOKENS_FOLLOWING_SEMI_IN_seq_of_statements_549 = Set[ 1, 10, 17, 40, 41, 50, 55, 58, 60, 62, 87, 100, 103, 104, 112, 113, 114, 116, 132, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_statement_IN_seq_of_statements_553 = Set[ 4 ]
    TOKENS_FOLLOWING_SEMI_IN_seq_of_statements_555 = Set[ 1, 10, 17, 40, 41, 50, 55, 58, 60, 62, 87, 100, 103, 104, 112, 113, 114, 116, 132, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_assignment_statement_IN_statement_570 = Set[ 1 ]
    TOKENS_FOLLOWING_exit_statement_IN_statement_575 = Set[ 1 ]
    TOKENS_FOLLOWING_goto_statement_IN_statement_580 = Set[ 1 ]
    TOKENS_FOLLOWING_case_statement_IN_statement_585 = Set[ 1 ]
    TOKENS_FOLLOWING_if_statement_IN_statement_590 = Set[ 1 ]
    TOKENS_FOLLOWING_loop_statement_IN_statement_596 = Set[ 1 ]
    TOKENS_FOLLOWING_null_statement_IN_statement_602 = Set[ 1 ]
    TOKENS_FOLLOWING_raise_statement_IN_statement_607 = Set[ 1 ]
    TOKENS_FOLLOWING_return_statement_IN_statement_612 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_statement_IN_statement_617 = Set[ 1 ]
    TOKENS_FOLLOWING_plsql_block_IN_statement_622 = Set[ 1 ]
    TOKENS_FOLLOWING_function_call_IN_statement_628 = Set[ 1 ]
    TOKENS_FOLLOWING_LLABEL_IN_plsql_block_643 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_label_name_IN_plsql_block_645 = Set[ 11 ]
    TOKENS_FOLLOWING_RLABEL_IN_plsql_block_647 = Set[ 40, 41, 50, 55, 60, 103, 104, 161 ]
    TOKENS_FOLLOWING_T__60_IN_plsql_block_658 = Set[ 40, 41, 50, 60, 103, 104, 161 ]
    TOKENS_FOLLOWING_declare_spec_IN_plsql_block_664 = Set[ 40, 41, 50, 55, 60, 103, 104, 161 ]
    TOKENS_FOLLOWING_T__55_IN_plsql_block_676 = Set[ 10, 17, 40, 41, 50, 55, 58, 60, 62, 87, 100, 103, 104, 112, 113, 114, 116, 132, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_seq_of_statements_IN_plsql_block_682 = Set[ 54, 61 ]
    TOKENS_FOLLOWING_T__61_IN_plsql_block_688 = Set[ 63 ]
    TOKENS_FOLLOWING_exception_handler_IN_plsql_block_692 = Set[ 54, 63 ]
    TOKENS_FOLLOWING_T__54_IN_plsql_block_705 = Set[ 1, 40, 41 ]
    TOKENS_FOLLOWING_label_name_IN_plsql_block_709 = Set[ 1 ]
    TOKENS_FOLLOWING_variable_declaration_IN_declare_spec_725 = Set[ 1 ]
    TOKENS_FOLLOWING_subtype_declaration_IN_declare_spec_731 = Set[ 1 ]
    TOKENS_FOLLOWING_cursor_declaration_IN_declare_spec_737 = Set[ 1 ]
    TOKENS_FOLLOWING_exception_declaration_IN_declare_spec_743 = Set[ 1 ]
    TOKENS_FOLLOWING_record_declaration_IN_declare_spec_749 = Set[ 1 ]
    TOKENS_FOLLOWING_plsql_table_declaration_IN_declare_spec_755 = Set[ 1 ]
    TOKENS_FOLLOWING_varray_declaration_IN_declare_spec_761 = Set[ 1 ]
    TOKENS_FOLLOWING_procedure_declaration_IN_declare_spec_766 = Set[ 1 ]
    TOKENS_FOLLOWING_function_declaration_IN_declare_spec_772 = Set[ 1 ]
    TOKENS_FOLLOWING_type_declaration_IN_declare_spec_777 = Set[ 1 ]
    TOKENS_FOLLOWING_pragma_declaration_IN_declare_spec_783 = Set[ 1 ]
    TOKENS_FOLLOWING_keyPRAGMA_IN_pragma_declaration_794 = Set[ 40 ]
    TOKENS_FOLLOWING_keyRESTRICT_REFERENCES_IN_pragma_declaration_801 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_pragma_declaration_803 = Set[ 16, 40, 41, 59 ]
    TOKENS_FOLLOWING_T__59_IN_pragma_declaration_807 = Set[ 12 ]
    TOKENS_FOLLOWING_function_name_IN_pragma_declaration_811 = Set[ 12 ]
    TOKENS_FOLLOWING_COMMA_IN_pragma_declaration_817 = Set[ 13, 14, 15, 16, 40, 41 ]
    TOKENS_FOLLOWING_pragma_param_IN_pragma_declaration_819 = Set[ 8, 12 ]
    TOKENS_FOLLOWING_RPAREN_IN_pragma_declaration_824 = Set[ 4 ]
    TOKENS_FOLLOWING_keyEXCEPTION_INIT_IN_pragma_declaration_831 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_pragma_declaration_833 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_exception_name_IN_pragma_declaration_835 = Set[ 12 ]
    TOKENS_FOLLOWING_COMMA_IN_pragma_declaration_837 = Set[ 13, 14, 15, 16 ]
    TOKENS_FOLLOWING_literal_IN_pragma_declaration_839 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_pragma_declaration_841 = Set[ 4 ]
    TOKENS_FOLLOWING_keyAUTONOMOUS_TRANSACTION_IN_pragma_declaration_847 = Set[ 4 ]
    TOKENS_FOLLOWING_keySERIALLY_REUSABLE_IN_pragma_declaration_853 = Set[ 4 ]
    TOKENS_FOLLOWING_keyBUILTIN_IN_pragma_declaration_859 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_pragma_declaration_861 = Set[ 13, 14, 15, 16, 40, 41 ]
    TOKENS_FOLLOWING_pragma_params_IN_pragma_declaration_863 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_pragma_declaration_865 = Set[ 4 ]
    TOKENS_FOLLOWING_keyFIPSFLAG_IN_pragma_declaration_871 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_pragma_declaration_873 = Set[ 13, 14, 15, 16, 40, 41 ]
    TOKENS_FOLLOWING_pragma_params_IN_pragma_declaration_875 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_pragma_declaration_877 = Set[ 4 ]
    TOKENS_FOLLOWING_keyINTERFACE_IN_pragma_declaration_883 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_pragma_declaration_885 = Set[ 13, 14, 15, 16, 40, 41 ]
    TOKENS_FOLLOWING_pragma_params_IN_pragma_declaration_887 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_pragma_declaration_889 = Set[ 4 ]
    TOKENS_FOLLOWING_keyNEW_NAMES_IN_pragma_declaration_895 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_pragma_declaration_897 = Set[ 13, 14, 15, 16, 40, 41 ]
    TOKENS_FOLLOWING_pragma_params_IN_pragma_declaration_899 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_pragma_declaration_901 = Set[ 4 ]
    TOKENS_FOLLOWING_keyTIMESTAMP_IN_pragma_declaration_907 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_pragma_declaration_909 = Set[ 13, 14, 15, 16, 40, 41 ]
    TOKENS_FOLLOWING_pragma_params_IN_pragma_declaration_911 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_pragma_declaration_913 = Set[ 4 ]
    TOKENS_FOLLOWING_SEMI_IN_pragma_declaration_921 = Set[ 1 ]
    TOKENS_FOLLOWING_pragma_param_IN_pragma_params_932 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_pragma_params_936 = Set[ 13, 14, 15, 16, 40, 41 ]
    TOKENS_FOLLOWING_pragma_param_IN_pragma_params_938 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_set_IN_pragma_param_952 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_pragma_param_963 = Set[ 1 ]
    TOKENS_FOLLOWING_QUOTED_STRING_IN_pragma_param_968 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_pragma_param_973 = Set[ 1 ]
    TOKENS_FOLLOWING_lvalue_IN_assignment_statement_989 = Set[ 6 ]
    TOKENS_FOLLOWING_ASSIGN_IN_assignment_statement_991 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_plsql_expression_IN_assignment_statement_993 = Set[ 1 ]
    TOKENS_FOLLOWING_lvalue_IN_lvalues_1005 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_lvalues_1009 = Set[ 17, 40, 41 ]
    TOKENS_FOLLOWING_lvalue_IN_lvalues_1011 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_variable_name_IN_lvalue_1024 = Set[ 1 ]
    TOKENS_FOLLOWING_record_name_IN_lvalue_1029 = Set[ 5 ]
    TOKENS_FOLLOWING_DOT_IN_lvalue_1031 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_field_name_IN_lvalue_1033 = Set[ 1 ]
    TOKENS_FOLLOWING_plsql_table_name_IN_lvalue_1038 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_lvalue_1040 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_subscript_IN_lvalue_1042 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_lvalue_1044 = Set[ 1, 5 ]
    TOKENS_FOLLOWING_DOT_IN_lvalue_1048 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_field_name_IN_lvalue_1050 = Set[ 1, 5 ]
    TOKENS_FOLLOWING_COLON_IN_lvalue_1058 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_host_variable_IN_lvalue_1060 = Set[ 1, 17 ]
    TOKENS_FOLLOWING_COLON_IN_lvalue_1064 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_host_variable_IN_lvalue_1066 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_field_name_1080 = Set[ 1 ]
    TOKENS_FOLLOWING_plsql_expression_IN_subscript_1092 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_host_variable_1105 = Set[ 1 ]
    TOKENS_FOLLOWING_T__62_IN_goto_statement_1117 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_label_name_IN_goto_statement_1119 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_label_name_1131 = Set[ 1 ]
    TOKENS_FOLLOWING_keyEXIT_IN_exit_statement_1143 = Set[ 1, 40, 41, 63 ]
    TOKENS_FOLLOWING_label_name_IN_exit_statement_1147 = Set[ 1, 63 ]
    TOKENS_FOLLOWING_T__63_IN_exit_statement_1154 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_plsql_condition_IN_exit_statement_1156 = Set[ 1 ]
    TOKENS_FOLLOWING_T__64_IN_datatype_1171 = Set[ 1 ]
    TOKENS_FOLLOWING_T__65_IN_datatype_1177 = Set[ 1 ]
    TOKENS_FOLLOWING_T__66_IN_datatype_1182 = Set[ 1 ]
    TOKENS_FOLLOWING_T__67_IN_datatype_1187 = Set[ 1 ]
    TOKENS_FOLLOWING_T__68_IN_datatype_1193 = Set[ 1 ]
    TOKENS_FOLLOWING_set_IN_datatype_1199 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_datatype_1219 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_datatype_1221 = Set[ 8, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_datatype_1225 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_datatype_1227 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_datatype_1232 = Set[ 1 ]
    TOKENS_FOLLOWING_T__73_IN_datatype_1240 = Set[ 1, 7, 74 ]
    TOKENS_FOLLOWING_T__74_IN_datatype_1244 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_datatype_1250 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_datatype_1252 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_datatype_1254 = Set[ 1 ]
    TOKENS_FOLLOWING_T__74_IN_datatype_1262 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_datatype_1266 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_datatype_1268 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_datatype_1270 = Set[ 1 ]
    TOKENS_FOLLOWING_T__75_IN_datatype_1278 = Set[ 1 ]
    TOKENS_FOLLOWING_T__76_IN_datatype_1283 = Set[ 1 ]
    TOKENS_FOLLOWING_keyINTERVAL_IN_datatype_1288 = Set[ 40 ]
    TOKENS_FOLLOWING_keyDAY_IN_datatype_1290 = Set[ 7, 77 ]
    TOKENS_FOLLOWING_LPAREN_IN_datatype_1294 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_datatype_1296 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_datatype_1298 = Set[ 77 ]
    TOKENS_FOLLOWING_T__77_IN_datatype_1303 = Set[ 40 ]
    TOKENS_FOLLOWING_keySECOND_IN_datatype_1305 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_datatype_1309 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_datatype_1311 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_datatype_1313 = Set[ 1 ]
    TOKENS_FOLLOWING_keyINTERVAL_IN_datatype_1321 = Set[ 40 ]
    TOKENS_FOLLOWING_keyYEAR_IN_datatype_1323 = Set[ 7, 77 ]
    TOKENS_FOLLOWING_LPAREN_IN_datatype_1327 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_datatype_1329 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_datatype_1331 = Set[ 77 ]
    TOKENS_FOLLOWING_T__77_IN_datatype_1336 = Set[ 40 ]
    TOKENS_FOLLOWING_keyMONTH_IN_datatype_1338 = Set[ 1 ]
    TOKENS_FOLLOWING_keyTIME_IN_datatype_1345 = Set[ 1, 7, 78 ]
    TOKENS_FOLLOWING_keyTIMESTAMP_IN_datatype_1349 = Set[ 1, 7, 78 ]
    TOKENS_FOLLOWING_LPAREN_IN_datatype_1355 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_datatype_1357 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_datatype_1359 = Set[ 1, 78 ]
    TOKENS_FOLLOWING_T__78_IN_datatype_1366 = Set[ 40 ]
    TOKENS_FOLLOWING_keyLOCAL_IN_datatype_1370 = Set[ 40 ]
    TOKENS_FOLLOWING_keyTIME_IN_datatype_1375 = Set[ 40 ]
    TOKENS_FOLLOWING_keyZONE_IN_datatype_1377 = Set[ 1 ]
    TOKENS_FOLLOWING_T__79_IN_datatype_1384 = Set[ 1 ]
    TOKENS_FOLLOWING_T__80_IN_datatype_1389 = Set[ 1 ]
    TOKENS_FOLLOWING_T__81_IN_datatype_1394 = Set[ 1 ]
    TOKENS_FOLLOWING_T__82_IN_datatype_1399 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_datatype_1403 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_datatype_1405 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_datatype_1407 = Set[ 1 ]
    TOKENS_FOLLOWING_T__83_IN_datatype_1415 = Set[ 1 ]
    TOKENS_FOLLOWING_T__84_IN_datatype_1420 = Set[ 40 ]
    TOKENS_FOLLOWING_keyPRECISION_IN_datatype_1422 = Set[ 1 ]
    TOKENS_FOLLOWING_T__85_IN_datatype_1427 = Set[ 1, 7, 40, 86 ]
    TOKENS_FOLLOWING_keyVARYING_IN_datatype_1436 = Set[ 1, 7, 86 ]
    TOKENS_FOLLOWING_LPAREN_IN_datatype_1443 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_datatype_1445 = Set[ 8, 40, 85 ]
    TOKENS_FOLLOWING_keyBYTE_IN_datatype_1449 = Set[ 8 ]
    TOKENS_FOLLOWING_T__85_IN_datatype_1453 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_datatype_1458 = Set[ 1, 86 ]
    TOKENS_FOLLOWING_T__86_IN_datatype_1465 = Set[ 87 ]
    TOKENS_FOLLOWING_T__87_IN_datatype_1467 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_identifier_IN_datatype_1471 = Set[ 1 ]
    TOKENS_FOLLOWING_column_spec_IN_datatype_1475 = Set[ 18 ]
    TOKENS_FOLLOWING_CHARSET_ATTR_IN_datatype_1477 = Set[ 1 ]
    TOKENS_FOLLOWING_T__88_IN_datatype_1487 = Set[ 1, 7, 86 ]
    TOKENS_FOLLOWING_LPAREN_IN_datatype_1509 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_datatype_1511 = Set[ 8, 40, 85 ]
    TOKENS_FOLLOWING_keyBYTE_IN_datatype_1515 = Set[ 8 ]
    TOKENS_FOLLOWING_T__85_IN_datatype_1519 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_datatype_1524 = Set[ 1, 86 ]
    TOKENS_FOLLOWING_T__86_IN_datatype_1531 = Set[ 87 ]
    TOKENS_FOLLOWING_T__87_IN_datatype_1533 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_identifier_IN_datatype_1537 = Set[ 1 ]
    TOKENS_FOLLOWING_column_spec_IN_datatype_1541 = Set[ 18 ]
    TOKENS_FOLLOWING_CHARSET_ATTR_IN_datatype_1543 = Set[ 1 ]
    TOKENS_FOLLOWING_T__89_IN_datatype_1553 = Set[ 1, 7, 86 ]
    TOKENS_FOLLOWING_LPAREN_IN_datatype_1574 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_datatype_1576 = Set[ 8, 40, 85 ]
    TOKENS_FOLLOWING_keyBYTE_IN_datatype_1580 = Set[ 8 ]
    TOKENS_FOLLOWING_T__85_IN_datatype_1584 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_datatype_1589 = Set[ 1, 86 ]
    TOKENS_FOLLOWING_T__86_IN_datatype_1596 = Set[ 87 ]
    TOKENS_FOLLOWING_T__87_IN_datatype_1598 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_identifier_IN_datatype_1602 = Set[ 1 ]
    TOKENS_FOLLOWING_column_spec_IN_datatype_1606 = Set[ 18 ]
    TOKENS_FOLLOWING_CHARSET_ATTR_IN_datatype_1608 = Set[ 1 ]
    TOKENS_FOLLOWING_T__86_IN_datatype_1618 = Set[ 1, 7, 40 ]
    TOKENS_FOLLOWING_keyVARYING_IN_datatype_1622 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_datatype_1629 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_datatype_1631 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_datatype_1633 = Set[ 1 ]
    TOKENS_FOLLOWING_T__90_IN_datatype_1641 = Set[ 1, 7, 40 ]
    TOKENS_FOLLOWING_keyVARYING_IN_datatype_1649 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_datatype_1656 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_datatype_1658 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_datatype_1660 = Set[ 1 ]
    TOKENS_FOLLOWING_T__91_IN_datatype_1668 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_datatype_1673 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_datatype_1675 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_datatype_1677 = Set[ 1 ]
    TOKENS_FOLLOWING_T__92_IN_datatype_1685 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_datatype_1689 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_datatype_1691 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_datatype_1693 = Set[ 1 ]
    TOKENS_FOLLOWING_T__93_IN_datatype_1701 = Set[ 85, 86 ]
    TOKENS_FOLLOWING_set_IN_datatype_1704 = Set[ 1, 7, 40 ]
    TOKENS_FOLLOWING_keyVARYING_IN_datatype_1716 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_datatype_1723 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_datatype_1725 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_datatype_1727 = Set[ 1 ]
    TOKENS_FOLLOWING_T__94_IN_datatype_1735 = Set[ 1 ]
    TOKENS_FOLLOWING_T__95_IN_datatype_1740 = Set[ 1 ]
    TOKENS_FOLLOWING_T__96_IN_datatype_1745 = Set[ 1 ]
    TOKENS_FOLLOWING_T__97_IN_datatype_1750 = Set[ 1, 86 ]
    TOKENS_FOLLOWING_T__86_IN_datatype_1754 = Set[ 87 ]
    TOKENS_FOLLOWING_T__87_IN_datatype_1756 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_identifier_IN_datatype_1760 = Set[ 1 ]
    TOKENS_FOLLOWING_column_spec_IN_datatype_1764 = Set[ 18 ]
    TOKENS_FOLLOWING_CHARSET_ATTR_IN_datatype_1766 = Set[ 1 ]
    TOKENS_FOLLOWING_T__98_IN_datatype_1776 = Set[ 1 ]
    TOKENS_FOLLOWING_T__99_IN_datatype_1781 = Set[ 1 ]
    TOKENS_FOLLOWING_T__100_IN_datatype_1786 = Set[ 1 ]
    TOKENS_FOLLOWING_T__101_IN_datatype_1792 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_datatype_1796 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_datatype_1798 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_datatype_1800 = Set[ 1 ]
    TOKENS_FOLLOWING_datatype_IN_type_spec_1814 = Set[ 1 ]
    TOKENS_FOLLOWING_column_spec_IN_type_spec_1821 = Set[ 19 ]
    TOKENS_FOLLOWING_TYPE_ATTR_IN_type_spec_1823 = Set[ 1 ]
    TOKENS_FOLLOWING_table_spec_IN_type_spec_1829 = Set[ 20 ]
    TOKENS_FOLLOWING_ROWTYPE_ATTR_IN_type_spec_1831 = Set[ 1 ]
    TOKENS_FOLLOWING_type_name_IN_type_spec_1837 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_type_spec_1841 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_type_spec_1843 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_type_spec_1845 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_type_name_1859 = Set[ 1, 5 ]
    TOKENS_FOLLOWING_DOT_IN_type_name_1863 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_identifier_IN_type_name_1865 = Set[ 1, 5 ]
    TOKENS_FOLLOWING_parameter_spec_IN_parameter_specs_1879 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_parameter_specs_1883 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_parameter_spec_IN_parameter_specs_1885 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_parameter_name_IN_parameter_spec_1899 = Set[ 1, 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102 ]
    TOKENS_FOLLOWING_T__102_IN_parameter_spec_1903 = Set[ 1, 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_type_spec_IN_parameter_spec_1910 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_parameter_name_1925 = Set[ 1 ]
    TOKENS_FOLLOWING_keyCURSOR_IN_cursor_spec_1936 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_cursor_name_IN_cursor_spec_1938 = Set[ 7, 164 ]
    TOKENS_FOLLOWING_LPAREN_IN_cursor_spec_1945 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_parameter_specs_IN_cursor_spec_1947 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_cursor_spec_1949 = Set[ 164 ]
    TOKENS_FOLLOWING_keyRETURN_IN_cursor_spec_1956 = Set[ 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_return_type_IN_cursor_spec_1958 = Set[ 4 ]
    TOKENS_FOLLOWING_SEMI_IN_cursor_spec_1960 = Set[ 1 ]
    TOKENS_FOLLOWING_T__103_IN_procedure_spec_1973 = Set[ 16, 40, 41 ]
    TOKENS_FOLLOWING_procedure_name_IN_procedure_spec_1975 = Set[ 4, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_procedure_spec_1981 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_arguments_IN_procedure_spec_1983 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_procedure_spec_1985 = Set[ 4 ]
    TOKENS_FOLLOWING_SEMI_IN_procedure_spec_1990 = Set[ 1 ]
    TOKENS_FOLLOWING_T__104_IN_function_spec_2001 = Set[ 16, 40, 41, 59 ]
    TOKENS_FOLLOWING_function_name_IN_function_spec_2003 = Set[ 7, 164 ]
    TOKENS_FOLLOWING_LPAREN_IN_function_spec_2010 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_arguments_IN_function_spec_2012 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_function_spec_2014 = Set[ 164 ]
    TOKENS_FOLLOWING_keyRETURN_IN_function_spec_2021 = Set[ 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_return_type_IN_function_spec_2023 = Set[ 4 ]
    TOKENS_FOLLOWING_SEMI_IN_function_spec_2025 = Set[ 1 ]
    TOKENS_FOLLOWING_exception_name_IN_exception_declaration_2036 = Set[ 61 ]
    TOKENS_FOLLOWING_T__61_IN_exception_declaration_2038 = Set[ 4 ]
    TOKENS_FOLLOWING_SEMI_IN_exception_declaration_2040 = Set[ 1 ]
    TOKENS_FOLLOWING_exception_name_IN_exception_names_2051 = Set[ 1, 51 ]
    TOKENS_FOLLOWING_T__51_IN_exception_names_2055 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_exception_name_IN_exception_names_2057 = Set[ 1, 51 ]
    TOKENS_FOLLOWING_exception_package_name_IN_exception_name_2073 = Set[ 5 ]
    TOKENS_FOLLOWING_DOT_IN_exception_name_2075 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_identifier_IN_exception_name_2080 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_exception_package_name_2091 = Set[ 1 ]
    TOKENS_FOLLOWING_record_type_dec_IN_record_declaration_2110 = Set[ 1 ]
    TOKENS_FOLLOWING_keyTYPE_IN_record_type_dec_2123 = Set[ 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_type_name_IN_record_type_dec_2125 = Set[ 52 ]
    TOKENS_FOLLOWING_T__52_IN_record_type_dec_2127 = Set[ 163 ]
    TOKENS_FOLLOWING_keyRECORD_IN_record_type_dec_2129 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_record_type_dec_2134 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_field_specs_IN_record_type_dec_2136 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_record_type_dec_2138 = Set[ 4 ]
    TOKENS_FOLLOWING_SEMI_IN_record_type_dec_2140 = Set[ 1 ]
    TOKENS_FOLLOWING_field_spec_IN_field_specs_2155 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_field_specs_2159 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_field_spec_IN_field_specs_2161 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_column_name_IN_field_spec_2174 = Set[ 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_type_spec_IN_field_spec_2176 = Set[ 1, 6, 57, 59 ]
    TOKENS_FOLLOWING_T__57_IN_field_spec_2181 = Set[ 58 ]
    TOKENS_FOLLOWING_T__58_IN_field_spec_2183 = Set[ 1, 6, 59 ]
    TOKENS_FOLLOWING_set_IN_field_spec_2192 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_plsql_expression_IN_field_spec_2202 = Set[ 1 ]
    TOKENS_FOLLOWING_table_type_dec_IN_plsql_table_declaration_2215 = Set[ 1 ]
    TOKENS_FOLLOWING_keyTYPE_IN_table_type_dec_2227 = Set[ 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_type_name_IN_table_type_dec_2229 = Set[ 52 ]
    TOKENS_FOLLOWING_T__52_IN_table_type_dec_2231 = Set[ 105 ]
    TOKENS_FOLLOWING_T__105_IN_table_type_dec_2233 = Set[ 106 ]
    TOKENS_FOLLOWING_T__106_IN_table_type_dec_2238 = Set[ 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_type_spec_IN_table_type_dec_2240 = Set[ 4, 57, 107 ]
    TOKENS_FOLLOWING_T__57_IN_table_type_dec_2244 = Set[ 58 ]
    TOKENS_FOLLOWING_T__58_IN_table_type_dec_2246 = Set[ 4, 107 ]
    TOKENS_FOLLOWING_T__107_IN_table_type_dec_2255 = Set[ 108 ]
    TOKENS_FOLLOWING_T__108_IN_table_type_dec_2257 = Set[ 64, 89, 95 ]
    TOKENS_FOLLOWING_T__64_IN_table_type_dec_2265 = Set[ 4 ]
    TOKENS_FOLLOWING_T__95_IN_table_type_dec_2272 = Set[ 4 ]
    TOKENS_FOLLOWING_T__89_IN_table_type_dec_2279 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_table_type_dec_2281 = Set[ 15 ]
    TOKENS_FOLLOWING_integer_IN_table_type_dec_2283 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_table_type_dec_2285 = Set[ 4 ]
    TOKENS_FOLLOWING_SEMI_IN_table_type_dec_2299 = Set[ 1 ]
    TOKENS_FOLLOWING_plsql_table_name_IN_table_var_dec_2310 = Set[ 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_type_name_IN_table_var_dec_2312 = Set[ 4 ]
    TOKENS_FOLLOWING_SEMI_IN_table_var_dec_2314 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_plsql_table_name_2325 = Set[ 1, 5 ]
    TOKENS_FOLLOWING_DOT_IN_plsql_table_name_2329 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_identifier_IN_plsql_table_name_2331 = Set[ 1, 5 ]
    TOKENS_FOLLOWING_keyTYPE_IN_varray_declaration_2345 = Set[ 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_type_name_IN_varray_declaration_2347 = Set[ 52 ]
    TOKENS_FOLLOWING_T__52_IN_varray_declaration_2349 = Set[ 40 ]
    TOKENS_FOLLOWING_keyVARRAY_IN_varray_declaration_2356 = Set[ 7 ]
    TOKENS_FOLLOWING_keyVARYING_IN_varray_declaration_2360 = Set[ 40 ]
    TOKENS_FOLLOWING_keyARRAY_IN_varray_declaration_2362 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_varray_declaration_2366 = Set[ 15 ]
    TOKENS_FOLLOWING_integer_IN_varray_declaration_2368 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_varray_declaration_2370 = Set[ 106 ]
    TOKENS_FOLLOWING_T__106_IN_varray_declaration_2374 = Set[ 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_type_spec_IN_varray_declaration_2376 = Set[ 1, 57 ]
    TOKENS_FOLLOWING_T__57_IN_varray_declaration_2380 = Set[ 58 ]
    TOKENS_FOLLOWING_T__58_IN_varray_declaration_2382 = Set[ 1 ]
    TOKENS_FOLLOWING_procedure_body_IN_procedure_declaration_2396 = Set[ 1 ]
    TOKENS_FOLLOWING_proc_fun_start_IN_procedure_body_2409 = Set[ 103 ]
    TOKENS_FOLLOWING_T__103_IN_procedure_body_2414 = Set[ 16, 40, 41 ]
    TOKENS_FOLLOWING_procedure_name_IN_procedure_body_2417 = Set[ 7, 52, 53 ]
    TOKENS_FOLLOWING_LPAREN_IN_procedure_body_2424 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_argument_IN_procedure_body_2426 = Set[ 8, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_procedure_body_2430 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_argument_IN_procedure_body_2432 = Set[ 8, 12 ]
    TOKENS_FOLLOWING_RPAREN_IN_procedure_body_2437 = Set[ 52, 53 ]
    TOKENS_FOLLOWING_set_IN_procedure_body_2445 = Set[ 40, 41, 50, 55, 60, 103, 104, 161 ]
    TOKENS_FOLLOWING_declare_spec_IN_procedure_body_2472 = Set[ 40, 41, 50, 55, 60, 103, 104, 161 ]
    TOKENS_FOLLOWING_T__55_IN_procedure_body_2483 = Set[ 10, 17, 40, 41, 50, 55, 58, 60, 62, 87, 100, 103, 104, 112, 113, 114, 116, 132, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_seq_of_statements_IN_procedure_body_2491 = Set[ 54, 61 ]
    TOKENS_FOLLOWING_T__61_IN_procedure_body_2499 = Set[ 54, 63 ]
    TOKENS_FOLLOWING_exception_handler_IN_procedure_body_2503 = Set[ 54, 63 ]
    TOKENS_FOLLOWING_T__54_IN_procedure_body_2513 = Set[ 4, 16, 40, 41 ]
    TOKENS_FOLLOWING_procedure_name_IN_procedure_body_2517 = Set[ 4 ]
    TOKENS_FOLLOWING_SEMI_IN_procedure_body_2522 = Set[ 1 ]
    TOKENS_FOLLOWING_T__55_IN_begin_block_2533 = Set[ 10, 17, 40, 41, 50, 55, 58, 60, 62, 87, 100, 103, 104, 112, 113, 114, 116, 132, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_seq_of_statements_IN_begin_block_2539 = Set[ 54, 61 ]
    TOKENS_FOLLOWING_T__61_IN_begin_block_2547 = Set[ 63 ]
    TOKENS_FOLLOWING_exception_handler_IN_begin_block_2551 = Set[ 54, 63 ]
    TOKENS_FOLLOWING_T__54_IN_begin_block_2561 = Set[ 1 ]
    TOKENS_FOLLOWING_T__63_IN_exception_handler_2573 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_exception_names_IN_exception_handler_2575 = Set[ 109 ]
    TOKENS_FOLLOWING_T__109_IN_exception_handler_2577 = Set[ 10, 17, 40, 41, 50, 55, 58, 60, 62, 87, 100, 103, 104, 112, 113, 114, 116, 132, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_seq_of_statements_IN_exception_handler_2581 = Set[ 1 ]
    TOKENS_FOLLOWING_T__50_IN_proc_fun_start_2592 = Set[ 1, 51 ]
    TOKENS_FOLLOWING_T__51_IN_proc_fun_start_2596 = Set[ 40 ]
    TOKENS_FOLLOWING_keyREPLACE_IN_proc_fun_start_2598 = Set[ 1 ]
    TOKENS_FOLLOWING_proc_fun_start_IN_function_body_2614 = Set[ 104 ]
    TOKENS_FOLLOWING_T__104_IN_function_body_2619 = Set[ 16, 40, 41, 59 ]
    TOKENS_FOLLOWING_function_name_IN_function_body_2622 = Set[ 7, 164 ]
    TOKENS_FOLLOWING_LPAREN_IN_function_body_2629 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_arguments_IN_function_body_2631 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_function_body_2633 = Set[ 164 ]
    TOKENS_FOLLOWING_keyRETURN_IN_function_body_2641 = Set[ 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_return_type_IN_function_body_2643 = Set[ 52, 53 ]
    TOKENS_FOLLOWING_set_IN_function_body_2645 = Set[ 40, 41, 50, 55, 60, 103, 104, 161 ]
    TOKENS_FOLLOWING_declare_spec_IN_function_body_2672 = Set[ 40, 41, 50, 55, 60, 103, 104, 161 ]
    TOKENS_FOLLOWING_T__55_IN_function_body_2683 = Set[ 10, 17, 40, 41, 50, 55, 58, 60, 62, 87, 100, 103, 104, 112, 113, 114, 116, 132, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_seq_of_statements_IN_function_body_2691 = Set[ 54, 61 ]
    TOKENS_FOLLOWING_T__61_IN_function_body_2699 = Set[ 63 ]
    TOKENS_FOLLOWING_exception_handler_IN_function_body_2703 = Set[ 54, 63 ]
    TOKENS_FOLLOWING_T__54_IN_function_body_2713 = Set[ 4, 16, 40, 41, 59 ]
    TOKENS_FOLLOWING_function_name_IN_function_body_2717 = Set[ 4 ]
    TOKENS_FOLLOWING_SEMI_IN_function_body_2722 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_function_name_2733 = Set[ 1 ]
    TOKENS_FOLLOWING_QUOTED_STRING_IN_function_name_2737 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_procedure_name_2749 = Set[ 1 ]
    TOKENS_FOLLOWING_QUOTED_STRING_IN_procedure_name_2753 = Set[ 1 ]
    TOKENS_FOLLOWING_argument_IN_arguments_2765 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_arguments_2769 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_argument_IN_arguments_2771 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_argument_name_IN_argument_2785 = Set[ 1, 6, 40, 41, 56, 59, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 159 ]
    TOKENS_FOLLOWING_keyOUT_IN_argument_2789 = Set[ 1, 6, 40, 41, 56, 59, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_T__102_IN_argument_2793 = Set[ 159 ]
    TOKENS_FOLLOWING_keyOUT_IN_argument_2795 = Set[ 1, 6, 40, 41, 56, 59, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_T__102_IN_argument_2799 = Set[ 1, 6, 40, 41, 56, 59, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_argument_type_IN_argument_2805 = Set[ 1, 6, 59 ]
    TOKENS_FOLLOWING_set_IN_argument_2814 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_plsql_expression_IN_argument_2824 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_argument_name_2838 = Set[ 1 ]
    TOKENS_FOLLOWING_type_spec_IN_argument_type_2849 = Set[ 1 ]
    TOKENS_FOLLOWING_set_IN_value_2860 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_value_2871 = Set[ 1 ]
    TOKENS_FOLLOWING_quoted_string_IN_value_2876 = Set[ 1 ]
    TOKENS_FOLLOWING_T__110_IN_value_2881 = Set[ 1 ]
    TOKENS_FOLLOWING_T__111_IN_value_2885 = Set[ 1 ]
    TOKENS_FOLLOWING_T__58_IN_value_2890 = Set[ 1 ]
    TOKENS_FOLLOWING_type_spec_IN_return_type_2901 = Set[ 1 ]
    TOKENS_FOLLOWING_function_body_IN_function_declaration_2912 = Set[ 1 ]
    TOKENS_FOLLOWING_user_defined_function_IN_function_call_2923 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_function_call_2929 = Set[ 7, 8, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_call_parameters_IN_function_call_2933 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_function_call_2938 = Set[ 1 ]
    TOKENS_FOLLOWING_plsql_table_name_IN_collection_function_call_2952 = Set[ 1 ]
    TOKENS_FOLLOWING_variable_name_IN_variable_names_2963 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_variable_names_2967 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_variable_name_IN_variable_names_2969 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_identifier_IN_variable_name_2982 = Set[ 1 ]
    TOKENS_FOLLOWING_T__58_IN_null_statement_2993 = Set[ 1 ]
    TOKENS_FOLLOWING_keyRAISE_IN_raise_statement_3005 = Set[ 1, 40, 41 ]
    TOKENS_FOLLOWING_exception_name_IN_raise_statement_3009 = Set[ 1 ]
    TOKENS_FOLLOWING_keyRETURN_IN_return_statement_3024 = Set[ 1, 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_plsql_expression_IN_return_statement_3028 = Set[ 1 ]
    TOKENS_FOLLOWING_LLABEL_IN_loop_statement_3044 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_label_name_IN_loop_statement_3046 = Set[ 11 ]
    TOKENS_FOLLOWING_RLABEL_IN_loop_statement_3048 = Set[ 10, 112, 158, 167 ]
    TOKENS_FOLLOWING_keyWHILE_IN_loop_statement_3057 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_plsql_condition_IN_loop_statement_3060 = Set[ 10, 112, 158, 167 ]
    TOKENS_FOLLOWING_T__112_IN_loop_statement_3069 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_numeric_loop_param_IN_loop_statement_3086 = Set[ 10, 112, 158, 167 ]
    TOKENS_FOLLOWING_cursor_loop_param_IN_loop_statement_3102 = Set[ 10, 112, 158, 167 ]
    TOKENS_FOLLOWING_keyLOOP_IN_loop_statement_3123 = Set[ 10, 17, 40, 41, 50, 55, 58, 60, 62, 87, 100, 103, 104, 112, 113, 114, 116, 132, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_seq_of_statements_IN_loop_statement_3127 = Set[ 54 ]
    TOKENS_FOLLOWING_T__54_IN_loop_statement_3131 = Set[ 10, 112, 158, 167 ]
    TOKENS_FOLLOWING_keyLOOP_IN_loop_statement_3133 = Set[ 1, 40, 41 ]
    TOKENS_FOLLOWING_label_name_IN_loop_statement_3140 = Set[ 1 ]
    TOKENS_FOLLOWING_index_name_IN_numeric_loop_param_3154 = Set[ 102 ]
    TOKENS_FOLLOWING_T__102_IN_numeric_loop_param_3156 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_keyREVERSE_IN_numeric_loop_param_3160 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_integer_expr_IN_numeric_loop_param_3165 = Set[ 9 ]
    TOKENS_FOLLOWING_DOUBLEDOT_IN_numeric_loop_param_3167 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_integer_expr_IN_numeric_loop_param_3169 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_index_name_3180 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_integer_expr_3192 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_cursor_name_3203 = Set[ 1 ]
    TOKENS_FOLLOWING_record_name_IN_cursor_loop_param_3214 = Set[ 102 ]
    TOKENS_FOLLOWING_T__102_IN_cursor_loop_param_3216 = Set[ 7, 40, 41 ]
    TOKENS_FOLLOWING_cursor_name_IN_cursor_loop_param_3222 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_cursor_loop_param_3226 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_plsql_expressions_IN_cursor_loop_param_3228 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_cursor_loop_param_3230 = Set[ 1 ]
    TOKENS_FOLLOWING_LPAREN_IN_cursor_loop_param_3239 = Set[ 116 ]
    TOKENS_FOLLOWING_select_statement_IN_cursor_loop_param_3241 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_cursor_loop_param_3243 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_record_name_3258 = Set[ 1 ]
    TOKENS_FOLLOWING_T__113_IN_commit_statement_3269 = Set[ 1 ]
    TOKENS_FOLLOWING_T__114_IN_if_statement_3280 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_plsql_condition_IN_if_statement_3283 = Set[ 109 ]
    TOKENS_FOLLOWING_T__109_IN_if_statement_3285 = Set[ 10, 17, 40, 41, 50, 55, 58, 60, 62, 87, 100, 103, 104, 112, 113, 114, 116, 132, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_seq_of_statements_IN_if_statement_3287 = Set[ 54, 115, 157 ]
    TOKENS_FOLLOWING_keyELSIF_IN_if_statement_3297 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_plsql_condition_IN_if_statement_3299 = Set[ 109 ]
    TOKENS_FOLLOWING_T__109_IN_if_statement_3301 = Set[ 10, 17, 40, 41, 50, 55, 58, 60, 62, 87, 100, 103, 104, 112, 113, 114, 116, 132, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_seq_of_statements_IN_if_statement_3303 = Set[ 54, 115, 157 ]
    TOKENS_FOLLOWING_T__115_IN_if_statement_3314 = Set[ 10, 17, 40, 41, 50, 55, 58, 60, 62, 87, 100, 103, 104, 112, 113, 114, 116, 132, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_seq_of_statements_IN_if_statement_3316 = Set[ 54 ]
    TOKENS_FOLLOWING_T__54_IN_if_statement_3323 = Set[ 114 ]
    TOKENS_FOLLOWING_T__114_IN_if_statement_3325 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_command_IN_sql_statement_3336 = Set[ 1 ]
    TOKENS_FOLLOWING_to_modify_data_IN_sql_command_3347 = Set[ 1 ]
    TOKENS_FOLLOWING_to_control_data_IN_sql_command_3352 = Set[ 1 ]
    TOKENS_FOLLOWING_select_command_IN_to_modify_data_3363 = Set[ 1 ]
    TOKENS_FOLLOWING_insert_command_IN_to_modify_data_3368 = Set[ 1 ]
    TOKENS_FOLLOWING_update_command_IN_to_modify_data_3373 = Set[ 1 ]
    TOKENS_FOLLOWING_delete_command_IN_to_modify_data_3378 = Set[ 1 ]
    TOKENS_FOLLOWING_set_transaction_command_IN_to_modify_data_3383 = Set[ 1 ]
    TOKENS_FOLLOWING_close_statement_IN_to_control_data_3394 = Set[ 1 ]
    TOKENS_FOLLOWING_commit_statement_IN_to_control_data_3399 = Set[ 1 ]
    TOKENS_FOLLOWING_fetch_statement_IN_to_control_data_3404 = Set[ 1 ]
    TOKENS_FOLLOWING_lock_table_statement_IN_to_control_data_3409 = Set[ 1 ]
    TOKENS_FOLLOWING_open_statement_IN_to_control_data_3414 = Set[ 1 ]
    TOKENS_FOLLOWING_rollback_statement_IN_to_control_data_3419 = Set[ 1 ]
    TOKENS_FOLLOWING_savepoint_statement_IN_to_control_data_3424 = Set[ 1 ]
    TOKENS_FOLLOWING_select_statement_IN_select_command_3435 = Set[ 1 ]
    TOKENS_FOLLOWING_select_expression_IN_select_statement_3449 = Set[ 1 ]
    TOKENS_FOLLOWING_T__116_IN_select_expression_3464 = Set[ 7, 10, 13, 14, 15, 16, 17, 21, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 118, 119, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_set_IN_select_expression_3468 = Set[ 7, 10, 13, 14, 15, 16, 17, 21, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 118, 119, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_select_list_IN_select_expression_3483 = Set[ 40, 120, 121 ]
    TOKENS_FOLLOWING_keyBULK_IN_select_expression_3489 = Set[ 40 ]
    TOKENS_FOLLOWING_keyCOLLECT_IN_select_expression_3491 = Set[ 120, 121 ]
    TOKENS_FOLLOWING_T__120_IN_select_expression_3500 = Set[ 17, 40, 41 ]
    TOKENS_FOLLOWING_lvalues_IN_select_expression_3502 = Set[ 121 ]
    TOKENS_FOLLOWING_T__121_IN_select_expression_3509 = Set[ 7, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_join_clause_IN_select_expression_3515 = Set[ 1, 40, 122, 123, 124, 125, 127, 128, 129, 130, 133 ]
    TOKENS_FOLLOWING_LPAREN_IN_select_expression_3519 = Set[ 7, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_join_clause_IN_select_expression_3521 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_select_expression_3523 = Set[ 1, 40, 122, 123, 124, 125, 127, 128, 129, 130, 133 ]
    TOKENS_FOLLOWING_table_reference_list_IN_select_expression_3527 = Set[ 1, 40, 122, 123, 124, 125, 127, 128, 129, 130, 133 ]
    TOKENS_FOLLOWING_where_clause_IN_select_expression_3535 = Set[ 1, 40, 122, 123, 124, 125, 128, 129, 130, 133 ]
    TOKENS_FOLLOWING_hierarchical_query_clause_IN_select_expression_3542 = Set[ 1, 40, 122, 123, 124, 125, 130, 133 ]
    TOKENS_FOLLOWING_group_by_clause_IN_select_expression_3549 = Set[ 1, 40, 122, 123, 124, 125, 133 ]
    TOKENS_FOLLOWING_T__122_IN_select_expression_3558 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_condition_IN_select_expression_3560 = Set[ 1, 40, 123, 124, 125, 133 ]
    TOKENS_FOLLOWING_model_clause_IN_select_expression_3567 = Set[ 1, 123, 124, 125, 133 ]
    TOKENS_FOLLOWING_T__123_IN_select_expression_3578 = Set[ 7, 40, 41, 100, 105, 116, 119 ]
    TOKENS_FOLLOWING_T__119_IN_select_expression_3582 = Set[ 7, 40, 41, 100, 105, 116 ]
    TOKENS_FOLLOWING_T__124_IN_select_expression_3592 = Set[ 7, 40, 41, 100, 105, 116 ]
    TOKENS_FOLLOWING_T__125_IN_select_expression_3599 = Set[ 7, 40, 41, 100, 105, 116 ]
    TOKENS_FOLLOWING_select_expression_IN_select_expression_3611 = Set[ 1, 133 ]
    TOKENS_FOLLOWING_subquery_IN_select_expression_3619 = Set[ 1, 133 ]
    TOKENS_FOLLOWING_order_by_clause_IN_select_expression_3635 = Set[ 1 ]
    TOKENS_FOLLOWING_ASTERISK_IN_select_list_3649 = Set[ 1 ]
    TOKENS_FOLLOWING_displayed_column_IN_select_list_3656 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_select_list_3660 = Set[ 7, 10, 13, 14, 15, 16, 17, 21, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 118, 119, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_displayed_column_IN_select_list_3662 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_T__121_IN_table_reference_list_from_3677 = Set[ 7, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_table_reference_list_IN_table_reference_list_from_3679 = Set[ 1 ]
    TOKENS_FOLLOWING_selected_table_IN_table_reference_list_3690 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_table_reference_list_3694 = Set[ 7, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_selected_table_IN_table_reference_list_3696 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_selected_table_IN_join_clause_3710 = Set[ 40 ]
    TOKENS_FOLLOWING_inner_cross_join_clause_IN_join_clause_3714 = Set[ 1, 40 ]
    TOKENS_FOLLOWING_outer_join_clause_IN_join_clause_3718 = Set[ 1, 40 ]
    TOKENS_FOLLOWING_keyINNER_IN_inner_cross_join_clause_3733 = Set[ 40 ]
    TOKENS_FOLLOWING_keyJOIN_IN_inner_cross_join_clause_3738 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_table_name_IN_inner_cross_join_clause_3740 = Set[ 40, 126 ]
    TOKENS_FOLLOWING_T__126_IN_inner_cross_join_clause_3744 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_condition_IN_inner_cross_join_clause_3746 = Set[ 1 ]
    TOKENS_FOLLOWING_keyUSING_IN_inner_cross_join_clause_3750 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_inner_cross_join_clause_3752 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_column_specs_IN_inner_cross_join_clause_3754 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_inner_cross_join_clause_3756 = Set[ 1 ]
    TOKENS_FOLLOWING_keyCROSS_IN_inner_cross_join_clause_3765 = Set[ 40 ]
    TOKENS_FOLLOWING_keyNATURAL_IN_inner_cross_join_clause_3769 = Set[ 40 ]
    TOKENS_FOLLOWING_keyINNER_IN_inner_cross_join_clause_3773 = Set[ 40 ]
    TOKENS_FOLLOWING_keyJOIN_IN_inner_cross_join_clause_3779 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_table_name_IN_inner_cross_join_clause_3781 = Set[ 1 ]
    TOKENS_FOLLOWING_query_partition_clause_IN_outer_join_clause_3793 = Set[ 40 ]
    TOKENS_FOLLOWING_outer_join_type_IN_outer_join_clause_3802 = Set[ 40 ]
    TOKENS_FOLLOWING_keyJOIN_IN_outer_join_clause_3804 = Set[ 7, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_keyNATURAL_IN_outer_join_clause_3810 = Set[ 40 ]
    TOKENS_FOLLOWING_outer_join_type_IN_outer_join_clause_3814 = Set[ 40 ]
    TOKENS_FOLLOWING_keyJOIN_IN_outer_join_clause_3819 = Set[ 7, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_selected_table_IN_outer_join_clause_3827 = Set[ 1, 40, 126 ]
    TOKENS_FOLLOWING_query_partition_clause_IN_outer_join_clause_3831 = Set[ 1, 40, 126 ]
    TOKENS_FOLLOWING_T__126_IN_outer_join_clause_3840 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_condition_IN_outer_join_clause_3842 = Set[ 1 ]
    TOKENS_FOLLOWING_keyUSING_IN_outer_join_clause_3846 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_outer_join_clause_3848 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_column_specs_IN_outer_join_clause_3850 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_outer_join_clause_3852 = Set[ 1 ]
    TOKENS_FOLLOWING_keyPARTITION_IN_query_partition_clause_3865 = Set[ 108 ]
    TOKENS_FOLLOWING_T__108_IN_query_partition_clause_3867 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expression_list_IN_query_partition_clause_3869 = Set[ 1 ]
    TOKENS_FOLLOWING_keyFULL_IN_outer_join_type_3881 = Set[ 1, 40 ]
    TOKENS_FOLLOWING_keyLEFT_IN_outer_join_type_3885 = Set[ 1, 40 ]
    TOKENS_FOLLOWING_keyRIGHT_IN_outer_join_type_3889 = Set[ 1, 40 ]
    TOKENS_FOLLOWING_keyOUTER_IN_outer_join_type_3895 = Set[ 1 ]
    TOKENS_FOLLOWING_LPAREN_IN_outer_join_sign_3908 = Set[ 13 ]
    TOKENS_FOLLOWING_PLUS_IN_outer_join_sign_3910 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_outer_join_sign_3912 = Set[ 1 ]
    TOKENS_FOLLOWING_T__127_IN_where_clause_3922 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_condition_IN_where_clause_3924 = Set[ 1 ]
    TOKENS_FOLLOWING_T__128_IN_hierarchical_query_clause_3936 = Set[ 78 ]
    TOKENS_FOLLOWING_T__78_IN_hierarchical_query_clause_3938 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_condition_IN_hierarchical_query_clause_3940 = Set[ 129 ]
    TOKENS_FOLLOWING_T__129_IN_hierarchical_query_clause_3945 = Set[ 108 ]
    TOKENS_FOLLOWING_T__108_IN_hierarchical_query_clause_3947 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_keyNOCYCLE_IN_hierarchical_query_clause_3951 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_condition_IN_hierarchical_query_clause_3956 = Set[ 1 ]
    TOKENS_FOLLOWING_T__130_IN_group_by_clause_3966 = Set[ 108 ]
    TOKENS_FOLLOWING_T__108_IN_group_by_clause_3968 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_group_by_exprs_IN_group_by_clause_3970 = Set[ 1 ]
    TOKENS_FOLLOWING_group_by_expr_IN_group_by_exprs_3980 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_group_by_exprs_3984 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_group_by_expr_IN_group_by_exprs_3986 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_rollup_cube_clause_IN_group_by_expr_3999 = Set[ 1 ]
    TOKENS_FOLLOWING_grouping_sets_clause_IN_group_by_expr_4004 = Set[ 1 ]
    TOKENS_FOLLOWING_grouping_expression_list_IN_group_by_expr_4009 = Set[ 1 ]
    TOKENS_FOLLOWING_keyROLLUP_IN_rollup_cube_clause_4021 = Set[ 7 ]
    TOKENS_FOLLOWING_keyCUBE_IN_rollup_cube_clause_4025 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_rollup_cube_clause_4029 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_grouping_expression_list_IN_rollup_cube_clause_4031 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_rollup_cube_clause_4033 = Set[ 1 ]
    TOKENS_FOLLOWING_keyGROUPING_IN_grouping_sets_clause_4043 = Set[ 40 ]
    TOKENS_FOLLOWING_keySETS_IN_grouping_sets_clause_4045 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_grouping_sets_clause_4047 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_grouping_expression_list_IN_grouping_sets_clause_4049 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_grouping_sets_clause_4051 = Set[ 1 ]
    TOKENS_FOLLOWING_grouping_sets_expr_IN_grouping_sets_exprs_4061 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_grouping_sets_exprs_4065 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_grouping_sets_expr_IN_grouping_sets_exprs_4067 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_rollup_cube_clause_IN_grouping_sets_expr_4080 = Set[ 1 ]
    TOKENS_FOLLOWING_grouping_expression_list_IN_grouping_sets_expr_4084 = Set[ 1 ]
    TOKENS_FOLLOWING_keyMODEL_IN_model_clause_4094 = Set[ 40, 118, 164 ]
    TOKENS_FOLLOWING_cell_reference_options_IN_model_clause_4098 = Set[ 40, 118, 164 ]
    TOKENS_FOLLOWING_return_rows_clause_IN_model_clause_4106 = Set[ 40, 118, 164 ]
    TOKENS_FOLLOWING_reference_model_IN_model_clause_4115 = Set[ 40, 118, 164 ]
    TOKENS_FOLLOWING_main_model_IN_model_clause_4120 = Set[ 1 ]
    TOKENS_FOLLOWING_keyIGNORE_IN_cell_reference_options_4134 = Set[ 40 ]
    TOKENS_FOLLOWING_keyKEEP_IN_cell_reference_options_4138 = Set[ 40 ]
    TOKENS_FOLLOWING_keyNAV_IN_cell_reference_options_4142 = Set[ 1, 118 ]
    TOKENS_FOLLOWING_T__118_IN_cell_reference_options_4151 = Set[ 40 ]
    TOKENS_FOLLOWING_keyDIMENSION_IN_cell_reference_options_4155 = Set[ 1 ]
    TOKENS_FOLLOWING_keySINGLE_IN_cell_reference_options_4159 = Set[ 40, 118, 164 ]
    TOKENS_FOLLOWING_keyREFERENCE_IN_cell_reference_options_4161 = Set[ 1 ]
    TOKENS_FOLLOWING_keyRETURN_IN_return_rows_clause_4176 = Set[ 40, 119 ]
    TOKENS_FOLLOWING_keyUPDATED_IN_return_rows_clause_4180 = Set[ 131 ]
    TOKENS_FOLLOWING_T__119_IN_return_rows_clause_4184 = Set[ 131 ]
    TOKENS_FOLLOWING_T__131_IN_return_rows_clause_4188 = Set[ 1 ]
    TOKENS_FOLLOWING_keyREFERENCE_IN_reference_model_4198 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_reference_model_name_IN_reference_model_4200 = Set[ 126 ]
    TOKENS_FOLLOWING_T__126_IN_reference_model_4202 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_reference_model_4204 = Set[ 7, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_subquery_IN_reference_model_4206 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_reference_model_4208 = Set[ 40 ]
    TOKENS_FOLLOWING_model_column_clauses_IN_reference_model_4212 = Set[ 40, 118 ]
    TOKENS_FOLLOWING_cell_reference_options_IN_reference_model_4216 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_reference_model_name_4228 = Set[ 1 ]
    TOKENS_FOLLOWING_keyMAIN_IN_main_model_4240 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_main_model_name_IN_main_model_4242 = Set[ 40 ]
    TOKENS_FOLLOWING_model_column_clauses_IN_main_model_4247 = Set[ 7, 40, 118 ]
    TOKENS_FOLLOWING_cell_reference_options_IN_main_model_4253 = Set[ 7, 40, 118 ]
    TOKENS_FOLLOWING_model_rules_clause_IN_main_model_4257 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_main_model_name_4267 = Set[ 1 ]
    TOKENS_FOLLOWING_query_partition_clause_IN_model_column_clauses_4279 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_column_spec_IN_model_column_clauses_4283 = Set[ 40 ]
    TOKENS_FOLLOWING_keyDIMENSION_IN_model_column_clauses_4293 = Set[ 108 ]
    TOKENS_FOLLOWING_T__108_IN_model_column_clauses_4295 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_model_column_clauses_4297 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_model_columns_IN_model_column_clauses_4299 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_model_column_clauses_4301 = Set[ 40 ]
    TOKENS_FOLLOWING_keyMEASURES_IN_model_column_clauses_4305 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_model_column_clauses_4307 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_model_columns_IN_model_column_clauses_4309 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_model_column_clauses_4311 = Set[ 1 ]
    TOKENS_FOLLOWING_model_column_IN_model_columns_4321 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_model_columns_4325 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_model_column_IN_model_columns_4327 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_sql_expression_IN_model_column_4340 = Set[ 1, 40, 41, 53, 100 ]
    TOKENS_FOLLOWING_T__53_IN_model_column_4346 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_column_spec_IN_model_column_4351 = Set[ 1 ]
    TOKENS_FOLLOWING_keyRULES_IN_model_rules_clause_4366 = Set[ 7, 40, 132 ]
    TOKENS_FOLLOWING_T__132_IN_model_rules_clause_4370 = Set[ 7, 40 ]
    TOKENS_FOLLOWING_keyUPSERT_IN_model_rules_clause_4374 = Set[ 7, 40, 119 ]
    TOKENS_FOLLOWING_T__119_IN_model_rules_clause_4378 = Set[ 7, 40 ]
    TOKENS_FOLLOWING_keyAUTOMATIC_IN_model_rules_clause_4390 = Set[ 133 ]
    TOKENS_FOLLOWING_keySEQUENTIAL_IN_model_rules_clause_4394 = Set[ 133 ]
    TOKENS_FOLLOWING_T__133_IN_model_rules_clause_4398 = Set[ 7, 40 ]
    TOKENS_FOLLOWING_keyITERATE_IN_model_rules_clause_4410 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_model_rules_clause_4412 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_model_rules_clause_4414 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_model_rules_clause_4416 = Set[ 7, 40 ]
    TOKENS_FOLLOWING_keyUNTIL_IN_model_rules_clause_4420 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_model_rules_clause_4422 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_condition_IN_model_rules_clause_4424 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_model_rules_clause_4426 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_model_rules_clause_4436 = Set[ 40, 41, 100, 132 ]
    TOKENS_FOLLOWING_model_rules_exprs_IN_model_rules_clause_4438 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_model_rules_clause_4440 = Set[ 1 ]
    TOKENS_FOLLOWING_model_rules_expr_IN_model_rules_exprs_4450 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_model_rules_exprs_4454 = Set[ 40, 41, 100, 132 ]
    TOKENS_FOLLOWING_model_rules_expr_IN_model_rules_exprs_4456 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_T__132_IN_model_rules_expr_4471 = Set[ 40, 41, 100, 132 ]
    TOKENS_FOLLOWING_keyUPSERT_IN_model_rules_expr_4475 = Set[ 40, 41, 100, 119, 132 ]
    TOKENS_FOLLOWING_T__119_IN_model_rules_expr_4479 = Set[ 40, 41, 100, 132 ]
    TOKENS_FOLLOWING_cell_assignment_IN_model_rules_expr_4487 = Set[ 22, 133 ]
    TOKENS_FOLLOWING_order_by_clause_IN_model_rules_expr_4491 = Set[ 22 ]
    TOKENS_FOLLOWING_EQ_IN_model_rules_expr_4496 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expression_IN_model_rules_expr_4498 = Set[ 1 ]
    TOKENS_FOLLOWING_measure_column_IN_cell_assignment_4508 = Set[ 23 ]
    TOKENS_FOLLOWING_LBRACK_IN_cell_assignment_4510 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_multi_column_for_loop_IN_cell_assignment_4514 = Set[ 24 ]
    TOKENS_FOLLOWING_cell_assignment_exprs_IN_cell_assignment_4518 = Set[ 24 ]
    TOKENS_FOLLOWING_RBRACK_IN_cell_assignment_4522 = Set[ 1 ]
    TOKENS_FOLLOWING_cell_assignment_expr_IN_cell_assignment_exprs_4532 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_cell_assignment_exprs_4536 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_cell_assignment_expr_IN_cell_assignment_exprs_4538 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_sql_condition_IN_cell_assignment_expr_4551 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_cell_assignment_expr_4555 = Set[ 1 ]
    TOKENS_FOLLOWING_single_column_for_loop_IN_cell_assignment_expr_4559 = Set[ 1 ]
    TOKENS_FOLLOWING_column_name_IN_measure_column_4569 = Set[ 1 ]
    TOKENS_FOLLOWING_T__112_IN_single_column_for_loop_4579 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_column_name_IN_single_column_for_loop_4581 = Set[ 102, 121, 134 ]
    TOKENS_FOLLOWING_T__102_IN_single_column_for_loop_4587 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_single_column_for_loop_4589 = Set[ 7, 13, 14, 15, 16, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_literals_IN_single_column_for_loop_4593 = Set[ 8 ]
    TOKENS_FOLLOWING_subquery_IN_single_column_for_loop_4597 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_single_column_for_loop_4601 = Set[ 1 ]
    TOKENS_FOLLOWING_T__134_IN_single_column_for_loop_4609 = Set[ 16 ]
    TOKENS_FOLLOWING_pattern_IN_single_column_for_loop_4611 = Set[ 121 ]
    TOKENS_FOLLOWING_T__121_IN_single_column_for_loop_4616 = Set[ 13, 14, 15, 16 ]
    TOKENS_FOLLOWING_literal_IN_single_column_for_loop_4618 = Set[ 77 ]
    TOKENS_FOLLOWING_T__77_IN_single_column_for_loop_4620 = Set[ 13, 14, 15, 16 ]
    TOKENS_FOLLOWING_literal_IN_single_column_for_loop_4622 = Set[ 40 ]
    TOKENS_FOLLOWING_keyINCREMENT_IN_single_column_for_loop_4626 = Set[ 13, 14, 15, 16 ]
    TOKENS_FOLLOWING_keyDECREMENT_IN_single_column_for_loop_4630 = Set[ 13, 14, 15, 16 ]
    TOKENS_FOLLOWING_literal_IN_single_column_for_loop_4634 = Set[ 1 ]
    TOKENS_FOLLOWING_set_IN_literal_4648 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_literal_4659 = Set[ 1 ]
    TOKENS_FOLLOWING_QUOTED_STRING_IN_literal_4664 = Set[ 1 ]
    TOKENS_FOLLOWING_literal_IN_literals_4674 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_literals_4678 = Set[ 13, 14, 15, 16 ]
    TOKENS_FOLLOWING_literal_IN_literals_4680 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_LPAREN_IN_bracket_literals_4693 = Set[ 13, 14, 15, 16 ]
    TOKENS_FOLLOWING_literals_IN_bracket_literals_4695 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_bracket_literals_4697 = Set[ 1 ]
    TOKENS_FOLLOWING_bracket_literals_IN_bracket_literals_list_4707 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_bracket_literals_list_4711 = Set[ 7 ]
    TOKENS_FOLLOWING_bracket_literals_IN_bracket_literals_list_4713 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_QUOTED_STRING_IN_pattern_4726 = Set[ 1 ]
    TOKENS_FOLLOWING_T__112_IN_multi_column_for_loop_4736 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_multi_column_for_loop_4738 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_column_specs_IN_multi_column_for_loop_4740 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_multi_column_for_loop_4742 = Set[ 102 ]
    TOKENS_FOLLOWING_T__102_IN_multi_column_for_loop_4744 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_multi_column_for_loop_4746 = Set[ 7, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_bracket_literals_list_IN_multi_column_for_loop_4750 = Set[ 8 ]
    TOKENS_FOLLOWING_subquery_IN_multi_column_for_loop_4754 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_multi_column_for_loop_4758 = Set[ 1 ]
    TOKENS_FOLLOWING_T__133_IN_order_by_clause_4768 = Set[ 40, 108 ]
    TOKENS_FOLLOWING_keySIBLINGS_IN_order_by_clause_4772 = Set[ 108 ]
    TOKENS_FOLLOWING_T__108_IN_order_by_clause_4777 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_order_by_exprs_IN_order_by_clause_4779 = Set[ 1 ]
    TOKENS_FOLLOWING_order_by_expr_IN_order_by_exprs_4789 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_order_by_exprs_4793 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_order_by_expr_IN_order_by_exprs_4795 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_sql_expression_IN_order_by_expr_4810 = Set[ 1, 40, 135, 136 ]
    TOKENS_FOLLOWING_set_IN_order_by_expr_4820 = Set[ 1, 40 ]
    TOKENS_FOLLOWING_keyNULLS_IN_order_by_expr_4833 = Set[ 40 ]
    TOKENS_FOLLOWING_keyFIRST_IN_order_by_expr_4835 = Set[ 1 ]
    TOKENS_FOLLOWING_keyNULLS_IN_order_by_expr_4839 = Set[ 40 ]
    TOKENS_FOLLOWING_keyLAST_IN_order_by_expr_4841 = Set[ 1 ]
    TOKENS_FOLLOWING_T__112_IN_for_update_clause_4854 = Set[ 132 ]
    TOKENS_FOLLOWING_T__132_IN_for_update_clause_4856 = Set[ 1, 40, 106, 137 ]
    TOKENS_FOLLOWING_T__106_IN_for_update_clause_4860 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_column_specs_IN_for_update_clause_4862 = Set[ 1, 40, 137 ]
    TOKENS_FOLLOWING_keyWAIT_IN_for_update_clause_4869 = Set[ 15 ]
    TOKENS_FOLLOWING_integer_IN_for_update_clause_4871 = Set[ 1 ]
    TOKENS_FOLLOWING_T__137_IN_for_update_clause_4875 = Set[ 1 ]
    TOKENS_FOLLOWING_T__127_IN_where_condition_whole_4889 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_condition_IN_where_condition_whole_4891 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_condition_IN_where_condition_4902 = Set[ 1 ]
    TOKENS_FOLLOWING_column_spec_IN_displayed_column_4916 = Set[ 5 ]
    TOKENS_FOLLOWING_DOT_IN_displayed_column_4918 = Set[ 21 ]
    TOKENS_FOLLOWING_ASTERISK_IN_displayed_column_4920 = Set[ 1, 40, 41, 53, 100 ]
    TOKENS_FOLLOWING_sql_expression_IN_displayed_column_4929 = Set[ 1, 40, 41, 53, 100 ]
    TOKENS_FOLLOWING_objalias_IN_displayed_column_4939 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_identifier_IN_schema_name_4962 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_identifier_IN_table_name_4973 = Set[ 1 ]
    TOKENS_FOLLOWING_nested_expression_IN_nested_expressions_4984 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_nested_expressions_4988 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_nested_expression_IN_nested_expressions_4990 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_sql_expression_IN_nested_expression_5006 = Set[ 1 ]
    TOKENS_FOLLOWING_plsql_expression_IN_nested_expression_5013 = Set[ 1 ]
    TOKENS_FOLLOWING_expr_bool_IN_plsql_condition_5030 = Set[ 1 ]
    TOKENS_FOLLOWING_plsql_expression_IN_plsql_expressions_5041 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_plsql_expressions_5045 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_plsql_expression_IN_plsql_expressions_5047 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_expr_bool_IN_plsql_expression_5068 = Set[ 1 ]
    TOKENS_FOLLOWING_expr_or_IN_expr_bool_5080 = Set[ 1, 51 ]
    TOKENS_FOLLOWING_T__51_IN_expr_bool_5084 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_or_IN_expr_bool_5086 = Set[ 1, 51 ]
    TOKENS_FOLLOWING_expr_and_IN_expr_or_5099 = Set[ 1, 138 ]
    TOKENS_FOLLOWING_T__138_IN_expr_or_5103 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_and_IN_expr_or_5105 = Set[ 1, 138 ]
    TOKENS_FOLLOWING_T__57_IN_expr_and_5120 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_not_IN_expr_and_5125 = Set[ 1 ]
    TOKENS_FOLLOWING_expr_add_IN_expr_not_5135 = Set[ 1, 22, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 52, 57, 102, 134, 139 ]
    TOKENS_FOLLOWING_relational_op_IN_expr_not_5142 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_add_IN_expr_not_5144 = Set[ 1, 22, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 52, 57, 102, 134, 139 ]
    TOKENS_FOLLOWING_FOUND_ATTR_IN_expr_not_5150 = Set[ 1, 22, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 52, 57, 102, 134, 139 ]
    TOKENS_FOLLOWING_NOTFOUND_ATTR_IN_expr_not_5154 = Set[ 1, 22, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 52, 57, 102, 134, 139 ]
    TOKENS_FOLLOWING_ISOPEN_ATTR_IN_expr_not_5158 = Set[ 1, 22, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 52, 57, 102, 134, 139 ]
    TOKENS_FOLLOWING_ROWCOUNT_ATTR_IN_expr_not_5162 = Set[ 1, 22, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 52, 57, 102, 134, 139 ]
    TOKENS_FOLLOWING_BULK_ROWCOUNT_ATTR_IN_expr_not_5166 = Set[ 1, 22, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 52, 57, 102, 134, 139 ]
    TOKENS_FOLLOWING_T__52_IN_expr_not_5172 = Set[ 57, 58 ]
    TOKENS_FOLLOWING_T__57_IN_expr_not_5176 = Set[ 58 ]
    TOKENS_FOLLOWING_T__58_IN_expr_not_5181 = Set[ 1, 22, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 52, 57, 102, 134, 139 ]
    TOKENS_FOLLOWING_T__57_IN_expr_not_5189 = Set[ 134 ]
    TOKENS_FOLLOWING_T__134_IN_expr_not_5194 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_add_IN_expr_not_5196 = Set[ 1, 22, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 52, 57, 102, 134, 139 ]
    TOKENS_FOLLOWING_T__57_IN_expr_not_5204 = Set[ 139 ]
    TOKENS_FOLLOWING_T__139_IN_expr_not_5209 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_add_IN_expr_not_5211 = Set[ 138 ]
    TOKENS_FOLLOWING_T__138_IN_expr_not_5213 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_add_IN_expr_not_5215 = Set[ 1, 22, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 52, 57, 102, 134, 139 ]
    TOKENS_FOLLOWING_T__57_IN_expr_not_5223 = Set[ 102 ]
    TOKENS_FOLLOWING_T__102_IN_expr_not_5228 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_expr_not_5230 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_nested_expressions_IN_expr_not_5232 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_expr_not_5234 = Set[ 1, 22, 25, 26, 27, 28, 29, 34, 35, 36, 37, 38, 52, 57, 102, 134, 139 ]
    TOKENS_FOLLOWING_set_IN_boolean_literal_0 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_sql_expressions_5265 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_sql_expressions_5269 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expression_IN_sql_expressions_5271 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_expr_add_IN_sql_expression_5291 = Set[ 1 ]
    TOKENS_FOLLOWING_expr_mul_IN_expr_add_5301 = Set[ 1, 13, 14, 30 ]
    TOKENS_FOLLOWING_set_IN_expr_add_5305 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_mul_IN_expr_add_5319 = Set[ 1, 13, 14, 30 ]
    TOKENS_FOLLOWING_expr_sign_IN_expr_mul_5332 = Set[ 1, 21, 31 ]
    TOKENS_FOLLOWING_set_IN_expr_mul_5336 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_sign_IN_expr_mul_5346 = Set[ 1, 21, 31 ]
    TOKENS_FOLLOWING_set_IN_expr_sign_5359 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_pow_IN_expr_sign_5370 = Set[ 1 ]
    TOKENS_FOLLOWING_expr_expr_IN_expr_pow_5380 = Set[ 1, 32 ]
    TOKENS_FOLLOWING_EXPONENT_IN_expr_pow_5384 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_expr_IN_expr_pow_5386 = Set[ 1, 32 ]
    TOKENS_FOLLOWING_expr_paren_IN_expr_expr_5407 = Set[ 1 ]
    TOKENS_FOLLOWING_function_expression_IN_expr_expr_5420 = Set[ 1 ]
    TOKENS_FOLLOWING_case_expression_IN_expr_expr_5440 = Set[ 1 ]
    TOKENS_FOLLOWING_cursor_expression_IN_expr_expr_5453 = Set[ 1 ]
    TOKENS_FOLLOWING_simple_expression_IN_expr_expr_5466 = Set[ 1 ]
    TOKENS_FOLLOWING_select_expression_IN_expr_expr_5479 = Set[ 1 ]
    TOKENS_FOLLOWING_boolean_literal_IN_simple_expression_5490 = Set[ 1 ]
    TOKENS_FOLLOWING_T__140_IN_simple_expression_5495 = Set[ 25, 26, 27, 28, 29 ]
    TOKENS_FOLLOWING_set_IN_simple_expression_5497 = Set[ 1 ]
    TOKENS_FOLLOWING_column_spec_IN_simple_expression_5530 = Set[ 1 ]
    TOKENS_FOLLOWING_QUOTED_STRING_IN_simple_expression_5536 = Set[ 1 ]
    TOKENS_FOLLOWING_NUMBER_IN_simple_expression_5541 = Set[ 1 ]
    TOKENS_FOLLOWING_T__58_IN_simple_expression_5546 = Set[ 1 ]
    TOKENS_FOLLOWING_expr_prior_IN_compound_expression_5558 = Set[ 1 ]
    TOKENS_FOLLOWING_LPAREN_IN_expr_paren_5570 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_nested_expression_IN_expr_paren_5574 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_expr_paren_5576 = Set[ 1 ]
    TOKENS_FOLLOWING_T__141_IN_expr_prior_5588 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_add_IN_expr_prior_5590 = Set[ 1 ]
    TOKENS_FOLLOWING_T__142_IN_case_expression_5600 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 63, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_simple_case_expression_IN_case_expression_5604 = Set[ 54, 115 ]
    TOKENS_FOLLOWING_searched_case_expression_IN_case_expression_5608 = Set[ 54, 115 ]
    TOKENS_FOLLOWING_else_case_expression_IN_case_expression_5614 = Set[ 54 ]
    TOKENS_FOLLOWING_T__54_IN_case_expression_5619 = Set[ 1 ]
    TOKENS_FOLLOWING_nested_expression_IN_simple_case_expression_5629 = Set[ 63 ]
    TOKENS_FOLLOWING_T__63_IN_simple_case_expression_5633 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_nested_expression_IN_simple_case_expression_5635 = Set[ 109 ]
    TOKENS_FOLLOWING_T__109_IN_simple_case_expression_5637 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_nested_expression_IN_simple_case_expression_5639 = Set[ 1, 63 ]
    TOKENS_FOLLOWING_T__63_IN_searched_case_expression_5654 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_nested_condition_IN_searched_case_expression_5656 = Set[ 109 ]
    TOKENS_FOLLOWING_T__109_IN_searched_case_expression_5658 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_nested_expression_IN_searched_case_expression_5660 = Set[ 1, 63 ]
    TOKENS_FOLLOWING_T__115_IN_else_case_expression_5673 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_nested_expression_IN_else_case_expression_5675 = Set[ 1 ]
    TOKENS_FOLLOWING_label_name_IN_case_statement_5687 = Set[ 142 ]
    TOKENS_FOLLOWING_T__142_IN_case_statement_5692 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 63, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_simple_case_statement_IN_case_statement_5697 = Set[ 54, 115 ]
    TOKENS_FOLLOWING_searched_case_statement_IN_case_statement_5701 = Set[ 54, 115 ]
    TOKENS_FOLLOWING_else_case_statement_IN_case_statement_5707 = Set[ 54 ]
    TOKENS_FOLLOWING_T__54_IN_case_statement_5712 = Set[ 142 ]
    TOKENS_FOLLOWING_T__142_IN_case_statement_5714 = Set[ 1, 40, 41 ]
    TOKENS_FOLLOWING_label_name_IN_case_statement_5718 = Set[ 1 ]
    TOKENS_FOLLOWING_plsql_expression_IN_simple_case_statement_5731 = Set[ 63 ]
    TOKENS_FOLLOWING_T__63_IN_simple_case_statement_5735 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_plsql_expression_IN_simple_case_statement_5737 = Set[ 109 ]
    TOKENS_FOLLOWING_T__109_IN_simple_case_statement_5739 = Set[ 10, 17, 40, 41, 50, 55, 58, 60, 62, 87, 100, 103, 104, 112, 113, 114, 116, 132, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_seq_of_statements_IN_simple_case_statement_5741 = Set[ 1, 63 ]
    TOKENS_FOLLOWING_T__63_IN_searched_case_statement_5756 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_plsql_expression_IN_searched_case_statement_5758 = Set[ 109 ]
    TOKENS_FOLLOWING_T__109_IN_searched_case_statement_5760 = Set[ 10, 17, 40, 41, 50, 55, 58, 60, 62, 87, 100, 103, 104, 112, 113, 114, 116, 132, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_seq_of_statements_IN_searched_case_statement_5762 = Set[ 1, 63 ]
    TOKENS_FOLLOWING_T__115_IN_else_case_statement_5775 = Set[ 10, 17, 40, 41, 50, 55, 58, 60, 62, 87, 100, 103, 104, 112, 113, 114, 116, 132, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_seq_of_statements_IN_else_case_statement_5777 = Set[ 1 ]
    TOKENS_FOLLOWING_keyCURSOR_IN_cursor_expression_5787 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_cursor_expression_5789 = Set[ 7, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_subquery_IN_cursor_expression_5791 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_cursor_expression_5793 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_datetime_expression_5803 = Set[ 143 ]
    TOKENS_FOLLOWING_T__143_IN_datetime_expression_5805 = Set[ 40 ]
    TOKENS_FOLLOWING_keyLOCAL_IN_datetime_expression_5811 = Set[ 1 ]
    TOKENS_FOLLOWING_keyTIME_IN_datetime_expression_5817 = Set[ 40 ]
    TOKENS_FOLLOWING_keyZONE_IN_datetime_expression_5819 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_keyDBTIMEZONE_IN_datetime_expression_5823 = Set[ 1 ]
    TOKENS_FOLLOWING_keySESSIONTIMEZONE_IN_datetime_expression_5827 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_datetime_expression_5831 = Set[ 1 ]
    TOKENS_FOLLOWING_function_call_IN_function_expression_5847 = Set[ 1, 5 ]
    TOKENS_FOLLOWING_DOT_IN_function_expression_5851 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_nested_expression_IN_function_expression_5853 = Set[ 1 ]
    TOKENS_FOLLOWING_keyCOUNT_IN_function_expression_5867 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_function_expression_5869 = Set[ 7, 10, 13, 14, 15, 16, 17, 21, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_ASTERISK_IN_function_expression_5873 = Set[ 8 ]
    TOKENS_FOLLOWING_nested_expression_IN_function_expression_5877 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_function_expression_5881 = Set[ 1 ]
    TOKENS_FOLLOWING_T__117_IN_function_expression_5887 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_LPAREN_IN_function_expression_5891 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_nested_expression_IN_function_expression_5893 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_function_expression_5895 = Set[ 1 ]
    TOKENS_FOLLOWING_nested_expression_IN_function_expression_5899 = Set[ 1 ]
    TOKENS_FOLLOWING_keyCOUNT_IN_special_expression_5921 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_special_expression_5923 = Set[ 7, 10, 13, 14, 15, 16, 17, 21, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_ASTERISK_IN_special_expression_5927 = Set[ 8 ]
    TOKENS_FOLLOWING_nested_expression_IN_special_expression_5931 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_special_expression_5935 = Set[ 1 ]
    TOKENS_FOLLOWING_T__117_IN_special_expression_5941 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_special_expression_5943 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_nested_expression_IN_special_expression_5945 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_special_expression_5947 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_interval_expression_5961 = Set[ 40 ]
    TOKENS_FOLLOWING_keyDAY_IN_interval_expression_5967 = Set[ 7, 77 ]
    TOKENS_FOLLOWING_LPAREN_IN_interval_expression_5971 = Set[ 15 ]
    TOKENS_FOLLOWING_leading_field_precision_IN_interval_expression_5973 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_interval_expression_5975 = Set[ 77 ]
    TOKENS_FOLLOWING_T__77_IN_interval_expression_5980 = Set[ 40 ]
    TOKENS_FOLLOWING_keySECOND_IN_interval_expression_5982 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_interval_expression_5986 = Set[ 15 ]
    TOKENS_FOLLOWING_fractional_second_precision_IN_interval_expression_5988 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_interval_expression_5990 = Set[ 1 ]
    TOKENS_FOLLOWING_keyYEAR_IN_interval_expression_5999 = Set[ 7, 77 ]
    TOKENS_FOLLOWING_LPAREN_IN_interval_expression_6003 = Set[ 15 ]
    TOKENS_FOLLOWING_leading_field_precision_IN_interval_expression_6005 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_interval_expression_6007 = Set[ 77 ]
    TOKENS_FOLLOWING_T__77_IN_interval_expression_6012 = Set[ 40 ]
    TOKENS_FOLLOWING_keyMONTH_IN_interval_expression_6014 = Set[ 1 ]
    TOKENS_FOLLOWING_integer_IN_leading_field_precision_6028 = Set[ 1 ]
    TOKENS_FOLLOWING_integer_IN_fractional_second_precision_6039 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_sequence_name_6090 = Set[ 1 ]
    TOKENS_FOLLOWING_NUMBER_IN_integer_6100 = Set[ 1 ]
    TOKENS_FOLLOWING_T__53_IN_objalias_6118 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_sql_identifier_IN_objalias_6123 = Set[ 1 ]
    TOKENS_FOLLOWING_column_spec_IN_column_specs_6136 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_column_specs_6140 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_column_spec_IN_column_specs_6142 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_sql_identifier_IN_column_spec_6156 = Set[ 1, 5 ]
    TOKENS_FOLLOWING_DOT_IN_column_spec_6160 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_sql_identifier_IN_column_spec_6162 = Set[ 1, 5 ]
    TOKENS_FOLLOWING_DOT_IN_column_spec_6166 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_sql_identifier_IN_column_spec_6168 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_identifier_IN_column_name_6185 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_identifier_IN_nested_table_6195 = Set[ 1 ]
    TOKENS_FOLLOWING_schema_name_IN_nested_table_column_name_6207 = Set[ 5 ]
    TOKENS_FOLLOWING_DOT_IN_nested_table_column_name_6209 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_table_name_IN_nested_table_column_name_6214 = Set[ 5 ]
    TOKENS_FOLLOWING_DOT_IN_nested_table_column_name_6216 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_nested_table_IN_nested_table_column_name_6218 = Set[ 5 ]
    TOKENS_FOLLOWING_DOT_IN_nested_table_column_name_6220 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_column_name_IN_nested_table_column_name_6222 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_identifier_IN_user_defined_function_6233 = Set[ 1, 5 ]
    TOKENS_FOLLOWING_DOT_IN_user_defined_function_6237 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_sql_identifier_IN_user_defined_function_6239 = Set[ 1, 5 ]
    TOKENS_FOLLOWING_DOT_IN_user_defined_function_6246 = Set[ 141, 144, 145 ]
    TOKENS_FOLLOWING_set_IN_user_defined_function_6248 = Set[ 1 ]
    TOKENS_FOLLOWING_table_spec_IN_selected_table_6277 = Set[ 1, 40, 41, 53, 100 ]
    TOKENS_FOLLOWING_T__105_IN_selected_table_6283 = Set[ 7, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_keyTHE_IN_selected_table_6287 = Set[ 7, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_subquery_IN_selected_table_6292 = Set[ 1, 40, 41, 53, 100 ]
    TOKENS_FOLLOWING_objalias_IN_selected_table_6298 = Set[ 1 ]
    TOKENS_FOLLOWING_schema_name_IN_table_spec_6314 = Set[ 5 ]
    TOKENS_FOLLOWING_DOT_IN_table_spec_6316 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_table_name_IN_table_spec_6321 = Set[ 1, 33 ]
    TOKENS_FOLLOWING_AT_SIGN_IN_table_spec_6325 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_link_name_IN_table_spec_6327 = Set[ 1 ]
    TOKENS_FOLLOWING_schema_name_IN_table_alias_6343 = Set[ 5 ]
    TOKENS_FOLLOWING_DOT_IN_table_alias_6345 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_table_name_IN_table_alias_6350 = Set[ 1, 33, 40, 41, 53, 100 ]
    TOKENS_FOLLOWING_AT_SIGN_IN_table_alias_6354 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_link_name_IN_table_alias_6356 = Set[ 1, 40, 41, 53, 100 ]
    TOKENS_FOLLOWING_objalias_IN_table_alias_6363 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_identifier_IN_link_name_6377 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_or_IN_nested_condition_6389 = Set[ 1 ]
    TOKENS_FOLLOWING_expr_bool_IN_nested_condition_6396 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_or_IN_sql_condition_6413 = Set[ 1 ]
    TOKENS_FOLLOWING_LPAREN_IN_condition_paren_6424 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_condition_IN_condition_paren_6426 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_condition_paren_6428 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_and_IN_condition_or_6438 = Set[ 1, 51 ]
    TOKENS_FOLLOWING_T__51_IN_condition_or_6442 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_condition_and_IN_condition_or_6444 = Set[ 1, 51 ]
    TOKENS_FOLLOWING_condition_not_IN_condition_and_6457 = Set[ 1, 138 ]
    TOKENS_FOLLOWING_T__138_IN_condition_and_6461 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_condition_not_IN_condition_and_6463 = Set[ 1, 138 ]
    TOKENS_FOLLOWING_T__57_IN_condition_not_6476 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_condition_expr_IN_condition_not_6478 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_expr_IN_condition_not_6483 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_exists_IN_condition_expr_6493 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_is_IN_condition_expr_6498 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_comparison_IN_condition_expr_6503 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_group_comparison_IN_condition_expr_6508 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_in_IN_condition_expr_6513 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_is_a_set_IN_condition_expr_6518 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_is_any_IN_condition_expr_6523 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_is_empty_IN_condition_expr_6528 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_is_of_type_IN_condition_expr_6533 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_is_present_IN_condition_expr_6538 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_like_IN_condition_expr_6543 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_memeber_IN_condition_expr_6548 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_between_IN_condition_expr_6553 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_regexp_like_IN_condition_expr_6558 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_submultiset_IN_condition_expr_6563 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_equals_path_IN_condition_expr_6568 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_under_path_IN_condition_expr_6573 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_paren_IN_condition_expr_6578 = Set[ 1 ]
    TOKENS_FOLLOWING_T__144_IN_condition_exists_6588 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_condition_exists_6590 = Set[ 116 ]
    TOKENS_FOLLOWING_select_command_IN_condition_exists_6592 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_condition_exists_6594 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_condition_is_6604 = Set[ 52 ]
    TOKENS_FOLLOWING_T__52_IN_condition_is_6606 = Set[ 40, 57, 58 ]
    TOKENS_FOLLOWING_T__57_IN_condition_is_6610 = Set[ 40, 58 ]
    TOKENS_FOLLOWING_keyNAN_IN_condition_is_6617 = Set[ 1 ]
    TOKENS_FOLLOWING_keyINFINITE_IN_condition_is_6621 = Set[ 1 ]
    TOKENS_FOLLOWING_T__58_IN_condition_is_6625 = Set[ 1 ]
    TOKENS_FOLLOWING_LPAREN_IN_condition_comparison_6637 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expressions_IN_condition_comparison_6639 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_condition_comparison_6641 = Set[ 7, 22, 34 ]
    TOKENS_FOLLOWING_outer_join_sign_IN_condition_comparison_6645 = Set[ 22, 34 ]
    TOKENS_FOLLOWING_set_IN_condition_comparison_6650 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_condition_comparison_6660 = Set[ 116 ]
    TOKENS_FOLLOWING_select_command_IN_condition_comparison_6662 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_condition_comparison_6664 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_outer_join_sign_IN_condition_comparison_6668 = Set[ 1 ]
    TOKENS_FOLLOWING_T__141_IN_condition_comparison_6678 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expression_IN_condition_comparison_6683 = Set[ 7, 22, 34, 35, 36, 37, 38 ]
    TOKENS_FOLLOWING_outer_join_sign_IN_condition_comparison_6687 = Set[ 22, 34, 35, 36, 37, 38 ]
    TOKENS_FOLLOWING_set_IN_condition_comparison_6692 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_T__141_IN_condition_comparison_6720 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expression_IN_condition_comparison_6727 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_condition_comparison_6731 = Set[ 116 ]
    TOKENS_FOLLOWING_select_command_IN_condition_comparison_6733 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_condition_comparison_6735 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_outer_join_sign_IN_condition_comparison_6741 = Set[ 1 ]
    TOKENS_FOLLOWING_LPAREN_IN_condition_group_comparison_6754 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expressions_IN_condition_group_comparison_6756 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_condition_group_comparison_6758 = Set[ 22, 34 ]
    TOKENS_FOLLOWING_set_IN_condition_group_comparison_6760 = Set[ 40, 119, 146 ]
    TOKENS_FOLLOWING_T__146_IN_condition_group_comparison_6772 = Set[ 7 ]
    TOKENS_FOLLOWING_keySOME_IN_condition_group_comparison_6776 = Set[ 7 ]
    TOKENS_FOLLOWING_T__119_IN_condition_group_comparison_6780 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_condition_group_comparison_6784 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_grouping_expression_list_IN_condition_group_comparison_6788 = Set[ 8 ]
    TOKENS_FOLLOWING_select_command_IN_condition_group_comparison_6792 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_condition_group_comparison_6796 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_condition_group_comparison_6801 = Set[ 22, 34, 35, 36, 37, 38 ]
    TOKENS_FOLLOWING_set_IN_condition_group_comparison_6803 = Set[ 40, 119, 146 ]
    TOKENS_FOLLOWING_T__146_IN_condition_group_comparison_6831 = Set[ 7 ]
    TOKENS_FOLLOWING_keySOME_IN_condition_group_comparison_6835 = Set[ 7 ]
    TOKENS_FOLLOWING_T__119_IN_condition_group_comparison_6839 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_condition_group_comparison_6843 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expressions_IN_condition_group_comparison_6847 = Set[ 8 ]
    TOKENS_FOLLOWING_select_command_IN_condition_group_comparison_6851 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_condition_group_comparison_6855 = Set[ 1 ]
    TOKENS_FOLLOWING_LPAREN_IN_condition_in_6865 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expressions_IN_condition_in_6867 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_condition_in_6869 = Set[ 57, 102 ]
    TOKENS_FOLLOWING_T__57_IN_condition_in_6873 = Set[ 102 ]
    TOKENS_FOLLOWING_T__102_IN_condition_in_6878 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_condition_in_6880 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_grouping_expression_list_IN_condition_in_6884 = Set[ 8 ]
    TOKENS_FOLLOWING_select_command_IN_condition_in_6888 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_condition_in_6892 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_condition_in_6897 = Set[ 57, 102 ]
    TOKENS_FOLLOWING_T__57_IN_condition_in_6901 = Set[ 102 ]
    TOKENS_FOLLOWING_T__102_IN_condition_in_6906 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_condition_in_6908 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expression_list_IN_condition_in_6912 = Set[ 8 ]
    TOKENS_FOLLOWING_select_command_IN_condition_in_6916 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_condition_in_6920 = Set[ 1 ]
    TOKENS_FOLLOWING_nested_table_column_name_IN_condition_is_a_set_6930 = Set[ 52 ]
    TOKENS_FOLLOWING_T__52_IN_condition_is_a_set_6932 = Set[ 40, 57 ]
    TOKENS_FOLLOWING_T__57_IN_condition_is_a_set_6936 = Set[ 40, 57 ]
    TOKENS_FOLLOWING_keyA_IN_condition_is_a_set_6941 = Set[ 87 ]
    TOKENS_FOLLOWING_T__87_IN_condition_is_a_set_6943 = Set[ 1 ]
    TOKENS_FOLLOWING_column_name_IN_condition_is_any_6955 = Set[ 52 ]
    TOKENS_FOLLOWING_T__52_IN_condition_is_any_6957 = Set[ 146 ]
    TOKENS_FOLLOWING_T__146_IN_condition_is_any_6962 = Set[ 1 ]
    TOKENS_FOLLOWING_nested_table_column_name_IN_condition_is_empty_6972 = Set[ 52 ]
    TOKENS_FOLLOWING_T__52_IN_condition_is_empty_6974 = Set[ 40, 57 ]
    TOKENS_FOLLOWING_T__57_IN_condition_is_empty_6978 = Set[ 40, 57 ]
    TOKENS_FOLLOWING_keyEMPTY_IN_condition_is_empty_6983 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_condition_is_of_type_6993 = Set[ 52 ]
    TOKENS_FOLLOWING_T__52_IN_condition_is_of_type_6995 = Set[ 57, 106 ]
    TOKENS_FOLLOWING_T__57_IN_condition_is_of_type_6999 = Set[ 106 ]
    TOKENS_FOLLOWING_T__106_IN_condition_is_of_type_7004 = Set[ 7, 40 ]
    TOKENS_FOLLOWING_keyTYPE_IN_condition_is_of_type_7008 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_condition_is_of_type_7013 = Set[ 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_type_name_IN_condition_is_of_type_7015 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_condition_is_of_type_7017 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_is_of_type_name_IN_condition_is_of_type_names_7027 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_condition_is_of_type_names_7031 = Set[ 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_condition_is_of_type_name_IN_condition_is_of_type_names_7033 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_keyONLY_IN_condition_is_of_type_name_7048 = Set[ 40, 41, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101 ]
    TOKENS_FOLLOWING_type_name_IN_condition_is_of_type_name_7053 = Set[ 1 ]
    TOKENS_FOLLOWING_cell_reference_IN_condition_is_present_7063 = Set[ 52 ]
    TOKENS_FOLLOWING_T__52_IN_condition_is_present_7065 = Set[ 40 ]
    TOKENS_FOLLOWING_keyPRESENT_IN_condition_is_present_7067 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_condition_like_7077 = Set[ 40, 57, 134 ]
    TOKENS_FOLLOWING_T__57_IN_condition_like_7081 = Set[ 40, 57, 134 ]
    TOKENS_FOLLOWING_T__134_IN_condition_like_7088 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_keyLIKEC_IN_condition_like_7092 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_keyLIKE2_IN_condition_like_7096 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_keyLIKE4_IN_condition_like_7100 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expression_IN_condition_like_7104 = Set[ 1, 40 ]
    TOKENS_FOLLOWING_keyESCAPE_IN_condition_like_7108 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expression_IN_condition_like_7110 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_condition_memeber_7123 = Set[ 40, 57 ]
    TOKENS_FOLLOWING_T__57_IN_condition_memeber_7127 = Set[ 40, 57 ]
    TOKENS_FOLLOWING_keyMEMBER_IN_condition_memeber_7132 = Set[ 40, 41, 100, 106 ]
    TOKENS_FOLLOWING_T__106_IN_condition_memeber_7136 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_nested_table_column_name_IN_condition_memeber_7141 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_condition_between_7151 = Set[ 57, 139 ]
    TOKENS_FOLLOWING_T__57_IN_condition_between_7155 = Set[ 139 ]
    TOKENS_FOLLOWING_T__139_IN_condition_between_7160 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expression_IN_condition_between_7162 = Set[ 138 ]
    TOKENS_FOLLOWING_T__138_IN_condition_between_7164 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expression_IN_condition_between_7166 = Set[ 1 ]
    TOKENS_FOLLOWING_keyREGEXP_LIKE_IN_condition_regexp_like_7176 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_condition_regexp_like_7178 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_call_parameters_IN_condition_regexp_like_7180 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_condition_regexp_like_7182 = Set[ 1 ]
    TOKENS_FOLLOWING_nested_table_column_name_IN_condition_submultiset_7192 = Set[ 40, 57 ]
    TOKENS_FOLLOWING_T__57_IN_condition_submultiset_7196 = Set[ 40, 57 ]
    TOKENS_FOLLOWING_keySUBMULTISET_IN_condition_submultiset_7201 = Set[ 40, 41, 100, 106 ]
    TOKENS_FOLLOWING_T__106_IN_condition_submultiset_7205 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_nested_table_column_name_IN_condition_submultiset_7210 = Set[ 1 ]
    TOKENS_FOLLOWING_keyEQUALS_PATH_IN_condition_equals_path_7220 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_condition_equals_path_7222 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_column_name_IN_condition_equals_path_7224 = Set[ 12 ]
    TOKENS_FOLLOWING_COMMA_IN_condition_equals_path_7226 = Set[ 16 ]
    TOKENS_FOLLOWING_path_string_IN_condition_equals_path_7228 = Set[ 8, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_condition_equals_path_7232 = Set[ 15 ]
    TOKENS_FOLLOWING_correlation_integer_IN_condition_equals_path_7234 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_condition_equals_path_7239 = Set[ 1 ]
    TOKENS_FOLLOWING_keyUNDER_PATH_IN_condition_under_path_7249 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_condition_under_path_7251 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_column_name_IN_condition_under_path_7253 = Set[ 12 ]
    TOKENS_FOLLOWING_COMMA_IN_condition_under_path_7257 = Set[ 15 ]
    TOKENS_FOLLOWING_levels_IN_condition_under_path_7259 = Set[ 12 ]
    TOKENS_FOLLOWING_COMMA_IN_condition_under_path_7264 = Set[ 16 ]
    TOKENS_FOLLOWING_path_string_IN_condition_under_path_7266 = Set[ 8, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_condition_under_path_7270 = Set[ 15 ]
    TOKENS_FOLLOWING_correlation_integer_IN_condition_under_path_7272 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_condition_under_path_7277 = Set[ 1 ]
    TOKENS_FOLLOWING_integer_IN_levels_7287 = Set[ 1 ]
    TOKENS_FOLLOWING_integer_IN_correlation_integer_7297 = Set[ 1 ]
    TOKENS_FOLLOWING_QUOTED_STRING_IN_path_string_7307 = Set[ 1 ]
    TOKENS_FOLLOWING_expression_list_IN_grouping_expression_list_7317 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_grouping_expression_list_7321 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expression_list_IN_grouping_expression_list_7323 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_LPAREN_IN_expression_list_7336 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expressions_IN_expression_list_7338 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_expression_list_7340 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expressions_IN_expression_list_7345 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_identifier_IN_cell_reference_7355 = Set[ 1 ]
    TOKENS_FOLLOWING_call_parameter_IN_call_parameters_7365 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_call_parameters_7369 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_call_parameter_IN_call_parameters_7371 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_parameter_name_IN_call_parameter_7386 = Set[ 39 ]
    TOKENS_FOLLOWING_ARROW_IN_call_parameter_7388 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_nested_expression_IN_call_parameter_7393 = Set[ 1 ]
    TOKENS_FOLLOWING_set_IN_relational_op_0 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_exp_set_7443 = Set[ 1 ]
    TOKENS_FOLLOWING_subquery_IN_exp_set_7448 = Set[ 1 ]
    TOKENS_FOLLOWING_LPAREN_IN_subquery_7460 = Set[ 116 ]
    TOKENS_FOLLOWING_select_command_IN_subquery_7462 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_subquery_7464 = Set[ 1 ]
    TOKENS_FOLLOWING_T__128_IN_connect_clause_7478 = Set[ 78 ]
    TOKENS_FOLLOWING_T__78_IN_connect_clause_7480 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_condition_IN_connect_clause_7482 = Set[ 129 ]
    TOKENS_FOLLOWING_T__129_IN_connect_clause_7489 = Set[ 108 ]
    TOKENS_FOLLOWING_T__108_IN_connect_clause_7491 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_T__141_IN_connect_clause_7498 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expression_IN_connect_clause_7500 = Set[ 22, 34, 35, 36, 37, 38 ]
    TOKENS_FOLLOWING_relational_op_IN_connect_clause_7502 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expression_IN_connect_clause_7504 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expression_IN_connect_clause_7510 = Set[ 22, 34, 35, 36, 37, 38 ]
    TOKENS_FOLLOWING_relational_op_IN_connect_clause_7512 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expression_IN_connect_clause_7514 = Set[ 141 ]
    TOKENS_FOLLOWING_T__141_IN_connect_clause_7516 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_T__141_IN_connect_clause_7542 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_condition_IN_connect_clause_7546 = Set[ 1, 128 ]
    TOKENS_FOLLOWING_sql_expression_IN_connect_clause_7552 = Set[ 22, 34, 35, 36, 37, 38 ]
    TOKENS_FOLLOWING_relational_op_IN_connect_clause_7554 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_T__141_IN_connect_clause_7558 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expression_IN_connect_clause_7563 = Set[ 1, 128, 138 ]
    TOKENS_FOLLOWING_T__138_IN_connect_clause_7567 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_condition_IN_connect_clause_7569 = Set[ 1, 128 ]
    TOKENS_FOLLOWING_T__128_IN_connect_clause_7582 = Set[ 78 ]
    TOKENS_FOLLOWING_T__78_IN_connect_clause_7584 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_condition_IN_connect_clause_7586 = Set[ 1 ]
    TOKENS_FOLLOWING_T__130_IN_group_clause_7600 = Set[ 108 ]
    TOKENS_FOLLOWING_T__108_IN_group_clause_7602 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expression_IN_group_clause_7604 = Set[ 1, 12, 122 ]
    TOKENS_FOLLOWING_COMMA_IN_group_clause_7608 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expression_IN_group_clause_7610 = Set[ 1, 12, 122 ]
    TOKENS_FOLLOWING_T__122_IN_group_clause_7617 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_condition_IN_group_clause_7619 = Set[ 1 ]
    TOKENS_FOLLOWING_T__123_IN_set_clause_7637 = Set[ 119 ]
    TOKENS_FOLLOWING_T__119_IN_set_clause_7639 = Set[ 116 ]
    TOKENS_FOLLOWING_T__124_IN_set_clause_7645 = Set[ 116 ]
    TOKENS_FOLLOWING_T__125_IN_set_clause_7649 = Set[ 116 ]
    TOKENS_FOLLOWING_select_command_IN_set_clause_7653 = Set[ 1 ]
    TOKENS_FOLLOWING_T__133_IN_order_clause_7665 = Set[ 108 ]
    TOKENS_FOLLOWING_T__108_IN_order_clause_7667 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sorted_def_IN_order_clause_7669 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_order_clause_7673 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sorted_def_IN_order_clause_7675 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_sql_expression_IN_sorted_def_7699 = Set[ 1, 135, 136 ]
    TOKENS_FOLLOWING_NUMBER_IN_sorted_def_7711 = Set[ 1, 135, 136 ]
    TOKENS_FOLLOWING_set_IN_sorted_def_7715 = Set[ 1 ]
    TOKENS_FOLLOWING_T__112_IN_update_clause_7735 = Set[ 132 ]
    TOKENS_FOLLOWING_T__132_IN_update_clause_7737 = Set[ 1, 106, 137 ]
    TOKENS_FOLLOWING_T__106_IN_update_clause_7741 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_column_name_IN_update_clause_7743 = Set[ 1, 12, 137 ]
    TOKENS_FOLLOWING_COMMA_IN_update_clause_7747 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_column_name_IN_update_clause_7749 = Set[ 1, 12, 137 ]
    TOKENS_FOLLOWING_T__137_IN_update_clause_7759 = Set[ 1 ]
    TOKENS_FOLLOWING_T__147_IN_insert_command_7773 = Set[ 120 ]
    TOKENS_FOLLOWING_T__120_IN_insert_command_7775 = Set[ 7, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_table_reference_list_IN_insert_command_7777 = Set[ 7, 116, 148 ]
    TOKENS_FOLLOWING_LPAREN_IN_insert_command_7783 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_column_specs_IN_insert_command_7785 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_insert_command_7787 = Set[ 116, 148 ]
    TOKENS_FOLLOWING_T__148_IN_insert_command_7796 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_insert_command_7798 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_plsql_expressions_IN_insert_command_7800 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_insert_command_7802 = Set[ 1, 164, 165 ]
    TOKENS_FOLLOWING_select_statement_IN_insert_command_7808 = Set[ 1, 164, 165 ]
    TOKENS_FOLLOWING_returning_clause_IN_insert_command_7818 = Set[ 1 ]
    TOKENS_FOLLOWING_T__132_IN_update_command_7832 = Set[ 7, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_selected_table_IN_update_command_7834 = Set[ 87 ]
    TOKENS_FOLLOWING_T__87_IN_update_command_7838 = Set[ 7, 40, 41, 100 ]
    TOKENS_FOLLOWING_update_nested_column_specs_IN_update_command_7845 = Set[ 1, 127, 164, 165 ]
    TOKENS_FOLLOWING_update_column_specs_IN_update_command_7851 = Set[ 1, 127, 164, 165 ]
    TOKENS_FOLLOWING_T__127_IN_update_command_7861 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_keyCURRENT_OF_IN_update_command_7868 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_cursor_name_IN_update_command_7870 = Set[ 1, 164, 165 ]
    TOKENS_FOLLOWING_sql_condition_IN_update_command_7877 = Set[ 1, 164, 165 ]
    TOKENS_FOLLOWING_returning_clause_IN_update_command_7893 = Set[ 1 ]
    TOKENS_FOLLOWING_update_column_spec_IN_update_column_specs_7907 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_update_column_specs_7911 = Set[ 7, 40, 41, 100 ]
    TOKENS_FOLLOWING_update_column_spec_IN_update_column_specs_7913 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_column_spec_IN_update_column_spec_7927 = Set[ 22 ]
    TOKENS_FOLLOWING_EQ_IN_update_column_spec_7929 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expression_IN_update_column_spec_7931 = Set[ 1 ]
    TOKENS_FOLLOWING_update_nested_column_spec_IN_update_nested_column_specs_7942 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_COMMA_IN_update_nested_column_specs_7946 = Set[ 7 ]
    TOKENS_FOLLOWING_update_nested_column_spec_IN_update_nested_column_specs_7948 = Set[ 1, 12 ]
    TOKENS_FOLLOWING_LPAREN_IN_update_nested_column_spec_7962 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_column_specs_IN_update_nested_column_spec_7964 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_update_nested_column_spec_7966 = Set[ 22 ]
    TOKENS_FOLLOWING_EQ_IN_update_nested_column_spec_7968 = Set[ 7, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_subquery_IN_update_nested_column_spec_7970 = Set[ 1 ]
    TOKENS_FOLLOWING_T__145_IN_delete_command_7981 = Set[ 7, 40, 41, 100, 105, 121 ]
    TOKENS_FOLLOWING_T__121_IN_delete_command_7985 = Set[ 7, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_selected_table_IN_delete_command_7990 = Set[ 1, 127, 164, 165 ]
    TOKENS_FOLLOWING_T__127_IN_delete_command_7996 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_keyCURRENT_OF_IN_delete_command_8003 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_cursor_name_IN_delete_command_8005 = Set[ 1, 164, 165 ]
    TOKENS_FOLLOWING_sql_condition_IN_delete_command_8012 = Set[ 1, 164, 165 ]
    TOKENS_FOLLOWING_returning_clause_IN_delete_command_8028 = Set[ 1 ]
    TOKENS_FOLLOWING_keyRETURN_IN_returning_clause_8044 = Set[ 7, 10, 13, 14, 15, 16, 17, 21, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 118, 119, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_keyRETURNING_IN_returning_clause_8048 = Set[ 7, 10, 13, 14, 15, 16, 17, 21, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 118, 119, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_select_list_IN_returning_clause_8052 = Set[ 40, 120 ]
    TOKENS_FOLLOWING_keyBULK_IN_returning_clause_8056 = Set[ 40 ]
    TOKENS_FOLLOWING_keyCOLLECT_IN_returning_clause_8058 = Set[ 120 ]
    TOKENS_FOLLOWING_T__120_IN_returning_clause_8063 = Set[ 17, 40, 41 ]
    TOKENS_FOLLOWING_lvalues_IN_returning_clause_8065 = Set[ 1 ]
    TOKENS_FOLLOWING_T__87_IN_set_transaction_command_8076 = Set[ 40 ]
    TOKENS_FOLLOWING_keyTRANSACTION_IN_set_transaction_command_8078 = Set[ 40 ]
    TOKENS_FOLLOWING_keyREAD_IN_set_transaction_command_8080 = Set[ 40 ]
    TOKENS_FOLLOWING_keyONLY_IN_set_transaction_command_8082 = Set[ 1 ]
    TOKENS_FOLLOWING_keyCLOSE_IN_close_statement_8093 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_cursor_name_IN_close_statement_8095 = Set[ 1 ]
    TOKENS_FOLLOWING_T__149_IN_fetch_statement_8106 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_cursor_name_IN_fetch_statement_8108 = Set[ 120 ]
    TOKENS_FOLLOWING_T__120_IN_fetch_statement_8110 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_variable_names_IN_fetch_statement_8117 = Set[ 1 ]
    TOKENS_FOLLOWING_record_name_IN_fetch_statement_8123 = Set[ 1 ]
    TOKENS_FOLLOWING_T__150_IN_lock_table_statement_8138 = Set[ 105 ]
    TOKENS_FOLLOWING_T__105_IN_lock_table_statement_8140 = Set[ 7, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_table_reference_list_IN_lock_table_statement_8142 = Set[ 102 ]
    TOKENS_FOLLOWING_T__102_IN_lock_table_statement_8146 = Set[ 152, 153, 154 ]
    TOKENS_FOLLOWING_lock_mode_IN_lock_table_statement_8148 = Set[ 151 ]
    TOKENS_FOLLOWING_T__151_IN_lock_table_statement_8150 = Set[ 1, 137 ]
    TOKENS_FOLLOWING_T__137_IN_lock_table_statement_8154 = Set[ 1 ]
    TOKENS_FOLLOWING_T__152_IN_lock_mode_8168 = Set[ 153 ]
    TOKENS_FOLLOWING_T__153_IN_lock_mode_8170 = Set[ 1 ]
    TOKENS_FOLLOWING_T__152_IN_lock_mode_8175 = Set[ 154 ]
    TOKENS_FOLLOWING_T__154_IN_lock_mode_8177 = Set[ 1 ]
    TOKENS_FOLLOWING_T__153_IN_lock_mode_8182 = Set[ 132 ]
    TOKENS_FOLLOWING_T__132_IN_lock_mode_8184 = Set[ 1 ]
    TOKENS_FOLLOWING_T__153_IN_lock_mode_8189 = Set[ 1 ]
    TOKENS_FOLLOWING_T__153_IN_lock_mode_8194 = Set[ 152 ]
    TOKENS_FOLLOWING_T__152_IN_lock_mode_8196 = Set[ 154 ]
    TOKENS_FOLLOWING_T__154_IN_lock_mode_8198 = Set[ 1 ]
    TOKENS_FOLLOWING_T__154_IN_lock_mode_8203 = Set[ 1 ]
    TOKENS_FOLLOWING_keyOPEN_IN_open_statement_8214 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_cursor_name_IN_open_statement_8216 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_open_statement_8220 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_plsql_expressions_IN_open_statement_8222 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_open_statement_8224 = Set[ 1 ]
    TOKENS_FOLLOWING_keyROLLBACK_IN_rollback_statement_8238 = Set[ 1, 40, 77, 156 ]
    TOKENS_FOLLOWING_keyWORK_IN_rollback_statement_8242 = Set[ 1, 77, 156 ]
    TOKENS_FOLLOWING_T__77_IN_rollback_statement_8251 = Set[ 40, 41, 155 ]
    TOKENS_FOLLOWING_T__155_IN_rollback_statement_8255 = Set[ 40, 41, 155 ]
    TOKENS_FOLLOWING_savepoint_name_IN_rollback_statement_8260 = Set[ 1, 156 ]
    TOKENS_FOLLOWING_T__156_IN_rollback_statement_8269 = Set[ 16 ]
    TOKENS_FOLLOWING_quoted_string_IN_rollback_statement_8271 = Set[ 1 ]
    TOKENS_FOLLOWING_T__155_IN_savepoint_statement_8285 = Set[ 40, 41, 155 ]
    TOKENS_FOLLOWING_savepoint_name_IN_savepoint_statement_8287 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_savepoint_name_8298 = Set[ 1 ]
    TOKENS_FOLLOWING_set_IN_identifier_0 = Set[ 1 ]
    TOKENS_FOLLOWING_QUOTED_STRING_IN_quoted_string_8330 = Set[ 1 ]
    TOKENS_FOLLOWING_QUOTED_STRING_IN_match_string_8341 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyA_8380 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyAUTOMATIC_8409 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyCOUNT_8442 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyCROSS_8475 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyCUBE_8509 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyCURRENT_OF_8537 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyDAY_8572 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyDBTIMEZONE_8600 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyDECREMENT_8629 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyDIMENSION_8658 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyEMPTY_8691 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyEQUALS_PATH_8718 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyESCAPE_8750 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyFIRST_8783 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyFULL_8817 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyGROUPING_8847 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyIGNORE_8879 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyINCREMENT_8908 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyINFINITE_8938 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyINNER_8971 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyINTERVAL_9001 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyITERATE_9032 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyJOIN_9066 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyKEEP_9100 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyLAST_9134 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyLEFT_9168 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyLIKE2_9201 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyLIKE4_9234 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyLIKEC_9267 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyLOCAL_9300 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyMAIN_9334 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyMEASURES_9364 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyMEMBER_9396 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyMODEL_9429 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyMONTH_9462 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyNAN_9497 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyNATURAL_9528 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyNAV_9563 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyNOCYCLE_9594 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyNULLS_9627 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyONLY_9661 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyOUTER_9694 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyPARTITION_9723 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyPRECISION_9752 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyPRESENT_9783 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyREFERENCE_9812 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyREGEXP_LIKE_9839 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyRIGHT_9873 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyROLLUP_9905 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyRULES_9938 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keySECOND_9970 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keySECONDS_10001 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keySEQUENTIAL_10029 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keySESSIONTIMEZONE_10052 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keySETS_10086 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keySIBLINGS_10116 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keySINGLE_10148 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keySOME_10182 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keySUBMULTISET_10209 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyTIME_10243 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyTIMESTAMP_10272 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyTHE_10307 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyUNDER_PATH_10335 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyUNTIL_10368 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyUPDATED_10399 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyUPSERT_10431 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyWAIT_10465 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyYEAR_10499 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyZONE_10533 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyARRAY_10567 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyAUTONOMOUS_TRANSACTION_10583 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyBODY_10617 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyBUILTIN_10648 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyBULK_10682 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyBYTE_10716 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyCLOSE_10749 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyCOLLECT_10780 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyCURSOR_10812 = Set[ 1 ]
    TOKENS_FOLLOWING_T__157_IN_keyELSIF_10843 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyEXCEPTION_INIT_10868 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyEXIT_10902 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyFIPSFLAG_10932 = Set[ 1 ]
    TOKENS_FOLLOWING_T__104_IN_keyFUNCTION_10960 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyINTERFACE_10990 = Set[ 1 ]
    TOKENS_FOLLOWING_T__158_IN_keyLOOP_11022 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyNEW_11058 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyNEW_NAMES_11087 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyOPEN_11121 = Set[ 1 ]
    TOKENS_FOLLOWING_T__159_IN_keyOUT_11154 = Set[ 1 ]
    TOKENS_FOLLOWING_T__160_IN_keyPACKAGE_11184 = Set[ 1 ]
    TOKENS_FOLLOWING_T__161_IN_keyPRAGMA_11215 = Set[ 1 ]
    TOKENS_FOLLOWING_T__162_IN_keyRAISE_11247 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyRANGE_11281 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyREAD_11315 = Set[ 1 ]
    TOKENS_FOLLOWING_T__163_IN_keyRECORD_11345 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyREF_11381 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyREPLACE_11412 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyRESTRICT_REFERENCES_11431 = Set[ 1 ]
    TOKENS_FOLLOWING_T__164_IN_keyRETURN_11461 = Set[ 1 ]
    TOKENS_FOLLOWING_T__165_IN_keyRETURNING_11489 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyREVERSE_11521 = Set[ 1 ]
    TOKENS_FOLLOWING_T__166_IN_keyROLLBACK_11549 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keySERIALLY_REUSABLE_11571 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keySUBTYPE_11602 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyTRANSACTION_11629 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyTYPE_11663 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyUSING_11696 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyVARRAY_11728 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyVARYING_11759 = Set[ 1 ]
    TOKENS_FOLLOWING_T__167_IN_keyWHILE_11790 = Set[ 1 ]
    TOKENS_FOLLOWING_ID_IN_keyWORK_11825 = Set[ 1 ]
    TOKENS_FOLLOWING_identifier_IN_sql_identifier_11834 = Set[ 1 ]
    TOKENS_FOLLOWING_T__100_IN_sql_identifier_11839 = Set[ 1 ]
    TOKENS_FOLLOWING_type_declaration_IN_synpred13_Plsql_242 = Set[ 1 ]
    TOKENS_FOLLOWING_subtype_declaration_IN_synpred14_Plsql_247 = Set[ 1 ]
    TOKENS_FOLLOWING_keyNEW_IN_synpred27_Plsql_369 = Set[ 1 ]
    TOKENS_FOLLOWING_assignment_statement_IN_synpred43_Plsql_570 = Set[ 1 ]
    TOKENS_FOLLOWING_exit_statement_IN_synpred44_Plsql_575 = Set[ 1 ]
    TOKENS_FOLLOWING_case_statement_IN_synpred46_Plsql_585 = Set[ 1 ]
    TOKENS_FOLLOWING_loop_statement_IN_synpred48_Plsql_596 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_statement_IN_synpred52_Plsql_617 = Set[ 1 ]
    TOKENS_FOLLOWING_plsql_block_IN_synpred53_Plsql_622 = Set[ 1 ]
    TOKENS_FOLLOWING_subtype_declaration_IN_synpred62_Plsql_731 = Set[ 1 ]
    TOKENS_FOLLOWING_type_declaration_IN_synpred70_Plsql_777 = Set[ 1 ]
    TOKENS_FOLLOWING_keyRESTRICT_REFERENCES_IN_synpred73_Plsql_801 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred73_Plsql_803 = Set[ 16, 40, 41, 59 ]
    TOKENS_FOLLOWING_T__59_IN_synpred73_Plsql_807 = Set[ 12 ]
    TOKENS_FOLLOWING_function_name_IN_synpred73_Plsql_811 = Set[ 12 ]
    TOKENS_FOLLOWING_COMMA_IN_synpred73_Plsql_817 = Set[ 13, 14, 15, 16, 40, 41 ]
    TOKENS_FOLLOWING_pragma_param_IN_synpred73_Plsql_819 = Set[ 8, 12 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred73_Plsql_824 = Set[ 1 ]
    TOKENS_FOLLOWING_keyEXCEPTION_INIT_IN_synpred74_Plsql_831 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred74_Plsql_833 = Set[ 40, 41 ]
    TOKENS_FOLLOWING_exception_name_IN_synpred74_Plsql_835 = Set[ 12 ]
    TOKENS_FOLLOWING_COMMA_IN_synpred74_Plsql_837 = Set[ 13, 14, 15, 16 ]
    TOKENS_FOLLOWING_literal_IN_synpred74_Plsql_839 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred74_Plsql_841 = Set[ 1 ]
    TOKENS_FOLLOWING_keyAUTONOMOUS_TRANSACTION_IN_synpred75_Plsql_847 = Set[ 1 ]
    TOKENS_FOLLOWING_keySERIALLY_REUSABLE_IN_synpred76_Plsql_853 = Set[ 1 ]
    TOKENS_FOLLOWING_keyBUILTIN_IN_synpred77_Plsql_859 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred77_Plsql_861 = Set[ 13, 14, 15, 16, 40, 41 ]
    TOKENS_FOLLOWING_pragma_params_IN_synpred77_Plsql_863 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred77_Plsql_865 = Set[ 1 ]
    TOKENS_FOLLOWING_keyFIPSFLAG_IN_synpred78_Plsql_871 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred78_Plsql_873 = Set[ 13, 14, 15, 16, 40, 41 ]
    TOKENS_FOLLOWING_pragma_params_IN_synpred78_Plsql_875 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred78_Plsql_877 = Set[ 1 ]
    TOKENS_FOLLOWING_keyINTERFACE_IN_synpred79_Plsql_883 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred79_Plsql_885 = Set[ 13, 14, 15, 16, 40, 41 ]
    TOKENS_FOLLOWING_pragma_params_IN_synpred79_Plsql_887 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred79_Plsql_889 = Set[ 1 ]
    TOKENS_FOLLOWING_keyNEW_NAMES_IN_synpred80_Plsql_895 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred80_Plsql_897 = Set[ 13, 14, 15, 16, 40, 41 ]
    TOKENS_FOLLOWING_pragma_params_IN_synpred80_Plsql_899 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred80_Plsql_901 = Set[ 1 ]
    TOKENS_FOLLOWING_keyINTERVAL_IN_synpred114_Plsql_1288 = Set[ 40 ]
    TOKENS_FOLLOWING_keyDAY_IN_synpred114_Plsql_1290 = Set[ 7, 77 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred114_Plsql_1294 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_synpred114_Plsql_1296 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred114_Plsql_1298 = Set[ 77 ]
    TOKENS_FOLLOWING_T__77_IN_synpred114_Plsql_1303 = Set[ 40 ]
    TOKENS_FOLLOWING_keySECOND_IN_synpred114_Plsql_1305 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred114_Plsql_1309 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_synpred114_Plsql_1311 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred114_Plsql_1313 = Set[ 1 ]
    TOKENS_FOLLOWING_keyINTERVAL_IN_synpred116_Plsql_1321 = Set[ 40 ]
    TOKENS_FOLLOWING_keyYEAR_IN_synpred116_Plsql_1323 = Set[ 7, 77 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred116_Plsql_1327 = Set[ 15 ]
    TOKENS_FOLLOWING_NUMBER_IN_synpred116_Plsql_1329 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred116_Plsql_1331 = Set[ 77 ]
    TOKENS_FOLLOWING_T__77_IN_synpred116_Plsql_1336 = Set[ 40 ]
    TOKENS_FOLLOWING_keyMONTH_IN_synpred116_Plsql_1338 = Set[ 1 ]
    TOKENS_FOLLOWING_keyTIME_IN_synpred117_Plsql_1345 = Set[ 1 ]
    TOKENS_FOLLOWING_datatype_IN_synpred172_Plsql_1814 = Set[ 1 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred232_Plsql_2929 = Set[ 7, 8, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_call_parameters_IN_synpred232_Plsql_2933 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred232_Plsql_2938 = Set[ 1 ]
    TOKENS_FOLLOWING_numeric_loop_param_IN_synpred238_Plsql_3080 = Set[ 1 ]
    TOKENS_FOLLOWING_cursor_loop_param_IN_synpred239_Plsql_3096 = Set[ 1 ]
    TOKENS_FOLLOWING_keyREVERSE_IN_synpred242_Plsql_3160 = Set[ 1 ]
    TOKENS_FOLLOWING_close_statement_IN_synpred252_Plsql_3394 = Set[ 1 ]
    TOKENS_FOLLOWING_open_statement_IN_synpred256_Plsql_3414 = Set[ 1 ]
    TOKENS_FOLLOWING_join_clause_IN_synpred263_Plsql_3515 = Set[ 1 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred264_Plsql_3519 = Set[ 7, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_join_clause_IN_synpred264_Plsql_3521 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred264_Plsql_3523 = Set[ 1 ]
    TOKENS_FOLLOWING_where_clause_IN_synpred265_Plsql_3535 = Set[ 1 ]
    TOKENS_FOLLOWING_hierarchical_query_clause_IN_synpred266_Plsql_3542 = Set[ 1 ]
    TOKENS_FOLLOWING_group_by_clause_IN_synpred267_Plsql_3549 = Set[ 1 ]
    TOKENS_FOLLOWING_T__122_IN_synpred268_Plsql_3558 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_condition_IN_synpred268_Plsql_3560 = Set[ 1 ]
    TOKENS_FOLLOWING_model_clause_IN_synpred269_Plsql_3567 = Set[ 1 ]
    TOKENS_FOLLOWING_T__123_IN_synpred274_Plsql_3578 = Set[ 7, 40, 41, 100, 105, 116, 119 ]
    TOKENS_FOLLOWING_T__119_IN_synpred274_Plsql_3582 = Set[ 7, 40, 41, 100, 105, 116 ]
    TOKENS_FOLLOWING_T__124_IN_synpred274_Plsql_3592 = Set[ 7, 40, 41, 100, 105, 116 ]
    TOKENS_FOLLOWING_T__125_IN_synpred274_Plsql_3599 = Set[ 7, 40, 41, 100, 105, 116 ]
    TOKENS_FOLLOWING_select_expression_IN_synpred274_Plsql_3611 = Set[ 1 ]
    TOKENS_FOLLOWING_subquery_IN_synpred274_Plsql_3619 = Set[ 1 ]
    TOKENS_FOLLOWING_order_by_clause_IN_synpred275_Plsql_3635 = Set[ 1 ]
    TOKENS_FOLLOWING_COMMA_IN_synpred278_Plsql_3694 = Set[ 7, 40, 41, 100, 105 ]
    TOKENS_FOLLOWING_selected_table_IN_synpred278_Plsql_3696 = Set[ 1 ]
    TOKENS_FOLLOWING_inner_cross_join_clause_IN_synpred279_Plsql_3714 = Set[ 1 ]
    TOKENS_FOLLOWING_outer_join_clause_IN_synpred280_Plsql_3718 = Set[ 1 ]
    TOKENS_FOLLOWING_keyINNER_IN_synpred283_Plsql_3733 = Set[ 40 ]
    TOKENS_FOLLOWING_keyJOIN_IN_synpred283_Plsql_3738 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_table_name_IN_synpred283_Plsql_3740 = Set[ 40, 126 ]
    TOKENS_FOLLOWING_T__126_IN_synpred283_Plsql_3744 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_condition_IN_synpred283_Plsql_3746 = Set[ 1 ]
    TOKENS_FOLLOWING_keyUSING_IN_synpred283_Plsql_3750 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred283_Plsql_3752 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_column_specs_IN_synpred283_Plsql_3754 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred283_Plsql_3756 = Set[ 1 ]
    TOKENS_FOLLOWING_keyCROSS_IN_synpred284_Plsql_3765 = Set[ 1 ]
    TOKENS_FOLLOWING_outer_join_type_IN_synpred286_Plsql_3802 = Set[ 40 ]
    TOKENS_FOLLOWING_keyJOIN_IN_synpred286_Plsql_3804 = Set[ 1 ]
    TOKENS_FOLLOWING_outer_join_type_IN_synpred287_Plsql_3814 = Set[ 1 ]
    TOKENS_FOLLOWING_query_partition_clause_IN_synpred288_Plsql_3831 = Set[ 1 ]
    TOKENS_FOLLOWING_T__126_IN_synpred289_Plsql_3840 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_condition_IN_synpred289_Plsql_3842 = Set[ 1 ]
    TOKENS_FOLLOWING_keyUSING_IN_synpred290_Plsql_3846 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred290_Plsql_3848 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_column_specs_IN_synpred290_Plsql_3850 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred290_Plsql_3852 = Set[ 1 ]
    TOKENS_FOLLOWING_keyFULL_IN_synpred291_Plsql_3881 = Set[ 1 ]
    TOKENS_FOLLOWING_keyLEFT_IN_synpred292_Plsql_3885 = Set[ 1 ]
    TOKENS_FOLLOWING_keyOUTER_IN_synpred293_Plsql_3895 = Set[ 1 ]
    TOKENS_FOLLOWING_keyNOCYCLE_IN_synpred295_Plsql_3951 = Set[ 1 ]
    TOKENS_FOLLOWING_COMMA_IN_synpred296_Plsql_3984 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_group_by_expr_IN_synpred296_Plsql_3986 = Set[ 1 ]
    TOKENS_FOLLOWING_rollup_cube_clause_IN_synpred297_Plsql_3999 = Set[ 1 ]
    TOKENS_FOLLOWING_grouping_sets_clause_IN_synpred298_Plsql_4004 = Set[ 1 ]
    TOKENS_FOLLOWING_keyROLLUP_IN_synpred299_Plsql_4021 = Set[ 1 ]
    TOKENS_FOLLOWING_rollup_cube_clause_IN_synpred301_Plsql_4080 = Set[ 1 ]
    TOKENS_FOLLOWING_keyIGNORE_IN_synpred304_Plsql_4134 = Set[ 1 ]
    TOKENS_FOLLOWING_keyIGNORE_IN_synpred305_Plsql_4134 = Set[ 40 ]
    TOKENS_FOLLOWING_keyKEEP_IN_synpred305_Plsql_4138 = Set[ 40 ]
    TOKENS_FOLLOWING_keyNAV_IN_synpred305_Plsql_4142 = Set[ 1 ]
    TOKENS_FOLLOWING_keyDIMENSION_IN_synpred306_Plsql_4155 = Set[ 1 ]
    TOKENS_FOLLOWING_query_partition_clause_IN_synpred311_Plsql_4279 = Set[ 1, 40, 41, 100 ]
    TOKENS_FOLLOWING_column_spec_IN_synpred311_Plsql_4283 = Set[ 1 ]
    TOKENS_FOLLOWING_keyAUTOMATIC_IN_synpred318_Plsql_4390 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_condition_IN_synpred330_Plsql_4551 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_synpred331_Plsql_4555 = Set[ 1 ]
    TOKENS_FOLLOWING_keyINCREMENT_IN_synpred335_Plsql_4626 = Set[ 1 ]
    TOKENS_FOLLOWING_COMMA_IN_synpred343_Plsql_4793 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_order_by_expr_IN_synpred343_Plsql_4795 = Set[ 1 ]
    TOKENS_FOLLOWING_keyNULLS_IN_synpred346_Plsql_4833 = Set[ 40 ]
    TOKENS_FOLLOWING_keyFIRST_IN_synpred346_Plsql_4835 = Set[ 1 ]
    TOKENS_FOLLOWING_keyNULLS_IN_synpred347_Plsql_4839 = Set[ 40 ]
    TOKENS_FOLLOWING_keyLAST_IN_synpred347_Plsql_4841 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_synpred354_Plsql_5006 = Set[ 1 ]
    TOKENS_FOLLOWING_T__51_IN_synpred356_Plsql_5084 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_or_IN_synpred356_Plsql_5086 = Set[ 1 ]
    TOKENS_FOLLOWING_T__138_IN_synpred357_Plsql_5103 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_and_IN_synpred357_Plsql_5105 = Set[ 1 ]
    TOKENS_FOLLOWING_relational_op_IN_synpred359_Plsql_5142 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_add_IN_synpred359_Plsql_5144 = Set[ 1 ]
    TOKENS_FOLLOWING_FOUND_ATTR_IN_synpred360_Plsql_5150 = Set[ 1 ]
    TOKENS_FOLLOWING_NOTFOUND_ATTR_IN_synpred361_Plsql_5154 = Set[ 1 ]
    TOKENS_FOLLOWING_ISOPEN_ATTR_IN_synpred362_Plsql_5158 = Set[ 1 ]
    TOKENS_FOLLOWING_ROWCOUNT_ATTR_IN_synpred363_Plsql_5162 = Set[ 1 ]
    TOKENS_FOLLOWING_BULK_ROWCOUNT_ATTR_IN_synpred364_Plsql_5166 = Set[ 1 ]
    TOKENS_FOLLOWING_T__52_IN_synpred366_Plsql_5172 = Set[ 57, 58 ]
    TOKENS_FOLLOWING_T__57_IN_synpred366_Plsql_5176 = Set[ 58 ]
    TOKENS_FOLLOWING_T__58_IN_synpred366_Plsql_5181 = Set[ 1 ]
    TOKENS_FOLLOWING_T__57_IN_synpred368_Plsql_5189 = Set[ 134 ]
    TOKENS_FOLLOWING_T__134_IN_synpred368_Plsql_5194 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_add_IN_synpred368_Plsql_5196 = Set[ 1 ]
    TOKENS_FOLLOWING_T__57_IN_synpred370_Plsql_5204 = Set[ 139 ]
    TOKENS_FOLLOWING_T__139_IN_synpred370_Plsql_5209 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_add_IN_synpred370_Plsql_5211 = Set[ 138 ]
    TOKENS_FOLLOWING_T__138_IN_synpred370_Plsql_5213 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_add_IN_synpred370_Plsql_5215 = Set[ 1 ]
    TOKENS_FOLLOWING_T__57_IN_synpred372_Plsql_5223 = Set[ 102 ]
    TOKENS_FOLLOWING_T__102_IN_synpred372_Plsql_5228 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred372_Plsql_5230 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_nested_expressions_IN_synpred372_Plsql_5232 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred372_Plsql_5234 = Set[ 1 ]
    TOKENS_FOLLOWING_COMMA_IN_synpred374_Plsql_5269 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expression_IN_synpred374_Plsql_5271 = Set[ 1 ]
    TOKENS_FOLLOWING_set_IN_synpred377_Plsql_5305 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_mul_IN_synpred377_Plsql_5319 = Set[ 1 ]
    TOKENS_FOLLOWING_set_IN_synpred379_Plsql_5336 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_sign_IN_synpred379_Plsql_5346 = Set[ 1 ]
    TOKENS_FOLLOWING_EXPONENT_IN_synpred382_Plsql_5384 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expr_expr_IN_synpred382_Plsql_5386 = Set[ 1 ]
    TOKENS_FOLLOWING_expr_paren_IN_synpred383_Plsql_5401 = Set[ 1 ]
    TOKENS_FOLLOWING_function_expression_IN_synpred384_Plsql_5414 = Set[ 1 ]
    TOKENS_FOLLOWING_case_expression_IN_synpred385_Plsql_5434 = Set[ 1 ]
    TOKENS_FOLLOWING_cursor_expression_IN_synpred386_Plsql_5447 = Set[ 1 ]
    TOKENS_FOLLOWING_simple_expression_IN_synpred387_Plsql_5460 = Set[ 1 ]
    TOKENS_FOLLOWING_select_expression_IN_synpred388_Plsql_5473 = Set[ 1 ]
    TOKENS_FOLLOWING_column_spec_IN_synpred395_Plsql_5524 = Set[ 1 ]
    TOKENS_FOLLOWING_keyDBTIMEZONE_IN_synpred409_Plsql_5823 = Set[ 1 ]
    TOKENS_FOLLOWING_keySESSIONTIMEZONE_IN_synpred410_Plsql_5827 = Set[ 1 ]
    TOKENS_FOLLOWING_function_call_IN_synpred412_Plsql_5847 = Set[ 1, 5 ]
    TOKENS_FOLLOWING_DOT_IN_synpred412_Plsql_5851 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_nested_expression_IN_synpred412_Plsql_5853 = Set[ 1 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred415_Plsql_5891 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_nested_expression_IN_synpred415_Plsql_5893 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred415_Plsql_5895 = Set[ 1 ]
    TOKENS_FOLLOWING_keyDAY_IN_synpred420_Plsql_5967 = Set[ 7, 77 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred420_Plsql_5971 = Set[ 15 ]
    TOKENS_FOLLOWING_leading_field_precision_IN_synpred420_Plsql_5973 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred420_Plsql_5975 = Set[ 77 ]
    TOKENS_FOLLOWING_T__77_IN_synpred420_Plsql_5980 = Set[ 40 ]
    TOKENS_FOLLOWING_keySECOND_IN_synpred420_Plsql_5982 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred420_Plsql_5986 = Set[ 15 ]
    TOKENS_FOLLOWING_fractional_second_precision_IN_synpred420_Plsql_5988 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred420_Plsql_5990 = Set[ 1 ]
    TOKENS_FOLLOWING_DOT_IN_synpred427_Plsql_6237 = Set[ 40, 41, 100 ]
    TOKENS_FOLLOWING_sql_identifier_IN_synpred427_Plsql_6239 = Set[ 1 ]
    TOKENS_FOLLOWING_table_spec_IN_synpred431_Plsql_6277 = Set[ 1 ]
    TOKENS_FOLLOWING_objalias_IN_synpred434_Plsql_6298 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_or_IN_synpred440_Plsql_6389 = Set[ 1 ]
    TOKENS_FOLLOWING_T__51_IN_synpred441_Plsql_6442 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_condition_and_IN_synpred441_Plsql_6444 = Set[ 1 ]
    TOKENS_FOLLOWING_T__138_IN_synpred442_Plsql_6461 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_condition_not_IN_synpred442_Plsql_6463 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_is_IN_synpred445_Plsql_6498 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_comparison_IN_synpred446_Plsql_6503 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_group_comparison_IN_synpred447_Plsql_6508 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_in_IN_synpred448_Plsql_6513 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_is_a_set_IN_synpred449_Plsql_6518 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_is_any_IN_synpred450_Plsql_6523 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_is_empty_IN_synpred451_Plsql_6528 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_is_of_type_IN_synpred452_Plsql_6533 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_is_present_IN_synpred453_Plsql_6538 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_like_IN_synpred454_Plsql_6543 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_memeber_IN_synpred455_Plsql_6548 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_between_IN_synpred456_Plsql_6553 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_regexp_like_IN_synpred457_Plsql_6558 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_submultiset_IN_synpred458_Plsql_6563 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_equals_path_IN_synpred459_Plsql_6568 = Set[ 1 ]
    TOKENS_FOLLOWING_condition_under_path_IN_synpred460_Plsql_6573 = Set[ 1 ]
    TOKENS_FOLLOWING_keyNAN_IN_synpred462_Plsql_6617 = Set[ 1 ]
    TOKENS_FOLLOWING_keyINFINITE_IN_synpred463_Plsql_6621 = Set[ 1 ]
    TOKENS_FOLLOWING_outer_join_sign_IN_synpred466_Plsql_6668 = Set[ 1 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred467_Plsql_6637 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expressions_IN_synpred467_Plsql_6639 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred467_Plsql_6641 = Set[ 7, 22, 34 ]
    TOKENS_FOLLOWING_outer_join_sign_IN_synpred467_Plsql_6645 = Set[ 22, 34 ]
    TOKENS_FOLLOWING_set_IN_synpred467_Plsql_6650 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred467_Plsql_6660 = Set[ 116 ]
    TOKENS_FOLLOWING_select_command_IN_synpred467_Plsql_6662 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred467_Plsql_6664 = Set[ 1, 7 ]
    TOKENS_FOLLOWING_outer_join_sign_IN_synpred467_Plsql_6668 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_synpred476_Plsql_6727 = Set[ 1 ]
    TOKENS_FOLLOWING_outer_join_sign_IN_synpred477_Plsql_6741 = Set[ 1 ]
    TOKENS_FOLLOWING_grouping_expression_list_IN_synpred481_Plsql_6788 = Set[ 1 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred482_Plsql_6754 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expressions_IN_synpred482_Plsql_6756 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred482_Plsql_6758 = Set[ 22, 34 ]
    TOKENS_FOLLOWING_set_IN_synpred482_Plsql_6760 = Set[ 40, 119, 146 ]
    TOKENS_FOLLOWING_T__146_IN_synpred482_Plsql_6772 = Set[ 7 ]
    TOKENS_FOLLOWING_keySOME_IN_synpred482_Plsql_6776 = Set[ 7 ]
    TOKENS_FOLLOWING_T__119_IN_synpred482_Plsql_6780 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred482_Plsql_6784 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_grouping_expression_list_IN_synpred482_Plsql_6788 = Set[ 8 ]
    TOKENS_FOLLOWING_select_command_IN_synpred482_Plsql_6792 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred482_Plsql_6796 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expressions_IN_synpred490_Plsql_6847 = Set[ 1 ]
    TOKENS_FOLLOWING_grouping_expression_list_IN_synpred492_Plsql_6884 = Set[ 1 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred493_Plsql_6865 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expressions_IN_synpred493_Plsql_6867 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred493_Plsql_6869 = Set[ 57, 102 ]
    TOKENS_FOLLOWING_T__57_IN_synpred493_Plsql_6873 = Set[ 102 ]
    TOKENS_FOLLOWING_T__102_IN_synpred493_Plsql_6878 = Set[ 7 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred493_Plsql_6880 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_grouping_expression_list_IN_synpred493_Plsql_6884 = Set[ 8 ]
    TOKENS_FOLLOWING_select_command_IN_synpred493_Plsql_6888 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred493_Plsql_6892 = Set[ 1 ]
    TOKENS_FOLLOWING_expression_list_IN_synpred495_Plsql_6912 = Set[ 1 ]
    TOKENS_FOLLOWING_keyLIKEC_IN_synpred505_Plsql_7092 = Set[ 1 ]
    TOKENS_FOLLOWING_keyLIKE2_IN_synpred506_Plsql_7096 = Set[ 1 ]
    TOKENS_FOLLOWING_keyESCAPE_IN_synpred507_Plsql_7108 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expression_IN_synpred507_Plsql_7110 = Set[ 1 ]
    TOKENS_FOLLOWING_COMMA_IN_synpred516_Plsql_7321 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_expression_list_IN_synpred516_Plsql_7323 = Set[ 1 ]
    TOKENS_FOLLOWING_LPAREN_IN_synpred517_Plsql_7336 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 142, 145, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_expressions_IN_synpred517_Plsql_7338 = Set[ 8 ]
    TOKENS_FOLLOWING_RPAREN_IN_synpred517_Plsql_7340 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_synpred525_Plsql_7437 = Set[ 1 ]
    TOKENS_FOLLOWING_T__141_IN_synpred528_Plsql_7530 = Set[ 1 ]
    TOKENS_FOLLOWING_T__141_IN_synpred529_Plsql_7530 = Set[ 7, 10, 13, 14, 15, 16, 17, 40, 41, 50, 55, 57, 58, 60, 62, 87, 100, 103, 104, 110, 111, 112, 113, 114, 116, 117, 132, 140, 141, 142, 144, 145, 146, 147, 149, 150, 155, 158, 161, 162, 164, 166, 167 ]
    TOKENS_FOLLOWING_sql_condition_IN_synpred529_Plsql_7535 = Set[ 1 ]
    TOKENS_FOLLOWING_T__141_IN_synpred530_Plsql_7542 = Set[ 1 ]
    TOKENS_FOLLOWING_sql_expression_IN_synpred539_Plsql_7693 = Set[ 1 ]
    TOKENS_FOLLOWING_NUMBER_IN_synpred540_Plsql_7705 = Set[ 1 ]
    TOKENS_FOLLOWING_variable_names_IN_synpred561_Plsql_8117 = Set[ 1 ]

  end # class Parser < ANTLR3::Parser

  at_exit { Parser.main( ARGV ) } if __FILE__ == $0
end

